<!DOCTYPE html>
<html lang="ja-jp">
<head>
<meta charset="utf-8">
<meta name="generator" content="Hugo 0.20.5" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,700" rel="stylesheet" type="text/css">
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/styles/github.min.css">
<link rel="stylesheet" href="/css/normalize.css">
<link rel="stylesheet" href="/css/skeleton.css">
<link rel="stylesheet" href="/css/custom.css">
<link rel="alternate" href="/index.xml" type="application/rss+xml" title="LESS IS MORE">
<link rel="shortcut icon" href="/favicon.png" type="image/x-icon" />
<title>【音声合成編】Statistical Parametric Speech Synthesis Incorporating Generative Adversarial Networks [arXiv:1709.08041] - LESS IS MORE</title>
</head>
<body>

<div class="container">

	<header role="banner">
		<div class="header-logo">
			<a href="/"><img src="/images/r9y9.jpg" width="70" height="70"></a>
		</div>
		
	</header>


	<main role="main">
		<article itemscope itemtype="https://schema.org/BlogPosting">
			<h1 class="entry-title" itemprop="headline">【音声合成編】Statistical Parametric Speech Synthesis Incorporating Generative Adversarial Networks [arXiv:1709.08041]</h1>
			<span class="entry-meta"><time itemprop="datePublished" datetime="2017-10-09">October 09, 2017</time></span>
			<section itemprop="entry-text">
				

<p><strong><sup>10</sup>&frasl;<sub>11</sub> 追記</strong>: IEEE TASLPのペーパー (Open access) が公開されたようなので、リンクを貼っておきます: <a href="http://ieeexplore.ieee.org/document/8063435/">http://ieeexplore.ieee.org/document/8063435/</a></p>

<p>arXiv論文リンク: <a href="https://arxiv.org/abs/1709.08041">arXiv:1709.08041</a></p>

<p><a href="/blog/2017/10/05/ganvc/">前回の記事</a> の続きです。音響モデルの学習にGANを使うというアイデアは、声質変換だけでなく音声合成にも応用できます。<a href="http://festvox.org/cmu_arctic/">CMU ARCTIC</a> を使った英語音声合成の実験を行って、ある程度良い結果がでたので、まとめようと思います。音声サンプルだけ聴きたい方は真ん中の方まで読み飛ばしてください。</p>

<ul>
<li>コードはこちら: <a href="https:github.com/r9y9/gantts">r9y9/gantts | PyTorch implementation of GAN-based text-to-speech and voice conversion (VC) </a> (VCのコードも一緒です)</li>
<li>音声サンプル付きデモノートブックはこちら: <a href="http://nbviewer.jupyter.org/github/r9y9/gantts/blob/master/notebooks/Test%20TTS.ipynb">The effects of adversarial training in text-to-speech synthesis | nbviewer</a></li>
</ul>

<p>前回の記事でも書いた注意書きですが、厳密に同じ結果を再現しようとは思っていません。同様のアイデアを試す、といったことに主眼を置いています。</p>

<h2 id="実験">実験</h2>

<h3 id="実験条件">実験条件</h3>

<p><a href="http://festvox.org/cmu_arctic/">CMU ARCTIC</a> から、話者 <code>slt</code> のwavデータそれぞれ1131発話すべてを用います。
<a href="https://github.com/CSTR-Edinburgh/merlin">Merlin</a>  の slt デモの条件と同様に、1000を学習用、126を評価用、残り5をテスト用にします。継続長モデル（state-level）には <strong>Bidirectional-LSTM RNN</strong> を、音響モデルには <strong>Feed-forward型</strong> のニューラルネットを使用しました<sup class="footnote-ref" id="fnref:1"><a rel="footnote" href="#fn:1">1</a></sup>。継続長モデル、音響モデルの両方にGANを取り入れました。論文の肝である <strong>ADV loss</strong> についてですが、mgcのみ（0次は除く）を使って計算するパターンと、mgc + lf0で計算するパターンとで比較しました<sup class="footnote-ref" id="fnref:2"><a rel="footnote" href="#fn:2">2</a></sup>。</p>

<p>実験の結果 (ADV loss: mgcのみ) は、 <a href="https://github.com/r9y9/gantts/tree/a5ec247ba7ee1a160875661f8899f56f8010be5b">a5ec247</a> をチェックアウトして、下記のシェルを実行すると再現できます。</p>

<pre><code>./tts_demo.sh tts_test
</code></pre>

<p>データのダウンロード、特徴抽出、モデル学習、音声サンプル合成まで一通り行われます。<code>tts_test</code> の部分は何でもよいです。tensorboard用に吐くログイベント名、モデル出力先、音声サンプル出力先の決定に使われます。詳細はコードを参照ください。 (ADV loss: mgc + lf0) の結果は、<a href="https://github.com/r9y9/gantts/blob/a5ec247ba7ee1a160875661f8899f56f8010be5b/hparams.py">ハイパーパラメータ</a>を下記のように変更してシェルを実行すると再現できます。</p>

<pre><code class="language-diff">diff --git a/hparams.py b/hparams.py
index d82296c..e73dc57 100644
--- a/hparams.py
+++ b/hparams.py
@@ -175,7 +175,7 @@ tts_acoustic = tf.contrib.training.HParams(
     # Streams used for computing adversarial loss
     # NOTE: you should probably change discriminator's `in_dim`
     # if you change the adv_streams
-    adversarial_streams=[True, False, False, False],
+    adversarial_streams=[True, True, False, False],
     # Don't switch this on unless you are sure what you are doing
     # If True, you will need to adjast `in_dim` for discriminator.
     # Rationale for this is that power coefficients are less meaningful
@@ -202,7 +202,7 @@ tts_acoustic = tf.contrib.training.HParams(
     # Discriminator
     discriminator=&quot;MLP&quot;,
     discriminator_params={
-        &quot;in_dim&quot;: 24,
+        &quot;in_dim&quot;: 25,
         &quot;out_dim&quot;: 1,
         &quot;num_hidden&quot;: 2,
         &quot;hidden_dim&quot;: 256,
</code></pre>

<h3 id="変換音声の比較">変換音声の比較</h3>

<h4 id="音響モデルのみ適用-adv-loss-mgcのみ">音響モデルのみ適用 (ADV loss: mgcのみ)</h4>

<p>継続長モデルを適用しない、かつ ADV lossにmgcのみを用いる場合です。</p>

<ol>
<li>自然音声</li>
<li>ベースライン</li>
<li>GAN</li>
</ol>

<p>の順に音声を貼ります。聴きやすいように、soxで音量を正規化しています。</p>

<p><strong>arctic_b0535</strong></p>

<p><audio controls="controls" >
<source src="/audio/slt/arctic_b0535.wav" autoplay/>
Your browser does not support the audio element.
</audio></p>

<p><audio controls="controls" >
<source src="/audio/gantts/tts_order24/acoustic_only/baseline/test/arctic_b0535.wav" autoplay/>
Your browser does not support the audio element.
</audio></p>

<p><audio controls="controls" >
<source src="/audio/gantts/tts_order24/acoustic_only/gan/test/arctic_b0535.wav" autoplay/>
Your browser does not support the audio element.
</audio></p>

<p><strong>arctic_b0536</strong></p>

<p><audio controls="controls" >
<source src="/audio/slt/arctic_b0536.wav" autoplay/>
Your browser does not support the audio element.
</audio></p>

<p><audio controls="controls" >
<source src="/audio/gantts/tts_order24/acoustic_only/baseline/test/arctic_b0536.wav" autoplay/>
Your browser does not support the audio element.
</audio></p>

<p><audio controls="controls" >
<source src="/audio/gantts/tts_order24/acoustic_only/gan/test/arctic_b0536.wav" autoplay/>
Your browser does not support the audio element.
</audio></p>

<p><strong>arctic_b0537</strong></p>

<p><audio controls="controls" >
<source src="/audio/slt/arctic_b0537.wav" autoplay/>
Your browser does not support the audio element.
</audio></p>

<p><audio controls="controls" >
<source src="/audio/gantts/tts_order24/acoustic_only/baseline/test/arctic_b0537.wav" autoplay/>
Your browser does not support the audio element.
</audio></p>

<p><audio controls="controls" >
<source src="/audio/gantts/tts_order24/acoustic_only/gan/test/arctic_b0537.wav" autoplay/>
Your browser does not support the audio element.
</audio></p>

<p><strong>arctic_b0538</strong></p>

<p><audio controls="controls" >
<source src="/audio/slt/arctic_b0538.wav" autoplay/>
Your browser does not support the audio element.
</audio></p>

<p><audio controls="controls" >
<source src="/audio/gantts/tts_order24/acoustic_only/baseline/test/arctic_b0538.wav" autoplay/>
Your browser does not support the audio element.
</audio></p>

<p><audio controls="controls" >
<source src="/audio/gantts/tts_order24/acoustic_only/gan/test/arctic_b0538.wav" autoplay/>
Your browser does not support the audio element.
</audio></p>

<p><strong>arctic_b0539</strong></p>

<p><audio controls="controls" >
<source src="/audio/slt/arctic_b0539.wav" autoplay/>
Your browser does not support the audio element.
</audio></p>

<p><audio controls="controls" >
<source src="/audio/gantts/tts_order24/acoustic_only/baseline/test/arctic_b0539.wav" autoplay/>
Your browser does not support the audio element.
</audio></p>

<p><audio controls="controls" >
<source src="/audio/gantts/tts_order24/acoustic_only/gan/test/arctic_b0539.wav" autoplay/>
Your browser does not support the audio element.
</audio></p>

<p>VCの場合と同じように、音声の明瞭性が上がったように思います。</p>

<h4 id="音響モデル-継続長モデルを適用-adv-loss-mgcのみ">音響モデル＋継続長モデルを適用 (ADV loss: mgcのみ)</h4>

<p><strong>arctic_b0535</strong></p>

<p><audio controls="controls" >
<source src="/audio/slt/arctic_b0535.wav" autoplay/>
Your browser does not support the audio element.
</audio></p>

<p><audio controls="controls" >
<source src="/audio/gantts/tts_order24/duration_acoustic/baseline/test/arctic_b0535.wav" autoplay/>
Your browser does not support the audio element.
</audio></p>

<p><audio controls="controls" >
<source src="/audio/gantts/tts_order24/duration_acoustic/gan/test/arctic_b0535.wav" autoplay/>
Your browser does not support the audio element.
</audio></p>

<p><strong>arctic_b0536</strong></p>

<p><audio controls="controls" >
<source src="/audio/slt/arctic_b0536.wav" autoplay/>
Your browser does not support the audio element.
</audio></p>

<p><audio controls="controls" >
<source src="/audio/gantts/tts_order24/duration_acoustic/baseline/test/arctic_b0536.wav" autoplay/>
Your browser does not support the audio element.
</audio></p>

<p><audio controls="controls" >
<source src="/audio/gantts/tts_order24/duration_acoustic/gan/test/arctic_b0536.wav" autoplay/>
Your browser does not support the audio element.
</audio></p>

<p><strong>arctic_b0537</strong></p>

<p><audio controls="controls" >
<source src="/audio/slt/arctic_b0537.wav" autoplay/>
Your browser does not support the audio element.
</audio></p>

<p><audio controls="controls" >
<source src="/audio/gantts/tts_order24/duration_acoustic/baseline/test/arctic_b0537.wav" autoplay/>
Your browser does not support the audio element.
</audio></p>

<p><audio controls="controls" >
<source src="/audio/gantts/tts_order24/duration_acoustic/gan/test/arctic_b0537.wav" autoplay/>
Your browser does not support the audio element.
</audio></p>

<p><strong>arctic_b0538</strong></p>

<p><audio controls="controls" >
<source src="/audio/slt/arctic_b0538.wav" autoplay/>
Your browser does not support the audio element.
</audio></p>

<p><audio controls="controls" >
<source src="/audio/gantts/tts_order24/duration_acoustic/baseline/test/arctic_b0538.wav" autoplay/>
Your browser does not support the audio element.
</audio></p>

<p><audio controls="controls" >
<source src="/audio/gantts/tts_order24/duration_acoustic/gan/test/arctic_b0538.wav" autoplay/>
Your browser does not support the audio element.
</audio></p>

<p><strong>arctic_b0539</strong></p>

<p><audio controls="controls" >
<source src="/audio/slt/arctic_b0539.wav" autoplay/>
Your browser does not support the audio element.
</audio></p>

<p><audio controls="controls" >
<source src="/audio/gantts/tts_order24/duration_acoustic/baseline/test/arctic_b0539.wav" autoplay/>
Your browser does not support the audio element.
</audio></p>

<p><audio controls="controls" >
<source src="/audio/gantts/tts_order24/duration_acoustic/gan/test/arctic_b0539.wav" autoplay/>
Your browser does not support the audio element.
</audio></p>

<p>音声の明瞭性が上がっているとは思いますが、継続長に関しては、ベースライン/GANで差異がほとんどないように感じられると思います。これは、（僕が実験した範囲では少なくとも）DiscriminatorがGeneartorに勝ちやすくて (音響モデルの場合は、そんなことはない)、 ADV lossが下がるどころか上がってしまい、結果 MGE lossを最小化する場合とほとんど変わっていない、という結果になっています。論文に記載の内容とは異なり、state-levelの継続長モデルではあるものの、ハイパーパラメータなどなどいろいろ変えて試したのですが、上手くいきませんでした。</p>

<h4 id="adv-loss-mgc-vs-mgc-lf0">ADV loss: mgc vs mgc + lf0</h4>

<p>次に、ロスの比較です。F0の変化に着目しやすいように、継続長モデルを使わず、音響モデルのみを適用します。</p>

<ol>
<li>自然音声</li>
<li>ADV loss (mgcのみ, 24次元)</li>
<li>ADV loss (mgc + lf0, 25次元)</li>
</ol>

<p>の順に音声を貼ります。また、WORLD (dio + stonemask) で分析したF0の可視化結果も併せて貼っておきます。</p>

<p><strong>arctic_b0535</strong></p>

<p><audio controls="controls" >
<source src="/audio/slt/arctic_b0535.wav" autoplay/>
Your browser does not support the audio element.
</audio></p>

<p><audio controls="controls" >
<source src="/audio/gantts/tts_order24/acoustic_only/gan/test/arctic_b0535.wav" autoplay/>
Your browser does not support the audio element.
</audio></p>

<p><audio controls="controls" >
<source src="/audio/gantts/tts_order24_advf0/acoustic_only/gan/test/arctic_b0535.wav" autoplay/>
Your browser does not support the audio element.
</audio></p>

<div align="center"><img src="/images/gantts/arctic_b0535_f0.png" /></div>

<p><strong>arctic_b0536</strong></p>

<p><audio controls="controls" >
<source src="/audio/slt/arctic_b0536.wav" autoplay/>
Your browser does not support the audio element.
</audio></p>

<p><audio controls="controls" >
<source src="/audio/gantts/tts_order24/acoustic_only/gan/test/arctic_b0536.wav" autoplay/>
Your browser does not support the audio element.
</audio></p>

<p><audio controls="controls" >
<source src="/audio/gantts/tts_order24_advf0/acoustic_only/gan/test/arctic_b0536.wav" autoplay/>
Your browser does not support the audio element.
</audio></p>

<div align="center"><img src="/images/gantts/arctic_b0536_f0.png" /></div>

<p><strong>arctic_b0537</strong></p>

<p><audio controls="controls" >
<source src="/audio/slt/arctic_b0537.wav" autoplay/>
Your browser does not support the audio element.
</audio></p>

<p><audio controls="controls" >
<source src="/audio/gantts/tts_order24/acoustic_only/gan/test/arctic_b0537.wav" autoplay/>
Your browser does not support the audio element.
</audio></p>

<p><audio controls="controls" >
<source src="/audio/gantts/tts_order24_advf0/acoustic_only/gan/test/arctic_b0537.wav" autoplay/>
Your browser does not support the audio element.
</audio></p>

<div align="center"><img src="/images/gantts/arctic_b0537_f0.png" /></div>

<p><strong>arctic_b0538</strong></p>

<p><audio controls="controls" >
<source src="/audio/slt/arctic_b0538.wav" autoplay/>
Your browser does not support the audio element.
</audio></p>

<p><audio controls="controls" >
<source src="/audio/gantts/tts_order24/acoustic_only/gan/test/arctic_b0538.wav" autoplay/>
Your browser does not support the audio element.
</audio></p>

<p><audio controls="controls" >
<source src="/audio/gantts/tts_order24_advf0/acoustic_only/gan/test/arctic_b0538.wav" autoplay/>
Your browser does not support the audio element.
</audio></p>

<div align="center"><img src="/images/gantts/arctic_b0538_f0.png" /></div>

<p><strong>arctic_b0539</strong></p>

<p><audio controls="controls" >
<source src="/audio/slt/arctic_b0539.wav" autoplay/>
Your browser does not support the audio element.
</audio></p>

<p><audio controls="controls" >
<source src="/audio/gantts/tts_order24/acoustic_only/gan/test/arctic_b0539.wav" autoplay/>
Your browser does not support the audio element.
</audio></p>

<p><audio controls="controls" >
<source src="/audio/gantts/tts_order24_advf0/acoustic_only/gan/test/arctic_b0539.wav" autoplay/>
Your browser does not support the audio element.
</audio></p>

<div align="center"><img src="/images/gantts/arctic_b0539_f0.png" /></div>

<p>どうでしょうか。上手くいっている場合も（arctic_b537とか）あれば、上手くいっていない場合 (arctic_b539とか) もあるように思います。僕にはF0が不自然に揺れているように感じ場合が多くありました。ここでは5つしか音声を貼っていませんが、その他126個の評価用音声でも聴き比べていると、ADV lossにF0を入れない方がよい気がしました（あくまで僕の主観ですが</p>

<p>このあたりは、F0の抽出法、補間法に強く依存しそうです。今回は、F0抽出のパラメータをまったくチューニングしていないので、そのせいもあった（f0分析エラーに引っ張られて悪くなった）のかもしれません。</p>

<h3 id="global-variance-は補償されているのか">Global variance は補償されているのか？</h3>

<p>F0の話は終わりで、スペクトル特徴量に着目して結果を分析していきます。以下、ADV loss (mgcのみ)、継続長モデル＋音響モデルを適用したサンプルでの分析結果です。</p>

<div align="center"><img src="/images/gantts/arctic_b0537_gv.png" /></div>

<p>大まかに、論文で示されているのと同様の結果が得られました。なお、これは <code>arctic_b0537</code> の一発話に対して計算したもので、テストセットの平均ではありません（すいません）。また、これはテストセット中のサンプルの中で、GVが補償されていることがわかりやすい例をピックアップしました。ただし、他のテストサンプルにおいても同様の傾向が見られるのは確認しています。</p>

<h3 id="modulation-spectrum-変調スペクトル-は補償されているのか">Modulation spectrum (変調スペクトル) は補償されているのか？</h3>

<p>評価用の音声126発話それぞれで変調スペクトルを計算し、それらの平均を取り、適当な特徴量の次元をピックアップしたものを示します。横軸は変調周波数です。一番右端が50Hzです。</p>

<div align="center"><img src="/images/gantts/ms.png" /></div>

<p><code>arctic_b0537</code> の一発話に対して計算したものです。<strong>VCの場合とは異なり</strong>、ベースライン、GANともに、低次元であっても10Hzを越えた辺りから自然音声とは大きく異っています。これはなぜなのか、僕にはまだわかっていません。また、VCの場合と同様に、高次元になるほど、GANベースの方が変調スペクトルは自然音声に近いこともわかります。GANによって、変調スペクトルはある程度補償されていると言えると思います。</p>

<h3 id="特徴量の分布">特徴量の分布</h3>

<p><div align="center"><img src="/images/gantts/arctic_b0537_scatter.png" /></div></p>

<p><code>arctic_b0537</code> の一発話に対して計算したものです。論文で示されているほど顕著ではない気がしますが、おおまかに同様の結果が得られました。</p>

<h2 id="感想">感想</h2>

<ul>
<li>GANのチューニングは難しい。人力（直感）ハイパーパラメータのチューニングを試しましたが、大変でした。そしてあまりうまくできた自信がありません。潤沢な計算資源でなんとかしたい…</li>
<li>GANの学習は不安定（に感じる）が、通常の MSE loss の学習は安定で、かつBidirectional LSTM RNNは安定してよいです（結果をここに貼っていなくて申し訳ですが）。ただし、計算にものすごく時間がかかるのと、GPUメモリをかなり使うので、とりあえず通常のfeed forward型で実験した結果をまとめました</li>
<li>state-levelの継続長モデルに、GANを使うのはあまり上手くできませんでした。ここに貼ったサンプルからはわからないのですが（すいません）、GとDが上手く競い合わず、Dが勝ってしまう場合がほとんどでした（結果それが一番まし）。上手く競い合わせるようとすると、早口音声が生成されてしまったり、と失敗がありました。</li>
<li>F0を ADV lossに加えると、より自然音声に近づくと感じる場合もあるが、一方でF0が不自然に揺れてしまう場合もありました。これはF0の抽出法、補間法にも依存するので、調査が必要です</li>
<li>mgc, lf0, vuv, bapすべてで ADV lossに加えると、残念な結果を見ることになりました。理想的にはこれでも上手くいくと思って最初に試したのですが、だめでした。興味のある人はためしてみてください</li>
<li>mgcの0次（パワー成分）は、ADV lossに加えない方がよい。考えてみると、特にフレーム単位のモデルの場合（RNNではなく）、パワー情報はnatural/generated の識別にはほとんど寄与しなさそうです。これはArxivの方の論文には書いていないのですが（僕の見逃しでなければ）、<a href="http://sython.org/papers/ASJ/saito2017asja.pdf">ASJの原稿</a> には書いてあるんですよね。一つのハマりどころでした</li>
<li>DにRNNを使った実験も少しやってみたのですが、うまく競い合わせるのが難しそうでした。DにRNNを使うのは本質的には良いと思っているので、この辺りはもう少し色々試行錯誤したいと思っています</li>
</ul>

<h2 id="まとめ">まとめ</h2>

<p>GANの学習は大変でしたが、上手く学習できれば品質向上につながることを確認できました。今後、計算リソースが空き次第、RNNでの実験も進めようと思うのと、日本語でやってみようと思っています。</p>

<p>GANシリーズのその他記事へのリンクは以下の通りです。</p>

<ul>
<li><a href="/blog/2017/10/05/ganvc/">GAN 声質変換 (en) 編はこちら</a></li>
<li><a href="/blog/2017/10/10/gantts-jp/">GAN 音声合成 (ja) 編はこちら</a></li>
</ul>

<h2 id="参考">参考</h2>

<p>Arxivにあるペーパーだけでなく、その他いろいろ参考にしました。ありがとうございます。</p>

<ul>
<li><a href="https://arxiv.org/abs/1709.08041">Yuki Saito, Shinnosuke Takamichi, Hiroshi Saruwatari, &ldquo;Statistical Parametric Speech Synthesis Incorporating Generative Adversarial Networks&rdquo;, arXiv:1709.08041 [cs.SD], Sep. 2017</a></li>
<li><a href="http://sython.org/papers/SIG-SLP/saito201702slp.pdf">Yuki Saito, Shinnosuke Takamichi, and Hiroshi Saruwatari, &ldquo;Training algorithm to deceive anti-spoofing verification for DNN-based text-to-speech synthesis,&rdquo; IPSJ SIG Technical Report, 2017-SLP-115, no. 1, pp. 1-6, Feb., 2017. (in Japanese)</a></li>
<li><a href="https://www.jstage.jst.go.jp/article/transinf/E100.D/8/E100.D_2017EDL8034/_article">Yuki Saito, Shinnosuke Takamichi, and Hiroshi Saruwatari, &ldquo;Voice conversion using input-to-output highway networks,&rdquo; IEICE Transactions on Information and Systems, Vol.E100-D, No.8, pp.1925&ndash;1928, Aug. 2017</a></li>
<li><a href="https://www.slideshare.net/ShinnosukeTakamichi/dnnantispoofing">https://www.slideshare.net/ShinnosukeTakamichi/dnnantispoofing</a></li>
<li><a href="https://www.slideshare.net/YukiSaito8/Saito2017icassp">https://www.slideshare.net/YukiSaito8/Saito2017icassp</a></li>
<li><a href="https://github.com/SythonUK/whisperVC">https://github.com/SythonUK/whisperVC</a></li>
<li><a href="http://sython.org/papers/ASJ/saito2017asja.pdf">Yuki Saito, Shinnosuke Takamichi, and Hiroshi Saruwatari, &ldquo;Experimental investigation of divergences in adversarial DNN-based speech synthesis,&rdquo; Proc. ASJ, Spring meeting, 1-8-7, &ndash;, Sep., 2017. (in Japanese)</a></li>
</ul>
<div class="footnotes">

<hr />

<ol>
<li id="fn:1">継続長モデル、音響モデルともにRNNを使うと良くなることがわかっているのですが、計算リソースの都合上、今回は音響モデルはFeed-forwardにしました。Feed-forwardだと30分で終わる計算が、RNNだと数時間かかってしまうので…
 <a class="footnote-return" href="#fnref:1"><sup>[return]</sup></a></li>
<li id="fn:2">他も色々やったのですが、だいたい失敗でした。
 <a class="footnote-return" href="#fnref:2"><sup>[return]</sup></a></li>
</ol>
</div>

				
<div class="social">
    <div>
        <a href="https://twitter.com/share" class="twitter-share-button" data-via="r9y9" data-text="【音声合成編】Statistical Parametric Speech Synthesis Incorporating Generative Adversarial Networks [arXiv:1709.08041]" data-related="r9y9">Tweet</a>
        <script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>
    </div>
</div>


			</section>
		</article>
	</main>


	<footer role="contentinfo">
		<div class="hr"></div>
		<address>
			<div class="avatar-bottom">
				<a href="/">
					
					<img src="/images/r9y9.jpg">
					
				</a>
			</div>

		<div class="copyright">Copyright &copy;
			<a href="/about">Ryuichi YAMAMOTO</a> All rights reserved.

			<a href="https://github.com/r9y9">
				<span class="github">r9y9@Github</span>
			</a>
		</div>
		</address>
	</footer>

</div>

<script>
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','//www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-44433856-1', 'auto');
	ga('send', 'pageview');
</script>

<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.4/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>



<script type="text/x-mathjax-config">
     MathJax.Hub.Config({
         HTML: ["input/TeX","output/HTML-CSS"],
         TeX: {
                Macros: {
                         bm: ["\\boldsymbol{#1}", 1],
                         argmax: ["\\mathop{\\rm arg\\,max}\\limits"],
                         argmin: ["\\mathop{\\rm arg\\,min}\\limits"]},
                extensions: ["AMSmath.js","AMSsymbols.js"],
                equationNumbers: { autoNumber: "AMS" } },
         extensions: ["tex2jax.js"],
         jax: ["input/TeX","output/HTML-CSS"],
         tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ],
                    displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
                    processEscapes: true },
         "HTML-CSS": { availableFonts: ["TeX"],
                       linebreaks: { automatic: true } }
     });
 </script>

 <script type="text/x-mathjax-config">
     MathJax.Hub.Config({
       tex2jax: {
         skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
       }
     });
 </script>

 <script type="text/javascript" async
   src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML">
 </script>




</body>
</html>

