<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Recent &amp; Upcoming Talks | LESS IS MORE</title>
    <link>https://r9y9.github.io/event/</link>
      <atom:link href="https://r9y9.github.io/event/index.xml" rel="self" type="application/rss+xml" />
    <description>Recent &amp; Upcoming Talks</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>Copyright © Ryuichi YAMAMOTO All rights reserved.</copyright><lastBuildDate>Fri, 03 Dec 2021 13:00:00 +0900</lastBuildDate>
    <image>
      <url>https://r9y9.github.io/media/icon_hu71488a41e9448d472219f1cc71ecc0ad_259818_512x512_fill_lanczos_center_3.png</url>
      <title>Recent &amp; Upcoming Talks</title>
      <link>https://r9y9.github.io/event/</link>
    </image>
    
    <item>
      <title>国際会議Interspeech2021参加報告 / Report on Participation in Interspeech2021 @SLP研究会</title>
      <link>https://r9y9.github.io/talk/sp-interspeech2021report/</link>
      <pubDate>Fri, 03 Dec 2021 13:00:00 +0900</pubDate>
      <guid>https://r9y9.github.io/talk/sp-interspeech2021report/</guid>
      <description>&lt;h3 id=&#34;abstract-ja&#34;&gt;Abstract (ja)&lt;/h3&gt;
&lt;p&gt;2021 年 8 月 30 日から 9 月 3 日にかけてチェコ・ブルノおよびオンラインのハイブリッド形式で Interspeech2021 が開催された．ここでは，会議概要や最新の技術動向，注目の発表について報告する．&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>ここまで来た音声技術・今後の展望 / Current progress on speech technologies and its future prospects @ LINE DEV DAY 2020</title>
      <link>https://r9y9.github.io/talk/linedevday2020panel/</link>
      <pubDate>Wed, 25 Nov 2020 16:40:00 +0900</pubDate>
      <guid>https://r9y9.github.io/talk/linedevday2020panel/</guid>
      <description>&lt;h3 id=&#34;abstract-ja&#34;&gt;Abstract (ja)&lt;/h3&gt;
&lt;p&gt;人の音声をテキストに変換する音声認識技術、テキストから人の音声を生成する音声合成技術をはじめとした音声処理技術が目覚ましい速度で進歩を続けている。さらに、音声に限らないドアの開け閉めの音など一般の音を識別する音響シーン・イベント検出技術などの新しい技術分野が拓けつつある。本セッションでは、LINEから2名のエンジニア（木田祐介・山本龍一）がパネリストとして登壇し、音声認識・音声合成の現状を語る。さらに、同志社大学の井本桂右准教授に登壇いただき、今年国際会議(DCASE)を日本に誘致するなど、日本の研究者の活躍が目覚ましい音響シーン・イベント検出技術の分野の現状を語っていただく。これらの技術分野の進歩には深層学習の進歩が強い影響を与えているが、音声処理特有の要素がどのようにして深層学習と絡み合い技術進化につながっているか掘り下げていきたい。また、様々な音声処理分野で、分野間で共通要素として進展が進む技術要素と特有の要素の分析を通し、各技術分野の特性を明らかにしていきたい。そして、今後どのような方向性で技術が進化していくか、将来の展望について議論していきたい。&lt;/p&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/iSPBCot6n7g&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

</description>
    </item>
    
    <item>
      <title>Parallel WaveGAN: GPUを利用した高速かつ高品質な音声合成 / Parallel WaveGAN: Fast and High-Quality GPU Text-to-Speech @ LINE DEV DAY 2020</title>
      <link>https://r9y9.github.io/talk/linedevday2020pwg/</link>
      <pubDate>Wed, 25 Nov 2020 14:20:00 +0900</pubDate>
      <guid>https://r9y9.github.io/talk/linedevday2020pwg/</guid>
      <description>&lt;h3 id=&#34;abstract-ja&#34;&gt;Abstract (ja)&lt;/h3&gt;
&lt;p&gt;コンピュータによってテキストから人間の声を合成する技術は、テキスト音声合成と呼ばれます。LINE CLOVAのスマートスピーカーを初めとするユーザとのリアルタイムのインタラクションが必要なサービスでは、音声合成システムには合成品質が高いことだけでなく、高速に音声を生成できることが求められます。本セッションでは、高速かつ高品質な音声合成を実現するために、NAVERとLINEで共同で開発したGPUベースの音声合成の研究成果について発表します。従来の方法では、品質が良くても合成速度が遅い、合成速度は速い一方でモデルの学習に多大な時間がかかるなどの問題がありました。我々はそのような問題に対してどのようにアプローチしたのか、音声信号処理のトップカンファレンスICASSP 2020に採択された論文の内容を元に、近年の関連分野の発展を交えて紹介します。&lt;/p&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/BZxqf-Wkhig&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;/br&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/knzT7M6qsl0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

</description>
    </item>
    
    <item>
      <title>End-to-End 音声合成の研究を加速させるツールキット ESPnet-TTS / ESPnet-TTS: A toolkit to accelerate research on end-to-end speech synthesis @ ASJ 2020s</title>
      <link>https://r9y9.github.io/talk/asj-espnet2-tutorial/</link>
      <pubDate>Mon, 16 Mar 2020 13:00:00 +0900</pubDate>
      <guid>https://r9y9.github.io/talk/asj-espnet2-tutorial/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
