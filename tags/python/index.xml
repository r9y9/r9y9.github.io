<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Python on LESS IS MORE</title>
    <link>http://r9y9.github.io/tags/python/</link>
    <description>Recent content in Python on LESS IS MORE</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja-jp</language>
    <lastBuildDate>Thu, 14 Dec 2017 00:00:30 +0900</lastBuildDate>
    
	<atom:link href="http://r9y9.github.io/tags/python/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>ニューラルネットの学習過程の可視化を題材に、Jupyter &#43; Bokeh で動的な描画を行う方法の紹介 [Jupyter Advent Calendar 2017]</title>
      <link>http://r9y9.github.io/blog/2017/12/14/jupyter-bokeh/</link>
      <pubDate>Thu, 14 Dec 2017 00:00:30 +0900</pubDate>
      
      <guid>http://r9y9.github.io/blog/2017/12/14/jupyter-bokeh/</guid>
      <description>Line https://bokeh.pydata.org/en/latest/docs/reference/models/glyphs/line.html
VBar https://bokeh.pydata.org/en/latest/docs/reference/models/glyphs/vbar.html
HBar https://bokeh.pydata.org/en/latest/docs/reference/models/glyphs/hbar.html
ImageRGBA https://bokeh.pydata.org/en/latest/docs/reference/models/glyphs/image_rgba.html
ImageRGBA https://bokeh.pydata.org/en/latest/docs/reference/models/glyphs/image_rgba.html
前置き Jupyter Advent Calendar 2017 14日目の記事です。この記事は、Jupyter notebookで作成したものをnbconvertでmarkdownに変換し、手で少し修正して作りました。読み物としてはこの記事を、実行するにはノートブックの方を参照していただくのが良いかと思います。
 ノートブック (gist) nbviewer  概要 適当なニューラルネットの学習過程の可視化（ロス、正解率の遷移等）を題材にして、Bokehを使って動的にグラフを更新していくことによる可視化の実用例を紹介します。このノートブックの冒頭に、最後まで実行すると得られるグラフ一覧をまとめました。どうやってグラフを作るのか知りたい方は続きを読んでもらえればと思います。Bokehの詳細な使い方は、公式ドキュメントを参考にしてください。
なお、ここで紹介する例は、僕が過去に出た機械学習のコンペ (https://deepanalytics.jp/compe/36?tab=compedetail) で実際に使用したコードからほぼ取ってきました（8/218位でした）。グラフを動的に更新する方法は 公式ドキュメント に記述されていますが、そのサンプルの内容は「円を描画して色を変える」といった実用性皆無のものであること、またググっても例が多く見つからないことから、このような紹介記事を書くことにしました。参考になれば幸いです。
余談ではありますが、こと機械学習に関しては、tensorboardを使ったほうが簡単で良いと思います。僕は最近そうしています。 https://qiita.com/r9y9/items/d54162d37ec4f110f4b4. 色なり位置なり大きさなりを柔軟にカスタマイズしたい、あるいはノートブックで処理を完結させたい、と言った場合には、ここで紹介する方法も良いかもしれません。
%pylab inline  Populating the interactive namespace from numpy and matplotlib  from IPython.display import HTML, Image import IPython from os.path import exists def summary(): baseurl = &amp;quot;https://bokeh.pydata.org/en/latest/docs/reference/models/glyphs/&amp;quot; for (name, figname, url) in [ (&amp;quot;Line&amp;quot;, &amp;quot;line&amp;quot;, &amp;quot;line.html&amp;quot;), (&amp;quot;VBar&amp;quot;, &amp;quot;vbar&amp;quot;, &amp;quot;vbar.</description>
    </item>
    
    <item>
      <title>DNN音声合成のためのライブラリの紹介とDNN日本語音声合成の実装例</title>
      <link>http://r9y9.github.io/blog/2017/08/16/japanese-dnn-tts/</link>
      <pubDate>Wed, 16 Aug 2017 23:10:56 +0900</pubDate>
      
      <guid>http://r9y9.github.io/blog/2017/08/16/japanese-dnn-tts/</guid>
      <description>nnmnkwii というDNN音声合成のためのライブラリを公開しましたので、その紹介をします。
https://t.co/p8MnOxkVoH Library to build speech synthesis systems designed for easy and fast prototyping. Open sourced:)
&amp;mdash; 山本りゅういち (@r9y9) August 14, 2017 
ドキュメントの最新版は https://r9y9.github.io/nnmnkwii/latest/ です。以下に、いくつかリンクを貼っておきます。
 なぜ作ったのか、その背景の説明と設計 (日本語) クイックガイド DNN英語音声合成のチュートリアル  よろしければご覧ください1。
ドキュメントは、だいたい英語でお硬い雰囲気で書いたので、この記事では、日本語でカジュアルに背景などを説明しようと思うのと、（ドキュメントには英語音声合成の例しかないので）HTSのデモに同梱のATR503文のデータセットを使って、DNN日本語音声合成 を実装する例を示したいと思います。結果だけ知りたい方は、音声サンプルが下の方にあるので、適当に読み飛ばしてください。
なぜ作ったのか 一番大きな理由は、僕が 対話環境（Jupyter, IPython等） で使えるツールがほしかったからです2。 僕は結構前からREPL (Read-Eval-Print-Loop) 信者で、プログラミングのそれなりの時間をREPLで過ごします。 IDEも好きですし、emacsも好きなのですが、同じくらいJupyterやJuliaのREPLが好きです。 用途に応じて使い分けますが、特に何かデータを分析する必要があるような時に、即座にデータを可視化できるJupyter notebookは、僕にとってプログラミングに欠かせないものになっています。
ところが、HTSの後継として生まれたDNN音声合成ツールである Merlin は、コマンドラインツールとして使われる想定のもので、僕の要望を満たしてくれるものではありませんでした。 とはいえ、Merlinは優秀な音声研究者たちの産物であり、当然役に立つ部分も多く、使っていました。しかし、ことプロトタイピングにおいては、やはり対話環境でやりたいなあという思いが強まっていきました。
新しく作るのではなく、Merlinを使い続ける、Merlinを改善する方針も考えました。僕がMerlinを使い始めた頃、Merlinはpython3で動かなかったので、動くように プルリク を出したこともあるのですが、まぁレビューに数カ月もかかってしまったので、これは新しいものを作った方がいいな、と思うに至りました。
以上が、僕が新しくツール作ろうと思った理由です。
特徴 さて、Merlinに対する敬意と不満から生まれたツールでありますが、その特徴を簡単にまとめます。
 対話環境 での使用を前提に、設計されています。コマンドラインツールはありません。ユーザが必要に応じて作ればよい、という考えです。 DNN音声合成のデモをノートブック形式で提供しています。 大規模データでも扱えるように、データセットとデータセットのイテレーション（フレーム毎、発話毎の両方）のユーティリティが提供されています Merlinとは異なり、音響モデルは提供しません。自分で実装する必要があります（が、今の時代簡単ですよね、lstmでも数行で書けるので 任意の深層学習フレームワークと併せて使えるように、設計されています3（autogradパッケージのみ、今のところPyTorch依存です 言語特徴量の抽出の部分は、Merlinのコードをリファクタして用いています。そのせいもあって、Merlinのデモと同等のパフォーマンスを簡単に実現できます。  対象ユーザ まずはじめに、大雑把にいって、音声合成の研究（or その真似事）をしてみたい人が主な対象です。 自前のデータを元に、ブラックボックスでいいので音声合成エンジンを作りたい、という人には厳しいかもしれません。その前提を元に、少し整理します。</description>
    </item>
    
  </channel>
</rss>