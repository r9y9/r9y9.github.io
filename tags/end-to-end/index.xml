<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>end-to-end on LESS IS MORE</title>
    <link>http://r9y9.github.io/tags/end-to-end/</link>
    <description>Recent content in end-to-end on LESS IS MORE</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja-jp</language>
    <lastBuildDate>Sun, 12 Nov 2017 03:00:00 +0900</lastBuildDate>
    
	<atom:link href="http://r9y9.github.io/tags/end-to-end/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>日本語 End-to-end 音声合成に使えるコーパス JSUT の前処理 [arXiv:1711.00354]</title>
      <link>http://r9y9.github.io/blog/2017/11/12/jsut_ver1/</link>
      <pubDate>Sun, 12 Nov 2017 03:00:00 +0900</pubDate>
      
      <guid>http://r9y9.github.io/blog/2017/11/12/jsut_ver1/</guid>
      <description>コーパス配布先リンク: JSUT (Japanese speech corpus of Saruwatari Lab, University of Tokyo) - Shinnosuke Takamichi (高道 慎之介) 論文リンク: arXiv:1711.00354  三行まとめ  日本語End-to-end音声合成に使えるコーパスは神、ありがとうございます クリーンな音声であるとはいえ、冒頭/末尾の無音区間は削除されていない、またボタンポチッみたいな音も稀に入っているので注意 僕が行った無音区間除去の方法（Juliusで音素アライメントを取って云々）を記録しておくので、必要になった方は参考にどうぞ。ラベルファイルだけほしい人は連絡ください  JSUT とは ツイート引用： フリーの日本語音声コーパス（単一話者による10時間データ）を公開しました．音声研究等にお役立てください．https://t.co/94ShJY44mA pic.twitter.com/T0etDwD7cS
&amp;mdash; Shinnosuke Takamichi (高道 慎之介) (@forthshinji) October 26, 2017  
つい先月、JSUT という、日本語 End-to-end 音声合成の研究に使えることを前提に作られた、フリーの大規模音声コーパスが公開されました。詳細は上記リンク先を見てもらうとして、簡単に特徴をまとめると、以下のとおりです。
 単一日本語女性話者の音声10時間 無響室で収録されている、クリーンな音声コーパス 1 非営利目的で無料で使える  僕の知る限り、日本語 End-to-end 音声合成に関する研究はまだあまり発展していないように感じていたのですが、その理由の一つに誰でも自由に使えるコーパスがなかったことがあったように思います。このデータセットはとても貴重なので、ぜひ使っていきたいところです。 高道氏およびコーパスを整備してくださった方、本当にありがとうございます。
この記事では、僕が実際に日本語End-to-end音声合成の実験をしようと思った時に、必要になった前処理（最初と最後の無音区間の除去）について書きたいと思います。
問題 まずはじめに、最初と最後の無音区間を除去したい理由には、以下の二つがありました。
 Tacotronのようなattention付きseq2seqモデルにおいて、アライメントを学習するのに不都合なこと。句読点に起因する無音区間ならともかく、最初/最後の無音区間は、テキスト情報からはわからないので、直感的には不要であると思われます。参考までに、DeepVoice2の論文のsection 4.2 では、無音区間をトリミングするのがよかったと書かれています。 発話の前、発話の後に、微妙にノイズがある（息を大きく吸う音、ボタンをポチッ、みたいな機械音等）データがあり、そのノイズが不都合なこと。例えばTacotronのようなモデルでは、テキスト情報とスペクトログラムの関係性を学習したいので、テキストに関係のないノイズは可能な限り除去しておきたいところです。参考までに、ボタンポチノイズは 例えば basic5000/wav/BASIC5000_0008.wav に入っています  最初何も考えずに（ダメですが）データを入れたら、アライメントが上手く学習されないなーと思い、データを見ていたところ、後者に気づいた次第です。</description>
    </item>
    
  </channel>
</rss>