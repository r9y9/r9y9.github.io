<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Voice Conversion Machine Learning Speech Signal Processing on LESS IS MORE</title>
    <link>http://r9y9.github.io/categories/voice-conversion-machine-learning-speech-signal-processing/</link>
    <description>Recent content in Voice Conversion Machine Learning Speech Signal Processing on LESS IS MORE</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja-jp</language>
    <lastBuildDate>Wed, 12 Nov 2014 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="http://r9y9.github.io/categories/voice-conversion-machine-learning-speech-signal-processing/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>統計的声質変換クッソムズすぎワロタ（チュートリアル編）</title>
      <link>http://r9y9.github.io/blog/2014/11/12/statistical-voice-conversion-code/</link>
      <pubDate>Wed, 12 Nov 2014 00:00:00 +0000</pubDate>
      
      <guid>http://r9y9.github.io/blog/2014/11/12/statistical-voice-conversion-code/</guid>
      <description>はじめに こんばんは。統計的声質変換（以降、簡単に声質変換と書きます）って面白いなーと思っているのですが、興味を持つ人が増えたらいいなと思い、今回は簡単なチュートリアルを書いてみます。間違っている箇所があれば、指摘してもらえると助かります。よろしくどうぞ。
前回の記事（統計的声質変換クッソムズすぎワロタ（実装の話） - LESS IS MORE）では変換部分のコードのみを貼りましたが、今回はすべてのコードを公開します。なので、記事内で示す声質変換の結果を、この記事を読んでいる方が再現することも可能です。対象読者は、特に初学者の方で、声質変換を始めたいけれど論文からコードに落とすにはハードルが高いし、コードを動かしながら仕組みを理解していきたい、という方を想定しています。役に立てば幸いです。
コード https://github.com/r9y9/VoiceConversion.jl
Julia という言語で書かれています。Juliaがどんな言語かをさっと知るのには、以下のスライドがお勧めです。人それぞれ好きな言語で書けばいいと思いますが、個人的にJuliaで書くことになった経緯は、最後の方に簡単にまとめました。
  プログラミング言語 Julia の紹介  from Kentaro Iizuka  サードパーティライブラリ 声質変換は多くのコンポーネントによって成り立っていますが、すべてを自分で書くのは現実的ではありません。僕は、主に以下のライブラリを活用しています。
 WORLD - 音声分析合成のフレームワークとして、あるいは単にスペクトル包絡を抽出するツールとして使っています。Juliaラッパーを書きました。 SPTK - メル対数スペクトル近似（Mel-Log Spectrum Approximation; MLSA）フィルタを変換処理に使っています。これもJuliaラッパーを書きました。 sklearn - sklearn.mixture をGMMの学習に使っています。pythonのライブラリは、juliaから簡単に呼べます。  音声分析合成に関しては、アカデミック界隈ではよく使われているSTRAIGHTがありますが、WORLDの方がライセンスもゆるくソースも公開されていて、かつ性能も劣らない（正確な話は、森勢先生の論文を参照してください）ので、おすすめです。
VoiceConversion.jl でできること 追記 2015/01/07 この記事を書いた段階のv0.0.1は、依存ライブラリの変更のため、現在は動きません。すみません。何のためのタグだ、という気がしてきますが、、最低限masterは動作するようにしますので、そちらをお試しください（基本的には、新しいコードの方が改善されています）。それでも動かないときは、issueを投げてください。
2014/11/10現在（v0.0.1のタグを付けました）、できることは以下の通りです（外部ライブラリを叩いているものを含む）。
 音声波形からのメルケプストラムの抽出 DPマッチングによるパラレルデータの作成 GMMの学習 GMMベースのframe-by-frame特徴量変換 GMMベースのtrajectory特徴量変換 GMMベースのtrajectory特徴量変換（GV考慮版） 音声分析合成系WORLDを使った声質変換 MLSAフィルタを使った差分スペクトルに基づく声質変換  これらのうち、trajectory変換以外を紹介します。
チュートリアル：CMU_ARCTICを使ったGMMベースの声質変換（特徴抽出からパラレルデータの作成、GMMの学習、変換・合成処理まで） データセットにCMU_ARCTICを使って、GMMベースの声質変換（clb -&amp;gt; slt）を行う方法を説明します。なお、VoiceConversion.jl のv0.0.1を使います。ubuntuで主に動作確認をしていますが、macでも動くと思います。
0. 前準備 0.1. データセットのダウンロード Festvox: CMU_ARCTIC Databases を使います。コマンド一発ですべてダウンロードするスクリプトを書いたので、ご自由にどうぞ。</description>
    </item>
    
    <item>
      <title>統計的声質変換クッソムズすぎワロタ（実装の話）</title>
      <link>http://r9y9.github.io/blog/2014/07/13/statistical-voice-conversion-wakaran/</link>
      <pubDate>Sun, 13 Jul 2014 00:00:00 +0000</pubDate>
      
      <guid>http://r9y9.github.io/blog/2014/07/13/statistical-voice-conversion-wakaran/</guid>
      <description>2014/07/28 追記：
重み行列の構築の部分を改良したのでちょいアップデート。具体的にはdense matrixとして構築してからスパース行列に変換していたのを、はじめからスパース行列として構築するようにして無駄にメモリを使わないようにしました。あとdiffが見やすいようにgistにあげました https://gist.github.com/r9y9/88bda659c97f46f42525
まえがき 前回、統計的声質変換クッソムズすぎワロタ - LESS IS MORE という記事を書いたら研究者の方々等ちょいちょい反応してくださって嬉しかったです。差分スペクトル補正、その道の人が聴いても音質がいいそう。これはいい情報です。
Twitter引用: 統計的声質変換クッソムズすぎワロタ - LESS IS MORE http://t.co/8RkeXIf6Ym @r9y9さんから ムズすぎと言いながら，最後の音はしっかり出ているあたり凄いなぁ．
&amp;mdash; M. Morise (忍者系研究者) (@m_morise) July 5, 2014 
@ballforest 従来のパラメータ変換と比較すると、音質は従来よりもよさそうな気はしますがスペクトル包絡の性差ががっつりと影響しそうな気もするんですよね。
&amp;mdash; 縄文人（妖精系研究者なのです） (@dicekicker) July 5, 2014 
異性間に関しては、実験が必要ですね。異性間だとF0が結構変わってくると思いますが、差分スペクトル補正の場合そもそもF0をいじらないという前提なので、F0とスペクトル包絡が完全に独立でない（ですよね？）以上、同姓間に比べて音質は劣化する気はします。簡単にやったところ、少なくとも僕の主観的には劣化しました
ところで、結構いい感じにできたぜひゃっはーと思って、先輩に聞かせてみたら違いわかんねと言われて心が折れそうになりました。やはり現実はつらいです。
実装の話 さて、今回は少し実装のことを書こうと思います。学習&amp;amp;変換部分はPythonで書いています。その他はGo（※Goの話は書きません）。
トラジェクトリベースのパラメータ変換が遅いのは僕の実装が悪いからでした本当に申し訳ありませんでしたorz 前回トラジェクトリベースは処理が激重だと書きました。なんと、4秒程度の音声（フレームシフト5msで777フレーム）に対して変換部分に600秒ほどかかっていたのですが（重すぎワロタ）、結果から言えばPythonでも12秒くらいまでに高速化されました（混合数64, メルケプの次元数40+デルタ=80次元、分散共分散はfull）。本当にごめんなさい。
何ヶ月か前、ノリでトラジェクトリベースの変換を実装しようと思ってサクッと書いたのがそのままで、つまりとても効率の悪い実装になっていました。具体的には放置していた問題が二つあって、
 ナイーブな逆行列の計算 スパース性の無視  です。特に後者はかなりパフォーマンスに影響していました
ナイーブな逆行列の計算 numpy.linalg.invとnumpy.linalg.solveを用いた逆行列計算 - 睡眠不足？！ (id:sleepy_yoshi)
numpy.linalg.invを使っていましたよね。しかもnumpy.linalg.solveのほうが速いことを知っていながら。一ヶ月前の自分を問い詰めたい。numpy.linalg.solveで置き換えたら少し速くなりました。
 600秒 -&amp;gt; 570秒 （うろ覚え）  1.05倍の高速化（微妙）
スパース性の無視  T. Toda, A.</description>
    </item>
    
    <item>
      <title>統計的声質変換クッソムズすぎワロタ</title>
      <link>http://r9y9.github.io/blog/2014/07/05/statistical-voice-conversion-muzui/</link>
      <pubDate>Sat, 05 Jul 2014 00:00:00 +0000</pubDate>
      
      <guid>http://r9y9.github.io/blog/2014/07/05/statistical-voice-conversion-muzui/</guid>
      <description>2014/10/12 追記 少なくともGVのコードに致命的なバグがあったことがわかりました。よって、あまりあてにしないでください…（ごめんなさい
こんにちは。
最近、統計的声質変換の勉強をしていました。で、メジャーなGMM（混合ガウスモデル）ベースの変換を色々やってみたので、ちょろっと書きます。実は（というほどでもない?）シンプルなGMMベースの方法だと音質クッソ悪くなってしまうんですが、色々試してやっとまともに聞ける音質になったので、試行錯誤の形跡を残しておくとともに、音声サンプルを貼っておきます。ガチ勢の方はゆるりと見守ってください
基本的に、以下の論文を参考にしています
 T. Toda, A. W. Black, and K. Tokuda, “Voice conversion based on maximum likelihood estimation of spectral parameter trajectory,” IEEE Trans. Audio, Speech, Lang. Process, vol. 15, no. 8, pp. 2222–2235, Nov. 2007.  GMMベースの声質変換の基本 シンプルなGMMベースの声質変換は大きく二つのフェーズに分けられます。
 参照話者と目標話者のスペクトル特徴量の結合GMM $P(x,y)$を学習する 入力$x$が与えらたとき、$P(y|x)$が最大となるようにスペクトル特徴量を変換する  あらかじめ話者間の関係をデータから学習しておくことで、未知の入力が来た時にも変換が可能になるわけです。
具体的な変換プロセスとしては、音声を
 基本周波数 非周期性成分 スペクトル包絡  の3つに分解し、スペクトル包絡の部分（≒声質を表す特徴量）に対して変換を行い、最後に波形を再合成するといった方法がよく用いられます。基本周波数や非周期性成分も変換することがありますが、ここではとりあえず扱いません
シンプルな方法では、フレームごとに独立に変換を行います。
GMMベースのポイントは、東大の齋藤先生の以下のツイートを引用しておきます。
@shurabaP GMMベースの声質変換の肝は、入力xが与えられた時の出力yの条件付き確率P(y|x) が最大になるようにyを選ぶという確率的な考えです。私のショボい自作スクリプトですが、HTKを使ったGMMの学習レシピは研究室内部用に作ってあるので、もし必要なら公開しますよ。
&amp;mdash; Daisuke Saito (@dsk_saito) March 17, 2011</description>
    </item>
    
  </channel>
</rss>