<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Neural-Network RBM Machine-Learning on LESS IS MORE</title>
    <link>http://r9y9.github.io/categories/neural-network-rbm-machine-learning/</link>
    <description>Recent content in Neural-Network RBM Machine-Learning on LESS IS MORE</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja-jp</language>
    <lastBuildDate>Thu, 06 Mar 2014 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="http://r9y9.github.io/categories/neural-network-rbm-machine-learning/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Restricted Boltzmann Machines with MNIST</title>
      <link>http://r9y9.github.io/blog/2014/03/06/restricted-boltzmann-machines-mnist/</link>
      <pubDate>Thu, 06 Mar 2014 00:00:00 +0000</pubDate>
      
      <guid>http://r9y9.github.io/blog/2014/03/06/restricted-boltzmann-machines-mnist/</guid>
      <description>ディープ某を使った研究を再現してみたくて、最近某ニューラルネットに手を出し始めた。で、手始めにRestricted Boltzmann Machinesを実装してみたので、
 MNISTを使って学習した結果の重み（22*22=484個）を貼っとく（↑） 得た知見をまとめとく Goのコード貼っとく  ってな感じで書いておく
(本当はRBMについて自分なりの解釈を書こうと思ったのだけど、それはまた今度)
実験条件 データベースはmnist。手書き数字認識で有名なアレ。学習の条件は、
 隠れ層のユニット数: 500 mini-batch size: 20 iterationの回数: 15  対数尤度の変化  以下グラフに表示している生データ
0 -196.59046099622128 1 -70.31708616742365 2 -65.29499371647965 3 -62.37983267378022 4 -61.5359019358253 5 -60.917772257650164 6 -59.64207778426757 7 -59.42201674307857 8 -59.18497336138633 9 -58.277168243126305 10 -58.36279288392401 11 -58.57805165724595 12 -57.71043215987184 13 -58.17783142034138 14 -57.53629129936344 尤度上がると安心する。厳密に対数尤度を計算することは難しいので、Restricted Boltzmann Machines (RBM) | DeepLearning Tutorial にある擬似尤度を参考にした
学習時間 うちのcore2duoのPCで4時間弱だった気がする（うろ覚え
隠れ層のユニット数100だと、40分ほどだった
知見 今の所、試行錯誤して自分が得た知見は、
 sample by sampleのSGDよりmini-batch SGDの方が安定して尤度上がる mini-batch sizeを大きくしすぎると学習が進まない。20くらいがちょうど良かった k-CD のkを大きくしてもさほど学習結果変わらない（計算コストはけっこう増すけど） persistent CDを使ってもあまりよくならない（計算コストはけっこう増すけど） やっぱ1-CDで十分だった データの正規化方法によって結構結果も変わる。ノイズを足すかどうか、とか 学習率超重要すぎわろた。今回の場合は0.</description>
    </item>
    
  </channel>
</rss>