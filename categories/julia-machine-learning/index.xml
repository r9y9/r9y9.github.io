<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Julia Machine-Learning on LESS IS MORE</title>
    <link>http://r9y9.github.io/categories/julia-machine-learning/</link>
    <description>Recent content in Julia Machine-Learning on LESS IS MORE</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja-jp</language>
    <lastBuildDate>Wed, 20 Aug 2014 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="http://r9y9.github.io/categories/julia-machine-learning/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Gamma Process Non-negative Matrix Factorization (GaP-NMF) in Julia</title>
      <link>http://r9y9.github.io/blog/2014/08/20/gap-nmf-julia/</link>
      <pubDate>Wed, 20 Aug 2014 00:00:00 +0000</pubDate>
      
      <guid>http://r9y9.github.io/blog/2014/08/20/gap-nmf-julia/</guid>
      <description>最近 Julia で遊んでいて、その過程で非負値行列因子分解（NMF）のノンパラ版の一つであるGamma Process Non-negative Matrix Factorization (GaP-NMF) を書いてみました。（まぁmatlabコードの写経なんですが）
https://github.com/r9y9/BNMF.jl
元論文: Bayesian Nonparametric Matrix Factorization for Recorded Music by Matthew D. Hoffman et al. in ICML 2010.
デモ http://nbviewer.ipython.org/github/r9y9/BNMF.jl/blob/master/notebook/GaP-NMF.ipynb
適当な音声（音楽じゃなくてごめんなさい）に対して、GaP-NMFをfittingしてみた結果のメモです。$K=100$ で始めて、100回ほどイテレーションを回すと適度な数（12くらい）にtruncateしているのがわかると思います。予めモデルの複雑度を指定しなくても、データから適当な数を自動決定してくれる、ノンパラベイズの良いところですね。
ハマったところ  GIGの期待値を求めるのに必要な第二種変形ベッセル関数は、exponentially scaled versionを使いましょう。じゃないとInf地獄を見ることになると思います（つらい）。Juliaで言うなら besselkx で、scipyで言うなら scipy.special.kve です。  雑感  MatlabのコードをJuliaに書き直すのは簡単。ところどころ作法が違うけど（例えば配列の要素へのアクセスはmatlabはA(i,j)でJuliaはA[i,j]）、だいたい一緒 というかJuliaがMatlabに似すぎ？ Gamma分布に従う乱数は、Distributions,jl を使えばめっちゃ簡単に生成できた。素晴らしすぎる 行列演算がシンプルにかけてホント楽。pythonでもmatlabでもそうだけど（Goだとこれができないんですよ…） 第二種変形ベッセル関数とか、scipy.special にあるような特殊関数が標準である。素晴らしい。  Python版と速度比較 bp_nmf/code/gap_nmf と比較します。matlabはもってないので比較対象からはずします、ごめんなさい
Gistにベンチマークに使ったスクリプトと実行結果のメモを置いときました https://gist.github.com/r9y9/3d0c6a90dd155801c4c1
結果だけ書いておくと、あらゆる現実を（ry の音声にGaP-NMFをepochs=100でfittingするのにかかった時間は、
Julia: Mean elapsed time: 21.92968243 [sec] Python: Mean elapsed time: 18.3550617 [sec]  という結果になりました。つまりJuliaのほうが1.</description>
    </item>
    
  </channel>
</rss>