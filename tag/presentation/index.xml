<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Presentation | LESS IS MORE</title>
    <link>https://r9y9.github.io/tag/presentation/</link>
      <atom:link href="https://r9y9.github.io/tag/presentation/index.xml" rel="self" type="application/rss+xml" />
    <description>Presentation</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>Copyright © Ryuichi YAMAMOTO All rights reserved.</copyright><lastBuildDate>Tue, 25 Jan 2022 10:30:00 +0900</lastBuildDate>
    <image>
      <url>https://r9y9.github.io/media/icon_hu71488a41e9448d472219f1cc71ecc0ad_259818_512x512_fill_lanczos_center_3.png</url>
      <title>Presentation</title>
      <link>https://r9y9.github.io/tag/presentation/</link>
    </image>
    
    <item>
      <title>企業における音声合成の研究開発 / Research and development for TTS in industry @名古屋工業大学</title>
      <link>https://r9y9.github.io/talk/202201nit-lecture/</link>
      <pubDate>Tue, 25 Jan 2022 10:30:00 +0900</pubDate>
      <guid>https://r9y9.github.io/talk/202201nit-lecture/</guid>
      <description>&lt;p&gt;恩師である酒向先生 (&lt;a href=&#34;http://sakoweb.net/joomla3/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://sakoweb.net/joomla3/&lt;/a&gt;) にお声がけいただき、母校の名古屋工業大学で講義をさせていただきました。&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>国際会議Interspeech2021参加報告 / Report on Participation in Interspeech2021 @SLP研究会</title>
      <link>https://r9y9.github.io/talk/sp-interspeech2021report/</link>
      <pubDate>Fri, 03 Dec 2021 13:00:00 +0900</pubDate>
      <guid>https://r9y9.github.io/talk/sp-interspeech2021report/</guid>
      <description>&lt;h3 id=&#34;abstract-ja&#34;&gt;Abstract (ja)&lt;/h3&gt;
&lt;p&gt;2021 年 8 月 30 日から 9 月 3 日にかけてチェコ・ブルノおよびオンラインのハイブリッド形式で Interspeech2021 が開催された．ここでは，会議概要や最新の技術動向，注目の発表について報告する．&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>ここまで来た音声技術・今後の展望 / Current progress on speech technologies and its future prospects @ LINE DEV DAY 2020</title>
      <link>https://r9y9.github.io/talk/linedevday2020panel/</link>
      <pubDate>Wed, 25 Nov 2020 16:40:00 +0900</pubDate>
      <guid>https://r9y9.github.io/talk/linedevday2020panel/</guid>
      <description>&lt;h3 id=&#34;abstract-ja&#34;&gt;Abstract (ja)&lt;/h3&gt;
&lt;p&gt;人の音声をテキストに変換する音声認識技術、テキストから人の音声を生成する音声合成技術をはじめとした音声処理技術が目覚ましい速度で進歩を続けている。さらに、音声に限らないドアの開け閉めの音など一般の音を識別する音響シーン・イベント検出技術などの新しい技術分野が拓けつつある。本セッションでは、LINEから2名のエンジニア（木田祐介・山本龍一）がパネリストとして登壇し、音声認識・音声合成の現状を語る。さらに、同志社大学の井本桂右准教授に登壇いただき、今年国際会議(DCASE)を日本に誘致するなど、日本の研究者の活躍が目覚ましい音響シーン・イベント検出技術の分野の現状を語っていただく。これらの技術分野の進歩には深層学習の進歩が強い影響を与えているが、音声処理特有の要素がどのようにして深層学習と絡み合い技術進化につながっているか掘り下げていきたい。また、様々な音声処理分野で、分野間で共通要素として進展が進む技術要素と特有の要素の分析を通し、各技術分野の特性を明らかにしていきたい。そして、今後どのような方向性で技術が進化していくか、将来の展望について議論していきたい。&lt;/p&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/iSPBCot6n7g&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

</description>
    </item>
    
    <item>
      <title>Parallel WaveGAN: GPUを利用した高速かつ高品質な音声合成 / Parallel WaveGAN: Fast and High-Quality GPU Text-to-Speech @ LINE DEV DAY 2020</title>
      <link>https://r9y9.github.io/talk/linedevday2020pwg/</link>
      <pubDate>Wed, 25 Nov 2020 14:20:00 +0900</pubDate>
      <guid>https://r9y9.github.io/talk/linedevday2020pwg/</guid>
      <description>&lt;h3 id=&#34;abstract-ja&#34;&gt;Abstract (ja)&lt;/h3&gt;
&lt;p&gt;コンピュータによってテキストから人間の声を合成する技術は、テキスト音声合成と呼ばれます。LINE CLOVAのスマートスピーカーを初めとするユーザとのリアルタイムのインタラクションが必要なサービスでは、音声合成システムには合成品質が高いことだけでなく、高速に音声を生成できることが求められます。本セッションでは、高速かつ高品質な音声合成を実現するために、NAVERとLINEで共同で開発したGPUベースの音声合成の研究成果について発表します。従来の方法では、品質が良くても合成速度が遅い、合成速度は速い一方でモデルの学習に多大な時間がかかるなどの問題がありました。我々はそのような問題に対してどのようにアプローチしたのか、音声信号処理のトップカンファレンスICASSP 2020に採択された論文の内容を元に、近年の関連分野の発展を交えて紹介します。&lt;/p&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/BZxqf-Wkhig&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;/br&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/knzT7M6qsl0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

</description>
    </item>
    
    <item>
      <title>End-to-End 音声合成の研究を加速させるツールキット ESPnet-TTS / ESPnet-TTS: A toolkit to accelerate research on end-to-end speech synthesis @ ASJ 2020s</title>
      <link>https://r9y9.github.io/talk/asj-espnet2-tutorial/</link>
      <pubDate>Mon, 16 Mar 2020 13:00:00 +0900</pubDate>
      <guid>https://r9y9.github.io/talk/asj-espnet2-tutorial/</guid>
      <description></description>
    </item>
    
    <item>
      <title>JuliaTokyo #3 Speech Signal Processing in Julia</title>
      <link>https://r9y9.github.io/blog/2015/04/26/juliatokyo3-speech-signal-processing-in-julia/</link>
      <pubDate>Sun, 26 Apr 2015 00:00:00 +0000</pubDate>
      <guid>https://r9y9.github.io/blog/2015/04/26/juliatokyo3-speech-signal-processing-in-julia/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://juliatokyo.connpass.com/event/13218/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;JuliaTokyo #3&lt;/a&gt;でLT発表してきました。前回の&lt;a href=&#34;https://juliatokyo.connpass.com/event/8010/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;JuliaTokyo #2&lt;/a&gt;でも発表したので、二回目でした。&lt;/p&gt;
&lt;h2 id=&#34;スライド&#34;&gt;スライド&lt;/h2&gt;
&lt;div align=&#34;center&#34;&gt;
&lt;iframe src=&#34;//www.slideshare.net/slideshow/embed_code/key/h4geMoK1msYqdY&#34; width=&#34;595&#34; height=&#34;485&#34; frameborder=&#34;0&#34; marginwidth=&#34;0&#34; marginheight=&#34;0&#34; scrolling=&#34;no&#34; style=&#34;border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;&#34; allowfullscreen&gt; &lt;/iframe&gt; &lt;div style=&#34;margin-bottom:5px&#34;&gt; &lt;strong&gt; &lt;a href=&#34;//www.slideshare.net/ryuichiy/juliatokyo-3-speech-signal-processing-in-julia-47403938&#34; title=&#34;JuliaTokyo #3 Speech Signal Processing in Julia&#34; target=&#34;_blank&#34;&gt;JuliaTokyo #3 Speech Signal Processing in Julia&lt;/a&gt; &lt;/strong&gt; from &lt;strong&gt;&lt;a href=&#34;//www.slideshare.net/ryuichiy&#34; target=&#34;_blank&#34;&gt;Ryuichi YAMAMOTO&lt;/a&gt;&lt;/strong&gt; &lt;/div&gt;
&lt;/div&gt;
&lt;h2 id=&#34;コード&#34;&gt;コード&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/r9y9/JuliaTokyo3&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/r9y9/JuliaTokyo3&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;三行まとめ&#34;&gt;三行まとめ&lt;/h2&gt;
&lt;p&gt;発表の内容を三行でまとめると、&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;音声ファイルの読み込み（or 書き込み）は[WAV.jl]((&lt;a href=&#34;https://github.com/dancasimiro/WAV.jl&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/dancasimiro/WAV.jl&lt;/a&gt;)を使おう&lt;/li&gt;
&lt;li&gt;基本的なデジタル信号処理は &lt;a href=&#34;https://github.com/JuliaDSP/DSP.jl&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;JuliaDSP/DSP.jl&lt;/a&gt; をチェック（※JuliaDSPにはウェーブレットとかもあるよ）&lt;/li&gt;
&lt;li&gt;音声に特化した信号処理は、&lt;a href=&#34;https://github.com/r9y9/WORLD.jl&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;r9y9/WORLD.jl&lt;/a&gt; がオススメです&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;という感じです。&lt;/p&gt;
&lt;p&gt;応用例として、歌声を分離する話（&lt;a href=&#34;https://github.com/r9y9/RobustPCA.jl&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;デモコード&lt;/a&gt;）、統計的声質変換（&lt;a href=&#34;http://r9y9.github.io/blog/2014/11/12/statistical-voice-conversion-code/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;統計的声質変換クッソムズすぎワロタ（チュートリアル編） - LESS IS MORE&lt;/a&gt;）、画像をスペクトログラムに足しこむ話とか、さっと紹介しました。&lt;/p&gt;
&lt;h2 id=&#34;補足&#34;&gt;補足&lt;/h2&gt;
&lt;p&gt;僕が使う/作ったパッケージを、あとで見返せるように最後のスライドにまとめておいたのですが、改めてここで整理しておきます。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/dancasimiro/WAV.jl&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;dancasimiro/WAV&lt;/a&gt; WAVファイルの読み込み&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/JuliaDSP/DSP.jl&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;JuliaDSP/DSP&lt;/a&gt; 窓関数、スペクトログラム、デジタルフィルタ&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/r9y9/WORLD.jl&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;r9y9/WORLD&lt;/a&gt; 音声分析・合成フレームワーク&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/r9y9/MelGeneralizedCepstrums.jl&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;r9y9/MelGeneralizedCepstrums&lt;/a&gt; メル一般化ケプストラム分析&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/r9y9/SynthesisFilters.jl&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;r9y9/SynthesisFilters&lt;/a&gt; メル一般化ケプストラムからの波形合成&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/r9y9/SPTK.jl&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;r9y9/SPTK&lt;/a&gt; 音声信号処理ツールキット&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/r9y9/RobustPCA.jl&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;r9y9/RobustPCA&lt;/a&gt; ロバスト主成分分析(歌声分離へ応用)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/r9y9/REAPER.jl&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;r9y9/REAPER&lt;/a&gt; 基本周波数推定&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/r9y9/VoiceConversion.jl&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;r9y9/VoiceConversion&lt;/a&gt; 統計的声質変換&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;上から順に、&lt;del&gt;汎用的かなーと思います&lt;/del&gt;&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;。僕が書いたパッケージの中では、&lt;strong&gt;WORLDのみ&lt;/strong&gt;公式パッケージにしています。理由は単純で、その他のパッケージはあまりユーザがいないだろうなーと思ったからです。かなりマニアックであったり、今後の方針が決まってなかったり（ごめんなさい）、応用的過ぎて全然汎用的でなかったり。WORLDは自信を持ってオススメできますので、Juliaで音声信号処理をやってみようかなと思った方は、ぜひお試しください。&lt;/p&gt;
&lt;h2 id=&#34;ざっくり感想&#34;&gt;ざっくり感想&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;＃Juliaわからん 本当に素晴らしいと思うので、僕も積極的に #Juliaわからん とつぶやいていこうと思います（詳しくは &lt;a href=&#34;https://twitter.com/chezou&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;@chezou&lt;/a&gt; さんの記事をどうぞ &lt;a href=&#34;http://chezou.hatenablog.com/entry/2015/04/26/222518&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;#JuliaTokyo で #juliaわからん という雑なレポジトリを立てた話をしたら julia.tokyo ができてた  - once upon a time,&lt;/a&gt;）。僕は、Julia に Theano が欲しいです。&lt;code&gt;T.grad&lt;/code&gt; 強力すぎる&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ccall&lt;/code&gt; かんたんとか言いましたが、ミスった書き方をしたときのエラーメッセージはあまり親切ではないので、つまずきやすいかも。僕は気合で何とかしています。&lt;/li&gt;
&lt;li&gt;Julia遅いんだけど？？？と言われたら、&lt;a href=&#34;https://twitter.com/bicycle1885&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;@bicycle1885&lt;/a&gt; さんの &lt;a href=&#34;http://www.slideshare.net/KentaSato/whats-wrong-47403774&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;What&amp;rsquo;s wrong with this Julia?&lt;/a&gt; を投げつけようと思います。&lt;/li&gt;
&lt;li&gt;かなり聴衆が限定的になってしまう話をしてしまったので、次発表するならJulia 言語自体の話をしようかなと思いました&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;最後に&#34;&gt;最後に&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://twitter.com/sorami&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;@sorami&lt;/a&gt;さんを筆頭とする運営の方々、本当にありがとうございました！楽しかったです。&lt;/p&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;とスライドに書いたけど、考えなおすと、僕が思う品質の高さ順、の方が正確です、失礼しました。MelGeneneralizedCepstrumsは一番気合入れて書いたけど、ユーザーがいるかといったらいないし、RobustPCAはさっと書いただけだけど、アルゴリズムとしては汎用的だし。またRobustPCAだけ毛色が違いますが、応用例で紹介したのでリストに入れておきました。&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
    </item>
    
    <item>
      <title>JuliaTokyo #2でBinDeps.jl についてLTしてきた</title>
      <link>https://r9y9.github.io/blog/2014/09/30/juliatokyo2/</link>
      <pubDate>Tue, 30 Sep 2014 00:00:00 +0000</pubDate>
      <guid>https://r9y9.github.io/blog/2014/09/30/juliatokyo2/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;juliatokyo.connpass.com/event/8010/&#34;&gt;JuliaTokyo #2 - connpass&lt;/a&gt;&lt;/p&gt;
&lt;script async class=&#34;speakerdeck-embed&#34; data-id=&#34;21106ae0285e01327810268beacd0cf3&#34; data-ratio=&#34;1.77777777777778&#34; src=&#34;//speakerdeck.com/assets/embed.js&#34;&gt;&lt;/script&gt;
&lt;h2 id=&#34;発表概要&#34;&gt;発表概要&lt;/h2&gt;
&lt;p&gt;C/C++ライブラリのラッパー（C++は現状のJuliaでは難しいけど）を作るときに、どうやってライブラリの依存関係を管理するか？という話です。結論としては、方法はいくつかありますが　BinDeps.jl というパッケージを使うのが楽で良いですよ、ということです。Githubのいろんなリポジトリをあさった僕の経験上、BinDeps.jl はバイナリの依存関係管理におけるデファクトスタンダードな気がしています。BinDeps.jl の使い方は、既存のパッケージのコードを読みまくって学ぶのがおすすめです。&lt;/p&gt;
&lt;p&gt;さて、途中で書くのに疲れてしまったのですが、&lt;a href=&#34;http://qiita.com/r9y9/items/73806e3ce7f3a372d0b3&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;自作のJuliaパッケージで、Cライブラリとの依存性を記述する - Qiita&lt;/a&gt; に以前似たような内容をまとめたので、併せてどうぞ。qiitaにも書きましたが、最適化関係のプロジェクトを集めた &lt;a href=&#34;http://www.juliaopt.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;JuliaOpt&lt;/a&gt; コミュニティでは、バイナリの依存関係管理にBinDeps.jlを使用することを推奨しています。&lt;/p&gt;
&lt;h2 id=&#34;雑感&#34;&gt;雑感&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;勉強会にはデータ分析界隈の人が多い印象。音声系の人はとても少なかった。&lt;/li&gt;
&lt;li&gt;R人気だった&lt;/li&gt;
&lt;li&gt;Go使ってる！って人と合わなかった（つらい）&lt;/li&gt;
&lt;li&gt;@show マクロ最高&lt;/li&gt;
&lt;li&gt;unicode最高&lt;/li&gt;
&lt;li&gt;懇親会では、なぜか途中から深層学習やベイズの話をしていた…&lt;/li&gt;
&lt;li&gt;いい忘れたけど僕もnightly build勢でした。毎日あたたかみのある手動pull &amp;amp; make をしています。&lt;/li&gt;
&lt;li&gt;Julia の話ができて楽しかったので、また参加したいなー&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;LTで &lt;a href=&#34;https://github.com/chezou/MeCab.jl&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;MeCab.jl&lt;/a&gt; について話をしてくれたchezouさんが、ちょうどBinDeps.jl に興味を持たれているようだったので、勉強会のあとに BinDeps.jl を使ってバイナリの管理を実装して、&lt;a href=&#34;https://github.com/chezou/MeCab.jl/pull/2&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;プルリク&lt;/a&gt;をしてみました。参考になればうれしいなーと思います。&lt;/p&gt;
&lt;p&gt;おしまい。&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
