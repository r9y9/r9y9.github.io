<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Deep Learning | LESS IS MORE</title>
    <link>https://r9y9.github.io/tag/deep-learning/</link>
      <atom:link href="https://r9y9.github.io/tag/deep-learning/index.xml" rel="self" type="application/rss+xml" />
    <description>Deep Learning</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>Copyright Â© Ryuichi YAMAMOTO All rights reserved.</copyright><lastBuildDate>Sun, 16 Oct 2022 14:50:26 +0900</lastBuildDate>
    <image>
      <url>https://r9y9.github.io/media/icon_hu71488a41e9448d472219f1cc71ecc0ad_259818_512x512_fill_lanczos_center_3.png</url>
      <title>Deep Learning</title>
      <link>https://r9y9.github.io/tag/deep-learning/</link>
    </image>
    
    <item>
      <title>NNSVS: Neural Network Based Singing Voice Synthesis Toolkit</title>
      <link>https://r9y9.github.io/projects/nnsvs/</link>
      <pubDate>Sun, 16 Oct 2022 14:50:26 +0900</pubDate>
      <guid>https://r9y9.github.io/projects/nnsvs/</guid>
      <description>&lt;p&gt;Submitted to &lt;a href=&#34;https://2023.ieeeicassp.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ICASSP 2023&lt;/a&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#authors&#34;&gt;Authors&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#abstract&#34;&gt;Abstract&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#systems&#34;&gt;Systems&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#samples&#34;&gt;Samples&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#svs&#34;&gt;SVS&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#as&#34;&gt;A/S&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;authors&#34;&gt;Authors&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Ryuichi Yamamoto (LINE Corp., Nagoya University)&lt;/li&gt;
&lt;li&gt;Reo Yoneyama (Nagoya University)&lt;/li&gt;
&lt;li&gt;Tomoki Toda (Nagoya University)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;This paper describes the design of NNSVS, open-source software for neural network-based singing voice synthesis research.
NNSVS is inspired by Sinsy, one of the open-source pioneers in singing voice synthesis research, and provides many new features such as multi-stream autoregressive models, autoregressive fundamental frequency models, and neural vocoders.
Furthermore, NNSVS provides extensive documentation and scripts to build complete singing voice synthesis systems.
Experimental results demonstrate that our best system significantly outperforms our reproduction of Sinsy and other baseline systems.
The toolkit is available on GitHub at &lt;a href=&#34;https://github.com/nnsvs/nnsvs&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/nnsvs/nnsvs&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;systems&#34;&gt;Systems&lt;/h2&gt;
&lt;p&gt;TBD&lt;/p&gt;
&lt;h2 id=&#34;samples&#34;&gt;Samples&lt;/h2&gt;
&lt;h3 id=&#34;svs&#34;&gt;SVS&lt;/h3&gt;
&lt;p&gt;Sample 1: 1st color&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Recording&lt;/th&gt;&lt;th&gt;NNSVS pre-trained&lt;/th&gt;&lt;th&gt;NNSVS-WORLD v1&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test01]-Recording.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test01]-NNSVS pre-trained.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test01]-NNSVS-WORLD v1.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;NNSVS-WORLD v2&lt;/th&gt;&lt;th&gt;NNSVS-WORLD v3&lt;/th&gt;&lt;th&gt;NNSVS-WORLD v4&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test01]-NNSVS-WORLD v2.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test01]-NNSVS-WORLD v3.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test01]-NNSVS-WORLD v4.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;NNSVS-Mel v1&lt;/th&gt;&lt;th&gt;NNSVS-Mel v2&lt;/th&gt;&lt;th&gt;NNSVS-Mel v3&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test01]-NNSVS-Mel v1.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test01]-NNSVS-Mel v2.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test01]-NNSVS-Mel v3.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Sinsy&lt;/th&gt;&lt;th&gt;Sinsy (pitch corr)&lt;/th&gt;&lt;th&gt;Sinsy (vibrato modeling)&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test01]-Sinsy.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test01]-Sinsy (pitch corr).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test01]-Sinsy (vibrato modeling).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Muskits RNN&lt;/th&gt;&lt;th&gt;DiffSinger&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test01]-Muskits RNN.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test01]-DiffSinger.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Sample 2: ARROW&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Recording&lt;/th&gt;&lt;th&gt;NNSVS pre-trained&lt;/th&gt;&lt;th&gt;NNSVS-WORLD v1&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test02]-Recording.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test02]-NNSVS pre-trained.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test02]-NNSVS-WORLD v1.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;NNSVS-WORLD v2&lt;/th&gt;&lt;th&gt;NNSVS-WORLD v3&lt;/th&gt;&lt;th&gt;NNSVS-WORLD v4&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test02]-NNSVS-WORLD v2.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test02]-NNSVS-WORLD v3.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test02]-NNSVS-WORLD v4.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;NNSVS-Mel v1&lt;/th&gt;&lt;th&gt;NNSVS-Mel v2&lt;/th&gt;&lt;th&gt;NNSVS-Mel v3&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test02]-NNSVS-Mel v1.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test02]-NNSVS-Mel v2.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test02]-NNSVS-Mel v3.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Sinsy&lt;/th&gt;&lt;th&gt;Sinsy (pitch corr)&lt;/th&gt;&lt;th&gt;Sinsy (vibrato modeling)&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test02]-Sinsy (vibrato modeling).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test02]-Sinsy (pitch corr).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test02]-Sinsy (vibrato modeling).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Muskits RNN&lt;/th&gt;&lt;th&gt;DiffSinger&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test02]-Muskits RNN.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test02]-DiffSinger.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Sample 3: BC&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Recording&lt;/th&gt;&lt;th&gt;NNSVS pre-trained&lt;/th&gt;&lt;th&gt;NNSVS-WORLD v1&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test03]-Recording.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test03]-NNSVS pre-trained.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test03]-NNSVS-WORLD v1.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;NNSVS-WORLD v2&lt;/th&gt;&lt;th&gt;NNSVS-WORLD v3&lt;/th&gt;&lt;th&gt;NNSVS-WORLD v4&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test03]-NNSVS-WORLD v2.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test03]-NNSVS-WORLD v3.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test03]-NNSVS-WORLD v4.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;NNSVS-Mel v1&lt;/th&gt;&lt;th&gt;NNSVS-Mel v2&lt;/th&gt;&lt;th&gt;NNSVS-Mel v3&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test03]-NNSVS-Mel v1.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test03]-NNSVS-Mel v2.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test03]-NNSVS-Mel v3.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Sinsy&lt;/th&gt;&lt;th&gt;Sinsy (pitch corr)&lt;/th&gt;&lt;th&gt;Sinsy (vibrato modeling)&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test03]-Sinsy.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test03]-Sinsy (pitch corr).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test03]-Sinsy (vibrato modeling).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Muskits RNN&lt;/th&gt;&lt;th&gt;DiffSinger&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test03]-Muskits RNN.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test03]-DiffSinger.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Sample 4: Close to you&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Recording&lt;/th&gt;&lt;th&gt;NNSVS pre-trained&lt;/th&gt;&lt;th&gt;NNSVS-WORLD v1&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test04]-Recording.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test04]-NNSVS pre-trained.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test04]-NNSVS-WORLD v1.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;NNSVS-WORLD v2&lt;/th&gt;&lt;th&gt;NNSVS-WORLD v3&lt;/th&gt;&lt;th&gt;NNSVS-WORLD v4&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test04]-NNSVS-WORLD v2.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test04]-NNSVS-WORLD v3.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test04]-NNSVS-WORLD v4.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;NNSVS-Mel v1&lt;/th&gt;&lt;th&gt;NNSVS-Mel v2&lt;/th&gt;&lt;th&gt;NNSVS-Mel v3&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test04]-NNSVS-Mel v1.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test04]-NNSVS-Mel v2.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test04]-NNSVS-Mel v3.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Sinsy&lt;/th&gt;&lt;th&gt;Sinsy (pitch corr)&lt;/th&gt;&lt;th&gt;Sinsy (vibrato modeling)&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test04]-Sinsy (vibrato modeling).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test04]-Sinsy (pitch corr).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test04]-Sinsy (vibrato modeling).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Muskits RNN&lt;/th&gt;&lt;th&gt;DiffSinger&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test04]-Muskits RNN.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test04]-DiffSinger.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Sample 5: ERROR&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Recording&lt;/th&gt;&lt;th&gt;NNSVS pre-trained&lt;/th&gt;&lt;th&gt;NNSVS-WORLD v1&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test05]-Recording.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test05]-NNSVS pre-trained.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test05]-NNSVS-WORLD v1.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;NNSVS-WORLD v2&lt;/th&gt;&lt;th&gt;NNSVS-WORLD v3&lt;/th&gt;&lt;th&gt;NNSVS-WORLD v4&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test05]-NNSVS-WORLD v2.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test05]-NNSVS-WORLD v3.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test05]-NNSVS-WORLD v4.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;NNSVS-Mel v1&lt;/th&gt;&lt;th&gt;NNSVS-Mel v2&lt;/th&gt;&lt;th&gt;NNSVS-Mel v3&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test05]-NNSVS-Mel v1.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test05]-NNSVS-Mel v2.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test05]-NNSVS-Mel v3.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Sinsy&lt;/th&gt;&lt;th&gt;Sinsy (pitch corr)&lt;/th&gt;&lt;th&gt;Sinsy (vibrato modeling)&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test05]-Sinsy (vibrato modeling).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test05]-Sinsy (pitch corr).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test05]-Sinsy (vibrato modeling).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Muskits RNN&lt;/th&gt;&lt;th&gt;DiffSinger&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test05]-Muskits RNN.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test05]-DiffSinger.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;h3 id=&#34;as&#34;&gt;A/S&lt;/h3&gt;
&lt;p&gt;Sample 1: 1st color&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Recording&lt;/th&gt;&lt;th&gt;hn-HiFi-GAN&lt;/th&gt;&lt;th&gt;hn-USFGAN-Mel&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/AnaSyn/[Test01]-Recording.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/AnaSyn/[Test01]-hn-HiFi-GAN.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/AnaSyn/[Test01]-hn-USFGAN-Mel.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;hn-USFGAN-WORLD&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/AnaSyn/[Test01]-hn-USFGAN-WORLD.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Sample 2: ARROW&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Recording&lt;/th&gt;&lt;th&gt;hn-HiFi-GAN&lt;/th&gt;&lt;th&gt;hn-USFGAN-Mel&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/AnaSyn/[Test02]-Recording.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/AnaSyn/[Test02]-hn-HiFi-GAN.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/AnaSyn/[Test02]-hn-USFGAN-Mel.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;hn-USFGAN-WORLD&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/AnaSyn/[Test02]-hn-USFGAN-WORLD.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Sample 3: BC&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Recording&lt;/th&gt;&lt;th&gt;hn-HiFi-GAN&lt;/th&gt;&lt;th&gt;hn-USFGAN-Mel&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/AnaSyn/[Test03]-Recording.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/AnaSyn/[Test03]-hn-HiFi-GAN.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/AnaSyn/[Test03]-hn-USFGAN-Mel.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;hn-USFGAN-WORLD&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/AnaSyn/[Test03]-hn-USFGAN-WORLD.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Sample 4: Close to you&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Recording&lt;/th&gt;&lt;th&gt;hn-HiFi-GAN&lt;/th&gt;&lt;th&gt;hn-USFGAN-Mel&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/AnaSyn/[Test04]-Recording.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/AnaSyn/[Test04]-hn-HiFi-GAN.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/AnaSyn/[Test04]-hn-USFGAN-Mel.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;hn-USFGAN-WORLD&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/AnaSyn/[Test04]-hn-USFGAN-WORLD.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Sample 5: ERROR&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Recording&lt;/th&gt;&lt;th&gt;hn-HiFi-GAN&lt;/th&gt;&lt;th&gt;hn-USFGAN-Mel&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/AnaSyn/[Test05]-Recording.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/AnaSyn/[Test05]-hn-HiFi-GAN.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/AnaSyn/[Test05]-hn-USFGAN-Mel.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;hn-USFGAN-WORLD&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/AnaSyn/[Test05]-hn-USFGAN-WORLD.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
</description>
    </item>
    
    <item>
      <title>Period VITS: Variational Inference With Explicit Pitch Modeling For End-to-End Emotional Speech Synthesis</title>
      <link>https://r9y9.github.io/projects/period-vits/</link>
      <pubDate>Sun, 16 Oct 2022 14:47:59 +0900</pubDate>
      <guid>https://r9y9.github.io/projects/period-vits/</guid>
      <description></description>
    </item>
    
    <item>
      <title>DRSpeech: Degradation-Robust Text-to-Speech Synthesis with Frame-Level and Utterance-Level Acoustic Representation Learning</title>
      <link>https://r9y9.github.io/projects/drspeech/</link>
      <pubDate>Mon, 04 Apr 2022 12:11:07 +0900</pubDate>
      <guid>https://r9y9.github.io/projects/drspeech/</guid>
      <description></description>
    </item>
    
    <item>
      <title>TTS-by-TTS 2: Data-selective Augmentation for Neural Speech Synthesis Using Ranking Support Vector Machine with Variational Autoencoder</title>
      <link>https://r9y9.github.io/projects/tts-by-tts2/</link>
      <pubDate>Mon, 04 Apr 2022 12:11:05 +0900</pubDate>
      <guid>https://r9y9.github.io/projects/tts-by-tts2/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Cross-Speaker Emotion Transfer for Low-Resource Text-to-Speech Using Non-Parallel Voice Conversion with Pitch-Shift Data Augmentation</title>
      <link>https://r9y9.github.io/projects/vc-tts-ps/</link>
      <pubDate>Mon, 04 Apr 2022 12:11:04 +0900</pubDate>
      <guid>https://r9y9.github.io/projects/vc-tts-ps/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A Unified Accent Estimation Method Based on Multi-Task Learning for Japanese Text-to-Speech</title>
      <link>https://r9y9.github.io/projects/mtl_accent/</link>
      <pubDate>Mon, 04 Apr 2022 12:11:03 +0900</pubDate>
      <guid>https://r9y9.github.io/projects/mtl_accent/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Language Model-Based Emotion Prediction Methods for Emotional Speech Synthesis Systems</title>
      <link>https://r9y9.github.io/projects/lmemotiontts/</link>
      <pubDate>Mon, 04 Apr 2022 12:11:01 +0900</pubDate>
      <guid>https://r9y9.github.io/projects/lmemotiontts/</guid>
      <description></description>
    </item>
    
    <item>
      <title>ESPnet2-TTS: Extending the Edge of TTS Research</title>
      <link>https://r9y9.github.io/projects/espnet2-tts/</link>
      <pubDate>Wed, 06 Oct 2021 20:42:37 +0900</pubDate>
      <guid>https://r9y9.github.io/projects/espnet2-tts/</guid>
      <description></description>
    </item>
    
    <item>
      <title>ttslearn: Library for Pythonã§å­¦ã¶é³å£°åæ (Text-to-speech with Python)</title>
      <link>https://r9y9.github.io/projects/ttslearn/</link>
      <pubDate>Wed, 11 Aug 2021 16:27:22 +0900</pubDate>
      <guid>https://r9y9.github.io/projects/ttslearn/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Voicing-Aware Parallel WaveGAN for High-Quality Speech Synthesis</title>
      <link>https://r9y9.github.io/projects/va-pwg/</link>
      <pubDate>Fri, 30 Jul 2021 12:11:03 +0900</pubDate>
      <guid>https://r9y9.github.io/projects/va-pwg/</guid>
      <description>&lt;p&gt;Submitted to &lt;a href=&#34;https://signalprocessingsociety.org/publications-resources/ieee-signal-processing-letters&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;IEEE signal processing letters&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#authors&#34;&gt;Authors&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#abstract&#34;&gt;Abstract&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#tts-samples&#34;&gt;TTS samples&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#m1-male&#34;&gt;M1 (male)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#m2-male&#34;&gt;M2 (male)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#f1-female&#34;&gt;F1 (female)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#f2-female&#34;&gt;F2 (female)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#acknowledgements&#34;&gt;Acknowledgements&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;authors&#34;&gt;Authors&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Ryuichi Yamamoto (LINE Corp.)&lt;/li&gt;
&lt;li&gt;Min-Jae Hwang (Search Solutions Inc.)&lt;/li&gt;
&lt;li&gt;Eunwoo Song (NAVER Corp.)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;This letter proposes a voicing-aware Parallel Wave- GAN (VA-PWG) vocoder for a neural text-to-speech (TTS) system. To generate a high-quality speech waveform, it is important to reflect the distinct characteristics of voiced and unvoiced speech signals well. However, it is difficult for the conventional PWG model to accurately represent this condition, since the single unified architectures of the generator and discriminator are insufficient to capture those characteristics. In the proposed method, both the generator and discriminator are divided into their subnetworks to individually model the voicing state-dependent characteristics of a speech signal. In particular, a VA-generator consisting of two sub-WaveNets generates the harmonic and noise components of a speech signal by inputting pitch-dependent sine wave and Gaussian noise sources, respectively. Likewise, a VA-discriminator consisting of two sub-discriminators learns the distinct characteristics of harmonic and noise components by feeding the voiced and unvoiced waveforms, respectively. Subjective evaluation results verified the effectiveness of the proposed VA-PWG vocoder by achieving a 4.25 mean opinion score from a speaker-independent training scenario that was 11% higher than that of a conventional PWG vocoder.&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/images/va-pwg.png&#34; width=&#34;80%&#34; /&gt;&lt;/div&gt;
&lt;h2 id=&#34;tts-samples&#34;&gt;TTS samples&lt;/h2&gt;
&lt;h3 id=&#34;m1-male&#34;&gt;M1 (male)&lt;/h3&gt;
&lt;p&gt;Sample 1: âé¹¿åå³¶çã§æå¤§éåº¦ä¸ãè¦³æ¸¬ãã¦ãã¾ããâ&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Recording&lt;/th&gt;&lt;th&gt;WaveNet&lt;/th&gt;&lt;th&gt;PWG&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/va-pwg/M1/TTS/[Test01]-Recording.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/va-pwg/M1/TTS/[Test01]-S1-WaveNet.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/va-pwg/M1/TTS/[Test01]-S2-PWG.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;VA-PWG-G&lt;/th&gt;&lt;th&gt;VA-PWG-D&lt;/th&gt;&lt;th&gt;VA-PWG-GD (proposed)&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/va-pwg/M1/TTS/[Test01]-S3-VA-PWG-G.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/va-pwg/M1/TTS/[Test01]-S4-VA-PWG-D.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/va-pwg/M1/TTS/[Test01]-S5-VA-PWG-GD (proposed).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Sample 2: âèå ç¬å¤ªéã®æç±å¤§é¸ã§ããâ&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Recording&lt;/th&gt;&lt;th&gt;WaveNet&lt;/th&gt;&lt;th&gt;PWG&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/va-pwg/M1/TTS/[Test02]-Recording.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/va-pwg/M1/TTS/[Test02]-S1-WaveNet.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/va-pwg/M1/TTS/[Test02]-S2-PWG.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;VA-PWG-G&lt;/th&gt;&lt;th&gt;VA-PWG-D&lt;/th&gt;&lt;th&gt;VA-PWG-GD (proposed)&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/va-pwg/M1/TTS/[Test02]-S3-VA-PWG-G.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/va-pwg/M1/TTS/[Test02]-S4-VA-PWG-D.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/va-pwg/M1/TTS/[Test02]-S5-VA-PWG-GD (proposed).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Sample 3: âããã§ãã¡ã®é¨ã¯ååã«æ¸ãããããâ&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Recording&lt;/th&gt;&lt;th&gt;WaveNet&lt;/th&gt;&lt;th&gt;PWG&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/va-pwg/M1/TTS/[Test03]-Recording.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/va-pwg/M1/TTS/[Test03]-S1-WaveNet.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/va-pwg/M1/TTS/[Test03]-S2-PWG.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;VA-PWG-G&lt;/th&gt;&lt;th&gt;VA-PWG-D&lt;/th&gt;&lt;th&gt;VA-PWG-GD (proposed)&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/va-pwg/M1/TTS/[Test03]-S3-VA-PWG-G.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/va-pwg/M1/TTS/[Test03]-S4-VA-PWG-D.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/va-pwg/M1/TTS/[Test03]-S5-VA-PWG-GD (proposed).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;h3 id=&#34;m2-male&#34;&gt;M2 (male)&lt;/h3&gt;
&lt;p&gt;Sample 1: âã¨ã¡ã®ãã¬ãªã³ãã£ã¼ã³ããã§ãã­ãâ&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Recording&lt;/th&gt;&lt;th&gt;WaveNet&lt;/th&gt;&lt;th&gt;PWG&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/va-pwg/M2/TTS/[Test01]-Recording.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/va-pwg/M2/TTS/[Test01]-S1-WaveNet.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/va-pwg/M2/TTS/[Test01]-S2-PWG.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;VA-PWG-G&lt;/th&gt;&lt;th&gt;VA-PWG-D&lt;/th&gt;&lt;th&gt;VA-PWG-GD (proposed)&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/va-pwg/M2/TTS/[Test01]-S3-VA-PWG-G.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/va-pwg/M2/TTS/[Test01]-S4-VA-PWG-D.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/va-pwg/M2/TTS/[Test01]-S5-VA-PWG-GD (proposed).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Sample 2: âå¾¡äºç´ã¯ãäºæ³ä¸æ¥ã§ãã­ãâ&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Recording&lt;/th&gt;&lt;th&gt;WaveNet&lt;/th&gt;&lt;th&gt;PWG&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/va-pwg/M2/TTS/[Test02]-Recording.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/va-pwg/M2/TTS/[Test02]-S1-WaveNet.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/va-pwg/M2/TTS/[Test02]-S2-PWG.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;VA-PWG-G&lt;/th&gt;&lt;th&gt;VA-PWG-D&lt;/th&gt;&lt;th&gt;VA-PWG-GD (proposed)&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/va-pwg/M2/TTS/[Test02]-S3-VA-PWG-G.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/va-pwg/M2/TTS/[Test02]-S4-VA-PWG-D.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/va-pwg/M2/TTS/[Test02]-S5-VA-PWG-GD (proposed).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Sample 3: âãããã¡ã®ãã­ã¼ãªã¼ããã§ãã­ãâ&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Recording&lt;/th&gt;&lt;th&gt;WaveNet&lt;/th&gt;&lt;th&gt;PWG&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/va-pwg/M2/TTS/[Test03]-Recording.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/va-pwg/M2/TTS/[Test03]-S1-WaveNet.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/va-pwg/M2/TTS/[Test03]-S2-PWG.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;VA-PWG-G&lt;/th&gt;&lt;th&gt;VA-PWG-D&lt;/th&gt;&lt;th&gt;VA-PWG-GD (proposed)&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/va-pwg/M2/TTS/[Test03]-S3-VA-PWG-G.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/va-pwg/M2/TTS/[Test03]-S4-VA-PWG-D.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/va-pwg/M2/TTS/[Test03]-S5-VA-PWG-GD (proposed).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;h3 id=&#34;f1-female&#34;&gt;F1 (female)&lt;/h3&gt;
&lt;p&gt;Sample 1: âãããããã«ãå©ãã¦ãããªãã¦ã¯ã¨ãå®¶ã«é£ãã¦å¸°ãã¾ããã¨ããâ&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Recording&lt;/th&gt;&lt;th&gt;WaveNet&lt;/th&gt;&lt;th&gt;PWG&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/va-pwg/F1/TTS/[Test01]-Recording.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/va-pwg/F1/TTS/[Test01]-S1-WaveNet.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/va-pwg/F1/TTS/[Test01]-S2-PWG.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;VA-PWG-G&lt;/th&gt;&lt;th&gt;VA-PWG-D&lt;/th&gt;&lt;th&gt;VA-PWG-GD (proposed)&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/va-pwg/F1/TTS/[Test01]-S3-VA-PWG-G.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/va-pwg/F1/TTS/[Test01]-S4-VA-PWG-D.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/va-pwg/F1/TTS/[Test01]-S5-VA-PWG-GD (proposed).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Sample 2: âå¤±ç¤¼ã®ãªããããç¬é¡ã§æ¨æ¶ãã¦ãâ&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Recording&lt;/th&gt;&lt;th&gt;WaveNet&lt;/th&gt;&lt;th&gt;PWG&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/va-pwg/F1/TTS/[Test02]-Recording.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/va-pwg/F1/TTS/[Test02]-S1-WaveNet.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/va-pwg/F1/TTS/[Test02]-S2-PWG.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;VA-PWG-G&lt;/th&gt;&lt;th&gt;VA-PWG-D&lt;/th&gt;&lt;th&gt;VA-PWG-GD (proposed)&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/va-pwg/F1/TTS/[Test02]-S3-VA-PWG-G.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/va-pwg/F1/TTS/[Test02]-S4-VA-PWG-D.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/va-pwg/F1/TTS/[Test02]-S5-VA-PWG-GD (proposed).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Sample 3: âç§ãã¦ããã®ã§ãã¡ãã£ã¨æå¤ãªæ°ããã¾ããã¼ãâ&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Recording&lt;/th&gt;&lt;th&gt;WaveNet&lt;/th&gt;&lt;th&gt;PWG&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/va-pwg/F1/TTS/[Test03]-Recording.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/va-pwg/F1/TTS/[Test03]-S1-WaveNet.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/va-pwg/F1/TTS/[Test03]-S2-PWG.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;VA-PWG-G&lt;/th&gt;&lt;th&gt;VA-PWG-D&lt;/th&gt;&lt;th&gt;VA-PWG-GD (proposed)&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/va-pwg/F1/TTS/[Test03]-S3-VA-PWG-G.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/va-pwg/F1/TTS/[Test03]-S4-VA-PWG-D.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/va-pwg/F1/TTS/[Test03]-S5-VA-PWG-GD (proposed).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;h3 id=&#34;f2-female&#34;&gt;F2 (female)&lt;/h3&gt;
&lt;p&gt;Sample 1: âããã¦ç®ã«çã¾ã£ãã®ã¯ããæ°ã«å¥ãã®å±éå±ã®åã«ããã´ãã®å±±ãâ&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Recording&lt;/th&gt;&lt;th&gt;WaveNet&lt;/th&gt;&lt;th&gt;PWG&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/va-pwg/F2/TTS/[Test01]-Recording.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/va-pwg/F2/TTS/[Test01]-S1-WaveNet.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/va-pwg/F2/TTS/[Test01]-S2-PWG.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;VA-PWG-G&lt;/th&gt;&lt;th&gt;VA-PWG-D&lt;/th&gt;&lt;th&gt;VA-PWG-GD (proposed)&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/va-pwg/F2/TTS/[Test01]-S3-VA-PWG-G.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/va-pwg/F2/TTS/[Test01]-S4-VA-PWG-D.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/va-pwg/F2/TTS/[Test01]-S5-VA-PWG-GD (proposed).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Sample 2: âä»ã²ã¨ã¤ãæéãè¶³ãããâ&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Recording&lt;/th&gt;&lt;th&gt;WaveNet&lt;/th&gt;&lt;th&gt;PWG&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/va-pwg/F2/TTS/[Test02]-Recording.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/va-pwg/F2/TTS/[Test02]-S1-WaveNet.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/va-pwg/F2/TTS/[Test02]-S2-PWG.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;VA-PWG-G&lt;/th&gt;&lt;th&gt;VA-PWG-D&lt;/th&gt;&lt;th&gt;VA-PWG-GD (proposed)&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/va-pwg/F2/TTS/[Test02]-S3-VA-PWG-G.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/va-pwg/F2/TTS/[Test02]-S4-VA-PWG-D.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/va-pwg/F2/TTS/[Test02]-S5-VA-PWG-GD (proposed).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Sample 3: âå®ã¯ãã®éã®åã«ãé«ãå±±ããã£ã¦ã­ãâ&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Recording&lt;/th&gt;&lt;th&gt;WaveNet&lt;/th&gt;&lt;th&gt;PWG&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/va-pwg/F2/TTS/[Test03]-Recording.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/va-pwg/F2/TTS/[Test03]-S1-WaveNet.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/va-pwg/F2/TTS/[Test03]-S2-PWG.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;VA-PWG-G&lt;/th&gt;&lt;th&gt;VA-PWG-D&lt;/th&gt;&lt;th&gt;VA-PWG-GD (proposed)&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/va-pwg/F2/TTS/[Test03]-S3-VA-PWG-G.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/va-pwg/F2/TTS/[Test03]-S4-VA-PWG-D.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/va-pwg/F2/TTS/[Test03]-S5-VA-PWG-GD (proposed).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;h2 id=&#34;acknowledgements&#34;&gt;Acknowledgements&lt;/h2&gt;
&lt;p&gt;Work performed with nVoice, Clova Voice, Naver Corp.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>High-fidelity Parallel WaveGAN with Multi-band Harmonic-plus-Noise Model</title>
      <link>https://r9y9.github.io/projects/mbhnpwg/</link>
      <pubDate>Fri, 02 Apr 2021 20:34:36 +0900</pubDate>
      <guid>https://r9y9.github.io/projects/mbhnpwg/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Phrase break prediction with bidirectional encoder representations in Japanese text-to-speech synthesis</title>
      <link>https://r9y9.github.io/projects/pbp_bert/</link>
      <pubDate>Fri, 02 Apr 2021 20:34:36 +0900</pubDate>
      <guid>https://r9y9.github.io/projects/pbp_bert/</guid>
      <description></description>
    </item>
    
    <item>
      <title>ããã¾ã§æ¥ãé³å£°æè¡ã»ä»å¾ã®å±æ / Current progress on speech technologies and its future prospects @ LINE DEV DAY 2020</title>
      <link>https://r9y9.github.io/talk/linedevday2020panel/</link>
      <pubDate>Wed, 25 Nov 2020 16:40:00 +0900</pubDate>
      <guid>https://r9y9.github.io/talk/linedevday2020panel/</guid>
      <description>&lt;h3 id=&#34;abstract-ja&#34;&gt;Abstract (ja)&lt;/h3&gt;
&lt;p&gt;äººã®é³å£°ããã­ã¹ãã«å¤æããé³å£°èªè­æè¡ããã­ã¹ãããäººã®é³å£°ãçæããé³å£°åææè¡ãã¯ããã¨ããé³å£°å¦çæè¡ãç®è¦ã¾ããéåº¦ã§é²æ­©ãç¶ãã¦ãããããã«ãé³å£°ã«éããªããã¢ã®éãéãã®é³ãªã©ä¸è¬ã®é³ãè­å¥ããé³é¿ã·ã¼ã³ã»ã¤ãã³ãæ¤åºæè¡ãªã©ã®æ°ããæè¡åéãæãã¤ã¤ãããæ¬ã»ãã·ã§ã³ã§ã¯ãLINEãã2åã®ã¨ã³ã¸ãã¢ï¼æ¨ç°ç¥ä»ã»å±±æ¬é¾ä¸ï¼ããããªã¹ãã¨ãã¦ç»å£ããé³å£°èªè­ã»é³å£°åæã®ç¾ç¶ãèªããããã«ãåå¿ç¤¾å¤§å­¦ã®äºæ¬æ¡å³åææã«ç»å£ããã ããä»å¹´å½éä¼è­°(DCASE)ãæ¥æ¬ã«èªè´ãããªã©ãæ¥æ¬ã®ç ç©¶èã®æ´»èºãç®è¦ã¾ããé³é¿ã·ã¼ã³ã»ã¤ãã³ãæ¤åºæè¡ã®åéã®ç¾ç¶ãèªã£ã¦ããã ãããããã®æè¡åéã®é²æ­©ã«ã¯æ·±å±¤å­¦ç¿ã®é²æ­©ãå¼·ãå½±é¿ãä¸ãã¦ããããé³å£°å¦çç¹æã®è¦ç´ ãã©ã®ããã«ãã¦æ·±å±¤å­¦ç¿ã¨çµ¡ã¿åãæè¡é²åã«ã¤ãªãã£ã¦ãããæãä¸ãã¦ãããããã¾ããæ§ããªé³å£°å¦çåéã§ãåééã§å±éè¦ç´ ã¨ãã¦é²å±ãé²ãæè¡è¦ç´ ã¨ç¹æã®è¦ç´ ã®åæãéããåæè¡åéã®ç¹æ§ãæããã«ãã¦ãããããããã¦ãä»å¾ã©ã®ãããªæ¹åæ§ã§æè¡ãé²åãã¦ããããå°æ¥ã®å±æã«ã¤ãã¦è­°è«ãã¦ããããã&lt;/p&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/iSPBCot6n7g&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

</description>
    </item>
    
    <item>
      <title>Parallel WaveGAN: GPUãå©ç¨ããé«éãã¤é«åè³ªãªé³å£°åæ / Parallel WaveGAN: Fast and High-Quality GPU Text-to-Speech @ LINE DEV DAY 2020</title>
      <link>https://r9y9.github.io/talk/linedevday2020pwg/</link>
      <pubDate>Wed, 25 Nov 2020 14:20:00 +0900</pubDate>
      <guid>https://r9y9.github.io/talk/linedevday2020pwg/</guid>
      <description>&lt;h3 id=&#34;abstract-ja&#34;&gt;Abstract (ja)&lt;/h3&gt;
&lt;p&gt;ã³ã³ãã¥ã¼ã¿ã«ãã£ã¦ãã­ã¹ãããäººéã®å£°ãåæããæè¡ã¯ããã­ã¹ãé³å£°åæã¨å¼ã°ãã¾ããLINE CLOVAã®ã¹ãã¼ãã¹ãã¼ã«ã¼ãåãã¨ããã¦ã¼ã¶ã¨ã®ãªã¢ã«ã¿ã¤ã ã®ã¤ã³ã¿ã©ã¯ã·ã§ã³ãå¿è¦ãªãµã¼ãã¹ã§ã¯ãé³å£°åæã·ã¹ãã ã«ã¯åæåè³ªãé«ããã¨ã ãã§ãªããé«éã«é³å£°ãçæã§ãããã¨ãæ±ãããã¾ããæ¬ã»ãã·ã§ã³ã§ã¯ãé«éãã¤é«åè³ªãªé³å£°åæãå®ç¾ããããã«ãNAVERã¨LINEã§å±åã§éçºããGPUãã¼ã¹ã®é³å£°åæã®ç ç©¶ææã«ã¤ãã¦çºè¡¨ãã¾ããå¾æ¥ã®æ¹æ³ã§ã¯ãåè³ªãè¯ãã¦ãåæéåº¦ãéããåæéåº¦ã¯éãä¸æ¹ã§ã¢ãã«ã®å­¦ç¿ã«å¤å¤§ãªæéãããããªã©ã®åé¡ãããã¾ãããæãã¯ãã®ãããªåé¡ã«å¯¾ãã¦ã©ã®ããã«ã¢ãã­ã¼ãããã®ããé³å£°ä¿¡å·å¦çã®ãããã«ã³ãã¡ã¬ã³ã¹ICASSP 2020ã«æ¡æãããè«æã®åå®¹ãåã«ãè¿å¹´ã®é¢é£åéã®çºå±ãäº¤ãã¦ç´¹ä»ãã¾ãã&lt;/p&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/BZxqf-Wkhig&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;/br&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/knzT7M6qsl0&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

</description>
    </item>
    
    <item>
      <title>Improved Parallel WaveGAN with perceptually weighted spectrogram loss</title>
      <link>https://r9y9.github.io/projects/pwg-pwsl/</link>
      <pubDate>Fri, 06 Nov 2020 16:43:44 +0900</pubDate>
      <guid>https://r9y9.github.io/projects/pwg-pwsl/</guid>
      <description></description>
    </item>
    
    <item>
      <title>TTS-by-TTS: TTS-driven Data Augmentation for Fast and High-Quality Speech Synthesis</title>
      <link>https://r9y9.github.io/projects/tts-by-tts/</link>
      <pubDate>Mon, 26 Oct 2020 16:37:12 +0900</pubDate>
      <guid>https://r9y9.github.io/projects/tts-by-tts/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Parallel waveform synthesis based on generative adversarial networks with voicing-aware conditional discriminators</title>
      <link>https://r9y9.github.io/projects/vuvd-pwg/</link>
      <pubDate>Wed, 21 Oct 2020 23:38:48 +0900</pubDate>
      <guid>https://r9y9.github.io/projects/vuvd-pwg/</guid>
      <description>&lt;p&gt;Preprint: &lt;a href=&#34;https://arxiv.org/abs/2010.14151&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;arXiv:2010.14151&lt;/a&gt; (accepted to &lt;a href=&#34;https://2021.ieeeicassp.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ICASSP 2021&lt;/a&gt;)&lt;/p&gt;
&lt;h2 id=&#34;table-of-contents&#34;&gt;Table of contents&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#analysis-synthesis&#34;&gt;Analysis/synthesis samples (Japanese)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#text-to-speech&#34;&gt;Text-to-speech samples (Japanese)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#bonus-analysis-synthesis-english&#34;&gt;Bonus: analysis/synthesis samples for CMU ARCTIC (English)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;authors&#34;&gt;Authors&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Ryuichi Yamamoto (LINE Corp.)&lt;/li&gt;
&lt;li&gt;Eunwoo Song (NAVER Corp.)&lt;/li&gt;
&lt;li&gt;Min-Jae Hwang (Search Solutions Inc.)&lt;/li&gt;
&lt;li&gt;Jae-Min Kim (NAVER Corp.)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;This paper proposes voicing-aware conditional discriminators for Parallel WaveGAN-based waveform synthesis systems. In this framework, we adopt a projection-based conditioning method that can significantly improve the discriminatorâs performance. Furthermore, the conventional discriminator is separated into two waveform discriminators for modeling voiced and unvoiced speech. As each discriminator learns the distinctive characteristics of the harmonic and noise components, respectively, the adversarial training process becomes more efficient, allowing the generator to produce more realistic speech waveforms. Subjective test results demonstrate the superiority of the proposed method over the conventional Parallel WaveGAN and WaveNet systems. In particular, our speaker-independently trained model within a FastSpeech 2 based text-to-speech framework achieves the mean opinion scores of 4.20, 4.18, 4.21, and 4.31 for four Japanese speakers, respectively.&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/images/icassp2021_fig.png&#34; width=&#34;50%&#34; /&gt;&lt;/div&gt;
&lt;h2 id=&#34;systems-for-comparision&#34;&gt;Systems for comparision&lt;/h2&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;System&lt;/th&gt;
&lt;th&gt;Voiced segments&lt;/th&gt;
&lt;th&gt;Unvoiced segments&lt;/th&gt;
&lt;th&gt;Discriminator conditioning&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;S1-WaveNet &lt;a href=&#34;https://arxiv.org/abs/1807.07281&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;[1]&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;S2-PWG &lt;a href=&#34;https://arxiv.org/abs/1910.11480&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;[2]&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;S3-PWG-cGAN-D&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;S4-PWG-V/UV-D&lt;/td&gt;
&lt;td&gt;$D^{\mathrm{{v}}}$&lt;/td&gt;
&lt;td&gt;$D^{\mathrm{{v}}}$&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;S5-PWG-V/UV-D&lt;/td&gt;
&lt;td&gt;$D^{\mathrm{{uv}}}$&lt;/td&gt;
&lt;td&gt;$D^{\mathrm{{v}}}$&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;S6-PWG-V/UV-D&lt;/td&gt;
&lt;td&gt;$D^{\mathrm{{uv}}}$&lt;/td&gt;
&lt;td&gt;$D^{\mathrm{{uv}}}$&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;S7-PWG-V/UV-D (proposed)&lt;/td&gt;
&lt;td&gt;$D^{\mathrm{{v}}}$&lt;/td&gt;
&lt;td&gt;$D^{\mathrm{{uv}}}$&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Recordings&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ul&gt;
&lt;li&gt;$D^{\mathrm{{v}}}$: 1-D dilated CNN discrimiantor with the reseptive field size of 127.&lt;/li&gt;
&lt;li&gt;$D^{\mathrm{{uv}}}$: 1-D CNN discrimiantor with the reseptive field size of 13.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;PWG denotes Parallel WaveGAN for short. Systems S2-PWG and S3-PWG-cGAN-D used $D^{\mathrm{{v}}}$  as the primary discriminator. &lt;strong&gt;Note that all the Parallel WaveGAN systems used the same generator architecture and training configurations; they only differed in the discriminator settings.&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;analysissynthesis&#34;&gt;Analysis/synthesis&lt;/h2&gt;
&lt;h3 id=&#34;f1-female&#34;&gt;F1 (female)&lt;/h3&gt;
&lt;p&gt;Sample 1&lt;/p&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Recording&lt;/th&gt;&lt;th&gt;S1-WaveNet&lt;/th&gt;&lt;th&gt;S2-PWG&lt;/th&gt;&lt;th&gt;&lt;font color=&#34;#0000cd&#34;&gt;S7-PWG-V/UV-D (ours)&lt;/font&gt;&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/F1/AnaSyn/[Test01]-R1-Ground truth.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/F1/AnaSyn/[Test01]-S1-WaveNet.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/F1/AnaSyn/[Test01]-S2-PWG.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/F1/AnaSyn/[Test01]-S7-PWG-VUV-D (ours).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;S3-PWG-cGAN-D&lt;/th&gt;&lt;th&gt;S4-PWG-V/UV-D&lt;/th&gt;&lt;th&gt;S5-PWG-V/UV-D&lt;/th&gt;&lt;th&gt;S6-PWG-V/UV-D&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/F1/AnaSyn/[Test01]-S3-PWG-cGAN-D.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/F1/AnaSyn/[Test01]-S4-PWG-VUV-D.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/F1/AnaSyn/[Test01]-S5-PWG-VUV-D.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/F1/AnaSyn/[Test01]-S6-PWG-VUV-D.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;h3 id=&#34;f2-female&#34;&gt;F2 (female)&lt;/h3&gt;
&lt;p&gt;Sample 1&lt;/p&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Recording&lt;/th&gt;&lt;th&gt;S1-WaveNet&lt;/th&gt;&lt;th&gt;S2-PWG&lt;/th&gt;&lt;th&gt;&lt;font color=&#34;#0000cd&#34;&gt;S7-PWG-V/UV-D (ours)&lt;/font&gt;&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/F2/AnaSyn/[Test01]-R1-Ground truth.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/F2/AnaSyn/[Test01]-S1-WaveNet.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/F2/AnaSyn/[Test01]-S2-PWG.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/F2/AnaSyn/[Test01]-S7-PWG-VUV-D (ours).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;S3-PWG-cGAN-D&lt;/th&gt;&lt;th&gt;S4-PWG-V/UV-D&lt;/th&gt;&lt;th&gt;S5-PWG-V/UV-D&lt;/th&gt;&lt;th&gt;S6-PWG-V/UV-D&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/F2/AnaSyn/[Test01]-S3-PWG-cGAN-D.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/F2/AnaSyn/[Test01]-S4-PWG-VUV-D.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/F2/AnaSyn/[Test01]-S5-PWG-VUV-D.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/F2/AnaSyn/[Test01]-S6-PWG-VUV-D.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;h3 id=&#34;m1-male&#34;&gt;M1 (male)&lt;/h3&gt;
&lt;p&gt;Sample 1&lt;/p&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Recording&lt;/th&gt;&lt;th&gt;S1-WaveNet&lt;/th&gt;&lt;th&gt;S2-PWG&lt;/th&gt;&lt;th&gt;&lt;font color=&#34;#0000cd&#34;&gt;S7-PWG-V/UV-D (ours)&lt;/font&gt;&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/M1/AnaSyn/[Test01]-R1-Ground truth.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/M1/AnaSyn/[Test01]-S1-WaveNet.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/M1/AnaSyn/[Test01]-S2-PWG.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/M1/AnaSyn/[Test01]-S7-PWG-VUV-D (ours).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;S3-PWG-cGAN-D&lt;/th&gt;&lt;th&gt;S4-PWG-V/UV-D&lt;/th&gt;&lt;th&gt;S5-PWG-V/UV-D&lt;/th&gt;&lt;th&gt;S6-PWG-V/UV-D&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/M1/AnaSyn/[Test01]-S3-PWG-cGAN-D.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/M1/AnaSyn/[Test01]-S4-PWG-VUV-D.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/M1/AnaSyn/[Test01]-S5-PWG-VUV-D.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/M1/AnaSyn/[Test01]-S6-PWG-VUV-D.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;h3 id=&#34;m2-male&#34;&gt;M2 (male)&lt;/h3&gt;
&lt;p&gt;Sample 1&lt;/p&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Recording&lt;/th&gt;&lt;th&gt;S1-WaveNet&lt;/th&gt;&lt;th&gt;S2-PWG&lt;/th&gt;&lt;th&gt;&lt;font color=&#34;#0000cd&#34;&gt;S7-PWG-V/UV-D (ours)&lt;/font&gt;&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/M2/AnaSyn/[Test01]-R1-Ground truth.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/M2/AnaSyn/[Test01]-S1-WaveNet.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/M2/AnaSyn/[Test01]-S2-PWG.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/M2/AnaSyn/[Test01]-S7-PWG-VUV-D (ours).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;S3-PWG-cGAN-D&lt;/th&gt;&lt;th&gt;S4-PWG-V/UV-D&lt;/th&gt;&lt;th&gt;S5-PWG-V/UV-D&lt;/th&gt;&lt;th&gt;S6-PWG-V/UV-D&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/M2/AnaSyn/[Test01]-S3-PWG-cGAN-D.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/M2/AnaSyn/[Test01]-S4-PWG-VUV-D.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/M2/AnaSyn/[Test01]-S5-PWG-VUV-D.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/M2/AnaSyn/[Test01]-S6-PWG-VUV-D.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;h2 id=&#34;text-to-speech&#34;&gt;Text-to-speech&lt;/h2&gt;
&lt;p&gt;FastSpeech 2 (&lt;a href=&#34;https://arxiv.org/abs/2006.04558&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;[3]&lt;/a&gt;) based acoustic models were used for text-to-speech experiments.&lt;/p&gt;
&lt;h3 id=&#34;f1-female-1&#34;&gt;F1 (female)&lt;/h3&gt;
&lt;p&gt;Sample 1&lt;/p&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Recording&lt;/th&gt;&lt;th&gt;FastSpeech 2 + WaveNet&lt;/th&gt;&lt;th&gt;FastSpeech 2 + PWG&lt;/th&gt;&lt;th&gt;&lt;font color=&#34;#0000cd&#34;&gt;FastSpeech 2 + PWG-V/UV-D (ours)&lt;/font&gt;&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/F1/TTS/[Test01]-R1-Ground truth.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/F1/TTS/[Test01]-S1-WaveNet.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/F1/TTS/[Test01]-S2-PWG.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/F1/TTS/[Test01]-S7-PWG-VUV-D (ours).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;FastSpeech 2 + PWG-cGAN-D&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/F1/TTS/[Test01]-S3-PWG-cGAN-D.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Sample 2&lt;/p&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Recording&lt;/th&gt;&lt;th&gt;FastSpeech 2 + WaveNet&lt;/th&gt;&lt;th&gt;FastSpeech 2 + PWG&lt;/th&gt;&lt;th&gt;&lt;font color=&#34;#0000cd&#34;&gt;FastSpeech 2 + PWG-V/UV-D (ours)&lt;/font&gt;&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/F1/TTS/[Test02]-R1-Ground truth.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/F1/TTS/[Test02]-S1-WaveNet.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/F1/TTS/[Test02]-S2-PWG.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/F1/TTS/[Test02]-S7-PWG-VUV-D (ours).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;FastSpeech 2 + PWG-cGAN-D&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/F1/TTS/[Test02]-S3-PWG-cGAN-D.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Sample 3&lt;/p&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Recording&lt;/th&gt;&lt;th&gt;FastSpeech 2 + WaveNet&lt;/th&gt;&lt;th&gt;FastSpeech 2 + PWG&lt;/th&gt;&lt;th&gt;&lt;font color=&#34;#0000cd&#34;&gt;FastSpeech 2 + PWG-V/UV-D (ours)&lt;/font&gt;&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/F1/TTS/[Test03]-R1-Ground truth.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/F1/TTS/[Test03]-S1-WaveNet.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/F1/TTS/[Test03]-S2-PWG.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/F1/TTS/[Test03]-S7-PWG-VUV-D (ours).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;FastSpeech 2 + PWG-cGAN-D&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/F1/TTS/[Test03]-S3-PWG-cGAN-D.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;h3 id=&#34;f2-female-1&#34;&gt;F2 (female)&lt;/h3&gt;
&lt;p&gt;Sample 1&lt;/p&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Recording&lt;/th&gt;&lt;th&gt;FastSpeech 2 + WaveNet&lt;/th&gt;&lt;th&gt;FastSpeech 2 + PWG&lt;/th&gt;&lt;th&gt;&lt;font color=&#34;#0000cd&#34;&gt;FastSpeech 2 + PWG-V/UV-D (ours)&lt;/font&gt;&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/F2/TTS/[Test01]-R1-Ground truth.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/F2/TTS/[Test01]-S1-WaveNet.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/F2/TTS/[Test01]-S2-PWG.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/F2/TTS/[Test01]-S7-PWG-VUV-D (ours).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;FastSpeech 2 + PWG-cGAN-D&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/F2/TTS/[Test01]-S3-PWG-cGAN-D.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Sample 2&lt;/p&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Recording&lt;/th&gt;&lt;th&gt;FastSpeech 2 + WaveNet&lt;/th&gt;&lt;th&gt;FastSpeech 2 + PWG&lt;/th&gt;&lt;th&gt;&lt;font color=&#34;#0000cd&#34;&gt;FastSpeech 2 + PWG-V/UV-D (ours)&lt;/font&gt;&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/F2/TTS/[Test02]-R1-Ground truth.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/F2/TTS/[Test02]-S1-WaveNet.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/F2/TTS/[Test02]-S2-PWG.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/F2/TTS/[Test02]-S7-PWG-VUV-D (ours).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;FastSpeech 2 + PWG-cGAN-D&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/F2/TTS/[Test02]-S3-PWG-cGAN-D.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Sample 3&lt;/p&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Recording&lt;/th&gt;&lt;th&gt;FastSpeech 2 + WaveNet&lt;/th&gt;&lt;th&gt;FastSpeech 2 + PWG&lt;/th&gt;&lt;th&gt;&lt;font color=&#34;#0000cd&#34;&gt;FastSpeech 2 + PWG-V/UV-D (ours)&lt;/font&gt;&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/F2/TTS/[Test03]-R1-Ground truth.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/F2/TTS/[Test03]-S1-WaveNet.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/F2/TTS/[Test03]-S2-PWG.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/F2/TTS/[Test03]-S7-PWG-VUV-D (ours).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;FastSpeech 2 + PWG-cGAN-D&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/F2/TTS/[Test03]-S3-PWG-cGAN-D.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;h3 id=&#34;m1-male-1&#34;&gt;M1 (male)&lt;/h3&gt;
&lt;p&gt;Sample 1&lt;/p&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Recording&lt;/th&gt;&lt;th&gt;FastSpeech 2 + WaveNet&lt;/th&gt;&lt;th&gt;FastSpeech 2 + PWG&lt;/th&gt;&lt;th&gt;&lt;font color=&#34;#0000cd&#34;&gt;FastSpeech 2 + PWG-V/UV-D (ours)&lt;/font&gt;&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/M1/TTS/[Test01]-R1-Ground truth.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/M1/TTS/[Test01]-S1-WaveNet.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/M1/TTS/[Test01]-S2-PWG.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/M1/TTS/[Test01]-S7-PWG-VUV-D (ours).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;FastSpeech 2 + PWG-cGAN-D&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/M1/TTS/[Test01]-S3-PWG-cGAN-D.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Sample 2&lt;/p&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Recording&lt;/th&gt;&lt;th&gt;FastSpeech 2 + WaveNet&lt;/th&gt;&lt;th&gt;FastSpeech 2 + PWG&lt;/th&gt;&lt;th&gt;&lt;font color=&#34;#0000cd&#34;&gt;FastSpeech 2 + PWG-V/UV-D (ours)&lt;/font&gt;&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/M1/TTS/[Test02]-R1-Ground truth.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/M1/TTS/[Test02]-S1-WaveNet.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/M1/TTS/[Test02]-S2-PWG.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/M1/TTS/[Test02]-S7-PWG-VUV-D (ours).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;FastSpeech 2 + PWG-cGAN-D&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/M1/TTS/[Test02]-S3-PWG-cGAN-D.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Sample 3&lt;/p&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Recording&lt;/th&gt;&lt;th&gt;FastSpeech 2 + WaveNet&lt;/th&gt;&lt;th&gt;FastSpeech 2 + PWG&lt;/th&gt;&lt;th&gt;&lt;font color=&#34;#0000cd&#34;&gt;FastSpeech 2 + PWG-V/UV-D (ours)&lt;/font&gt;&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/M1/TTS/[Test03]-R1-Ground truth.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/M1/TTS/[Test03]-S1-WaveNet.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/M1/TTS/[Test03]-S2-PWG.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/M1/TTS/[Test03]-S7-PWG-VUV-D (ours).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;FastSpeech 2 + PWG-cGAN-D&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/M1/TTS/[Test03]-S3-PWG-cGAN-D.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;h3 id=&#34;m2-male-1&#34;&gt;M2 (male)&lt;/h3&gt;
&lt;p&gt;Sample 1&lt;/p&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Recording&lt;/th&gt;&lt;th&gt;FastSpeech 2 + WaveNet&lt;/th&gt;&lt;th&gt;FastSpeech 2 + PWG&lt;/th&gt;&lt;th&gt;&lt;font color=&#34;#0000cd&#34;&gt;FastSpeech 2 + PWG-V/UV-D (ours)&lt;/font&gt;&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/M2/TTS/[Test01]-R1-Ground truth.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/M2/TTS/[Test01]-S1-WaveNet.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/M2/TTS/[Test01]-S2-PWG.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/M2/TTS/[Test01]-S7-PWG-VUV-D (ours).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;FastSpeech 2 + PWG-cGAN-D&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/M2/TTS/[Test01]-S3-PWG-cGAN-D.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Sample 2&lt;/p&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Recording&lt;/th&gt;&lt;th&gt;FastSpeech 2 + WaveNet&lt;/th&gt;&lt;th&gt;FastSpeech 2 + PWG&lt;/th&gt;&lt;th&gt;&lt;font color=&#34;#0000cd&#34;&gt;FastSpeech 2 + PWG-V/UV-D (ours)&lt;/font&gt;&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/M2/TTS/[Test02]-R1-Ground truth.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/M2/TTS/[Test02]-S1-WaveNet.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/M2/TTS/[Test02]-S2-PWG.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/M2/TTS/[Test02]-S7-PWG-VUV-D (ours).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;FastSpeech 2 + PWG-cGAN-D&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/M2/TTS/[Test02]-S3-PWG-cGAN-D.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Sample 3&lt;/p&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Recording&lt;/th&gt;&lt;th&gt;FastSpeech 2 + WaveNet&lt;/th&gt;&lt;th&gt;FastSpeech 2 + PWG&lt;/th&gt;&lt;th&gt;&lt;font color=&#34;#0000cd&#34;&gt;FastSpeech 2 + PWG-V/UV-D (ours)&lt;/font&gt;&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/M2/TTS/[Test03]-R1-Ground truth.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/M2/TTS/[Test03]-S1-WaveNet.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/M2/TTS/[Test03]-S2-PWG.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/M2/TTS/[Test03]-S7-PWG-VUV-D (ours).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;FastSpeech 2 + PWG-cGAN-D&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/M2/TTS/[Test03]-S3-PWG-cGAN-D.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;h2 id=&#34;bonus-analysissynthesis-english&#34;&gt;Bonus: Analysis/synthesis (English)&lt;/h2&gt;
&lt;p&gt;Samples for &lt;a href=&#34;http://www.festvox.org/cmu_arctic/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CMU ARCTIC database&lt;/a&gt; are provided as follows. The models were trained using total six speakers (clb, slt, bdl, rms, jmk, and ksp) in a speaker-independent way.
The models were similary configured as the above experiments.&lt;/p&gt;
&lt;h3 id=&#34;clb-female&#34;&gt;clb (female)&lt;/h3&gt;
&lt;p&gt;Sample 1&lt;/p&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Recording&lt;/th&gt;&lt;th&gt;PWG&lt;/th&gt;&lt;th&gt;PWG-cGAN-D&lt;/th&gt;&lt;th&gt;&lt;font color=&#34;#0000cd&#34;&gt;PWG-V/UV-D (ours)&lt;/font&gt;&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/bonus/clb/AnaSyn/[Test01]-clb_arctic_b0490_ref-Recording.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/bonus/clb/AnaSyn/[Test01]-clb_arctic_b0490_gen-PWG-VUV-D (ours).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/bonus/clb/AnaSyn/[Test01]-clb_arctic_b0490_gen-PWG-cGAN-D.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/bonus/clb/AnaSyn/[Test01]-clb_arctic_b0490_gen-PWG-VUV-D (ours).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Sample 2&lt;/p&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Recording&lt;/th&gt;&lt;th&gt;PWG&lt;/th&gt;&lt;th&gt;PWG-cGAN-D&lt;/th&gt;&lt;th&gt;&lt;font color=&#34;#0000cd&#34;&gt;PWG-V/UV-D (ours)&lt;/font&gt;&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/bonus/clb/AnaSyn/[Test02]-clb_arctic_b0491_ref-Recording.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/bonus/clb/AnaSyn/[Test02]-clb_arctic_b0491_gen-PWG-VUV-D (ours).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/bonus/clb/AnaSyn/[Test02]-clb_arctic_b0491_gen-PWG-cGAN-D.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/bonus/clb/AnaSyn/[Test02]-clb_arctic_b0491_gen-PWG-VUV-D (ours).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Sample 3&lt;/p&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Recording&lt;/th&gt;&lt;th&gt;PWG&lt;/th&gt;&lt;th&gt;PWG-cGAN-D&lt;/th&gt;&lt;th&gt;&lt;font color=&#34;#0000cd&#34;&gt;PWG-V/UV-D (ours)&lt;/font&gt;&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/bonus/clb/AnaSyn/[Test03]-clb_arctic_b0492_ref-Recording.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/bonus/clb/AnaSyn/[Test03]-clb_arctic_b0492_gen-PWG.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/bonus/clb/AnaSyn/[Test03]-clb_arctic_b0492_gen-PWG-cGAN-D.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/bonus/clb/AnaSyn/[Test03]-clb_arctic_b0492_gen-PWG-VUV-D (ours).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;h3 id=&#34;slt-female&#34;&gt;slt (female)&lt;/h3&gt;
&lt;p&gt;Sample 1&lt;/p&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Recording&lt;/th&gt;&lt;th&gt;PWG&lt;/th&gt;&lt;th&gt;PWG-cGAN-D&lt;/th&gt;&lt;th&gt;&lt;font color=&#34;#0000cd&#34;&gt;PWG-V/UV-D (ours)&lt;/font&gt;&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/bonus/slt/AnaSyn/[Test01]-slt_arctic_b0490_ref-Recording.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/bonus/slt/AnaSyn/[Test01]-slt_arctic_b0490_gen-PWG.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/bonus/slt/AnaSyn/[Test01]-slt_arctic_b0490_gen-PWG-cGAN-D.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/bonus/slt/AnaSyn/[Test01]-slt_arctic_b0490_gen-PWG-VUV-D (ours).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Sample 2&lt;/p&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Recording&lt;/th&gt;&lt;th&gt;PWG&lt;/th&gt;&lt;th&gt;PWG-cGAN-D&lt;/th&gt;&lt;th&gt;&lt;font color=&#34;#0000cd&#34;&gt;PWG-V/UV-D (ours)&lt;/font&gt;&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/bonus/slt/AnaSyn/[Test02]-slt_arctic_b0491_ref-Recording.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/bonus/slt/AnaSyn/[Test02]-slt_arctic_b0491_gen-PWG.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/bonus/slt/AnaSyn/[Test02]-slt_arctic_b0491_gen-PWG-cGAN-D.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/bonus/slt/AnaSyn/[Test02]-slt_arctic_b0491_gen-PWG-VUV-D (ours).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Sample 3&lt;/p&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Recording&lt;/th&gt;&lt;th&gt;PWG&lt;/th&gt;&lt;th&gt;PWG-cGAN-D&lt;/th&gt;&lt;th&gt;&lt;font color=&#34;#0000cd&#34;&gt;PWG-V/UV-D (ours)&lt;/font&gt;&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/bonus/slt/AnaSyn/[Test03]-slt_arctic_b0492_ref-Recording.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/bonus/slt/AnaSyn/[Test03]-slt_arctic_b0492_gen-PWG.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/bonus/slt/AnaSyn/[Test03]-slt_arctic_b0492_gen-PWG-cGAN-D.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/bonus/slt/AnaSyn/[Test03]-slt_arctic_b0492_gen-PWG-VUV-D (ours).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;h3 id=&#34;bdl-male&#34;&gt;bdl (male)&lt;/h3&gt;
&lt;p&gt;Sample 1&lt;/p&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Recording&lt;/th&gt;&lt;th&gt;PWG&lt;/th&gt;&lt;th&gt;PWG-cGAN-D&lt;/th&gt;&lt;th&gt;&lt;font color=&#34;#0000cd&#34;&gt;PWG-V/UV-D (ours)&lt;/font&gt;&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/bonus/bdl/AnaSyn/[Test01]-bdl_arctic_b0490_ref-Recording.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/bonus/bdl/AnaSyn/[Test01]-bdl_arctic_b0490_gen-PWG-VUV-D (ours).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/bonus/bdl/AnaSyn/[Test01]-bdl_arctic_b0490_gen-PWG-cGAN-D.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/bonus/bdl/AnaSyn/[Test01]-bdl_arctic_b0490_gen-PWG-VUV-D (ours).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Sample 2&lt;/p&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Recording&lt;/th&gt;&lt;th&gt;PWG&lt;/th&gt;&lt;th&gt;PWG-cGAN-D&lt;/th&gt;&lt;th&gt;&lt;font color=&#34;#0000cd&#34;&gt;PWG-V/UV-D (ours)&lt;/font&gt;&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/bonus/bdl/AnaSyn/[Test02]-bdl_arctic_b0491_ref-Recording.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/bonus/bdl/AnaSyn/[Test02]-bdl_arctic_b0491_gen-PWG-VUV-D (ours).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/bonus/bdl/AnaSyn/[Test02]-bdl_arctic_b0491_gen-PWG-cGAN-D.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/bonus/bdl/AnaSyn/[Test02]-bdl_arctic_b0491_gen-PWG-VUV-D (ours).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Sample 3&lt;/p&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Recording&lt;/th&gt;&lt;th&gt;PWG&lt;/th&gt;&lt;th&gt;PWG-cGAN-D&lt;/th&gt;&lt;th&gt;&lt;font color=&#34;#0000cd&#34;&gt;PWG-V/UV-D (ours)&lt;/font&gt;&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/bonus/bdl/AnaSyn/[Test03]-bdl_arctic_b0492_ref-Recording.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/bonus/bdl/AnaSyn/[Test03]-bdl_arctic_b0492_gen-PWG.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/bonus/bdl/AnaSyn/[Test03]-bdl_arctic_b0492_gen-PWG-cGAN-D.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/bonus/bdl/AnaSyn/[Test03]-bdl_arctic_b0492_gen-PWG-VUV-D (ours).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;h3 id=&#34;rms-male&#34;&gt;rms (male)&lt;/h3&gt;
&lt;p&gt;Sample 1&lt;/p&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Recording&lt;/th&gt;&lt;th&gt;PWG&lt;/th&gt;&lt;th&gt;PWG-cGAN-D&lt;/th&gt;&lt;th&gt;&lt;font color=&#34;#0000cd&#34;&gt;PWG-V/UV-D (ours)&lt;/font&gt;&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/bonus/rms/AnaSyn/[Test01]-rms_arctic_b0490_ref-Recording.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/bonus/rms/AnaSyn/[Test01]-rms_arctic_b0490_gen-PWG.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/bonus/rms/AnaSyn/[Test01]-rms_arctic_b0490_gen-PWG-cGAN-D.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/bonus/rms/AnaSyn/[Test01]-rms_arctic_b0490_gen-PWG-VUV-D (ours).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Sample 2&lt;/p&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Recording&lt;/th&gt;&lt;th&gt;PWG&lt;/th&gt;&lt;th&gt;PWG-cGAN-D&lt;/th&gt;&lt;th&gt;&lt;font color=&#34;#0000cd&#34;&gt;PWG-V/UV-D (ours)&lt;/font&gt;&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/bonus/rms/AnaSyn/[Test02]-rms_arctic_b0491_ref-Recording.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/bonus/rms/AnaSyn/[Test02]-rms_arctic_b0491_gen-PWG.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/bonus/rms/AnaSyn/[Test02]-rms_arctic_b0491_gen-PWG-cGAN-D.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/bonus/rms/AnaSyn/[Test02]-rms_arctic_b0491_gen-PWG-VUV-D (ours).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Sample 3&lt;/p&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Recording&lt;/th&gt;&lt;th&gt;PWG&lt;/th&gt;&lt;th&gt;PWG-cGAN-D&lt;/th&gt;&lt;th&gt;&lt;font color=&#34;#0000cd&#34;&gt;PWG-V/UV-D (ours)&lt;/font&gt;&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/bonus/rms/AnaSyn/[Test03]-rms_arctic_b0492_ref-Recording.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/bonus/rms/AnaSyn/[Test03]-rms_arctic_b0492_gen-PWG.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/bonus/rms/AnaSyn/[Test03]-rms_arctic_b0492_gen-PWG-cGAN-D.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/bonus/rms/AnaSyn/[Test03]-rms_arctic_b0492_gen-PWG-VUV-D (ours).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;h3 id=&#34;jmk-male&#34;&gt;jmk (male)&lt;/h3&gt;
&lt;p&gt;Sample 1&lt;/p&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Recording&lt;/th&gt;&lt;th&gt;PWG&lt;/th&gt;&lt;th&gt;PWG-cGAN-D&lt;/th&gt;&lt;th&gt;&lt;font color=&#34;#0000cd&#34;&gt;PWG-V/UV-D (ours)&lt;/font&gt;&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/bonus/jmk/AnaSyn/[Test01]-jmk_arctic_b0490_ref-Recording.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/bonus/jmk/AnaSyn/[Test01]-jmk_arctic_b0490_gen-PWG-VUV-D (ours).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/bonus/jmk/AnaSyn/[Test01]-jmk_arctic_b0490_gen-PWG-cGAN-D.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/bonus/jmk/AnaSyn/[Test01]-jmk_arctic_b0490_gen-PWG-VUV-D (ours).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Sample 2&lt;/p&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Recording&lt;/th&gt;&lt;th&gt;PWG&lt;/th&gt;&lt;th&gt;PWG-cGAN-D&lt;/th&gt;&lt;th&gt;&lt;font color=&#34;#0000cd&#34;&gt;PWG-V/UV-D (ours)&lt;/font&gt;&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/bonus/jmk/AnaSyn/[Test02]-jmk_arctic_b0491_ref-Recording.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/bonus/jmk/AnaSyn/[Test02]-jmk_arctic_b0491_gen-PWG-VUV-D (ours).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/bonus/jmk/AnaSyn/[Test02]-jmk_arctic_b0491_gen-PWG-cGAN-D.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/bonus/jmk/AnaSyn/[Test02]-jmk_arctic_b0491_gen-PWG-VUV-D (ours).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Sample 3&lt;/p&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Recording&lt;/th&gt;&lt;th&gt;PWG&lt;/th&gt;&lt;th&gt;PWG-cGAN-D&lt;/th&gt;&lt;th&gt;&lt;font color=&#34;#0000cd&#34;&gt;PWG-V/UV-D (ours)&lt;/font&gt;&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/bonus/jmk/AnaSyn/[Test03]-jmk_arctic_b0492_ref-Recording.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/bonus/jmk/AnaSyn/[Test03]-jmk_arctic_b0492_gen-PWG-cGAN-D.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/bonus/jmk/AnaSyn/[Test03]-jmk_arctic_b0492_gen-PWG-cGAN-D.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/bonus/jmk/AnaSyn/[Test03]-jmk_arctic_b0492_gen-PWG-VUV-D (ours).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;h3 id=&#34;ksp-male&#34;&gt;ksp (male)&lt;/h3&gt;
&lt;p&gt;Sample 1&lt;/p&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Recording&lt;/th&gt;&lt;th&gt;PWG&lt;/th&gt;&lt;th&gt;PWG-cGAN-D&lt;/th&gt;&lt;th&gt;&lt;font color=&#34;#0000cd&#34;&gt;PWG-V/UV-D (ours)&lt;/font&gt;&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/bonus/ksp/AnaSyn/[Test01]-ksp_arctic_b0490_ref-Recording.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/bonus/ksp/AnaSyn/[Test01]-ksp_arctic_b0490_gen-PWG.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/bonus/ksp/AnaSyn/[Test01]-ksp_arctic_b0490_gen-PWG-cGAN-D.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/bonus/ksp/AnaSyn/[Test01]-ksp_arctic_b0490_gen-PWG-VUV-D (ours).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Sample 2&lt;/p&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Recording&lt;/th&gt;&lt;th&gt;PWG&lt;/th&gt;&lt;th&gt;PWG-cGAN-D&lt;/th&gt;&lt;th&gt;&lt;font color=&#34;#0000cd&#34;&gt;PWG-V/UV-D (ours)&lt;/font&gt;&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/bonus/ksp/AnaSyn/[Test02]-ksp_arctic_b0491_ref-Recording.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/bonus/ksp/AnaSyn/[Test02]-ksp_arctic_b0491_gen-PWG-VUV-D (ours).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/bonus/ksp/AnaSyn/[Test02]-ksp_arctic_b0491_gen-PWG-cGAN-D.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/bonus/ksp/AnaSyn/[Test02]-ksp_arctic_b0491_gen-PWG-VUV-D (ours).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Sample 3&lt;/p&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Recording&lt;/th&gt;&lt;th&gt;PWG&lt;/th&gt;&lt;th&gt;PWG-cGAN-D&lt;/th&gt;&lt;th&gt;&lt;font color=&#34;#0000cd&#34;&gt;PWG-V/UV-D (ours)&lt;/font&gt;&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/bonus/ksp/AnaSyn/[Test03]-ksp_arctic_b0492_ref-Recording.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/bonus/ksp/AnaSyn/[Test03]-ksp_arctic_b0492_gen-PWG.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/bonus/ksp/AnaSyn/[Test03]-ksp_arctic_b0492_gen-PWG-cGAN-D.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2021-pwg-vuvd/bonus/ksp/AnaSyn/[Test03]-ksp_arctic_b0492_gen-PWG-VUV-D (ours).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;[1] W. Ping, K. Peng, and J. Chen, âClariNet: Parallel wave generation in end-to-end text-to-speech,â in Proc. ICLR, 2019 &lt;a href=&#34;https://arxiv.org/abs/1807.07281&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;arXiv&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;[2] R Yamamoto, E Song, and J.-M Kim, âParallel WaveGAN:A fast waveform generation model based on generative adversarial networks with multi-resolution spectrogram,â  in Proc. ICASSP, 2020, pp. 6199â6203. &lt;a href=&#34;https://arxiv.org/abs/1910.11480&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;arXiv&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;[3] Y Ren, C Hu, T Qin, S Zhao, Z Zhao, and T.-Y Liu, âFast-speech 2: Fast and high-quality end-to-end text-to-speech,âarXiv preprint arXiv:2006.04558, 2020. &lt;a href=&#34;https://arxiv.org/abs/2006.04558&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;arXiv&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;acknowledgements&#34;&gt;Acknowledgements&lt;/h2&gt;
&lt;p&gt;Work performed with nVoice, Clova Voice, Naver Corp.&lt;/p&gt;
&lt;h2 id=&#34;citation&#34;&gt;Citation&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;@inproceedings{yamamoto2020parallel,
  title={Parallel waveform synthesis based on generative adversarial networks with voicing-aware conditional discriminators},
  author={Ryuichi Yamamoto and Eunwoo Song and Min-Jae Hwang and Jae-Min Kim},
  booktitle=&amp;quot;Proc. of ICASSP (in press)&amp;quot;,
  year={2021},
}
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>NNSVS: Pytorchãã¼ã¹ã®ç ç©¶ç¨æ­å£°åæã©ã¤ãã©ãª</title>
      <link>https://r9y9.github.io/blog/2020/05/10/nnsvs/</link>
      <pubDate>Sun, 10 May 2020 14:42:25 +0900</pubDate>
      <guid>https://r9y9.github.io/blog/2020/05/10/nnsvs/</guid>
      <description>&lt;h2 id=&#34;summary&#34;&gt;Summary&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;ã³ã¼ã: &lt;a href=&#34;https://github.com/r9y9/nnsvs&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/r9y9/nnsvs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Discussion: &lt;a href=&#34;https://github.com/r9y9/nnsvs/issues/1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/r9y9/nnsvs/issues/1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://colab.research.google.com/github/r9y9/Colaboratory/blob/master/Neural_network_based_singing_voice_synthesis_demo_using_kiritan_singing_database_%28Japanese%29.ipynb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Demo on Google colab&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;æ¥ãæ¥ããæ¥ãæ¥ããã©ãã«æ¥ãããå±±ã«æ¥ããéã«æ¥ããéã«ãæ¥ããè±ããããè±ããããã©ãã«ãããå±±ã«ãããéã«ãããéã«ãããã&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;audio controls=&#34;controls&#34; &gt;&lt;source src=&#34;https://r9y9.github.io/audio/nnsvs/20200510_haru.wav&#34; autoplay/&gt;Your browser does not support the audio element.&lt;/audio&gt;&lt;/p&gt;
&lt;h2 id=&#34;nnsvs-ã¯ãªã«&#34;&gt;NNSVS ã¯ãªã«ï¼&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Neural network-based singing voice synthesis library for research&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;ç ç©¶ç¨éãç®çã¨ãããæ­å£°åæã¨ã³ã¸ã³ãä½ãããã®ãªã¼ãã³ã½ã¼ã¹ã®ã©ã¤ãã©ãªãä½ããã¨ãç®æãããã­ã¸ã§ã¯ãã§ãããã®ãã­ã¸ã§ã¯ãã«ã¤ãã¦ãèãã¦ãããã¨ãã¾ã¨ãã¦ãããã¨æãã¾ãã&lt;/p&gt;
&lt;h3 id=&#34;ãªãããã&#34;&gt;ãªããããï¼&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://n3utrino.work/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;NEUTRINO&lt;/a&gt; ã¬ãã«ã®åè³ªã®æ­å£°åæã¨ã³ã¸ã³ãä½ããã®ããã£ã¦ã¿ããã£ã&lt;/li&gt;
&lt;li&gt;ãªã¼ãã³ã½ã¼ã¹ã®ãã¼ã«ãã»ã¼ãªãåéãªã®ã§ããã¼ã«ãä½ãã¨èª°ãã®å½¹ã«ãç«ã£ã¦ããããªã¨æã£ããç ç©¶åéãçãä¸ããã¨è¯ãã§ãã­&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ã¨ããã®ãçç±ã§ããåèã®å²åãå¤§ãããå¾èã¯å»ºåã®è¦ç´ ãå¼·ãã§ããè¦ã¯ãã§ãããã©ãããã©ããã¦ãæ°ã«ãªã£ã¦ãæ°ãã¥ãããç±ä¸­ãã¦ãããã¨ããæãã§ãã&lt;/p&gt;
&lt;h3 id=&#34;ç ç©¶ç¨é&#34;&gt;ç ç©¶ç¨é&lt;/h3&gt;
&lt;p&gt;æ©æ¢°å­¦ç¿ãä¿¡å·å¦çã«ããç¨åº¦æããäººãæ³å®ãã¦ãã¾ããæ­å£°åææè¡ãä½¿ã£ã¦åµä½ãããäººã§ã¯ãªããã©ã®ããã«ããã°ããè¯ãæ­å£°åæãä½ããã¨ãã§ããã®ãï¼ã¨ãã£ãèå³ãæã¤äººãä¸»ãªå¯¾è±¡ã§ãã&lt;/p&gt;
&lt;p&gt;åµä½æ´»åã®ããã«æ­å£°åæã®æè¡ãä½¿ãå ´åã«ã¯ããã§ã«åªãããã¼ã«ãããã¨æãã¾ãã®ã§ããã¡ããä½¿ã£ã¦ããã ãã®ãããã¨æãã¾ã&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;ã&lt;a href=&#34;https://n3utrino.work/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;NEUTRINO&lt;/a&gt;ã&lt;a href=&#34;https://synthesizerv.com/jp/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Synthesizer V&lt;/a&gt;ã&lt;a href=&#34;http://cevio.jp/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CeVIO&lt;/a&gt; ãªã©&lt;/p&gt;
&lt;h3 id=&#34;ãªã¼ãã³ã½ã¼ã¹&#34;&gt;ãªã¼ãã³ã½ã¼ã¹&lt;/h3&gt;
&lt;p&gt;ãªã¼ãã³ã½ã¼ã¹ã§ãããã¨ãéè¦ãã¾ããæ­å£°åæã½ããã¦ã§ã¢ã¯å¤ãããã¾ããããªã¼ãã³ã½ã¼ã¹ã®ãã®ã¯å¤ãããã¾ãã&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;ããã®ãã­ã¸ã§ã¯ãã¯åãè¶£å³ã¨ãã¦å§ãããã®ã§ããã¸ãã¹ã«ããæ°ã¯ã¾ã£ãããªãã®ã§&lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;ãèª°ã§ãèªç±ã«ä½¿ããããã«ãããã¨æã£ã¦ãã¾ãããªã¼ãã³ãªã½ããã¦ã§ã¢ããç ç©¶åéã®ä¸å©ã«ãªããã¨ãæå¾ãã¦ãã¾ãã&lt;/p&gt;
&lt;h3 id=&#34;pytorchãã¼ã¹&#34;&gt;Pytorchãã¼ã¹&lt;/h3&gt;
&lt;p&gt;éå»ã« &lt;a href=&#34;https://github.com/r9y9/nnmnkwii&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;nnmnkwii&lt;/a&gt;ã¨ããé³å£°åæã®ããã®ã©ã¤ãã©ãªãä½ãã¾ããããã®éã«ã¯ãä»»æã®æ°å¤å¾®åã©ã¤ãã©ãªã¨ä½¿ããããã«ã¨èãã¦è¨­è¨ãã¾ããããnnsvsã¯ããã¦pytorchã«ä¾å­ããå½¢ã§ä½ãã¾ãã&lt;/p&gt;
&lt;p&gt;Pytorchã¨åãé¢ãã¦è¨­è¨ããã¨æ±ç¨çã«ããããä¸æ¹ã§ã&lt;a href=&#34;https://github.com/kaldi-asr/kaldi&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Kaldi&lt;/a&gt; ã&lt;a href=&#34;https://github.com/espnet/espnet&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ESPnet&lt;/a&gt; ã®ãããªãã­ã¸ã§ã¯ãã§æåãã¦ãã&lt;strong&gt;ã¬ã·ã&lt;/strong&gt;ã¨ãããã®ãä½ããããã§ããESPnetã«å¤å°é¢ãã£ã¦ãåç¾æ§ã®æä¿ã®éè¦æ§ãèº«ã«ãã¿ã¦æãã¤ã¤ããã®ã§ãPytorchãã¼ã¹ã®å­¦ç¿ãæ¨è«ãªã©ãæ­å£°åæã®ã¢ãã«ãæ§ç¯ããããã«å¿è¦ãªãã¹ã¦ãã²ã£ããããã½ããã¦ã§ã¢ãç®æãããã¨æãã¾ãã&lt;/p&gt;
&lt;h3 id=&#34;ã¬ã·ãã®æä¾&#34;&gt;ã¬ã·ãã®æä¾&lt;/h3&gt;
&lt;p&gt;åç¾æ§ãéè¦ãã¾ãããã®ããã«ãKaldiãESPnetã®æåã«ç¿ã£ã¦ãã¬ã·ãã¨ããå®é¨ãåç¾ããã®ã«å¿è¦ãªãã¹ã¦ã®ã¹ããããå«ã¾ããã¹ã¯ãªãããæä¾ãã¾ããã¬ã·ãã¯ããã¼ã¿ã®åå¦çãç¹å¾´éæ½åºãã¢ãã«å­¦ç¿ãæ¨è«ãæ³¢å½¢ã®åæãªã©ãå«ã¿ã¾ãã&lt;/p&gt;
&lt;p&gt;ä¾ãã°ããã®ãã­ã°ã®ãããã«è²¼ã£ãé³å£°ãµã³ãã«ãåæããã®ã«ä½¿ãããã¢ãã«ã¯ãå¬éããã¦ããã¬ã·ãã§åç¾ãããã¨ãå¯è½ã§ããæ­å£°åæã¨ã³ã¸ã³ãä½ãããã®ããã¨ãããããã®ãéæãªå½¢ã§æä¾ãã¾ãã&lt;/p&gt;
&lt;h2 id=&#34;ãã­ã¸ã§ã¯ãã®é²ãæ¹ã«ã¤ãã¦&#34;&gt;ãã­ã¸ã§ã¯ãã®é²ãæ¹ã«ã¤ãã¦&lt;/h2&gt;
&lt;p&gt;å®å¨ã«å®æãã¦ããå¬éãããã¨ããã¢ãã­ã¼ãã¨ã¯æ­£åå¯¾ã§ãæ§æ³ã®ã¿ã§å®æã¯ã¾ã£ããã§ãã¦ããªãç¶æããå§ãã¦ãé²æãå«ãã¦ãã¹ã¦ãªã¼ãã³ã§ç¢ºèªã§ãããããªç¶æã§é²ãã¾ããé²æã¯ &lt;a href=&#34;https://github.com/r9y9/nnsvs/issues/1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/r9y9/nnsvs/issues/1&lt;/a&gt; ããç¢ºèªã§ãã¾ãã&lt;/p&gt;
&lt;p&gt;éå»ã«&lt;a href=&#34;https://github.com/r9y9/wavenet_vocoder&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;wavenet vocoder&lt;/a&gt;ãã¤ãã£ãã¨ãã«ãåããããªæ¹æ³ã§ã¯ããã¾ãããçªç¶ç¥ããªãäººãã³ã¡ã³ããããããããã®ããªã¼ãã³ã½ã¼ã¹ã®é¢ç½ãã¨ããã®ä¸ã¤ã ã¨æã£ã¦ããã®ã§ããã®æ¹å¼ã§é²ãã¾ãã&lt;/p&gt;
&lt;h2 id=&#34;ç¾æç¹ã®ç¶æ³&#34;&gt;ç¾æç¹ã®ç¶æ³&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://zunko.jp/kiridev/login.php&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ãããããã¼ã¿ãã¼ã¹&lt;/a&gt;ãä½¿ã£ã¦ãparametric SVSï¼Sinsyã®ä¸­èº«ã«è¿ããã®ï¼ãä¸éãä½ããã¨ããã¾ã§ã§ãã¾ãããMusicXMLãå¥åã¨ãã¦ãé³å£°æ³¢å½¢ãåºåãã¾ããä½ã£ãæ­å£°åæã·ã¹ãã ã¯ãtime-lagã¢ãã«ãé³ç´ ç¶ç¶é·ã¢ãã«ãé³é¿ã¢ãã«ã®3ã¤ã®trainableãªã¢ãã«ã§æãç«ã£ã¦ãã¾ããé³æ¥½/è¨èªçç¹å¾´éã¯&lt;a href=&#34;https://github.com/r9y9/sinsy&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;sinsy&lt;/a&gt;ã§æ½åºãã¦ãé³å£°åæåæã«ã¯&lt;a href=&#34;https://github.com/mmorise/World&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;WORLD&lt;/a&gt;ãä½¿ãã¾ããä»çµã¿ã¯ãä»¥ä¸ã®è«æã®åå®¹ã«è¿ãã§ãã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Y. Hono et al, &amp;ldquo;Recent Development of the DNN-based Singing Voice Synthesis System â Sinsy,&amp;rdquo; Proc. of APSIPA, 2017. (&lt;a href=&#34;http://www.apsipa.org/proceedings/2018/pdfs/0001003.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PDF&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Mixture density networkã¯ä½¿ã£ã¦ããªããããã©ã¼ããã©ã¡ã¼ã¿ãæ¨å®ãã¦ããªãç­ãéãã¯ããããããã¾ããç¾æç¹ã§ã¯å£åsinsyã¨ãã£ãã¨ããã§ãã­ T.T&lt;/p&gt;
&lt;h2 id=&#34;éçºå±¥æ­´&#34;&gt;éçºå±¥æ­´&lt;/h2&gt;
&lt;h3 id=&#34;20200408-åæç&#34;&gt;2020/04/08 (åæç)&lt;/h3&gt;
&lt;p&gt;ä¸çªæåã«ã¤ãã£ããã®ã§ããè¦äºãªé³ç´æ­å£°åæã«ãªãã¾ãããTTSã®ä»çµã¿ãä½¿ãã ãã§ã¯å½ç¶ã ãã§ãããã¨ãããªãã§ããé³é¿ã¢ãã«ã§ã¯å¯¾æ°lf0ãäºæ¸¬ããããã«ãã¾ããããã®ããã¯time-lagã¢ãã«ãä½ã£ã¦ããªãã¦ãphonetic timeingã¯ã¢ããã¼ã·ã§ã³ããããã¼ã¿ã®ãã®ãä½¿ã£ã¦ãã¾ãã&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
&lt;iframe width=&#34;90%&#34; height=&#34;200&#34; scrolling=&#34;no&#34; frameborder=&#34;no&#34; allow=&#34;autoplay&#34; src=&#34;https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/792271372&amp;color=%23ff5500&amp;auto_play=false&amp;hide_related=false&amp;show_comments=true&amp;show_user=true&amp;show_reposts=false&amp;show_teaser=true&amp;visual=true&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;h3 id=&#34;20200426-æ¬ãã­ã°å·ç­æç¹ã§ã®ææ°ç&#34;&gt;2020/04/26 (æ¬ãã­ã°å·ç­æç¹ã§ã®ææ°ç)&lt;/h3&gt;
&lt;p&gt;Time-lag, duration, acoustic modelã®ãã¹ã¦ãä¸æ¦å®è£ãçµãã£ããã¼ã¸ã§ã³ã§ããlf0ã®çµ¶å¯¾å¤ãäºæ¸¬ããã®ã§ã¯ãªããrelativeãªlf0ãäºæ¸¬ããããã«å¤ãã¾ãããphonetic timing ã¯ãã¹ã¦äºæ¸¬ããããã®ãä½¿ã£ã¦ãã¾ããã²ã¨ã¨ããã§ããã«ã¯ããã§ãããå®æåº¦ã¯ãã¾ãã¡ã¨ããã®ãæ­£ç´ãªã¨ããã§ãã­&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
&lt;iframe width=&#34;90%&#34; height=&#34;200&#34; scrolling=&#34;no&#34; frameborder=&#34;no&#34; allow=&#34;autoplay&#34; src=&#34;https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/806654083&amp;color=%23ff5500&amp;auto_play=false&amp;hide_related=false&amp;show_comments=true&amp;show_user=true&amp;show_reposts=false&amp;show_teaser=true&amp;visual=true&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;h2 id=&#34;ä»å¾ã®äºå®&#34;&gt;ä»å¾ã®äºå®&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/r9y9/nnsvs/issues/1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/r9y9/nnsvs/issues/1&lt;/a&gt; ãéææ´æ°ãã¾ãããéè¦ãªãã®ãããã¤ããããã¢ãããã¾ãã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;é³é¿ã¢ãã«ã®å¼·å&lt;/strong&gt;ï¼ç¹ã«F0ã®ã¢ãã«åãé£ããå°è±¡ã§ãæ¹åãèãã¦ãã¾ãããã¾ã¯æ¬å½ã«é©å½ãªCNNãã¤ãã£ã¦ãã¾ãããautoreggresive modelã«å¤ãããã¨æã£ã¦ãã¾ããããã¤ãé¸æè¢ãããã¾ãããWaveNetã®ãããªã¢ãã«ã«ããäºå®ã§ããhttps://mtg.github.io/singing-synthesis-demos/ å½¼ãã®è«æãå¤§ãã«åèã«ããäºå®ã§ããNIIã®Wangããã®shallow ARã¢ãã«ãä½¿ãããããæéè¦èª²é¡ã§ãç®ä¸ãããã¨ãªã¹ãã«å¥ã£ã¦ãã¾ã&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;é¢æ£F0ã¢ããªã³ã°&lt;/strong&gt;: NIIã®Wangããã®è«æãå¤§å¤åèã«ãªãã¾ãããé³å£°åæã§ã¯åºãé£ç¶F0ãä½¿ããã¦ããå°è±¡ã§ãããé¢æ£F0ã¢ããªã³ã°ãè©¦ãããã¨æã£ã¦ãã¾ãã&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Transformerãªã©ã®å¼·åãªã¢ãã«&lt;/strong&gt;: ä»å¹´ã® &lt;a href=&#34;https://2020.ieeeicassp.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ICASSP 2020&lt;/a&gt; ã§ &lt;a href=&#34;https://mtg.github.io/singing-synthesis-demos/transformer/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Feed-forward Transformerãä½¿ã£ãæ­å£°åæã®ç ç©¶çºè¡¨&lt;/a&gt;ãããã¾ããããè¿å¹´ã®non-autoregressiveã¢ãã«ã®çºå±ã¯ãããã®ã§ãåæ§ã®ã¢ãã­ã¼ããè©¦ãã¦ã¿ããã¨æã£ã¦ãã¾ããè£½ååã¯èããªãããã©ããªã«ãã«ãã¦éãã¢ãã«ãä½¿ã£ã¦ããã&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ãã¥ã¼ã©ã«ãã³ã¼ã&lt;/strong&gt;: é³é¿ã¢ãã«ã®æ¹åãããç¨åº¦ã§ããã°ããã¥ã¼ã©ã«ãã³ã¼ããå¥ãã¦é«åè³ªã«ã§ããã¨ããã§ãã­ã&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;é³æ¥½/è¨èªç¹å¾´éã®ç°¡ç¥å&lt;/strong&gt;: ä»ã¯450æ¬¡åãããã®ç¹å¾´éãä½¿ã£ã¦ãã¾ãããhttps://mtg.github.io/singing-synthesis-demos/ å½¼ãã®ã°ã«ã¼ãã®ç ç©¶ãè¦ãã¨ããã£ã¨ã·ã³ãã«ã«ã§ãããã«æãã¦ãã¦ãã¾ããé³æ¥½/è¨èªç¹å¾´éã®æ½åºã¯ä»ã¯sinsyã«é ¼ãã£ããã§ãããã©ããã®ã¿ã¤ãã³ã°ã§ã·ã³ãã«ã«ãããã¨æã£ã¦ãã¾ãã&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Time-lag/duration modelã®æ¹å&lt;/strong&gt;: ç¾æç¹ã§ã¯ãã£ã¡ãéãªã¤ãããªã®ã§ãhttps://mtg.github.io/singing-synthesis-demos/ å½¼ãã®ç ç©¶ãè¦ç¿ã£ã¦ç´°é¨ã¾ã§è©°ããã&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;é³ç´ ã¢ã©ã¤ã¡ã³ããã¼ã«&lt;/strong&gt;: ããããDBã®é³ç´ ã¢ã©ã¤ã¡ã³ããå¾®å¦ã«ä¸æ­£ç¢ºãªã®ããã£ãããã¾ããä»ã®ã¨ããããç¨åº¦æä¿®æ­£ãã¦ãã¾ãããèªåã§ãã£ãã»ããããã®ã§ã¯ã¨æãã¦ãã¾ããã&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ãã®ä»ãã¼ã¿ã»ãã&lt;/strong&gt;: JVSãªã©ãããããDBã§ããç¨åº¦ã§ãã¦ããã§ããã­&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;ããã¾ã§æ­å£°åæããã£ã¦ã¿ã¦ã®ææ&#34;&gt;ããã¾ã§æ­å£°åæããã£ã¦ã¿ã¦ã®ææ&lt;/h2&gt;
&lt;p&gt;æ­å£°åæã¯ãã½ã ãºããã¯ã­ã¿&lt;/p&gt;
&lt;p&gt;æ°ãããã¨ã«ãã£ã¬ã³ã¸ããã®ã¯ã¨ã¦ãæ¥½ããã§ããããã£ã±ãé£ããã§ãã­ãé¢æ£åF0ãautoregressive modelã®å°å¥ã§ãããªãã®åè³ªã«æã£ã¦ãããã¨ããæ·¡ãæå¾ããã¦ãã¾ããããã¦ã©ããªããã¨ãããå°éã«é å¼µã£ã¦æ¹åãã¦ããã¾ãã&lt;/p&gt;
&lt;h2 id=&#34;åè&#34;&gt;åè&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;ãããããã¼ã¿ãã¼ã¹: &lt;a href=&#34;https://zunko.jp/kiridev/login.php&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://zunko.jp/kiridev/login.php&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;NEUTRINO: &lt;a href=&#34;https://n3utrino.work/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://n3utrino.work/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;NNSVS: &lt;a href=&#34;https://github.com/r9y9/nnsvs&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/r9y9/nnsvs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;NNSVS é²æ: &lt;a href=&#34;https://github.com/r9y9/nnsvs/issues/1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/r9y9/nnsvs/issues/1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;sinsy: &lt;a href=&#34;http://sinsy.sourceforge.net/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://sinsy.sourceforge.net/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;My fork of sinsy: &lt;a href=&#34;https://github.com/r9y9/sinsy&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/r9y9/sinsy&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;nnmnkwii: &lt;a href=&#34;https://github.com/r9y9/nnmnkwii&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/r9y9/nnmnkwii&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;WORLD: &lt;a href=&#34;https://github.com/mmorise/World&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/mmorise/World&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Y. Hono et al, &amp;ldquo;Recent Development of the DNN-based Singing Voice Synthesis System â Sinsy,&amp;rdquo; Proc. of APSIPA, 2017. (&lt;a href=&#34;http://www.apsipa.org/proceedings/2018/pdfs/0001003.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PDF&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;NEUTRINOä¸¦ã®åè³ªã®æ­å£°åæã¨ã³ã¸ã³ãä½ããããããªã¨ã¯æã£ã¦ãã¾ãããã¾ã ã¾ã éã®ãã¯é·ããã§ãã&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;&lt;a href=&#34;http://sinsy.sourceforge.net/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://sinsy.sourceforge.net/&lt;/a&gt; æåãªãã®ã«sinsyãããã¾ãããDNNã¢ãã«ã®å­¦ç¿ãªã©ããã¹ã¦ããªã¼ãã³ã½ã¼ã¹ãªããã§ã¯ããã¾ãã&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;ä¸ãä¸ã®å ´åã¯ãå¯ãã¦ãã ããâ¦&amp;#160;&lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
    </item>
    
    <item>
      <title>Neural text-to-speech with a modeling-by-generation excitation vocoder</title>
      <link>https://r9y9.github.io/projects/mbg_excitnet/</link>
      <pubDate>Wed, 22 Apr 2020 16:51:09 +0900</pubDate>
      <guid>https://r9y9.github.io/projects/mbg_excitnet/</guid>
      <description></description>
    </item>
    
    <item>
      <title>End-to-End é³å£°åæã®ç ç©¶ãå éããããã¼ã«ã­ãã ESPnet-TTS / ESPnet-TTS: A toolkit to accelerate research on end-to-end speech synthesis @ ASJ 2020s</title>
      <link>https://r9y9.github.io/talk/asj-espnet2-tutorial/</link>
      <pubDate>Mon, 16 Mar 2020 13:00:00 +0900</pubDate>
      <guid>https://r9y9.github.io/talk/asj-espnet2-tutorial/</guid>
      <description></description>
    </item>
    
    <item>
      <title>ESPnet-TTS: Unified, Reproducible, and Integratable Open Source End-to-End Text-to-Speech Toolkit</title>
      <link>https://r9y9.github.io/projects/espnet-tts/</link>
      <pubDate>Thu, 24 Oct 2019 16:21:27 +0900</pubDate>
      <guid>https://r9y9.github.io/projects/espnet-tts/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Parallel WaveGAN: A fast waveform generation model based on generative adversarial networks with multi-resolution spectrogram</title>
      <link>https://r9y9.github.io/projects/pwg/</link>
      <pubDate>Mon, 21 Oct 2019 20:18:27 +0900</pubDate>
      <guid>https://r9y9.github.io/projects/pwg/</guid>
      <description>&lt;p&gt;Preprint: &lt;a href=&#34;https://arxiv.org/abs/1910.11480&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;arXiv:1910.11480&lt;/a&gt; (accepted to &lt;a href=&#34;https://2020.ieeeicassp.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ICASSP 2020&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#audio-samples-japanese&#34;&gt;Audio samples (Japanese)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#audio-samples-english&#34;&gt;Audio samples (English)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;Japanese samples were used in the subjective evaluations reported in our paper.&lt;/em&gt;&lt;/p&gt;
&lt;h2 id=&#34;authors&#34;&gt;Authors&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Ryuichi Yamamoto (LINE Corp.)&lt;/li&gt;
&lt;li&gt;Eunwoo Song (NAVER Corp.)&lt;/li&gt;
&lt;li&gt;Jae-Min Kim (NAVER Corp.)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;We propose Parallel WaveGAN&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;, a distillation-free, fast, and small-footprint waveform generation method using a generative adversarial network. In the proposed method, a non-autoregressive WaveNet is trained by jointly optimizing multi-resolution spectrogram and adversarial loss functions, which can effectively capture the time-frequency distribution of the realistic speech waveform. As our method does not require density distillation used in the conventional teacher-student framework, the entire model can be easily trained even with a small number of parameters. In particular, the proposed Parallel WaveGAN has only 1.44 M parameters and can generate 24 kHz speech waveform 28.68 times faster than real-time on a single GPU environment. Perceptual listening test results verify that our proposed method achieves 4.16 mean opinion score within a Transformer-based text-to-speech framework, which is comparative to the best distillation-based Parallel WaveNet system.&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/images/icassp2020_fig.png&#34; width=&#34;60%&#34; /&gt;&lt;/div&gt;
&lt;h3 id=&#34;systems-used-for-comparision&#34;&gt;Systems used for comparision&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Ground truth&lt;/strong&gt;: Recorded speech.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;WaveNet&lt;/strong&gt;: Gaussian WaveNet &lt;a href=&#34;https://arxiv.org/abs/1807.07281&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;[1]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ClariNet-$L^{(1)}$&lt;/strong&gt;: ClariNet &lt;a href=&#34;https://arxiv.org/abs/1807.07281&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;[1]&lt;/a&gt; with the single STFT auxiliary loss&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ClariNet-$L^{(1,2,3)}$&lt;/strong&gt;: ClariNet with the multi-resolution STFT loss&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ClariNet-GAN-$L^{(1,2,3)}$&lt;/strong&gt;: ClariNet with the multi-resolution STFT and adversarial losses &lt;a href=&#34;https://arxiv.org/abs/1807.07281&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;[2]&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Parallel WaveGAN-$L^{(1)}$&lt;/strong&gt;: Parallel WaveGAN with th single STFT loss&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Parallel WaveGAN-$L^{(1,2,3)}$&lt;/strong&gt;: Parallel WaveGAN with the multi-resolution STFT loss&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;audio-samples-japanese&#34;&gt;Audio samples (Japanese)&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Analysis/synthesis&lt;/li&gt;
&lt;li&gt;Text-to-speech (Transformer TTS + vocoder models)&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;analysissynthesis&#34;&gt;Analysis/synthesis&lt;/h3&gt;
&lt;p&gt;Sample 1&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Ground truth&lt;/th&gt;&lt;th&gt;WaveNet&lt;/th&gt;&lt;th&gt;ClariNet-$L^{(1)}$&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/AnaSyn/[Sample01]-1-Ground truth.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/AnaSyn/[Sample01]-2-WaveNet.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/AnaSyn/[Sample01]-3-ClariNet (1spec).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;ClariNet-$L^{(1,2,3)}$&lt;/th&gt;&lt;th&gt;ClariNet-GAN-$L^{(1,2,3)}$&lt;/th&gt;&lt;th&gt;Parallel WaveGAN-$L^{(1)}$&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/AnaSyn/[Sample01]-4-ClariNet (3spec).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/AnaSyn/[Sample01]-5-ClariNet-GAN (3spec).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/AnaSyn/[Sample01]-6-Parallel WaveGAN (1spec).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Parallel WaveGAN-$L^{(1,2,3)}$ &lt;font color=&#34;#0000cd&#34;&gt;(ours)&lt;/font&gt;&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/AnaSyn/[Sample01]-7-Parallel WaveGAN (3spec) (ours).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Sample 2&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Ground truth&lt;/th&gt;&lt;th&gt;WaveNet&lt;/th&gt;&lt;th&gt;ClariNet-$L^{(1)}$&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/AnaSyn/[Sample02]-1-Ground truth.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/AnaSyn/[Sample02]-2-WaveNet.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/AnaSyn/[Sample02]-3-ClariNet (1spec).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;ClariNet-$L^{(1,2,3)}$&lt;/th&gt;&lt;th&gt;ClariNet-GAN-$L^{(1,2,3)}$&lt;/th&gt;&lt;th&gt;Parallel WaveGAN-$L^{(1)}$&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/AnaSyn/[Sample02]-4-ClariNet (3spec).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/AnaSyn/[Sample02]-5-ClariNet-GAN (3spec).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/AnaSyn/[Sample02]-6-Parallel WaveGAN (1spec).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Parallel WaveGAN-$L^{(1,2,3)}$ &lt;font color=&#34;#0000cd&#34;&gt;(ours)&lt;/font&gt;&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/AnaSyn/[Sample02]-7-Parallel WaveGAN (3spec) (ours).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Sample 3&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Ground truth&lt;/th&gt;&lt;th&gt;WaveNet&lt;/th&gt;&lt;th&gt;ClariNet-$L^{(1)}$&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/AnaSyn/[Sample03]-1-Ground truth.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/AnaSyn/[Sample03]-2-WaveNet.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/AnaSyn/[Sample03]-3-ClariNet (1spec).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;ClariNet-$L^{(1,2,3)}$&lt;/th&gt;&lt;th&gt;ClariNet-GAN-$L^{(1,2,3)}$&lt;/th&gt;&lt;th&gt;Parallel WaveGAN-$L^{(1)}$&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/AnaSyn/[Sample03]-4-ClariNet (3spec).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/AnaSyn/[Sample03]-5-ClariNet-GAN (3spec).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/AnaSyn/[Sample03]-6-Parallel WaveGAN (1spec).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Parallel WaveGAN-$L^{(1,2,3)}$ &lt;font color=&#34;#0000cd&#34;&gt;(ours)&lt;/font&gt;&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/AnaSyn/[Sample03]-7-Parallel WaveGAN (3spec) (ours).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Sample 4&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Ground truth&lt;/th&gt;&lt;th&gt;WaveNet&lt;/th&gt;&lt;th&gt;ClariNet-$L^{(1)}$&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/AnaSyn/[Sample04]-1-Ground truth.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/AnaSyn/[Sample04]-2-WaveNet.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/AnaSyn/[Sample04]-3-ClariNet (1spec).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;ClariNet-$L^{(1,2,3)}$&lt;/th&gt;&lt;th&gt;ClariNet-GAN-$L^{(1,2,3)}$&lt;/th&gt;&lt;th&gt;Parallel WaveGAN-$L^{(1)}$&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/AnaSyn/[Sample04]-4-ClariNet (3spec).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/AnaSyn/[Sample04]-5-ClariNet-GAN (3spec).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/AnaSyn/[Sample04]-6-Parallel WaveGAN (1spec).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Parallel WaveGAN-$L^{(1,2,3)}$ &lt;font color=&#34;#0000cd&#34;&gt;(ours)&lt;/font&gt;&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/AnaSyn/[Sample04]-7-Parallel WaveGAN (3spec) (ours).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Sample 5&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Ground truth&lt;/th&gt;&lt;th&gt;WaveNet&lt;/th&gt;&lt;th&gt;ClariNet-$L^{(1)}$&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/AnaSyn/[Sample05]-1-Ground truth.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/AnaSyn/[Sample05]-2-WaveNet.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/AnaSyn/[Sample05]-3-ClariNet (1spec).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;ClariNet-$L^{(1,2,3)}$&lt;/th&gt;&lt;th&gt;ClariNet-GAN-$L^{(1,2,3)}$&lt;/th&gt;&lt;th&gt;Parallel WaveGAN-$L^{(1)}$&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/AnaSyn/[Sample05]-4-ClariNet (3spec).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/AnaSyn/[Sample05]-5-ClariNet-GAN (3spec).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/AnaSyn/[Sample05]-6-Parallel WaveGAN (1spec).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Parallel WaveGAN-$L^{(1,2,3)}$ &lt;font color=&#34;#0000cd&#34;&gt;(ours)&lt;/font&gt;&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/AnaSyn/[Sample05]-7-Parallel WaveGAN (3spec) (ours).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;h3 id=&#34;text-to-speech&#34;&gt;Text-to-speech&lt;/h3&gt;
&lt;p&gt;Sample 1&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Ground truth&lt;/th&gt;&lt;th&gt;Transformer + WaveNet&lt;/th&gt;&lt;th&gt;Transformer + ClariNet-$L^{(1,2,3)}$&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/AnaSyn/[Sample01]-1-Ground truth.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/TTS/[Sample01]-2-WaveNet.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/TTS/[Sample01]-4-ClariNet (3spec).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Transformer + ClariNet-GAN-$L^{(1,2,3)}$&lt;/th&gt;&lt;th&gt;Transformer + Parallel WaveGAN--$L^{(1,2,3)}$ &lt;font color=&#34;#0000cd&#34;&gt;(ours)&lt;/font&gt;&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/TTS/[Sample01]-5-ClariNet-GAN (3spec).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/TTS/[Sample01]-7-Parallel WaveGAN (3spec) (ours).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Sample 2&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Ground truth&lt;/th&gt;&lt;th&gt;Transformer + WaveNet&lt;/th&gt;&lt;th&gt;Transformer + ClariNet-$L^{(1,2,3)}$&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/AnaSyn/[Sample02]-1-Ground truth.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/TTS/[Sample02]-2-WaveNet.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/TTS/[Sample02]-4-ClariNet (3spec).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Transformer + ClariNet-GAN-$L^{(1,2,3)}$&lt;/th&gt;&lt;th&gt;Transformer + Parallel WaveGAN--$L^{(1,2,3)}$ &lt;font color=&#34;#0000cd&#34;&gt;(ours)&lt;/font&gt;&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/TTS/[Sample02]-5-ClariNet-GAN (3spec).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/TTS/[Sample02]-7-Parallel WaveGAN (3spec) (ours).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Sample 3&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Ground truth&lt;/th&gt;&lt;th&gt;Transformer + WaveNet&lt;/th&gt;&lt;th&gt;Transformer + ClariNet-$L^{(1,2,3)}$&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/AnaSyn/[Sample03]-1-Ground truth.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/TTS/[Sample03]-2-WaveNet.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/TTS/[Sample03]-4-ClariNet (3spec).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Transformer + ClariNet-GAN-$L^{(1,2,3)}$&lt;/th&gt;&lt;th&gt;Transformer + Parallel WaveGAN--$L^{(1,2,3)}$ &lt;font color=&#34;#0000cd&#34;&gt;(ours)&lt;/font&gt;&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/TTS/[Sample03]-5-ClariNet-GAN (3spec).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/TTS/[Sample03]-7-Parallel WaveGAN (3spec) (ours).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Sample 4&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Ground truth&lt;/th&gt;&lt;th&gt;Transformer + WaveNet&lt;/th&gt;&lt;th&gt;Transformer + ClariNet-$L^{(1,2,3)}$&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/AnaSyn/[Sample04]-1-Ground truth.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/TTS/[Sample04]-2-WaveNet.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/TTS/[Sample04]-4-ClariNet (3spec).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Transformer + ClariNet-GAN-$L^{(1,2,3)}$&lt;/th&gt;&lt;th&gt;Transformer + Parallel WaveGAN--$L^{(1,2,3)}$ &lt;font color=&#34;#0000cd&#34;&gt;(ours)&lt;/font&gt;&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/TTS/[Sample04]-5-ClariNet-GAN (3spec).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/TTS/[Sample04]-7-Parallel WaveGAN (3spec) (ours).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Sample 5&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Ground truth&lt;/th&gt;&lt;th&gt;Transformer + WaveNet&lt;/th&gt;&lt;th&gt;Transformer + ClariNet-$L^{(1,2,3)}$&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/AnaSyn/[Sample05]-1-Ground truth.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/TTS/[Sample05]-2-WaveNet.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/TTS/[Sample05]-4-ClariNet (3spec).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Transformer + ClariNet-GAN-$L^{(1,2,3)}$&lt;/th&gt;&lt;th&gt;Transformer + Parallel WaveGAN--$L^{(1,2,3)}$ &lt;font color=&#34;#0000cd&#34;&gt;(ours)&lt;/font&gt;&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/TTS/[Sample05]-5-ClariNet-GAN (3spec).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/TTS/[Sample05]-7-Parallel WaveGAN (3spec) (ours).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;h2 id=&#34;audio-samples-english&#34;&gt;Audio samples (English)&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Analysis/synthesis&lt;/li&gt;
&lt;li&gt;Text-to-speech (&lt;a href=&#34;https://arxiv.org/abs/1910.10909&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ESPnet-TTS&lt;/a&gt; + Our Parallel WaveGAN)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a href=&#34;https://keithito.com/LJ-Speech-Dataset/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;LJSpeech dataset&lt;/a&gt; is used for the test. Mel-spectrograms (with the range of 70 - 7600 Hz&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;) were used for local conditioning.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Please note that the English samples were not used in the subjective evaluations reported in our paper.&lt;/em&gt;&lt;/p&gt;
&lt;h3 id=&#34;analysissynthesis-1&#34;&gt;Analysis/synthesis&lt;/h3&gt;
&lt;p&gt;That is reflected in definite and comprehensive operating procedures.&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Ground truth&lt;/th&gt;&lt;th&gt;WaveNet&lt;/th&gt;&lt;th&gt;ClariNet-$L^{(1)}$&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample01]-1-Ground truth.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample01]-2-WaveNet.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample01]-3-ClariNet (1spec).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;ClariNet-$L^{(1,2,3)}$&lt;/th&gt;&lt;th&gt;ClariNet-GAN-$L^{(1,2,3)}$&lt;/th&gt;&lt;th&gt;Parallel WaveGAN-$L^{(1)}$&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample01]-4-ClariNet (3spec).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample01]-5-ClariNet-GAN (3spec).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample01]-6-Parallel WaveGAN (1spec).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Parallel WaveGAN-$L^{(1,2,3)}$ &lt;font color=&#34;#0000cd&#34;&gt;(ours)&lt;/font&gt;&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample01]-7-Parallel WaveGAN (3spec) (ours).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;The commission also recommends.&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Ground truth&lt;/th&gt;&lt;th&gt;WaveNet&lt;/th&gt;&lt;th&gt;ClariNet-$L^{(1)}$&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample02]-1-Ground truth.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample02]-2-WaveNet.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample02]-3-ClariNet (1spec).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;ClariNet-$L^{(1,2,3)}$&lt;/th&gt;&lt;th&gt;ClariNet-GAN-$L^{(1,2,3)}$&lt;/th&gt;&lt;th&gt;Parallel WaveGAN-$L^{(1)}$&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample02]-4-ClariNet (3spec).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample02]-5-ClariNet-GAN (3spec).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample02]-6-Parallel WaveGAN (1spec).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Parallel WaveGAN-$L^{(1,2,3)}$ &lt;font color=&#34;#0000cd&#34;&gt;(ours)&lt;/font&gt;&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample02]-7-Parallel WaveGAN (3spec) (ours).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;That the secret service consciously set about the task of inculcating and maintaining the highest standard of excellence and esprit, for all of its personnel.&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Ground truth&lt;/th&gt;&lt;th&gt;WaveNet&lt;/th&gt;&lt;th&gt;ClariNet-$L^{(1)}$&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample03]-1-Ground truth.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample03]-2-WaveNet.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample03]-3-ClariNet (1spec).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;ClariNet-$L^{(1,2,3)}$&lt;/th&gt;&lt;th&gt;ClariNet-GAN-$L^{(1,2,3)}$&lt;/th&gt;&lt;th&gt;Parallel WaveGAN-$L^{(1)}$&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample03]-4-ClariNet (3spec).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample03]-5-ClariNet-GAN (3spec).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample03]-6-Parallel WaveGAN (1spec).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Parallel WaveGAN-$L^{(1,2,3)}$ &lt;font color=&#34;#0000cd&#34;&gt;(ours)&lt;/font&gt;&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample03]-7-Parallel WaveGAN (3spec) (ours).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;This involves tight and unswerving discipline as well as the promotion of an outstanding degree of dedication and loyalty to duty.&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Ground truth&lt;/th&gt;&lt;th&gt;WaveNet&lt;/th&gt;&lt;th&gt;ClariNet-$L^{(1)}$&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample04]-1-Ground truth.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample04]-2-WaveNet.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample04]-3-ClariNet (1spec).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;ClariNet-$L^{(1,2,3)}$&lt;/th&gt;&lt;th&gt;ClariNet-GAN-$L^{(1,2,3)}$&lt;/th&gt;&lt;th&gt;Parallel WaveGAN-$L^{(1)}$&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample04]-4-ClariNet (3spec).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample04]-5-ClariNet-GAN (3spec).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample04]-6-Parallel WaveGAN (1spec).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Parallel WaveGAN-$L^{(1,2,3)}$ &lt;font color=&#34;#0000cd&#34;&gt;(ours)&lt;/font&gt;&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample04]-7-Parallel WaveGAN (3spec) (ours).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;The commission emphasizes that it finds no causal connection between the assassination.&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Ground truth&lt;/th&gt;&lt;th&gt;WaveNet&lt;/th&gt;&lt;th&gt;ClariNet-$L^{(1)}$&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample05]-1-Ground truth.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample05]-2-WaveNet.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample05]-3-ClariNet (1spec).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;ClariNet-$L^{(1,2,3)}$&lt;/th&gt;&lt;th&gt;ClariNet-GAN-$L^{(1,2,3)}$&lt;/th&gt;&lt;th&gt;Parallel WaveGAN-$L^{(1)}$&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample05]-4-ClariNet (3spec).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample05]-5-ClariNet-GAN (3spec).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample05]-6-Parallel WaveGAN (1spec).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Parallel WaveGAN-$L^{(1,2,3)}$ &lt;font color=&#34;#0000cd&#34;&gt;(ours)&lt;/font&gt;&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample05]-7-Parallel WaveGAN (3spec) (ours).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;h3 id=&#34;text-to-speech-1&#34;&gt;Text-to-speech&lt;/h3&gt;
&lt;p&gt;We combined our Parallel WaveGAN with &lt;a href=&#34;https://arxiv.org/abs/1910.10909&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ESPnet-TTS&lt;/a&gt;. The systems used here are as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Transformer.v3&lt;/strong&gt;: Transformer.v3 presented in &lt;a href=&#34;https://arxiv.org/abs/1910.10909&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ESPnet-TTS&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;MoL WaveNet&lt;/strong&gt;: WaveNet with mixture of logistics output distribution (shipped with ESPnet). Pre-emphasis/de-emphasis were applied to reduce perceptual noise (similar to &lt;a href=&#34;https://arxiv.org/abs/1810.11846&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;LPCNet&lt;/a&gt;).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Parallel WaveGAN&lt;/strong&gt;: Our Parallel WaveGAN with multi-resolution spectrogram loss.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Note that &lt;strong&gt;Transformer.v3 + MoL WaveNet&lt;/strong&gt; is the same as used in &lt;a href=&#34;https://espnet.github.io/icassp2020-tts/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://espnet.github.io/icassp2020-tts/&lt;/a&gt;.
Mel-spectrograms (with the range of 70 - 11025 Hz) were used for local conditioning.&lt;/p&gt;
&lt;p&gt;That is reflected in definite and comprehensive operating procedures.&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Ground truth&lt;/th&gt;&lt;th&gt;Transformer.v3 + MoL WaveNet&lt;/th&gt;&lt;th&gt;Transformer.v3 + Parallel WaveGAN&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample01]-1-Ground truth.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/LJSpeech/TTS/[LJ-Sample01]-1-MoL-WaveNet.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/LJSpeech/TTS/[LJ-Sample01]-2-Parallel WaveGAN.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;The commission also recommends.&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Ground truth&lt;/th&gt;&lt;th&gt;Transformer.v3 + MoL WaveNet&lt;/th&gt;&lt;th&gt;Transformer.v3 + Parallel WaveGAN&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample02]-1-Ground truth.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/LJSpeech/TTS/[LJ-Sample02]-1-MoL-WaveNet.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/LJSpeech/TTS/[LJ-Sample02]-2-Parallel WaveGAN.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;That the secret service consciously set about the task of inculcating and maintaining the highest standard of excellence and esprit, for all of its personnel.&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Ground truth&lt;/th&gt;&lt;th&gt;Transformer.v3 + MoL WaveNet&lt;/th&gt;&lt;th&gt;Transformer.v3 + Parallel WaveGAN&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample03]-1-Ground truth.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/LJSpeech/TTS/[LJ-Sample03]-1-MoL-WaveNet.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/LJSpeech/TTS/[LJ-Sample03]-2-Parallel WaveGAN.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;This involves tight and unswerving discipline as well as the promotion of an outstanding degree of dedication and loyalty to duty.&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Ground truth&lt;/th&gt;&lt;th&gt;Transformer.v3 + MoL WaveNet&lt;/th&gt;&lt;th&gt;Transformer.v3 + Parallel WaveGAN&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample04]-1-Ground truth.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/LJSpeech/TTS/[LJ-Sample04]-1-MoL-WaveNet.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/LJSpeech/TTS/[LJ-Sample04]-2-Parallel WaveGAN.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;The commission emphasizes that it finds no causal connection between the assassination.&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Ground truth&lt;/th&gt;&lt;th&gt;Transformer.v3 + MoL WaveNet&lt;/th&gt;&lt;th&gt;Transformer.v3 + Parallel WaveGAN&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/LJSpeech/AnaSyn/[LJ-Sample05]-1-Ground truth.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/LJSpeech/TTS/[LJ-Sample05]-1-MoL-WaveNet.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/icassp2020/LJSpeech/TTS/[LJ-Sample05]-2-Parallel WaveGAN.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;W. Ping, K. Peng, and J. Chen, âClariNet: Parallel wave generation in end-to-end text-to-speech,â in Proc. ICLR, 2019 (&lt;a href=&#34;https://arxiv.org/abs/1807.07281&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;arXiv&lt;/a&gt;).&lt;/li&gt;
&lt;li&gt;R. Yamamoto, E. Song, and J.-M. Kim, âProbability density distillation with generative adversarial networks for high-quality parallel waveform generation,â in Proc. INTERSPEECH, 2019, pp. 699â703. (&lt;a href=&#34;https://www.isca-speech.org/archive/Interspeech_2019/abstracts/1965.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ISCA archive&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;acknowledgements&#34;&gt;Acknowledgements&lt;/h2&gt;
&lt;p&gt;Work performed with nVoice, Clova Voice, Naver Corp.&lt;/p&gt;
&lt;h2 id=&#34;citation&#34;&gt;Citation&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;@inproceedings{yamamoto2020parallel,
  title={Parallel {WaveGAN}: {A} fast waveform generation model based on generative adversarial networks with multi-resolution spectrogram},
  author={Yamamoto, Ryuichi and Song, Eunwoo and Kim, Jae-Min},
  booktitle	= &amp;quot;Proc. of ICASSP&amp;quot;,
  pages={6199--6203},
  year={2020}
}
&lt;/code&gt;&lt;/pre&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Note that our work is not closely related to an unsupervised waveform synthesis model, &lt;a href=&#34;https://arxiv.org/abs/1802.04208&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;WaveGAN&lt;/a&gt;.&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Audio quaility can be improved by using the full-band frequency range, but it may suffer from the over-smoothing problem in TTS.&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
    </item>
    
    <item>
      <title>Probability Density Distillation with Generative Adversarial Networks for High-Quality Parallel Waveform Generation</title>
      <link>https://r9y9.github.io/projects/gan-pwn/</link>
      <pubDate>Tue, 25 Jun 2019 17:20:29 +0900</pubDate>
      <guid>https://r9y9.github.io/projects/gan-pwn/</guid>
      <description>&lt;p&gt;Preprint: &lt;a href=&#34;https://arxiv.org/abs/1904.04472&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;arXiv:1904.04472&lt;/a&gt;, Published version: &lt;a href=&#34;https://www.isca-speech.org/archive_v0/Interspeech_2019/abstracts/1965.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ISCA Archive Interspeech 2019&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;authors&#34;&gt;Authors&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Ryuichi Yamamoto (LINE Corp.)&lt;/li&gt;
&lt;li&gt;Eunwoo Song (NAVER Corp.)&lt;/li&gt;
&lt;li&gt;Jae-Min Kim (NAVER Corp.)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;This paper proposes an effective probability density distillation (PDD) algorithm for WaveNet-based parallel waveform generation (PWG) systems. Recently proposed teacher-student frameworks in the PWG system have successfully achieved a real-time generation of speech signals. However, the difficulties optimizing the PDD criteria without auxiliary losses result in quality degradation of synthesized speech. To generate more natural speech signals within the teacher-student framework, we propose a novel optimization criterion based on generative adversarial networks (GANs). In the proposed method, the inverse autoregressive flow-based student model is incorporated as a generator in the GAN framework, and jointly optimized by the PDD mechanism with the proposed adversarial learning method. As this process encourages the student to model the distribution of realistic speech waveform, the perceptual quality of the synthesized speech becomes much more natural. Our experimental results verify that the PWG systems with the proposed method outperform both those using conventional approaches, and also autoregressive generation systems with a well-trained teacher WaveNet.&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/images/interspeech2019_fig.png&#34; width=&#34;90%&#34; /&gt;&lt;/div&gt;
&lt;h2 id=&#34;audio-samples&#34;&gt;Audio samples&lt;/h2&gt;
&lt;p&gt;There are 8 different systems, that include 6 parallel waveform generation systems (Student-*) trained by different optimization criteria as follows:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Ground truth&lt;/strong&gt;: Recorded speech.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Teacher&lt;/strong&gt;: Teacher Gaussian WaveNet &lt;a href=&#34;https://arxiv.org/abs/1807.07281&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;[1]&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Student-AX&lt;/strong&gt;: STFT auxiliary loss.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Student-AXAD&lt;/strong&gt;: STFT and adversarial losses.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Student-KL&lt;/strong&gt;: KLD loss (Ablation study; not used for subjective evaluations).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Student-KLAX&lt;/strong&gt;: KLD and STFT auxiliary losses.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Student-KLAXAD&lt;/strong&gt;: KLD, STFT, and adversarial losses (proposed).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Student-KLAXAD&lt;/strong&gt;*: Weights optimized version of the above (proposed).&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;copy-synthesis&#34;&gt;Copy-synthesis&lt;/h3&gt;
&lt;h4 id=&#34;japanese-female-speaker&#34;&gt;Japanese female speaker&lt;/h4&gt;
&lt;p&gt;Sample 1&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Ground truth&lt;/th&gt;&lt;th&gt;Teacher&lt;/th&gt;&lt;th&gt;Student-AX&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/interspeech2019/[Sample01]-1-Ground truth.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/interspeech2019/[Sample01]-2-Teacher.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/interspeech2019/[Sample01]-3-Student-AX (AuxLoss).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Student-AXAV&lt;/th&gt;&lt;th&gt;Student-KL&lt;/th&gt;&lt;th&gt;Student-KLAX&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/interspeech2019/[Sample01]-4-Student-AXAV (AuxLoss + AdvLoss).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/interspeech2019/[Sample01]-5-Student-KL (KLD only; ablation study).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/interspeech2019/[Sample01]-6-Student-KLAX (KLD + AuxLoss).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Student-KLAXAD&lt;/th&gt;&lt;th&gt;Student-KLAXAD*&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/interspeech2019/[Sample01]-7-Student-KLAXAD (Proposed; KLD + AuxLoss + AdvLoss).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/interspeech2019/[Sample01]-8-Student-KLAXAD (Proposed; weights optimized version).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Sample 2&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Ground truth&lt;/th&gt;&lt;th&gt;Teacher&lt;/th&gt;&lt;th&gt;Student-AX&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/interspeech2019/[Sample02]-1-Ground truth.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/interspeech2019/[Sample02]-2-Teacher.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/interspeech2019/[Sample02]-3-Student-AX (AuxLoss).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Student-AXAV&lt;/th&gt;&lt;th&gt;Student-KL&lt;/th&gt;&lt;th&gt;Student-KLAX&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/interspeech2019/[Sample02]-4-Student-AXAV (AuxLoss + AdvLoss).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/interspeech2019/[Sample02]-5-Student-KL (KLD only; ablation study).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/interspeech2019/[Sample02]-6-Student-KLAX (KLD + AuxLoss).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Student-KLAXAD&lt;/th&gt;&lt;th&gt;Student-KLAXAD*&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/interspeech2019/[Sample02]-7-Student-KLAXAD (Proposed; KLD + AuxLoss + AdvLoss).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/interspeech2019/[Sample02]-8-Student-KLAXAD (Proposed; weights optimized version).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Sample 3&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Ground truth&lt;/th&gt;&lt;th&gt;Teacher&lt;/th&gt;&lt;th&gt;Student-AX&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/interspeech2019/[Sample03]-1-Ground truth.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/interspeech2019/[Sample03]-2-Teacher.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/interspeech2019/[Sample03]-3-Student-AX (AuxLoss).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Student-AXAV&lt;/th&gt;&lt;th&gt;Student-KL&lt;/th&gt;&lt;th&gt;Student-KLAX&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/interspeech2019/[Sample03]-4-Student-AXAV (AuxLoss + AdvLoss).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/interspeech2019/[Sample03]-5-Student-KL (KLD only; ablation study).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/interspeech2019/[Sample03]-6-Student-KLAX (KLD + AuxLoss).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Student-KLAXAD&lt;/th&gt;&lt;th&gt;Student-KLAXAD*&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/interspeech2019/[Sample03]-7-Student-KLAXAD (Proposed; KLD + AuxLoss + AdvLoss).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/interspeech2019/[Sample03]-8-Student-KLAXAD (Proposed; weights optimized version).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Sample 4&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Ground truth&lt;/th&gt;&lt;th&gt;Teacher&lt;/th&gt;&lt;th&gt;Student-AX&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/interspeech2019/[Sample04]-1-Ground truth.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/interspeech2019/[Sample04]-2-Teacher.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/interspeech2019/[Sample04]-3-Student-AX (AuxLoss).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Student-AXAV&lt;/th&gt;&lt;th&gt;Student-KL&lt;/th&gt;&lt;th&gt;Student-KLAX&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/interspeech2019/[Sample04]-4-Student-AXAV (AuxLoss + AdvLoss).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/interspeech2019/[Sample04]-5-Student-KL (KLD only; ablation study).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/interspeech2019/[Sample04]-6-Student-KLAX (KLD + AuxLoss).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Student-KLAXAD&lt;/th&gt;&lt;th&gt;Student-KLAXAD*&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/interspeech2019/[Sample04]-7-Student-KLAXAD (Proposed; KLD + AuxLoss + AdvLoss).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/interspeech2019/[Sample04]-8-Student-KLAXAD (Proposed; weights optimized version).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Sample 5&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Ground truth&lt;/th&gt;&lt;th&gt;Teacher&lt;/th&gt;&lt;th&gt;Student-AX&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/interspeech2019/[Sample05]-1-Ground truth.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/interspeech2019/[Sample05]-2-Teacher.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/interspeech2019/[Sample05]-3-Student-AX (AuxLoss).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Student-AXAV&lt;/th&gt;&lt;th&gt;Student-KL&lt;/th&gt;&lt;th&gt;Student-KLAX&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/interspeech2019/[Sample05]-4-Student-AXAV (AuxLoss + AdvLoss).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/interspeech2019/[Sample05]-5-Student-KL (KLD only; ablation study).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/interspeech2019/[Sample05]-6-Student-KLAX (KLD + AuxLoss).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Student-KLAXAD&lt;/th&gt;&lt;th&gt;Student-KLAXAD*&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/interspeech2019/[Sample05]-7-Student-KLAXAD (Proposed; KLD + AuxLoss + AdvLoss).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/interspeech2019/[Sample05]-8-Student-KLAXAD (Proposed; weights optimized version).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;[1]: W. Ping, K. Peng, and J. Chen, âClariNet: Parallel wave generation in end-to-end text-to-speech,â in Proc. ICLR, 2019 (&lt;a href=&#34;https://arxiv.org/abs/1807.07281&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;arXiv&lt;/a&gt;).&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;acknowledgements&#34;&gt;Acknowledgements&lt;/h2&gt;
&lt;p&gt;Work performed with nVoice, Clova Voice, Naver Corp.&lt;/p&gt;
&lt;h2 id=&#34;citation&#34;&gt;Citation&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;@inproceedings{Yamamoto2019,
  author={Ryuichi Yamamoto and Eunwoo Song and Jae-Min Kim},
  title={{Probability Density Distillation with Generative Adversarial Networks for High-Quality Parallel Waveform Generation}},
  year=2019,
  booktitle={Proc. Interspeech 2019},
  pages={699--703},
  doi={10.21437/Interspeech.2019-1965},
  url={http://dx.doi.org/10.21437/Interspeech.2019-1965}
}
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title> WN-based TTSããã¾ãã / Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions [arXiv:1712.05884]</title>
      <link>https://r9y9.github.io/blog/2018/05/20/tacotron2/</link>
      <pubDate>Sun, 20 May 2018 14:21:30 +0900</pubDate>
      <guid>https://r9y9.github.io/blog/2018/05/20/tacotron2/</guid>
      <description>&lt;h2 id=&#34;summary&#34;&gt;Summary&lt;/h2&gt;
&lt;p&gt;Thank you for coming to see my blog post about WaveNet text-to-speech.&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron2/intro.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;ul&gt;
&lt;li&gt;è«æãªã³ã¯: &lt;a href=&#34;https://arxiv.org/abs/1712.05884&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://arxiv.org/abs/1712.05884&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;ãªã³ã©ã¤ã³ãã¢: &lt;a href=&#34;https://colab.research.google.com/github/r9y9/Colaboratory/blob/master/Tacotron2_and_WaveNet_text_to_speech_demo.ipynb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Tacotron2: WaveNet-based text-to-speech demo&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;ã³ã¼ã &lt;a href=&#34;https://github.com/r9y9/wavenet_vocoder&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;r9y9/wavenet_vocoder&lt;/a&gt;, &lt;a href=&#34;https://github.com/Rayhane-mamah/Tacotron-2&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Rayhane-mamah/Tacotron-2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;é³å£°ãµã³ãã«: &lt;a href=&#34;https://r9y9.github.io/wavenet_vocoder/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://r9y9.github.io/wavenet_vocoder/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;ä¸è¡ã¾ã¨ã&#34;&gt;ä¸è¡ã¾ã¨ã&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;èªä½WaveNet (&lt;strong&gt;WN&lt;/strong&gt;) ã¨æ¢å­å®è£Tacotron 2 (WNãé¤ã) ãçµã¿åããã¦ãè±èªTTSãä½ãã¾ãã&lt;/li&gt;
&lt;li&gt;LJSpeechãå­¦ç¿ãã¼ã¿ã¨ããå ´åãèªåå²ä¸ &lt;strong&gt;æé«åè³ª&lt;/strong&gt; ã®TTSãã§ããã¨æãã¾ã&lt;/li&gt;
&lt;li&gt;Tacotron 2ã¨ Deep Voice 3 ã®abstractãèª­ã¾ããé³å£°ãµã³ãã«ãè²¼ã£ã¦ããã¾ãã®ã§ãèå³ã®ããæ¹ã¯ã©ãã&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ãªããTacotron 2 ã®è§£èª¬ã¯ãã¾ãããç³ãè¨³ããã¾ããï¼ãªããªãåãã¾ã ååã«èª­ã¿è¾¼ãã§ããªãããï¼&lt;/p&gt;
&lt;h2 id=&#34;èæ¯&#34;&gt;èæ¯&lt;/h2&gt;
&lt;p&gt;éå»ã«ãWaveNetãå®è£ãã¾ããï¼åè: &lt;a href=&#34;https://r9y9.github.io/blog/2018/01/28/wavenet_vocoder/&#34;&gt;WaveNet vocoder ããã£ã¦ã¿ã¾ããã®ã§ããã®è¨é²ã§ã / WaveNet: A Generative Model for Raw Audio [arXiv:1609.03499]&lt;/a&gt;ï¼ãéå»è¨äºããå¼ç¨ãã¾ãã&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Tacotron2 ã¯ããã¨ã¯ããã°ã»ã¼ã§ããæãã§ãããç´è¿ã§ã¯åã®ä¸­ã§åªååº¦ãä½ãã®ããããã°ããå®é¨ãããäºå®ã¯ããã¾ãããèå³ã®ããæ¹ã¯ãã£ã¦ã¿ã¦ãã ããã&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;ãããããã¨ã®ä¸ã¤ã¨ãã¦ãã£ãã¨ã¯ãããå½åã®äºå®éããã¹ã¯ã©ããã§Tacotron 2ãå®è£ããæéã¯åããªãã£ãã®ã§ãããæ¢å­å®è£ãä½¿ã£ã¦ã¿ãã¨ããååã«ä¸æãåãã¦ããããã«æããã®ã§ããããããä½¿ããã¦ããã ããWaveNet TTSãå®ç¾ãããã¨ãã§ãã¾ãããã¨ããããã§ãçµæãããã«ã«ã¸ã¥ã¢ã«ã«æ®ãã¦ãããã¨ããè¶£æ¨ã®è¨äºã«ãªãã¾ãã&lt;/p&gt;
&lt;p&gt;ãªã¼ãã³ãªãã¼ã¿ã»ãããã³ã¼ããä½¿ã£ã¦ãå®éã©ã®ç¨åº¦ã®åè³ªãå¾ãããã®ãï¼å­¦ç¿/æ¨è«ã«ã©ã®ãããæéããããã®ãï¼ããã®ãæ°ã«ãªãæ¹ã«ã¯ãåèã«ãªãããããã¾ããã®ã§ããããããã°ç¶ããã©ããã&lt;/p&gt;
&lt;h2 id=&#34;å®é¨æ¡ä»¶&#34;&gt;å®é¨æ¡ä»¶&lt;/h2&gt;
&lt;p&gt;ç´°ããåå®¹ã¯ã³ã¼ãã«è­²ãã¨ãã¦ãéè¦ãªç¹ã ããªã¹ãã¢ãããã¾ã&lt;/p&gt;
&lt;h3 id=&#34;pre-trained-modelshyper-parameters-ã¸ã®ãªã³ã¯&#34;&gt;Pre-trained modelsãhyper parameters ã¸ã®ãªã³ã¯&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Tacotron2 (mel-spectrogram prediction part): trained 189k steps on LJSpeech dataset (&lt;a href=&#34;https://www.dropbox.com/s/vx7y4qqs732sqgg/pretrained.tar.gz?dl=0&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Pre-trained model&lt;/a&gt;, &lt;a href=&#34;https://github.com/r9y9/Tacotron-2/blob/9ce1a0e65b9217cdc19599c192c5cd68b4cece5b/hparams.py&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Hyper params&lt;/a&gt;).&lt;/li&gt;
&lt;li&gt;WaveNet: trained over 1000k steps on LJSpeech dataset (&lt;a href=&#34;https://www.dropbox.com/s/zdbfprugbagfp2w/20180510_mixture_lj_checkpoint_step000320000_ema.pth?dl=0&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Pre-trained model&lt;/a&gt;, &lt;a href=&#34;https://www.dropbox.com/s/0vsd7973w20eskz/20180510_mixture_lj_checkpoint_step000320000_ema.json?dl=0&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Hyper params&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;wavenet&#34;&gt;WaveNet&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;1000k stepä»¥ä¸è¨ç·´ãããã¢ãã« (2018/1/27ã«ä½ã£ããã®ã10æ¥ããã&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;å­¦ç¿ããï¼ããã¼ã¹ã«ãããã« 320k stepå­¦ç¿ï¼ç´3æ¥ï¼ãã¾ãããåå­¦ç¿ããã®ã¯ãä»¥åã®ã³ã¼ãã«ã¯ &lt;a href=&#34;https://github.com/r9y9/wavenet_vocoder/issues/33&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;wavenet_vocoder/issues/33&lt;/a&gt; ãããªãã°ããã£ãããã§ãã&lt;/li&gt;
&lt;li&gt;è©ä¾¡ã«ã¯ãexponential moving averagingããããã©ã¡ã¼ã¿ãä½¿ãã¾ãããdecay ãã©ã¡ã¼ã¿ã¯Taco2è«æã¨åã 0.9999&lt;/li&gt;
&lt;li&gt;å­¦ç¿ã«ã¯ãMel-spectrogram prediction networkã«ããåºåããã Ground-truth-aligned (GTA) ãªã¡ã«ã¹ãã¯ãã­ã°ã©ã ã§ã¯ãªããçé³å£°ããè¨ç®ãããã¡ã«ã¹ãã¯ãã­ã°ã©ã ãä½¿ãã¾ãããæéã®é½åä¸ãããã¾ããããGTAãä½¿ãã¨ããåè³ªãåä¸ããã¨èãããã¾ã&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;tacotron-2-mel-spectrogram-prediction&#34;&gt;Tacotron 2 (mel-spectrogram prediction)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/Rayhane-mamah/Tacotron-2&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/Rayhane-mamah/Tacotron-2&lt;/a&gt; ã«ã¯WaveNetå®è£ãå«ã¾ãã¦ãã¾ãããmel-spectrogram prediction ã®é¨åã ãä½¿ç¨ãã¾ãã&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/Rayhane-mamah/Tacotron-2/issues/30#issue-317360759&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/Rayhane-mamah/Tacotron-2/issues/30#issue-317360759&lt;/a&gt; ã§å¬éããã¦ãã 182k stepå­¦ç¿ãããã¢ãã«ããããã«7k stepã»ã©ï¼æ°æéãããï¼å­¦ç¿ããã¾ãããåå­¦ç¿ãããçç±ã¯ãèªåã®å®è£ã¨Rayhaneæ°ã®å®è£ã§æ³å®ããã¡ã«ã¹ãã¯ãã­ã°ã©ã ã®ã¬ã³ã¸ãç°ãªã£ã¦ããããã§ãï¼å: &lt;code&gt;[0, 1]&lt;/code&gt;, Rayhane: &lt;code&gt;[-4, 4]&lt;/code&gt;ï¼ãããããçµç·¯ããã&lt;code&gt;[-4, 4]&lt;/code&gt; ã®ã¬ã³ã¸ã§ãã£ãã¨ããï¼&lt;code&gt;[0, 4]&lt;/code&gt; ã«ãã¦å­¦ç¿ããªããã¾ãããç´æ¥ &lt;code&gt;[0, 1]&lt;/code&gt; ã«ãã¦å­¦ç¿ããªãã£ãã®ã¯ï¼ããã§ãåããã¨åã¯æã£ã¦ããã®ã§ããï¼ãmel-spectrogram ã®ã¬ã³ã¸ãå¤§ããåã£ãæ¹ãè¯ããã¨ããå ±åãããã¤ããã£ãããã§ãï¼ä¾ãã° &lt;a href=&#34;https://github.com/Rayhane-mamah/Tacotron-2/issues/4#issuecomment-377728945&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/Rayhane-mamah/Tacotron-2/issues/4#issuecomment-377728945&lt;/a&gt; )ãAttention seq2seq ã¯çµé¨ä¸å­¦ç¿ãé£ããã®ã§ãåã®ç´æãããåäººã®ç¥æµãåªåãããã¨ã«ããæ¬¡ç¬¬ã§ããWNã«å¥åããã¨ãã«ã¯ã Taco2ãåºåããã¡ã«ã¹ãã¯ãã­ã°ã©ã ã &lt;code&gt;c = np.interp(c, (0, 4), (0, 1))&lt;/code&gt; ã¨ã¬ã³ã¸ãå¤æãã¦ä¸ãã¾ãã&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;ãã¢é³å£°&#34;&gt;ãã¢é³å£°&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://r9y9.github.io/wavenet_vocoder/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://r9y9.github.io/wavenet_vocoder/&lt;/a&gt; ã«ãµã³ãã«ã¯ããããããã¾ããããããã§ã¯éããµã³ãã«ãã¨æããTacotron 2 ã¨ Deep Voice 3ã® abstract ãèª­ã¾ãã¦ã¿ã¾ããã
å­¦ç¿ãã¼ã¿ã«è¥å¹²æ®é¿ãä¹ã£ã¦ããã®ã§ï¼ãã¤ãºã£ã½ãï¼ãããåæ ããã¦ãã¾ã£ã¦ããã®ã§ãããåäººçã«ã¯ã¾ãã¾ãããçµæãå¾ãããã¨æã£ã¦ãã¾ããèå³ãããæ¹ã¯ãDeepVoice3ãªã©åã®éå»è¨äºã§è§¦ãã¦ããTTSçµæã¨æ¯ã¹ã¦ã¿ã¦ãã ããã&lt;/p&gt;
&lt;p&gt;ãªããæ¨è«ã®è¨ç®éåº¦ã¯,ãåã®ã­ã¼ã«ã«ç°å¢ï¼GTX 1080Ti, i7-7700Kï¼ã§ãã£ã¨ 170 timesteps / second ã¨ãã£ãæãã§ãããããã¯ãParallel WaveNet ã®è«æã§è§¦ãããã¦ããæ°å­ã¨ããã¾ãã«ä¸è´ãã¾ãã&lt;/p&gt;
&lt;p&gt;This paper describes Tacotron 2, a neural network architecture for speech synthesis directly from text.&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron2/20180510_mixture_lj_checkpoint_step000320000_ema_speech-mel-00001.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;The system is composed of a recurrent sequence-to-sequence feature prediction network that maps character embeddings to mel-scale spectrograms, followed by a modified WaveNet model acting as a vocoder to synthesize timedomain waveforms from those spectrograms.&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron2/20180510_mixture_lj_checkpoint_step000320000_ema_speech-mel-00002.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;Our model achieves a mean opinion score of 4.53 comparable to a MOS of 4.58 for professionally recorded speech.&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron2/20180510_mixture_lj_checkpoint_step000320000_ema_speech-mel-00003.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;To validate our design choices, we present ablation studies of key components of our system and evaluate the impact of using mel spectrograms as the input to WaveNet instead of linguistic, duration, and F0 features.&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron2/20180510_mixture_lj_checkpoint_step000320000_ema_speech-mel-00004.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;We further demonstrate that using a compact acoustic intermediate representation enables significant simplification of the WaveNet architecture.&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron2/20180510_mixture_lj_checkpoint_step000320000_ema_speech-mel-00005.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;We present Deep Voice 3, a fully-convolutional attention-based neural text-to-speech system.&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron2/20180510_mixture_lj_checkpoint_step000320000_ema_speech-mel-00006.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;Deep Voice 3 matches state-of-the-art neural speech synthesis systems in naturalness while training ten times faster.&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron2/20180510_mixture_lj_checkpoint_step000320000_ema_speech-mel-00007.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;We scale Deep Voice 3 to data set sizes unprecedented for TTS, training on more than eight hundred hours of audio from over two thousand speakers.&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron2/20180510_mixture_lj_checkpoint_step000320000_ema_speech-mel-00008.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;In addition, we identify common error modes of attention-based speech synthesis networks, demonstrate how to mitigate them, and compare several different waveform synthesis methods.&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron2/20180510_mixture_lj_checkpoint_step000320000_ema_speech-mel-00009.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;We also describe how to scale inference to ten million queries per day on one single-GPU server.&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron2/20180510_mixture_lj_checkpoint_step000320000_ema_speech-mel-00010.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;h2 id=&#34;ãªã³ã©ã¤ã³ãã¢&#34;&gt;ãªã³ã©ã¤ã³ãã¢&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://colab.research.google.com/github/r9y9/Colaboratory/blob/master/Tacotron2_and_WaveNet_text_to_speech_demo.ipynb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Tacotron2: WaveNet-based text-to-speech demo&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Google Colabã§åãããããã«ãã¢ãã¼ãããã¯ãä½ãã¾ãããç°å¢æ§ç¯ãä¸è¦ãªã®ã§ãæè»½ã«ãè©¦ãã§ãããã¨æãã¾ãã&lt;/p&gt;
&lt;h2 id=&#34;éè¨&#34;&gt;éè¨&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;WaveNetãå­¦ç¿ããã¨ãã«ãMel-spectrogram precition networkã®GTAãªåºåã§ãªããçã¡ã«ã¹ãã¯ãã­ã°ã©ã ããã®ã¾ã¾ä½¿ã£ã¦ãåè³ªã®è¯ãé³å£°åæãã§ããã®ã¯åäººçã«é©ãã§ãããããã¯ã¤ã¾ããTaco2ãã(non teacher-forcingãªæ¡ä»¶ã§) ååè¯ãã¡ã«ã¹ãã¯ãã­ã°ã©ã ãäºæ¸¬ã§ãã¦ãããã¨ãããã¨ãªã®ã ã¨æãã¾ãã&lt;/li&gt;
&lt;li&gt;åææ§ãåä¸ãããããã«ãåºåã127.5 åããã¨ãããã¨ããä»¶ã§ãããåã¯ãã£ã¦ãã¾ããããªããªããåãã¾ã ãã®æ¹æ³ã®å¦¥å½æ§ãçè§£ã§ãã¦ããªãããã§ãã&lt;a href=&#34;https://twitter.com/__dhgrs__/status/995962302896599040&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;@__dhgrs__ããã®å ±å&lt;/a&gt; ã«ããã¨ããã¯ãæå¹ã«åãããã§ãã­â¦&lt;/li&gt;
&lt;li&gt;ããã¾ã &lt;a href=&#34;http://www.monthly-hack.com/entry/2018/02/23/203208&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;@__dhgrs__ããã®ãã­ã°è¨äº&lt;/a&gt; ã«ãæ¸ããã¦ãã¾ãããMixture of Logistic distributions (MoLã¨ãã¾ã) ãä½¿ã£ãå ´åã¯ãcategoricalãèãã¦softmaxãä½¿ãå ´åã«æ¯ã¹ãã¨ååãªåè³ªãå¾ãã®ã«å¤§å¹ã«è¨ç®æéãå¿è¦ã«ãªãã¾ãã­ããä½é¨çã«ã¯10åç¨åº¦ã§ããè¨ç®ã«ãã¾ãã«æéããããã®ã§ãã¹ã¯ã©ããã§ä½åº¦ãå­¦ç¿ããã®ã¯å³ãããå­¦ç¿æ¸ã¿ã¢ãã«ãä½åº¦ãç¹°ãè¿ãfine turningãã¦ããã¨ãããç§ä¼ã®ã¿ã¬æ¹å¼ã§å­¦ç¿ãè¡ãã¾ããï¼åç¾æ§ãªãã§ããæºæï¼&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/Rayhane-mamah/Tacotron-2&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/Rayhane-mamah/Tacotron-2&lt;/a&gt; ä»åä½¿ããã¦ããã£ãTaco2å®è£ã¯ãåã®å®è£ãä¸é¨ä½¿ããã¦ããããã§ãããããã¨ã¯å¥ã® NVIDIA ããåºã &lt;a href=&#34;https://github.com/NVIDIA/tacotron2&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/NVIDIA/tacotron2&lt;/a&gt; ã®è¬è¾ã«ã¯åã®ååãå¥ãã¦ããã ãã¦ããããä»ã«ãããããã±ã¼ã¹ããããªãã«ãã£ã¦ãç«¯çã«ãã£ã¦åæ ã§ããããããããæãã§ãã&lt;/li&gt;
&lt;li&gt;éå¬éã®ãã¼ã¿ã»ãããä½¿ã£ã¦å­¦ç¿/çæããWaveNet TTS ã®ãµã³ãã«ãããã¾ããå¬éã§ããªãã®ã§ããã«ã¯ããã¦ãã¾ããããã¨ã¦ãé«åè³ªãªé³å£°åæï¼ä¸»è¦³ã§ããï¼ãã§ãããã¨ãç¢ºèªãã¦ãã¾ã&lt;/li&gt;
&lt;li&gt;ãã®ãã­ã¸ã§ã¯ããã¯ããããã¨ã§ããªãã¨åæ ã«ã&lt;a href=&#34;http://www.nict.go.jp/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;NICT&lt;/a&gt;ã§ã®ãã¼ã¯ã®æ©ä¼ãããããã¨ãã§ãã¾ããããªã¼ãã½ã¼ã¹ã«ã¤ãã¦æ¯éã¯ããã¨æãã¾ãããåäººçã«ã¯è¯ããã¨ãã¨ã¦ãå¤ããªã¨æãã¾ãããã¬ã¼ã³è³æã¯ãhttps://github.com/r9y9/wavenet_vocoder/issues/57 ã«ç½®ãã¦ããã¾ãï¼ããã¹ã©ã¤ãã ãã§èª­ã¿ç©ã¨ãã¦æç«ãããã®ã§ã¯ãªãã¨æãã¾ãããã¿ã¾ããï¼&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;ãããã«&#34;&gt;ãããã«&lt;/h2&gt;
&lt;p&gt;WaveNet TTSãããããä½ããã¨ãã§ãã¾ãããSample-levelã§autoregressive modelãèããã¨ããã¢ãã­ã¼ããæ¬å½ã«åããã®ãçåã ã£ãã®ã§ãããå®éã«ä½ã£ã¦ã¿ã¦ãä¸æãè¡ãã¨ãããã¨ãä½æãããã¨ãã§ãã¾ããããã§ããã&lt;/p&gt;
&lt;p&gt;Googleã®ç ç©¶èãã¾ãç´ æ´ãããç ç©¶ããããã¨ããããã¾ããWaveNetã¯æ¬å½ã«ãããã£ã&lt;/p&gt;
&lt;h2 id=&#34;åè&#34;&gt;åè&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1609.03499&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Aaron van den Oord, Sander Dieleman, Heiga Zen, et al, &amp;ldquo;WaveNet: A Generative Model for Raw Audio&amp;rdquo;, 	arXiv:1609.03499, Sep 2016.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1711.10433&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Aaron van den Oord, Yazhe Li, Igor Babuschkin, et al, &amp;ldquo;Parallel WaveNet: Fast High-Fidelity Speech Synthesis&amp;rdquo;, 	arXiv:1711.10433, Nov 2017.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.isca-speech.org/archive/Interspeech_2017/pdfs/0314.PDF&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Tamamori, Akira, et al. &amp;ldquo;Speaker-dependent WaveNet vocoder.&amp;rdquo; Proceedings of Interspeech. 2017.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1712.05884&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Jonathan Shen, Ruoming Pang, Ron J. Weiss, et al, &amp;ldquo;Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions&amp;rdquo;, arXiv:1712.05884, Dec 2017.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1710.07654&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Wei Ping, Kainan Peng, Andrew Gibiansky, et al, &amp;ldquo;Deep Voice 3: 2000-Speaker Neural Text-to-Speech&amp;rdquo;, arXiv:1710.07654, Oct. 2017.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1611.09482&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Tom Le Paine, Pooya Khorrami, Shiyu Chang, et al, &amp;ldquo;Fast Wavenet Generation Algorithm&amp;rdquo;, arXiv:1611.09482, Nov. 2016&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.monthly-hack.com/entry/2018/02/23/203208&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;VQ-VAEã®è¿½è©¦ã§å¾ãWaveNetã®ãã¦ãã¦ãã¾ã¨ãã¦ã¿ãã - Monthly Hacker&amp;rsquo;s Blog&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;ææ§ãªè¡¨ç¾ã§ç³ãè¨³ãããã¾ãã&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;åãä½¿ã£ãå½æã¯ãWNã®é¨åã¯ååã«ãã¹ãããã¦ããªãã£ãã®ã¨ãWNã®ã³ã¼ãã¯åã®ã³ã¼ããtfã«translateããæããªï¼èèããããã£ã¦ã¾ãï¼ã®ã§ãWNã¯èªåã®å®è£ãä½¿ã£ãæ¬¡ç¬¬ã§ã&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;</description>
    </item>
    
    <item>
      <title>ã108 è©±èç·¨ãDeep Voice 3: 2000-Speaker Neural Text-to-Speech / arXiv:1710.07654 [cs.SD]</title>
      <link>https://r9y9.github.io/blog/2017/12/22/deepvoice3_multispeaker/</link>
      <pubDate>Fri, 22 Dec 2017 15:30:00 +0900</pubDate>
      <guid>https://r9y9.github.io/blog/2017/12/22/deepvoice3_multispeaker/</guid>
      <description>&lt;h2 id=&#34;summary&#34;&gt;Summary&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;è«æãªã³ã¯: &lt;a href=&#34;https://arxiv.org/abs/1710.07654&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;arXiv:1710.07654&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;ã³ã¼ã: &lt;a href=&#34;https://github.com/r9y9/deepvoice3_pytorch&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/r9y9/deepvoice3_pytorch&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;VCTK: &lt;a href=&#34;https://datashare.ed.ac.uk/handle/10283/2950&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://datashare.ed.ac.uk/handle/10283/2950&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;é³å£°ãµã³ãã«ã¾ã¨ã: &lt;a href=&#34;https://r9y9.github.io/deepvoice3_pytorch/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://r9y9.github.io/deepvoice3_pytorch/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;ä¸è¡ã¾ã¨ã&#34;&gt;ä¸è¡ã¾ã¨ã&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1710.07654&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;arXiv:1710.07654: Deep Voice 3: 2000-Speaker Neural Text-to-Speech&lt;/a&gt; ãèª­ãã§ãè¤æ°è©±èã®å ´åã®ã¢ãã«ãå®è£ãã¾ãã&lt;/li&gt;
&lt;li&gt;è«æã®ã¿ã¤ãã«éãã®2000è©±èã¨ã¯ããã¾ãããã&lt;a href=&#34;https://datashare.ed.ac.uk/handle/10283/2950&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;VCTK&lt;/a&gt; ãä½¿ã£ã¦ã108 è©±èå¯¾å¿ã®è±èªTTSã¢ãã«ãä½ãã¾ããï¼å­¦ç¿æé1æ¥ãããï¼&lt;/li&gt;
&lt;li&gt;å¥åããè©±èIDãå¤ãããã¨ã§ãä¸ã¤ã®ã¢ãã«ã§ããªã¨ã¼ã·ã§ã³ã«å¯ãã é³å£°ãµã³ãã«ãçæã§ãããã¨ãç¢ºèªãã¾ãã&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;æ¦è¦&#34;&gt;æ¦è¦&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://r9y9.github.io/blog/2017/12/13/deepvoice3/&#34;&gt;ãåä¸è©±èç·¨ãDeep Voice 3: 2000-Speaker Neural Text-to-Speech / arXiv:1710.07654 [cs.SD]&lt;/a&gt; ã®ç¶ç·¨ã§ãã&lt;/p&gt;
&lt;p&gt;è«ææ¦è¦ã¯ååç´¹ä»ãããã®ã¨åããªã®ã§ãè©±èã®æ¡ä»¶ä»ãã®é¨åã«ã¤ãã¦ã®ã¿ç°¡åã«è¿°ã¹ã¾ãããªããè©±èã®æ¡ä»¶ä»ãã«é¢ãã¦ã¯ãDeepVoice2ã®è«æ (&lt;a href=&#34;https://arxiv.org/abs/1705.08947&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;arXiv:1705.08947 [cs.CL]&lt;/a&gt;) ã®æ¹ãè©³ããã§ãã&lt;/p&gt;
&lt;p&gt;ã¾ãåºæ¬çã«ãè©±èã®æå ±ã¯ trainable embedding ã¨ãã¦ã¢ãã«ã«çµã¿è¾¼ã¿ã¾ããtext embeddingã®ãããã«ãããã¯ã¼ã¯ã®å¥åã®ä¸ç®æã«å¥ãããããªè¨­è¨ã§ã¯å­¦ç¿ãä¸æãããªãï¼è©±èæå ±ãç¡è¦ããããã«ãªã£ã¦ãã¾ãã®ã ã¨æãã¾ãï¼ããããããã¯ã¼ã¯ã®ããããã¨ããã«å¥ããã®ããã¤ã³ãã®ããã§ããå·ä½çã«ã¯ãEncoder, Decoder (+ Attention), Converterã®ãã¹ã¦ã«å¥ãã¾ããããã«å·ä½çã«ã¯ããããã¯ã¼ã¯ã®åºæ¬è¦ç´ ã§ãã Gated linear unit + Conv1d ã®ãã¹ã¦ã«å¥ãã¾ããè©³ç´°ã¯è«æã«è¨è¼ã®architectureã®å³ãåç§ãã¦ãã ããã&lt;/p&gt;
&lt;p&gt;è©±èã®æ¡ä»¶ä»ãã«é¢ãã¦ãä¸ã¤æ³¨æãå ããã¨ããã°ãæ¬è«æã«ã¯æç¤ºçã«æ¸ããã¦ãã¾ãããã speaker embeddingã¯åæéstepãã¹ã¦ã«expandãã¦ç¨ããã®ã ã¨æãã¾ãï¼ã§ãªãã¨å®è£ããã¨ãã«å°ãï¼ãDeepVoice2ã®è«æã«ã¯ãã®æ¨ãæç¤ºçã«æ¸ããã¦ãã¾ãã&lt;/p&gt;
&lt;h2 id=&#34;vctk-ã®åå¦ç&#34;&gt;VCTK ã®åå¦ç&lt;/h2&gt;
&lt;p&gt;å®é¨ã«å¥ãåã«ãVCTKã®åå¦çã«ã¤ãã¦ãç°¡åã«ã¾ã¨ãããã¨æãã¾ããVCTKã®é³å£°ãã¼ã¿ã«ã¯ãæ°ç§ã«æ¸¡ãç¡é³åºéããããªãã«å¥ã£ã¦ããã®ã§ããããåãé¤ãå¿è¦ãããã¾ããä»¥åã&lt;a href=&#34;https://r9y9.github.io/blog/2017/11/12/jsut_ver1/&#34;&gt;æ¥æ¬èª End-to-end é³å£°åæã«ä½¿ããã³ã¼ãã¹ JSUT ã®åå¦ç&lt;/a&gt; ã§æ¸ããåå®¹ã¨åãããã«ãé³ç´ ã¢ã©ã¤ã¡ã³ããåã£ã¦ç¡é³åºéãé¤å»ãã¾ããåã¯ä»¥ä¸ã®äºã¤ã®æ¹æ³ããããã¾ããã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/lowerquality/gentle&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Gentle&lt;/a&gt; (&lt;a href=&#34;https://github.com/kaldi-asr/kaldi&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Kaldi&lt;/a&gt;ãã¼ã¹)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/CSTR-Edinburgh/merlin&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Merlin&lt;/a&gt; ä»å±ã®ã¢ã©ã¤ã¡ã³ããã¼ã« (&lt;a href=&#34;http://festvox.org/cmu_arctic/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;festvox&lt;/a&gt;ãã¼ã¹) (&lt;a href=&#34;https://gist.github.com/kastnerkyle/cc0ac48d34860c5bb3f9112f4d9a0300&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ä¾¿å©ã¹ã¯ãªãã&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;è«æä¸­ã«ã¯ãï¼ç¡é³é¤å»ã®ãããã¨ããæèã§ã¯ãªãã®ã§ãã&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;ï¼Gentleãä½¿ã£ãæ¨ãæ¸ããã¦ãã¾ããããããè©¦ããã¨ããã¢ã©ã¤ã¡ã³ããå¤±æããã±ã¼ã¹ããããªãã«ããã&lt;a href=&#34;https://github.com/facebookresearch/loop&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;loop&lt;/a&gt; ã¯å¾èã®æ¹æ³ãç¨ãã¦ããè¯ãçµæãåºã¦ãããã¨ãããçµè«ã¨ãã¦ã¯åã¯å¾èãæ¡ç¨ãã¾ããããªããä¸¡æ¹ã®ã³ã¼ãã¯æ®ãã¦ããã®ã§ãæ°ã«ãªãæ¹ã¯ä¸¡æ¹ãããã¦ã¿ã¦ãã ããã&lt;/p&gt;
&lt;h2 id=&#34;å®é¨&#34;&gt;å®é¨&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://datashare.ed.ac.uk/handle/10283/2950&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;VCTK&lt;/a&gt; ã®108è©±èåã®ãã¹ã¦&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;ãä½¿ç¨ãã¦ã20æéãããï¼30ä¸ã¹ããã x 2ï¼å­¦ç¿ãã¾ããã30ä¸ã¹ãããå­¦ç¿ããå¾ã§ããã¢ãã«ããã¼ã¹ã«ãããã«30ä¸ã¹ãããå­¦ç¿ãã¾ãã&lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;ãã¢ãã«ã¯ãåä¸è©±èã®å ´åã¨ã»ã¨ãã©åãã§ãããå¤æ´ãå ããç¹ãä»¥ä¸ã«ã¾ã¨ãã¾ãã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;å±é&lt;/strong&gt;: Speaker embedding ãè¿½å ãã¾ããã&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;å±é&lt;/strong&gt;: Speaker embeddingããã¹ã¦ã®æéã¹ãããã«expandãããã¨ãDropoutãé©ç¨ããããã«ãã¾ããï¼è«æã«ã¯æ¸ãã¦ãã¾ããããçµè«ããè¨ãã°éè¦ã§ããâ¦ï¼&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Decoder&lt;/strong&gt;: ã¢ãã³ã·ã§ã³ã®ã¬ã¤ã¤ã¼æ°ã2ãã1ã«æ¸ããã¾ãã&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;è¨ç®éåº¦ã¯ãããããµã¤ãº16ã§ã8.6 step/sec ãããã§ãããGPUã¡ã¢ãªã®ä½¿ç¨éã¯9GBç¨åº¦ã§ãããConvolution Blockãã¨ã«Linearã¬ã¤ã¤ã¼ãè¿½å ãããã®ã§ããããªãã«ã¡ã¢ãªä½¿ç¨éãå¢ãã¾ããPyTorch v0.3.0ãä½¿ãã¾ããã&lt;/p&gt;
&lt;p&gt;å­¦ç¿ã«ä½¿ç¨ããã³ãã³ãã¯ä»¥ä¸ã§ãã&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;python train.py --data-root=./data/vctk --checkpoint-dir=checkpoints_vctk \
   --hparams=&amp;quot;preset=deepvoice3_vctk,builder=deepvoice3_multispeaker&amp;quot; \
   --log-event-path=log/deepvoice3_multispeaker_vctk_preset \
   --load-embedding=20171221_deepvoice3_checkpoint_step000300000.pth
 # &amp;lt;&amp;lt; 30ä¸ã¹ãããã§ä¸æ¦æã¡åã &amp;gt;&amp;gt;
 # ããä¸åº¦0ãã30ä¸ã¹ãããã¾ã§å­¦ç¿ããªãã
 python train.py --data-root=./data/vctk --checkpoint-dir=checkpoints_vctk_fineturn \
   --hparams=&amp;quot;preset=deepvoice3_vctk,builder=deepvoice3_multispeaker&amp;quot; \
   --log-event-path=log/deepvoice3_multispeaker_vctk_preset_fine \
   --restore-parts=./checkpoints_vctk/checkpont_step000300000.pth
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;å­¦ç¿ãé«éåãããããLJSpeechã§30ä¸ã¹ãããå­¦ç¿ããã¢ãã«ã®embeddingã®é¨åãåå©ç¨ãã¾ãããã¾ããcyclic annealingã®ãããªå¹æãå¾ããããã¨ãæå¾ãã¦ãä¸åº¦å­¦ç¿ãæã¡åã£ã¦ãããã«0stepãããã¡ã¤ã³ãã¥ã¼ãã³ã°ãã¦ã¿ã¾ããã&lt;/p&gt;
&lt;p&gt;ã³ã¼ãã®ã³ãããããã·ã¥ã¯ &lt;a href=&#34;https://github.com/r9y9/deepvoice3_pytorch/tree/0421749af908905d181f089f06956fddd0982d47&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;0421749&lt;/a&gt; ã§ããæ­£ç¢ºãªãã¤ãã¼ãã©ã¡ã¼ã¿ãç¥ãããå ´åã¯ãããããè¾¿ããã¨æãã¾ãã&lt;/p&gt;
&lt;h3 id=&#34;ã¢ã©ã¤ã¡ã³ãã®å­¦ç¿éç¨-30ä¸ã¹ããã&#34;&gt;ã¢ã©ã¤ã¡ã³ãã®å­¦ç¿éç¨ (~30ä¸ã¹ããã)&lt;/h3&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/images/deepvoice3_multispeaker/alignments.gif&#34; /&gt;&lt;/div&gt;
&lt;h3 id=&#34;å­¦ç¿ããã-speaker-embedding-ã®å¯è¦å&#34;&gt;å­¦ç¿ããã Speaker embedding ã®å¯è¦å&lt;/h3&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/images/deepvoice3_multispeaker/speaker_embedding.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;è«æã®appendixã«æ¸ããã¦ããã®ã¨åãããã«ãå­¦ç¿ãããEmbeddingã«å¯¾ãã¦PCAãããã¦å¯è¦åãã¾ãããè«æã®å³ã¨ã¯å°ãç°ãªãã¾ãããæå¾éããç·å¥³ã¯ã»ã¼ç·å½¢åé¢ã§ããããã«ãªã£ã¦ãããã¨ã¯ç¢ºèªã§ãã¾ããã&lt;/p&gt;
&lt;h3 id=&#34;é³å£°ãµã³ãã«&#34;&gt;é³å£°ãµã³ãã«&lt;/h3&gt;
&lt;p&gt;æåã«åã®ææ³ãè¿°ã¹ã¦ããã¨ãLJSpeechã§åä¸è©±èã¢ãã«ãå­¦ç¿ããå ´åã¨æ¯ã¹ãã¨ãæ±åãã«ããå°è±¡ãããã¾ãããæå­ãã¹ã­ãããããã¨ãã£ãã¨ã©ã¼ã±ã¼ã¹ãæ¯è¼ãã¦å¤ãããã«æãã¾ããã
ãããããµã³ãã«ãè²¼ãã®ã¯å¤§å¤ãªã®ã§ãèå³ã®ããæ¹ã¯èªåã§é©å½ãªæªç¥ãã­ã¹ããä¸ãã¦åæãã¦ã¿ã¦ãã ãããå­¦ç¿æ¸ã¿ã¢ãã«ã¯ &lt;a href=&#34;https://github.com/r9y9/deepvoice3_pytorch#pretrained-models&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;deepvoice3_pytorch#pretrained-models&lt;/a&gt; ãããã¦ã³ã­ã¼ãã§ããããã«ãã¦ããã¾ãã&lt;/p&gt;
&lt;h3 id=&#34;loophttpsytaigmangithubioloopnetwork-3-multiple-speakers-from-vctk-ã¨åãæç« &#34;&gt;&lt;a href=&#34;https://ytaigman.github.io/loop/#network-3-multiple-speakers-from-vctk&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Loop&lt;/a&gt; ã¨åãæç« &lt;/h3&gt;
&lt;p&gt;Some have accepted this as a miracle without any physical explanation&lt;/p&gt;
&lt;p&gt;(69 chars, 11 words)&lt;/p&gt;
&lt;p&gt;speaker IDãè¥ãé ã«12ãµã³ãã«ã®è©±èID ãä¸ãã¦ãåæããçµæãè²¼ã£ã¦ããã¾ãã&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;225, 23,  F,    English,    Southern,  England&lt;/strong&gt; (ID, AGE,  GENDER,  ACCENTS,  REGION)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/deepvoice3_multispeaker/loop/0_20171222_deepvoice3_vctk108_checkpoint_step000300000_speaker0.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;&lt;strong&gt;226,  22,  M,    English,    Surrey&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/deepvoice3_multispeaker/loop/0_20171222_deepvoice3_vctk108_checkpoint_step000300000_speaker1.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;&lt;strong&gt;227,  38,  M,    English,    Cumbria&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/deepvoice3_multispeaker/loop/0_20171222_deepvoice3_vctk108_checkpoint_step000300000_speaker2.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;&lt;strong&gt;228,  22,  F,    English,    Southern  England&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/deepvoice3_multispeaker/loop/0_20171222_deepvoice3_vctk108_checkpoint_step000300000_speaker3.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;&lt;strong&gt;229,  23,  F,    English,    Southern  England&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/deepvoice3_multispeaker/loop/0_20171222_deepvoice3_vctk108_checkpoint_step000300000_speaker4.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;&lt;strong&gt;230,  22,  F,    English,    Stockton-on-tees&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/deepvoice3_multispeaker/loop/0_20171222_deepvoice3_vctk108_checkpoint_step000300000_speaker5.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;&lt;strong&gt;231,  23,  F,    English,    Southern  England&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/deepvoice3_multispeaker/loop/0_20171222_deepvoice3_vctk108_checkpoint_step000300000_speaker6.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;&lt;strong&gt;232,  23,  M,    English,    Southern  England&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/deepvoice3_multispeaker/loop/0_20171222_deepvoice3_vctk108_checkpoint_step000300000_speaker7.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;&lt;strong&gt;233,  23,  F,    English,    Staffordshire&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/deepvoice3_multispeaker/loop/0_20171222_deepvoice3_vctk108_checkpoint_step000300000_speaker8.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;&lt;strong&gt;234,  22,  F,    Scottish,  West  Dumfries&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/deepvoice3_multispeaker/loop/0_20171222_deepvoice3_vctk108_checkpoint_step000300000_speaker9.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;&lt;strong&gt;236,  23,  F,    English,    Manchester&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/deepvoice3_multispeaker/loop/0_20171222_deepvoice3_vctk108_checkpoint_step000300000_speaker10.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;&lt;strong&gt;237,  22,  M,    Scottish,  Fife&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/deepvoice3_multispeaker/loop/0_20171222_deepvoice3_vctk108_checkpoint_step000300000_speaker11.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;å£°è³ªã ãã§ãªããè©±éã«ãããªã¨ã¼ã·ã§ã³ãåºã¦ããã®ããããã¾ãã&lt;code&gt;231&lt;/code&gt; ã®æåã§ä¸é¨é³ãæ¶ãã¦ãã¾ãï¼ãããã£ãã¨ã©ã¼ã±ã¼ã¹ã¯ããããã¾ãï¼ã&lt;/p&gt;
&lt;h4 id=&#34;keithitotacotron-ã®ãµã³ãã«httpskeithitogithubioaudio-samples-ã¨åãæç« &#34;&gt;&lt;a href=&#34;https://keithito.github.io/audio-samples/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;keithito/tacotron ã®ãµã³ãã«&lt;/a&gt; ã¨åãæç« &lt;/h4&gt;
&lt;p&gt;ç°¡åã«æ±åæ§è½ããã§ãã¯ããããã«ãæªç¥æç« ã§ãã¹ããã¾ãã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ç·æ§ (292,  23,  M,    NorthernIrish,  Belfast)&lt;/li&gt;
&lt;li&gt;å¥³æ§ (288,  22,  F,    Irish,  Dublin)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ã®äºã¤ã®ãµã³ãã«ãè²¼ã£ã¦ããã¾ãã&lt;/p&gt;
&lt;p&gt;Scientists at the CERN laboratory say they have discovered a new particle.&lt;/p&gt;
&lt;p&gt;(74 chars, 13 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/deepvoice3_multispeaker/3_keithito/0_20171222_deepvoice3_vctk108_checkpoint_step000300000_speaker62.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/deepvoice3_multispeaker/3_keithito/0_20171222_deepvoice3_vctk108_checkpoint_step000300000_speaker62_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/deepvoice3_multispeaker/3_keithito/0_20171222_deepvoice3_vctk108_checkpoint_step000300000_speaker61.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/deepvoice3_multispeaker/3_keithito/0_20171222_deepvoice3_vctk108_checkpoint_step000300000_speaker61_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;There&amp;rsquo;s a way to measure the acute emotional intelligence that has never gone out of style.&lt;/p&gt;
&lt;p&gt;(91 chars, 18 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/deepvoice3_multispeaker/3_keithito/1_20171222_deepvoice3_vctk108_checkpoint_step000300000_speaker62.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/deepvoice3_multispeaker/3_keithito/1_20171222_deepvoice3_vctk108_checkpoint_step000300000_speaker62_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/deepvoice3_multispeaker/3_keithito/1_20171222_deepvoice3_vctk108_checkpoint_step000300000_speaker61.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/deepvoice3_multispeaker/3_keithito/1_20171222_deepvoice3_vctk108_checkpoint_step000300000_speaker61_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;President Trump met with other leaders at the Group of 20 conference.&lt;/p&gt;
&lt;p&gt;(69 chars, 13 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/deepvoice3_multispeaker/3_keithito/2_20171222_deepvoice3_vctk108_checkpoint_step000300000_speaker62.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/deepvoice3_multispeaker/3_keithito/2_20171222_deepvoice3_vctk108_checkpoint_step000300000_speaker62_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/deepvoice3_multispeaker/3_keithito/2_20171222_deepvoice3_vctk108_checkpoint_step000300000_speaker61.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/deepvoice3_multispeaker/3_keithito/2_20171222_deepvoice3_vctk108_checkpoint_step000300000_speaker61_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;The Senate&amp;rsquo;s bill to repeal and replace the Affordable Care Act is now imperiled.&lt;/p&gt;
&lt;p&gt;(81 chars, 16 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/deepvoice3_multispeaker/3_keithito/3_20171222_deepvoice3_vctk108_checkpoint_step000300000_speaker62.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/deepvoice3_multispeaker/3_keithito/3_20171222_deepvoice3_vctk108_checkpoint_step000300000_speaker62_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/deepvoice3_multispeaker/3_keithito/3_20171222_deepvoice3_vctk108_checkpoint_step000300000_speaker61.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/deepvoice3_multispeaker/3_keithito/3_20171222_deepvoice3_vctk108_checkpoint_step000300000_speaker61_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;Generative adversarial network or variational auto-encoder.&lt;/p&gt;
&lt;p&gt;(59 chars, 7 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/deepvoice3_multispeaker/3_keithito/4_20171222_deepvoice3_vctk108_checkpoint_step000300000_speaker62.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/deepvoice3_multispeaker/3_keithito/4_20171222_deepvoice3_vctk108_checkpoint_step000300000_speaker62_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/deepvoice3_multispeaker/3_keithito/4_20171222_deepvoice3_vctk108_checkpoint_step000300000_speaker61.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/deepvoice3_multispeaker/3_keithito/4_20171222_deepvoice3_vctk108_checkpoint_step000300000_speaker61_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;The buses aren&amp;rsquo;t the problem, they actually provide a solution.&lt;/p&gt;
&lt;p&gt;(63 chars, 13 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/deepvoice3_multispeaker/3_keithito/5_20171222_deepvoice3_vctk108_checkpoint_step000300000_speaker62.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/deepvoice3_multispeaker/3_keithito/5_20171222_deepvoice3_vctk108_checkpoint_step000300000_speaker62_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/deepvoice3_multispeaker/3_keithito/5_20171222_deepvoice3_vctk108_checkpoint_step000300000_speaker61.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/deepvoice3_multispeaker/3_keithito/5_20171222_deepvoice3_vctk108_checkpoint_step000300000_speaker61_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;ã¨ããã©ããé³ãæãã¦ããã®ãç®ç«ã¡ã¾ããè²ãå®é¨ãã¾ãããããã¯ãåä¸è©±è 24hã®ãã¼ã¿ã§å­¦ç¿ããã¢ãã«ã«æ¯ã¹ãã¨ãä¸è©±èããã30å~1hç¨åº¦ã®ãã¼ã¿ã§ã¯ãæ±åãããã®ãé£ããå°è±¡ãæã¡ã¾ããã&lt;/p&gt;
&lt;h2 id=&#34;ã¾ã¨ã&#34;&gt;ã¾ã¨ã&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;è¤æ°è©±èçã®DeepVoice3ãå®è£ãã¦ãå®éã«108è©±èã®ãã¼ã¿ã»ããã§å­¦ç¿ãããããªãã«åããã¨ãç¢ºèªã§ãã¾ãã&lt;/li&gt;
&lt;li&gt;è¤æ°è©±èçã®DeepVoice3ã§ã¯ãã¢ãã³ã·ã§ã³ã®å­¦ç¿ãåä¸è©±èã®å ´åã¨æ¯ã¹ã¦é£ããå°è±¡ã§ãããã¢ãã³ã·ã§ã³ã¬ã¤ã¤ã¼ã®æ°ã2ãã1ã«æ¸ããã¨ãã¢ã©ã¤ã¡ã³ãããã£ããããå¾åã«ãããã¨ãç¢ºèªãã¾ããã&lt;/li&gt;
&lt;li&gt;VCTKã®åå¦çå¤§äºããã¡ãã¨ãã¾ããã&lt;/li&gt;
&lt;li&gt;Speaker embedding ã«Dropoutããããã®ã¯ãè«æã«ã¯è¨è¼ããã¦ãã¾ããããçµæããè¨ã£ã¦éè¦ã§ããããªãã¨ãé³å£°ã®åè³ªä»¥åã®åé¡ã¨ãã¦ãæå­ãæ­£ããçºé³ãããªããã¨ãã£ãç¾è±¡ã«é­éãã¾ããã&lt;/li&gt;
&lt;li&gt;Speaker embedding ããã¹ã¦ã®æå»ã«åä¸ã®å¤ãexpandãã¦ãã¾ãã¨éå­¦ç¿ããããã®ã§ã¯ãªããããäºæ¸¬ãåã«ãåæå»ã§ã©ã³ãã æ§ãããããã¨ã§ãã®åé¡ãç·©åã§ããªããã¨èããDropoutãè¶³ãã¦ã¿ã¾ãããä¸æãè¨ã£ãããã«æãã¾ã&lt;/li&gt;
&lt;li&gt;è«æã®åå®¹ã«ã¤ãã¦è©³ããè§¦ãã¦ãã¾ããããå®ã¯ãã£ããéã¨ããããæç« ã¨å³ã«ä¸ä¸è´ããã£ãããã¾ãï¼ä¾ãã°å³1ã«ããEncoder PreNet/PostNet ã¯æç« ä¸­ã§èª¬æããªãï¼ãèèã«é£çµ¡ãã¦ç¢ºèªããã®ãä¸çªè¯ãã®ã§ãããã©ãããã¢ãã«ãªãä¸æããããèãã¦è©¦è¡é¯èª¤ããã®ãæ¥½ããã®ã§ãä»åã¯é°å²æ°ã§å®è£ãã¾ããããããªãã«ä¸æãåãã¦ããããã«æãã¾ã&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;æ¬¡ã¯ãDeepVoice3ãTacotron 2 (&lt;a href=&#34;https://arxiv.org/abs/1712.0588&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;arXiv:1712.05884 [cs.CL]&lt;/a&gt;) ã§æå¹æ§ãç¤ºããã¦ãã WaveNet Vocoder ãå®è£ãã¦ãåè³ªãæ¹åãã¦ã¿ããã¨æã£ã¦ãã¾ãã&lt;/p&gt;
&lt;h2 id=&#34;åè&#34;&gt;åè&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1710.07654&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Wei Ping, Kainan Peng, Andrew Gibiansky, et al, &amp;ldquo;Deep Voice 3: 2000-Speaker Neural Text-to-Speech&amp;rdquo;, arXiv:1710.07654, Oct. 2017.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1705.08947&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Sercan Arik, Gregory Diamos, Andrew Gibiansky,, et al, &amp;ldquo;Deep Voice 2: Multi-Speaker Neural Text-to-Speech&amp;rdquo;, arXiv:1705.08947, May 2017.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1712.05884&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Jonathan Shen, Ruoming Pang, Ron J. Weiss, et al, &amp;ldquo;Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions&amp;rdquo;, arXiv:1712.05884, Dec 2017.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;é¢é£è¨äº&#34;&gt;é¢é£è¨äº&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://r9y9.github.io/blog/2017/12/13/deepvoice3/&#34;&gt;ãåä¸è©±èç·¨ãDeep Voice 3: 2000-Speaker Neural Text-to-Speech / arXiv:1710.07654 [cs.SD] | LESS IS MORE&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://r9y9.github.io/blog/2017/11/23/dctts/&#34;&gt;Efficiently Trainable Text-to-Speech System Based on Deep Convolutional Networks with Guided Attention. [arXiv:1710.08969] | LESS IS MORE&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://r9y9.github.io/blog/2017/11/12/jsut_ver1/&#34;&gt;æ¥æ¬èª End-to-end é³å£°åæã«ä½¿ããã³ã¼ãã¹ JSUT ã®åå¦ç | LESS IS MORE&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;VCTKã®ç¡é³åºéé¤å»ã®ããã¨ããæèã§ã¯ãªãããã­ã¹ãã«short pause / long pause ãæ¿å¥ããããã§ã&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;transcriptionããªã1è©±è (p315) ã®ãã¼ã¿ã¯é¤ãã¦ãã¾ã&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Dropoutããã¤ãããã¨ã­ã¹ãä¸ããã«ãããä¸æ¹ã§ãããããã¨æ±åãã«ããå°è±¡ãããã¾ãããã®ã§ãDropoutãã¤ãã§ããç¨åº¦æ±åããããã¨ãDropoutããããã«ãã¦fine turningãããã¨ãã£ãæ¦ç¥ãåã£ã¦ã¿ã¾ããã&amp;#160;&lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
    </item>
    
    <item>
      <title>ãåä¸è©±èç·¨ãDeep Voice 3: 2000-Speaker Neural Text-to-Speech / arXiv:1710.07654 [cs.SD]</title>
      <link>https://r9y9.github.io/blog/2017/12/13/deepvoice3/</link>
      <pubDate>Wed, 13 Dec 2017 12:15:00 +0900</pubDate>
      <guid>https://r9y9.github.io/blog/2017/12/13/deepvoice3/</guid>
      <description>&lt;h2 id=&#34;summary&#34;&gt;Summary&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;è«æãªã³ã¯: &lt;a href=&#34;https://arxiv.org/abs/1710.07654&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;arXiv:1710.07654&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;ã³ã¼ã: &lt;a href=&#34;https://github.com/r9y9/deepvoice3_pytorch&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/r9y9/deepvoice3_pytorch&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;ä¸è¡ã¾ã¨ã&#34;&gt;ä¸è¡ã¾ã¨ã&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1710.07654&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;arXiv:1710.07654: Deep Voice 3: 2000-Speaker Neural Text-to-Speech&lt;/a&gt; ãèª­ãã§ãåä¸è©±èã®å ´åã®ã¢ãã«ãå®è£ãã¾ããï¼è¤æ°è©±èã®å ´åã¯ãä»å®é¨ä¸­ã§ã (&lt;a href=&#34;https://github.com/r9y9/deepvoice3_pytorch/pull/6&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;deepvoice3_pytorch/#6&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1710.08969&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;arXiv:1710.08969&lt;/a&gt; ã¨åãããRNNã§ã¯ãªãCNNãä½¿ãã®ãèã§ã&lt;/li&gt;
&lt;li&gt;ä¾ã«ãã£ã¦ &lt;a href=&#34;https://keithito.com/LJ-Speech-Dataset/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;LJSpeech Dataset&lt;/a&gt; ãä½¿ã£ã¦ãè±èªTTSã¢ãã«ãä½ãã¾ããï¼å­¦ç¿æéåæ¥ãããï¼ãè«æã«è¨è¼ã®ãã¤ãã¼ãã©ã¡ã¼ã¿ã§ã¯è¯ãçµæãå¾ãããªãã£ãã®ã§ããã&lt;a href=&#34;https://arxiv.org/abs/1710.08969&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;arXiv:1710.08969&lt;/a&gt; ã®ã¢ã¤ãã¢ãããã¤ãåãããã¨ã§ãè¯ãçµæãå¾ããã¨ãã§ãã¾ããã&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;æ¦è¦&#34;&gt;æ¦è¦&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://r9y9.github.io/blog/2017/11/23/dctts/&#34;&gt;Efficiently Trainable Text-to-Speech System Based on Deep Convolutional Networks with Guided Attention. [arXiv:1710.08969]&lt;/a&gt; ã§ç´¹ä»ããæ¹æ³ã¨ãã¢ããã¼ã·ã§ã³ãåºæ¬çãªæ¹æ³è«ã¯ã¾ã£ããåãã®ããçç¥ãã¾ããã¢ãã«ã®ã¢ã¼ã­ãã¯ãã£ãç°ãªãã¾ããããã®ç¹ã«ã¤ãã¦ãååè¿°ã¹ãã®ã§ããã¡ããåç§ãã ããã
ä»åã®è¨äºã§ã¯ãDeepVoice3ã®ã¢ã¼ã­ãã¯ãã£ããã¼ã¹ã«ããæ¹æ³ã§ã®å®é¨çµæãã¾ã¨ãã¾ãã&lt;/p&gt;
&lt;h2 id=&#34;äºåå®é¨&#34;&gt;äºåå®é¨&lt;/h2&gt;
&lt;p&gt;ã¯ããã«ãå¯è½ãªéãè«æã«å¿ å®ã«ãè«æã«è¨è¼ã®ã¢ãã«ã¢ã¼ã­ãã¯ãã£ããã¤ãã¼ãã©ã¡ã¼ã¿ã§ãã¬ã¤ã¤ã¼æ°ãConvã¬ã¤ã¤ã¼ã®ã«ã¼ãã«æ°ãè¥å¹²å¢ãããã¢ãã«ã§è©¦ãã¾ãããï¼å¢ãããªãã¨ãLJSpeechã§ã¯ã¤ã³ããã¼ã·ã§ã³ãæªããé³å£°ãçæããã¦ãã¾ãã¾ããï¼ãããããã©ããããã©ã¼ããããã£ããããªé³å£°ãçæãããå¾åã«ããã¾ãããè²ãè©¦è¡é¯èª¤ãã¦æ¹è¯ããã®ã§ãããè©³ç´°ã¯å¾è¿°ããã¨ãã¦ãæ¹è¯å/æ¹è¯å¾ã®é³å£°ãµã³ãã«ãä»¥ä¸ã«ç¤ºãã¾ãã&lt;/p&gt;
&lt;p&gt;Generative adversarial network or variational auto-encoder.&lt;/p&gt;
&lt;p&gt;(59 chars, 7 words)&lt;/p&gt;
&lt;p&gt;æ¹è¯åï¼&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/deepvoice3/yobi/3_checkpoint_step000530000.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;æ¹è¯å¾ï¼&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/deepvoice3/yobi/4_checkpoint_step000210000.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;ãããã§ãããããçµæ§éãã¾ããã­ããªããæ¹è¯åã®ã¢ãã«ã¯53ä¸ã¤ãã¬ã¼ã·ã§ã³ãæ¹è¯å¾ã¯21ä¸ã¤ãã¬ã¼ã·ã§ã³å­¦ç¿ãã¾ãããåæ°ãå¢ããã°ããã¨ãããã®ã§ã¯ãªãããã§ãï¼å½ããåã§ããï¼ãçµè«ããããã¨ãã¢ãã«ã®èªç±åº¦ãè¶³ããªãã£ãã®ãåè³ªãåä¸ãã«ããã£ãåå ã§ã¯ãªããã¨èãã¦ãã¾ãã&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2017/12/21 è¿½è¨&lt;/strong&gt;ï¼ããã¾ããã21ä¸ã¤ãã¬ã¼ã·ã§ã³ã®ã¢ãã«ã¯ãä½ãããå¥ã®äºåå­¦ç¿ããã¢ãã«ãããããã«å­¦ç¿ãããããªæ°ããã¦ãã¾ããâ¦ããã ãåè¨ã§53ä¸ãã¤ãã¬ã¼ã·ã§ã³ãã¦ããªãã®ã¯ééããªãã¨æãã¾ãç³ãè¨³ãããã¾ãã&lt;/p&gt;
&lt;h2 id=&#34;å®é¨&#34;&gt;å®é¨&lt;/h2&gt;
&lt;p&gt;ååã¨åãã &lt;a href=&#34;https://keithito.com/LJ-Speech-Dataset/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;LJSpeech Dataset&lt;/a&gt; ãä½¿ã£ã¦ã11æéãããï¼21ä¸ã¹ãããï¼å­¦ç¿ãã¾ãããã¢ãã«ã¯ãDeepVoice3ã§ææ¡ããã¦ãããã®ãå°ããããã¾ãããã©ã®ãããªå¤æ´ãããã®ããä»¥ä¸ã«ã¾ã¨ãã¾ãã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Encoder&lt;/strong&gt;: ã¬ã¤ã¤ã¼æ°ãå¢ããããã£ã³ãã«æ°ãå¤§ãããã¾ãããä»£ããã«ã«ã¼ãã«æ°ã¯7ãã3ã«æ¸ããã¾ãã&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Decoder&lt;/strong&gt;: ã¡ã«å¨æ³¢æ°ã¹ãã¯ãã­ã°ã©ã ã®è¤æ°ãã¬ã¼ã ãDecoderã®1-stepã§äºæ¸¬ããã®ã§ã¯ãªãã&lt;a href=&#34;https://arxiv.org/abs/1710.08969&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;arXiv:1710.08969&lt;/a&gt; ã§è¿°ã¹ããã¦ããããã«ã1-stepã§ï¼ç²ãï¼1ãã¬ã¼ã ãäºæ¸¬ãã¦ãConvTransposed1d ã«ããåã®æéè§£ååº¦ã¾ã§ã¢ãããµã³ããªã³ã°ããï¼è¦ã¯æéæ¹åã®ã¢ãããµã³ããªã³ã°ãã¢ãã«ã§å­¦ç¿ããï¼ããã«ãã¾ãã&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Decoder&lt;/strong&gt;: ã¢ãã³ã·ã§ã³ã®åã«ãããã¤ãConv1d + ReLUãè¶³ãã¾ãã&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Converter&lt;/strong&gt;: ConvTransposed1dãäºã¤å¥ãã¦ãæéè§£ååº¦ã4åã«ã¢ãããµã³ããªã³ã°ããããã«ãã¾ãã&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Converter&lt;/strong&gt;: ãã£ã³ãã«æ°ãå¤§ãããã¾ãã&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Decoder/Converter&lt;/strong&gt;: ã¬ã¤ã¤ã¼ã®æå¾ã«Sigmoidãè¿½å ãã¾ãã&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Loss&lt;/strong&gt;: Guided attention lossãå ãã¾ãã&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Loss&lt;/strong&gt;: Binary divergenceãå ãã¾ãã&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;å±é&lt;/strong&gt;: Linearã1x1 convolutionã«å¤ãã¾ãããDilationãå¤§ããã¨ãã¾ãã&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ä¸è¨å¤æ´ç¹ã«ã¤ãã¦ãæ¬æ¥ãªãã°ãExtensiveã«å®é¨ãã¦ãã©ããã©ã®ç¨åº¦æå¹ãèª¿ã¹ãã®ãä¸çªè¯ãã®ã§ãããè¨ç®è³æºã®é½åã«ãããé¨åçã«ãããã£ã¦ãã¾ããï¼ããã¾ããï¼ãé¨åçã¨ã¯ãããããã£ããã¨ã¯æå¾ã«ã¾ã¨ãã¦ããã¾ãã&lt;/p&gt;
&lt;p&gt;è¨ç®éåº¦ã¯ãããããµã¤ãº16ã§ã5.3 step/sec ãããã®è¨ç®éåº¦ã§ããã&lt;a href=&#34;https://arxiv.org/abs/1710.08969&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;arXiv:1710.08969&lt;/a&gt; ããã¯è¥å¹²éããããã§ããGPUã¡ã¢ãªã®ä½¿ç¨éã¯5 ~ 6GBç¨åº¦ã§ãããPyTorch v0.3.0ãä½¿ãã¾ããã&lt;/p&gt;
&lt;p&gt;å­¦ç¿ã«ä½¿ç¨ããã³ãã³ãã¯ä»¥ä¸ã§ãã&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;python train.py --checkpoint-dir=checkpoints_deepvoice3 \
    --hparams=&amp;quot;use_preset=True,builder=deepvoice3&amp;quot; \
    --log-event-path=log/deepvoice3_preset
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;ã³ã¼ãã®ã³ãããããã·ã¥ã¯ &lt;a href=&#34;https://github.com/r9y9/deepvoice3_pytorch/tree/7bcf1d070448b4127b41bdf3a1e34c9fea382054&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;7bcf1d0704&lt;/a&gt; ã§ããæ­£ç¢ºãªãã¤ãã¼ãã©ã¡ã¼ã¿ãç¥ãããå ´åã¯ãããããè¾¿ããã¨æãã¾ãã&lt;/p&gt;
&lt;h3 id=&#34;ã¢ã©ã¤ã¡ã³ãã®å­¦ç¿éç¨&#34;&gt;ã¢ã©ã¤ã¡ã³ãã®å­¦ç¿éç¨&lt;/h3&gt;
&lt;p&gt;ä»åã®å®é¨ã§ã¯ã¢ãã³ã·ã§ã³ã¬ã¤ã¤ã¼ã¯äºã¤ï¼æåã¨æå¾ï¼ããã¾ãããä»¥ä¸ã«å¹³åãåã£ããã®ãç¤ºãã¾ãã&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/images/deepvoice3/alignment.gif&#34; /&gt;&lt;/div&gt;
&lt;h3 id=&#34;åç¨®ã­ã¹ã®é·ç§»&#34;&gt;åç¨®ã­ã¹ã®é·ç§»&lt;/h3&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/images/deepvoice3/deepvoice3_tensorboard.png&#34; /&gt;&lt;/div&gt;
&lt;h3 id=&#34;é³å£°ãµã³ãã«&#34;&gt;é³å£°ãµã³ãã«&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://r9y9.github.io/blog/2017/11/23/dctts/&#34;&gt;ååã®è¨äº&lt;/a&gt; ã§è²¼ã£ããµã³ãã«ã¨ã¾ã£ããåãæç« ãç¨ãã¾ãããèå³ã®ããæ¹ã¯è´ãæ¯ã¹ã¦ã¿ã¦ãã ããã&lt;/p&gt;
&lt;h4 id=&#34;httpstachi-higithubiotts_samples-ãã&#34;&gt;&lt;a href=&#34;https://tachi-hi.github.io/tts_samples/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://tachi-hi.github.io/tts_samples/&lt;/a&gt; ãã&lt;/h4&gt;
&lt;p&gt;icassp stands for the international conference on acoustics, speech and signal processing.&lt;/p&gt;
&lt;p&gt;(90 chars, 14 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/deepvoice3/nyanko/0_checkpoint_step000210000.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/deepvoice3/nyanko/0_checkpoint_step000210000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;a matrix is positive definite, if all eigenvalues are positive.&lt;/p&gt;
&lt;p&gt;(63 chars, 12 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/deepvoice3/nyanko/2_checkpoint_step000210000.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/deepvoice3/nyanko/2_checkpoint_step000210000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;a spectrogram is obtained by applying es-tee-ef-tee to a signal.&lt;/p&gt;
&lt;p&gt;(64 chars, 11 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/deepvoice3/nyanko/6_checkpoint_step000210000.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/deepvoice3/nyanko/6_checkpoint_step000210000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;h4 id=&#34;keithitotacotron-ã®ãµã³ãã«httpskeithitogithubioaudio-samples-ã¨åãæç« &#34;&gt;&lt;a href=&#34;https://keithito.github.io/audio-samples/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;keithito/tacotron ã®ãµã³ãã«&lt;/a&gt; ã¨åãæç« &lt;/h4&gt;
&lt;p&gt;Scientists at the CERN laboratory say they have discovered a new particle.&lt;/p&gt;
&lt;p&gt;(74 chars, 13 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/deepvoice3/3_keithito/0_checkpoint_step000210000.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/deepvoice3/3_keithito/0_checkpoint_step000210000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;There&amp;rsquo;s a way to measure the acute emotional intelligence that has never gone out of style.&lt;/p&gt;
&lt;p&gt;(91 chars, 18 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/deepvoice3/3_keithito/1_checkpoint_step000210000.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/deepvoice3/3_keithito/1_checkpoint_step000210000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;President Trump met with other leaders at the Group of 20 conference.&lt;/p&gt;
&lt;p&gt;(69 chars, 13 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/deepvoice3/3_keithito/2_checkpoint_step000210000.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/deepvoice3/3_keithito/2_checkpoint_step000210000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;The Senate&amp;rsquo;s bill to repeal and replace the Affordable Care Act is now imperiled.&lt;/p&gt;
&lt;p&gt;(81 chars, 16 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/deepvoice3/3_keithito/3_checkpoint_step000210000.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/deepvoice3/3_keithito/3_checkpoint_step000210000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;Generative adversarial network or variational auto-encoder.&lt;/p&gt;
&lt;p&gt;(59 chars, 7 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/deepvoice3/3_keithito/4_checkpoint_step000210000.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/deepvoice3/3_keithito/4_checkpoint_step000210000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;The buses aren&amp;rsquo;t the problem, they actually provide a solution.&lt;/p&gt;
&lt;p&gt;(63 chars, 13 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/deepvoice3/3_keithito/5_checkpoint_step000210000.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/deepvoice3/3_keithito/5_checkpoint_step000210000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;h2 id=&#34;ã¾ã¨ã&#34;&gt;ã¾ã¨ã&lt;/h2&gt;
&lt;p&gt;ä»¥ä¸ãç¥è¦ãã¾ã¨ãã¾ãããããã¾ã§ãã®å¾åããããã¨ããç¨åº¦ã«åãæ­¢ãã¦ãã ããã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Tacotron, DeepVoice3ã§è¿°ã¹ããã¦ããããã«ã¡ã«å¨æ³¢æ°ã¹ãã¯ãã­ã°ã©ã ã®è¤æ°ãã¬ã¼ã ãDecoderã®1-stepã§äºæ¸¬ãããããã&lt;a href=&#34;https://arxiv.org/abs/1710.08969&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;arXiv:1710.08969&lt;/a&gt; ã§è¿°ã¹ããã¦ããããã«ã1-stepã§ï¼ç²ãï¼1ãã¬ã¼ã ãäºæ¸¬ãã¦ãConvTransposed1d ã«ããåã®æéè§£ååº¦ã¾ã§ã¢ãããµã³ããªã³ã°ããæ¹ãè¯ããçæãããé³å£°ã®ããã©ã¼ãã®ãããªç¾è±¡ãç·©åãããããã«æãã&lt;/li&gt;
&lt;li&gt;Dilationãå¤§ãããã¦ããå¤§ããªåè³ªã®å¤åã¯ãªãããã«æãã&lt;/li&gt;
&lt;li&gt;Guided-attentionã¯ãã¢ãã³ã·ã§ã³ãæ©ãmonotonicã«ãªãã¨ããæå³ã§è¯ãããã ããåè³ªã«å¤§ããªå½±é¿ã¯ãªãããã«æãã&lt;/li&gt;
&lt;li&gt;Encoderã®ã¬ã¤ã¤ã¼æ°ãå¤§ããããã®ã¯å¹æãã&lt;/li&gt;
&lt;li&gt;Converterã®ãã£ã³ãã«æ°ãå¤§ããããã®ã¯å¹æãã&lt;/li&gt;
&lt;li&gt;Binary divergence lossã¯ãå­¦ç¿ãå®å®ãããããã«ãDeepVoice3é¢¨ã®ã¢ã¼ã­ãã¯ãã£ã§ãæå¹ã ã£ã&lt;/li&gt;
&lt;li&gt;Encoder/Converterã¯ &lt;a href=&#34;https://arxiv.org/abs/1710.08969&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;arXiv:1710.08969&lt;/a&gt; ã®ãã®ããDecoderã¯DeepVoice3ã®ãã®ããã¨ãããã¿ã¼ã³ã§è©¦ãããã¨ãããã¾ããã&lt;a href=&#34;https://arxiv.org/abs/1710.08969&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;arXiv:1710.08969&lt;/a&gt;ã«æ¯ã¹ã¦è¥å¹²åè³ªãè½ã¡ãããã«æãããã®ã®ãã»ã¼åç­ã¨è¨ãããããªåè³ªãå¾ããã¾ããã&lt;a href=&#34;https://arxiv.org/abs/1710.08969&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;arXiv:1710.08969&lt;/a&gt; ã§ã¯Decoderã«20ã¬ã¤ã¤ã¼ä»¥ä¸ä½¿ã£ã¦ãã¾ããã10æªæºã§ããããªãã®åè³ªã«ãªã£ãããã«æãã¾ãï¼ä¸ã§è²¼ã£ãé³å£°ãµã³ãã«ãã¾ãã«ãã®ä¾ã§ãï¼&lt;/li&gt;
&lt;li&gt;åè³ªãæ¹è¯ããããã«ã&lt;a href=&#34;https://arxiv.org/abs/1710.08969&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;arXiv:1710.08969&lt;/a&gt; ããè²ãã¢ã¤ãã¢ãåãã¾ããããéã«DeepVoice3ã®ã¢ã¤ãã¢ã§è¯ãã£ãã¨æãããã®ã«ãDecoderã®å¥åã«ã(ã¡ã«å¨æ³¢æ°ã®æ¬¡åã¾ã§å°ãããã¦ãSigmoidãéãã¦å¾ãããï¼ã¡ã«å¨æ³¢æ°ã¹ãã¯ãã­ã°ã©ã ãä½¿ãã®ã§ã¯ãªããã®åã®hidden stateãä½¿ããã¨ãã£ããã¨ãããã¾ãããå¾éããµãããããSigmoidããã¾ãªãããããã¹ãã¯ãã­ã°ã©ã ã«å¯¾ããL1 Lossã®æ¸å°ãç¢ºå®ã«éããªãã¾ãã (&lt;a href=&#34;https://github.com/r9y9/deepvoice3_pytorch/commit/22a674803f2994af2b818635a0501e4417834936&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;22a6748&lt;/a&gt;)ã&lt;/li&gt;
&lt;li&gt;ãã®è¨äºã«è²¼ã£ãé³å£°ãµã³ãã«ã«ããã¦ãåé ­ã®aãæãã¦ããä¾ãç®ç«ã¡ã¾ãããéå»ã«ãã£ãå®é¨ã§ã¯ããããä¾ã¯ç¨ã ã£ãã®ã§ãä½ããã¤ãã¼ãã©ã¡ã¼ã¿ãèª¤ã£ã¦ããã£ããã ã¨æãã¾ãï¼é&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;åè&#34;&gt;åè&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1710.07654&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Wei Ping, Kainan Peng, Andrew Gibiansky, et al, &amp;ldquo;Deep Voice 3: 2000-Speaker Neural Text-to-Speech&amp;rdquo;, arXiv:1710.07654, Oct. 2017.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1705.03122&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Jonas Gehring, Michael Auli, David Grangier, et al, &amp;ldquo;Convolutional Sequence to Sequence Learning&amp;rdquo;, arXiv:1705.03122, May 2017.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://r9y9.github.io/blog/2017/11/23/dctts/&#34;&gt;Efficiently Trainable Text-to-Speech System Based on Deep Convolutional Networks with Guided Attention. [arXiv:1710.08969] | LESS IS MORE&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;é¢é£è¨äº&#34;&gt;é¢é£è¨äº&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://r9y9.github.io/blog/2017/11/23/dctts/&#34;&gt;Efficiently Trainable Text-to-Speech System Based on Deep Convolutional Networks with Guided Attention. [arXiv:1710.08969] | LESS IS MORE&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Efficiently Trainable Text-to-Speech System Based on Deep Convolutional Networks with Guided Attention. [arXiv:1710.08969]</title>
      <link>https://r9y9.github.io/blog/2017/11/23/dctts/</link>
      <pubDate>Thu, 23 Nov 2017 19:30:00 +0900</pubDate>
      <guid>https://r9y9.github.io/blog/2017/11/23/dctts/</guid>
      <description>&lt;h2 id=&#34;summary&#34;&gt;Summary&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;è«æãªã³ã¯: &lt;a href=&#34;https://arxiv.org/abs/1710.08969&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;arXiv:1710.08969&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;ã³ã¼ã: &lt;a href=&#34;https://github.com/r9y9/deepvoice3_pytorch&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/r9y9/deepvoice3_pytorch&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;ä¸è¡ã¾ã¨ã&#34;&gt;ä¸è¡ã¾ã¨ã&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1710.08969&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;arXiv:1710.08969: Efficiently Trainable Text-to-Speech System Based on Deep Convolutional Networks with Guided Attention.&lt;/a&gt; ãèª­ãã§ãå®è£ãã¾ãã&lt;/li&gt;
&lt;li&gt;RNNã§ã¯ãªãCNNãä½¿ãã®ãèã§ããªã¼ãã³ã½ã¼ã¹Tacotronã¨åç­ä»¥ä¸ã®åè³ªã§ãããªããã&lt;strong&gt;é«éã« (ä¸æ¥ç¨åº¦ã§) å­¦ç¿ã§ãã&lt;/strong&gt; ã®ãå£²ãã®ããã§ãã&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://keithito.com/LJ-Speech-Dataset/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;LJSpeech Dataset&lt;/a&gt; ãä½¿ã£ã¦ãè±èªTTSã¢ãã«ãä½ãã¾ããï¼å­¦ç¿æéä¸æ¥ãããï¼ãå®å¨åç¾ã¨ã¾ã§ã¯ããã¾ããããå¤§ã¾ãã«è«æã®ä¸»å¼µãç¢ºèªã§ãã¾ããã&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;åç½®ã&#34;&gt;åç½®ã&lt;/h2&gt;
&lt;p&gt;æ¬å½ã¯ &lt;a href=&#34;https://arxiv.org/abs/1710.07654&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;DeepVoice3&lt;/a&gt; ã®å®è£ããã¦ããã®ã§ãããã©ããä¸æããããªãã£ãã®ã§æ°åãå¤ãã¦ãã£ã¦ã¿ã¾ããã
ä»¥å Tacotronã«é¢ããé·ããã­ã°è¨äº (&lt;a href=&#34;https://r9y9.github.io/blog/2017/10/15/tacotron/&#34;&gt;ãªã³ã¯&lt;/a&gt;) ãæ¸ãã¦ãã¾ã£ãã®ã§ãããèª­ãæ¹ãæ¸ãæ¹ãã¤ããã®ã§ãç°¡æ½ã«ã¾ã¨ãããã¨ã«ãã¾ãããèå³ã®ããäººã¯ç¶ããã©ããã&lt;/p&gt;
&lt;h2 id=&#34;æ¦è¦&#34;&gt;æ¦è¦&lt;/h2&gt;
&lt;p&gt;End-to-endãã­ã¹ãé³å£°åæ (Text-to-speech synthesis; TTS) ã®ããã® &lt;strong&gt;Attentionä»ãç³ã¿è¾¼ã¿ãã¥ã¼ã©ã«ããã (CNN)&lt;/strong&gt; ãææ¡ããã¦ãã¾ããSampleRNN, Char2Wav, Tacotronãªã©ã®å¾æ¥ææ¡ããã¦ããRNNããã¼ã¹ã¨ããæ¹æ³ã§ã¯ãã¢ãã«ã®æ§é ä¸è¨ç®ãä¸¦ååãã«ããã
å­¦ç¿/æ¨è«ã«æéãããããã¨ãåé¡ã¨ãã¦ããã¾ãããæ¬è«æã§ã¯ãä¸»ã«ä»¥ä¸ã®äºã¤ã®ã¢ã¤ãã¢ã«ãã£ã¦ãå¾æ¥æ³ããéãå­¦ç¿ã§ããã¢ãã«ãææ¡ãã¦ãã¾ãã&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;RNNã§ã¯ãªãCNNãä½¿ããã¨ (åèè«æ: &lt;a href=&#34;https://arxiv.org/abs/1705.03122&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;arXiv:1705.03122&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Attentionãmotonicã«ãªããããããå¹æãæã¤Lossãèãããã¨ (&lt;strong&gt;Guided attention&lt;/strong&gt;)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;å®é¨ã§ã¯ããªã¼ãã³ã½ã¼ã¹Tacotron (&lt;a href=&#34;https://github.com/keithito/tacotron&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;keithito/tacotron&lt;/a&gt;) ã®12æ¥å­¦ç¿ãããã¢ãã«ã¨æ¯è¼ããä¸»è¦³è©ä¾¡ã«ããåç­ä»¥ä¸ã®åè³ªãå¾ããããã¨ãç¤ºããã¦ãã¾ãã&lt;/p&gt;
&lt;h3 id=&#34;deepvoice3httpsarxivorgabs171007654-ã¨ã®éã&#34;&gt;&lt;a href=&#34;https://arxiv.org/abs/1710.07654&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;DeepVoice3&lt;/a&gt; ã¨ã®éã&lt;/h3&gt;
&lt;p&gt;ã»ã¼åææã«çºè¡¨ãããDeepVoice3ãåãããCNNããã¼ã¹ã¨ãããã®ã§ããè«æãèª­ã¿ã¾ããããã¢ããã¼ã·ã§ã³ã¨ã¢ãã­ã¼ãã®åºæ¬ã¯ DeepVoice3 ã¨åãã«æãã¾ããããããããããã¯ã¼ã¯æ§é ã¯ DeepVoice3ã¨ã¯å¤§ããç°ãªãã¾ããããã¤ãææ¡æ³ã®ç¹å¾´ãæããã¨ãä»¥ä¸ã®ã¨ããã§ãã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ãããã¯ã¼ã¯ãæ·±ãï¼DeepVoice3ã ã¨Encoder, Decoder, Converter ãããã10æªæºã§ããããã®è«æã§ã¯Decoderã ãã§20ä»¥ä¸ï¼ããã¹ã¦ã«ããã¦æ·±ãã§ããã«ã¼ãã«ãµã¤ãºã¯3ã¨å°ããã§ã&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;
&lt;li&gt;Fully-connected layer ã§ã¯ãªã1x1 convolutionãä½¿ã£ã¦ãã¾ã&lt;/li&gt;
&lt;li&gt;ãã£ã³ãã«æ°ãå¤§ããï¼256ã¨ã512ã¨ããããã«ãããã¯ã¼ã¯åã§äºåã«ãªã£ã¦ãããããï¼ãDeepVoice3ã ã¨Encoderã¯64ã§ã&lt;/li&gt;
&lt;li&gt;ã¬ã¤ã¤ã¼ã®æ·±ãã«å¯¾ãã¦ææ°ä¸ã«å¤§ãããªãDilationãä½¿ã£ã¦ãã¾ãï¼DeepVoiceã§ã¯ãã¹ã¦dilation=1ï¼&lt;/li&gt;
&lt;li&gt;ã¢ãã³ã·ã§ã³ã¬ã¤ã¤ã¼ã¯ä¸ã¤ï¼DeepVoice3ã¯è¤æ°&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;DeepVoice3ã¯ã&lt;a href=&#34;https://arxiv.org/abs/1705.03122&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;arXiv:1705.03122&lt;/a&gt; ã®ã¢ãã«æ§é ã¨ããªãä¼¼éã£ã¦ããä¸æ¹ã§ãæ¬è«æã§ã¯ï¼åèæç®ã¨ãã¦ããããã¦ãã¾ããï¼å½±ãå½¢ããªããããå¤ãã£ã¦ãããã¨ããå°è±¡ãåãã¾ãã&lt;/p&gt;
&lt;p&gt;ã­ã¹ã«é¢ãã¦ã¯ãGuided attentionã«é¢ããã­ã¹ãå ããã®ã«å ãã¦ãTacotronãDeepVoice3ã¨ã¯ç°ãªããã¹ãã¯ãã­ã°ã©ã /ã¡ã«ã¹ãã¯ãã­ã°ã©ã ã«é¢ãã¦ binary divergence (å®ç¾©ã¯è«æåç§) ãã­ã¹ã«å ãã¦ããã¨ããéããããã¾ãã&lt;/p&gt;
&lt;h2 id=&#34;å®é¨&#34;&gt;å®é¨&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://keithito.com/LJ-Speech-Dataset/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;LJSpeech Dataset&lt;/a&gt; ãä½¿ã£ã¦ã17æéãããï¼26.5ä¸ã¹ãããï¼å­¦ç¿ãã¾ãããè¨ç®è³æºã®é½åä¸ãSSRNã®ãã£ã³ãã«æ°ã¯512ã§ã¯ãªããã®ååã®256ã«ãã¾ããã&lt;/p&gt;
&lt;p&gt;ãªããå®è£ããã«ããã£ã¦ã¯ãå³å¯ã«åç¾ãããã¨ã¯ãããè²ãé°å²æ°ã§ãã¾ããã¾ããããã¨ãã¨DeepVoice3ã®å®è£ããã¦ããã®ããããã¢ã¤ãã¢ãããã¤ãåãã¦ãã¾ããä¾ãã°ããã³ã¼ãã®åºåããã¤æ­¢ããããã¨ããdone flag predictionããããã¯ã¼ã¯ã«å¥ãã¦ãã¾ããDropoutã«ã¤ãã¦è¨åãããã¾ãããããªãã¨æ±åãã«ããå°è±¡ããã£ãã®ã§&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;ãè¶³ãã¾ããã&lt;/p&gt;
&lt;p&gt;è¨ç®éåº¦ã¯ãããããµã¤ãº16ã§ã4.3 step/sec ãããã®è¨ç®éåº¦ã§ãããåã®ãã·ã³ã®GPUã¯GTX 1080Ti ã§ããä½¿ç¨ãããã¤ãã¼ãã©ã¡ã¼ã¿ã¯&lt;a href=&#34;https://github.com/r9y9/deepvoice3_pytorch/blob/70dc880fae185d96effaee97f0ce55b5c0d13b61/hparams.py&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ãã¡ã&lt;/a&gt;ã§ããå­¦ç¿ã«ä½¿ç¨ããã³ãã³ãã¯ä»¥ä¸ã§ãï¼ã¡ã¢ï¼ã&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;python train.py --data-root=./data/ljspeech --checkpoint-dir=checkpoints_nyanko \
    --hparams=&amp;quot;use_preset=True,builder=nyanko&amp;quot; \
    --log-event-path=log/nyanko_preset
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;ã¢ã©ã¤ã¡ã³ãã®å­¦ç¿éç¨&#34;&gt;ã¢ã©ã¤ã¡ã³ãã®å­¦ç¿éç¨&lt;/h3&gt;
&lt;p&gt;æ°ä¸ã¹ãããã§ãç¶ºéºã«monotonicã«ãªãã¾ãããGIFã¯ãåãé³å£°ã«å¯¾ããã¢ã©ã¤ã¡ã³ãã§ã¯ãªããæ¯åº¦éãï¼ã©ã³ãã ãªï¼é³å£°ãµã³ãã«ã«å¯¾ããã¢ã©ã¤ã¡ã³ããè¨ç®ãã¦ããã£ã¤ãããã®ã§ãï¼ããããããããã¾ãã&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/images/dctts/alignment.gif&#34; /&gt;&lt;/div&gt;
&lt;h3 id=&#34;åç¨®ã­ã¹ã®é·ç§»&#34;&gt;åç¨®ã­ã¹ã®é·ç§»&lt;/h3&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/images/dctts/dctts_tensorboard.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;è¦ã¥ããã¦ç³ãè¨³ããã¾ããã¨ããæãã§ãããåã®ããã®ç°¡æã­ã°ã¨ãããã¨ã§è²¼ã£ã¦ããã¾ããbinary divergenceã¯ãããã«åæããããã§ããã&lt;/p&gt;
&lt;h3 id=&#34;é³å£°ãµã³ãã«&#34;&gt;é³å£°ãµã³ãã«&lt;/h3&gt;
&lt;h4 id=&#34;å¬å¼é³å£°ãµã³ãã«httpstachi-higithubiotts_samples-ã¨åãæç« æç²&#34;&gt;&lt;a href=&#34;https://tachi-hi.github.io/tts_samples/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;å¬å¼é³å£°ãµã³ãã«&lt;/a&gt; ã¨åãæç« ï¼æç²ï¼&lt;/h4&gt;
&lt;p&gt;å¬å¼ãµã³ãã«ã¨ã®æ¯è¼ã§ãã11/23æç¹ã§ãå¬å¼ã®ãµã³ãã«æ°ã15åã¨å¤ãã®ã§ãé©å½ã«3ã¤é¸ã³ã¾ãããå¬å¼ã¨æ¯ã¹ãã¨å°ãç°ãªã£ã¦ããå°è±¡ãåãã¾ãããã¾ãã¾ãè¯ãããªã¨æãã¾ããï¼ææ§ã§ãã&lt;/p&gt;
&lt;p&gt;icassp stands for the international conference on acoustics, speech and signal processing.&lt;/p&gt;
&lt;p&gt;(90 chars, 14 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/nyanko/6_nyanko/0_checkpoint_step000265000.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/nyanko/6_nyanko/0_checkpoint_step000265000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;a matrix is positive definite, if all eigenvalues are positive.&lt;/p&gt;
&lt;p&gt;(63 chars, 12 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/nyanko/6_nyanko/2_checkpoint_step000265000.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/nyanko/6_nyanko/2_checkpoint_step000265000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;a spectrogram is obtained by applying es-tee-ef-tee to a signal.&lt;/p&gt;
&lt;p&gt;(64 chars, 11 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/nyanko/6_nyanko/6_checkpoint_step000265000.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/nyanko/6_nyanko/6_checkpoint_step000265000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;h4 id=&#34;keithitotacotron-ã®ãµã³ãã«httpskeithitogithubioaudio-samples-ã¨åãæç« &#34;&gt;&lt;a href=&#34;https://keithito.github.io/audio-samples/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;keithito/tacotron ã®ãµã³ãã«&lt;/a&gt; ã¨åãæç« &lt;/h4&gt;
&lt;p&gt;Scientists at the CERN laboratory say they have discovered a new particle.&lt;/p&gt;
&lt;p&gt;(74 chars, 13 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/nyanko/3_keithito/0_checkpoint_step000265000.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/nyanko/3_keithito/0_checkpoint_step000265000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;There&amp;rsquo;s a way to measure the acute emotional intelligence that has never gone out of style.&lt;/p&gt;
&lt;p&gt;(91 chars, 18 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/nyanko/3_keithito/1_checkpoint_step000265000.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/nyanko/3_keithito/1_checkpoint_step000265000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;President Trump met with other leaders at the Group of 20 conference.&lt;/p&gt;
&lt;p&gt;(69 chars, 13 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/nyanko/3_keithito/2_checkpoint_step000265000.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/nyanko/3_keithito/2_checkpoint_step000265000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;The Senate&amp;rsquo;s bill to repeal and replace the Affordable Care Act is now imperiled.&lt;/p&gt;
&lt;p&gt;(81 chars, 16 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/nyanko/3_keithito/3_checkpoint_step000265000.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/nyanko/3_keithito/3_checkpoint_step000265000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;Generative adversarial network or variational auto-encoder.&lt;/p&gt;
&lt;p&gt;(59 chars, 7 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/nyanko/3_keithito/4_checkpoint_step000265000.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/nyanko/3_keithito/4_checkpoint_step000265000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;The buses aren&amp;rsquo;t the problem, they actually provide a solution.&lt;/p&gt;
&lt;p&gt;(63 chars, 13 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/nyanko/3_keithito/5_checkpoint_step000265000.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/nyanko/3_keithito/5_checkpoint_step000265000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;h2 id=&#34;ã¾ã¨ã--ããã£ããã¨ãªã©&#34;&gt;ã¾ã¨ã &amp;amp; ããã£ããã¨ãªã©&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Tacotronã§ã¯å­¦ç¿ã«ä½æ¥ãããã£ã¦ãã¾ãããï¼è¨ç®ãéã1æ¥ã§10ä¸stepç¨åº¦ï¼ã1æ¥ã§ãããªãã®åè³ªã«ãªãã¾ããã&lt;/li&gt;
&lt;li&gt;Guided atetntionãããã¨ãç¢ºãã«éãattentionãmonotonicã«ãªãã¾ããã&lt;/li&gt;
&lt;li&gt;2æéç¨åº¦ã®å­¦ç¿ã§ã¯ &lt;a href=&#34;https://tachi-hi.github.io/tts_samples/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ãã&lt;/a&gt; ã«ããã®ã¨åç¨åº¦ã®åè³ªã«ã¯ãªãã¾ããã§ããâ¦&lt;/li&gt;
&lt;li&gt;DeepVoice3ã®ã¢ãã«ã¢ã¼ã­ãã¯ãã£ã§å­¦ç¿ããå ´åã¨æ¯ã¹ãã¨ãåè³ªã¯åä¸ãã¾ãã&lt;/li&gt;
&lt;li&gt;DeepVoice3ã¨æ¯ã¹ãã¨ãæ·±ããããªã®ãå­¦ç¿ãé£ããããã«æãã¾ãããéã¿ã®åæåã®ãã©ã¡ã¼ã¿ãã¡ãã£ã¨ãããã¨ãsigmoidã®åºåã0 or 1ã«ãªã£ã¦å­¦ç¿ãæ­¢ã¾ããã¨ãã£ããã¨ãããã¾ãããéã¿ã®åæåã¯ã¨ã¦ãéè¦ã§ãã&lt;/li&gt;
&lt;li&gt;ä¸è¨ã«ãé¢é£ãã¦ãå¾éã®ãã«ã ãççºçã«å¤§ãããªããã¨ããã°ãã°ãããã¯ãªããã³ã°ãå¥ãã¾ããï¼éè¦ã§ããï¼&lt;/li&gt;
&lt;li&gt;Binary divergenceãã­ã¹ã«ããã¦ãåè³ªã«ã¯å½±é¿ããªãããã«æãã¾ããããã ããªãã¨å­¦ç¿åæã«å¾éãççºããããã£ãã§ã&lt;/li&gt;
&lt;li&gt;ææ¡æ³ã¯è²ããªã¢ã¤ãã¢ãçãè¾¼ã¾ãã¦ããã®ã§ãããå®éã®ã¨ããã©ããéè¦ãªè¦ç´ ãªã®ããã¨ãã£ãç¹ã«é¢ãã¦ã¯ãè«æã§ã¯æããã«ããã¦ããªãã£ãããã«æãã¾ããä»å¾ãã®è¾ºããæããã«ããè«æããã£ã¦ãããã®ã§ã¯ãªããã¨æãã¾ããã&lt;/li&gt;
&lt;li&gt;å­¦ç¿ã«ä½¿ãGPUã¡ã¢ãªéãTacotronããå¤ãï¼SSRNã®ãã£ã³ãã«æ°512, ããããµã¤ãº16ã§ &lt;del&gt;8GBããã&lt;/del&gt; 5~6GB ãããã§ããï¼â¦â¦å³ããâ¦â¦&lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;
&lt;li&gt;2017/12/19è¿½è¨: Dropoutãªãã ã¨ãå¥åãã­ã¹ãã¨ã¯ç¡ç¸ã®è±èªãããä½ããçæãããããã«ãªã£ã¦ãã¾ãã¾ãããDropoutã¯ãã¯ãéè¦ã§ãã&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ä¸çªã®å­¦ã³ã¯ããããã¯ã¼ã¯ã®éã¿ã®åæåæ¹æ³ã¯éè¦ãã¨ãããã¨ã§ãããããã¾ã&lt;/p&gt;
&lt;h2 id=&#34;åè&#34;&gt;åè&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1710.08969&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Hideyuki Tachibana, Katsuya Uenoyama, Shunsuke Aihara, &amp;ldquo;Efficiently Trainable Text-to-Speech System Based on Deep Convolutional Networks with Guided Attention&amp;rdquo;. arXiv:1710.08969, Oct 2017.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1710.07654&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Wei Ping, Kainan Peng, Andrew Gibiansky, et al, &amp;ldquo;Deep Voice 3: 2000-Speaker Neural Text-to-Speech&amp;rdquo;, arXiv:1710.07654, Oct. 2017.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1705.03122&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Jonas Gehring, Michael Auli, David Grangier, et al, &amp;ldquo;Convolutional Sequence to Sequence Learning&amp;rdquo;, arXiv:1705.03122, May 2017.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/He_Delving_Deep_into_ICCV_2015_paper.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;He, Kaiming, et al. &amp;ldquo;Delving deep into rectifiers: Surpassing human-level performance on imagenet classification.&amp;rdquo; Proceedings of the IEEE international conference on computer vision. 2015.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;DeepVoice3ã§ã«ã¼ãã«ãµã¤ãº3ã§è©¦ãã¨ãå¨ç¶ãã¾ãããã¾ããã§ãã&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;æ¨è«æã«ã¢ãã³ã·ã§ã³ã®å¶ç´ãããã¦ããããµããµããµããµããµããã¿ãããªç¹°ãè¿ããèµ·ãã¦ãã¾ãã¾ãã&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;è«æã§ã¯ã¨ã³ã³ã¼ããã³ã¼ãã®å­¦ç¿ã¨SRNNã®å­¦ç¿ãå¥ãã§ãããªã£ã¦ãã¾ãããåã¯ä¸ç·ã«ããã¾ããããã®ãããããã¾ã&amp;#160;&lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
    </item>
    
    <item>
      <title>Tacotron: Towards End-to-End Speech Synthesis / arXiv:1703.10135 [cs.CL]</title>
      <link>https://r9y9.github.io/blog/2017/10/15/tacotron/</link>
      <pubDate>Sun, 15 Oct 2017 14:00:00 +0900</pubDate>
      <guid>https://r9y9.github.io/blog/2017/10/15/tacotron/</guid>
      <description>&lt;p&gt;Googleã2017å¹´4æã«çºè¡¨ããEnd-to-Endã®é³å£°åæã¢ãã« &lt;a href=&#34;https://arxiv.org/abs/1703.10135&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Tacotron: Towards End-to-End Speech Synthesis / arXiv:1703.10135 [cs.CL]&lt;/a&gt; ã«èå³ããã£ãã®ã§ãèªåã§ãåæ§ã®ã¢ãã«ãå®è£ãã¦å®é¨ãã¦ã¿ã¾ãããçµæããã£ããã¨ãªã©ãã¾ã¨ãã¦ãããã¨æãã¾ãã&lt;/p&gt;
&lt;p&gt;Googleã«ããTacotronã®é³å£°ãµã³ãã«ã¯ã &lt;a href=&#34;https://google.github.io/tacotron/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://google.github.io/tacotron/&lt;/a&gt; ããè´ãã¾ããåã®å®è£ã«ããé³å£°ãµã³ãã«ã¯ãã®è¨äºã®çãä¸­ãããããããããã¯  &lt;a href=&#34;http://nbviewer.jupyter.org/github/r9y9/tacotron_pytorch/blob/f98eda7336726cdfe4ab97ae867cc7f71353de50/notebooks/Test%20Tacotron.ipynb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Test Tacotron.ipynb | nbviewer&lt;/a&gt;&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; ããè´ããã¨ãã§ãã¾ãã&lt;/p&gt;
&lt;p&gt;ã¨ã¦ãé·ãè¨äºã«ãªã£ã¦ãã¾ã£ãã®ã§ãçµè«ã®ã¿ç¥ãããæ¹ã¯ãä¸çªæå¾ã¾ã§é£ã°ãã¦ãã ãããæå¾ã®æ¹ã®ã¾ã¨ãã»ã¯ã·ã§ã³ã«ãå®é¨ããä¸ã§åãå¾ãç¥è¦ãã¾ã¨ã¾ã£ã¦ãã¾ãã&lt;/p&gt;
&lt;h2 id=&#34;æ¦è¦&#34;&gt;æ¦è¦&lt;/h2&gt;
&lt;p&gt;è«æã®ã¿ã¤ãã«ã«ãããéããEnd-to-Endãç®æãã¦ãã¾ããå¸åçãªï¼è¤éã«ããªããã¡ãªï¼é³å£°åæã·ã¹ãã ã®æ§æè¦ç´ ã§ããã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;è¨èªä¾å­ã®ãã­ã¹ãå¦çãã­ã³ãã¨ã³ã&lt;/li&gt;
&lt;li&gt;è¨èªç¹å¾´éã¨é³é¿ç¹å¾´éã®ãããã³ã° (HMMãªãDNNãªã)&lt;/li&gt;
&lt;li&gt;æ³¢å½¢åæã®ããã¯ã¨ã³ã&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ãä¸ã¤ã®ã¢ãã«ã§éæãããã¨ããã&lt;strong&gt;attentionä»ãseq2seqã¢ãã«&lt;/strong&gt; ãææ¡ãã¦ãã¾ãããã ãã&lt;strong&gt;Toward&lt;/strong&gt; ã¨ããããã«ãå®å¨ã«End-to-Endã§ã¯ãªãããããã¯ã¼ã¯ã¯æ³¢å½¢ã§ã¯ãªã &lt;strong&gt;æ¯å¹ã¹ãã¯ãã­ã°ã©ã &lt;/strong&gt; ãåºåããGriffin limã®æ¹æ³ã«ãã£ã¦ä½ç¸ãå¾©åããéç­æéãã¼ãªã¨å¤æããããã¨ã«ãã£ã¦ãæçµçãªæ³¢å½¢ãå¾ã¾ããæ ¹æ¬ã«ããã¢ã¤ãã¢èªä½ã¯ã·ã³ãã«ã§ããããã®ãããªEnd-to-Endã«è¿ãã¢ãã«ã§é«åè³ªãªé³å£°åæãå®ç¾ããã®ã¯å°é£ã§ãããããè«æã§ã¯å­¦ç¿ãä¸æãããããããããã®ããã¤ãã®ãã¯ããã¯ãææ¡ãããã¨ãã£ãä¸»å¼µã§ããä»¥ä¸ã«ããã¤ãããã¯ã¢ãããã¾ãã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ã¨ã³ã³ã¼ãã« &lt;strong&gt;CBFG&lt;/strong&gt; (1-D convolution bank + highway network + bidirectional GRU) ã¨ããã¢ã¸ã¥ã¼ã«ãä½¿ã&lt;/li&gt;
&lt;li&gt;ãã³ã¼ãã®åºåãã¹ãã¯ãã­ã°ã©ã ã§ã¯ãªãï¼ããä½æ¬¡åã®ï¼&lt;strong&gt;ã¡ã«å¨æ³¢æ°ã¹ãã¯ãã­ã°ã©ã &lt;/strong&gt; ã«ãããã¹ãã¯ãã­ã°ã©ã ã¯ã¢ã©ã¤ã¡ã³ããå­¦ç¿ããã«ã¯åé·ãªããã&lt;/li&gt;
&lt;li&gt;ã¹ãã¯ãã­ã°ã©ã ã¯ãã¡ã«å¨æ³¢æ°ã¹ãã¯ãã­ã°ã©ã ã«å¯¾ãã¦ &lt;strong&gt;CBFG&lt;/strong&gt; ãéãã¦å¾ã&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ãã®ä»ãBatchNormalizationãå¥ããããDropoutãå¥ããããGRUãã¹ã¿ãã¯ããããã¨è²ãããã¾ãããæ­£ç´ãªã¨ãããã©ããã©ã®ãããå¹æãããã®ãã¯ããã£ã¦ãã¾ããï¼èª¿ã¹ãã«ã¯ãéæ¹ããªãæéããããã¾ãï¼ããè«æã®ä¸»å¼µã«ããã¨ãããããæå¹ãªããã§ãã&lt;/p&gt;
&lt;h2 id=&#34;æ¢å­å®è£&#34;&gt;æ¢å­å®è£&lt;/h2&gt;
&lt;p&gt;Googleã¯å®è£ãå¬éãã¦ãã¾ãããããªã¼ãã³ã½ã¼ã¹å®è£ãããã¤ãããã¾ãã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/Kyubyong/tacotron&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/Kyubyong/tacotron&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/barronalex/Tacotron&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/barronalex/Tacotron&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/keithito/tacotron&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/keithito/tacotron&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;èªåã§å®è£ããåã«ãä¸è¨ããã¹ã¦ãç°¡åã«è©¦ããããçæãããé³å£°ãµã³ãã«ãæ¯è¼ããä¸ã§ãåã¯ &lt;a href=&#34;https://github.com/keithito/tacotron&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;keithito/tacotron&lt;/a&gt; ãä¸çªè¯ãããã«æãã¾ãããæãè¯ãã¨æã£ãç¹ã¯ãkeithito ããã¯ã&lt;a href=&#34;https://keithito.com/LJ-Speech-Dataset/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;LJ Speech Dataset&lt;/a&gt; ã¨ããåä¸è©±èã®è±èªèª­ã¿ä¸ãé³å£° &lt;strong&gt;ç´24æéã®ãã¼ã¿ã»ãããæ§ç¯&lt;/strong&gt; ããããã &lt;strong&gt;public domainã§å¬é&lt;/strong&gt; ãã¦ãããã¨ã§ãããã®ãã¼ã¿ã»ããã¯è²´éã§ãã&lt;a href=&#34;https://keithito.github.io/audio-samples/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ãã¢é³å£°ãµã³ãã«&lt;/a&gt;ã¯ããã®ãã¼ã¿ã»ãããä½¿ã£ãçµæã§ããããä»ã¨æ¯ã¹ã¦ã¨ã¦ãé«åè³ªã«æãã¾ãããèªåã§ãè©¦ãã¦ã¿ã¦ã1æéç¨åº¦ã§è±èªãããé³å£°ãçæã§ããããã«ãªã£ãã®ã¨ãããã«æ°æéã§ã¢ã©ã¤ã¡ã³ããå­¦ç¿ããããã¨ãç¢ºèªãã¾ããã&lt;/p&gt;
&lt;p&gt;ãªããä¸è¨3ã¤ãã¹ã¦ã§å­¦ç¿ã¹ã¯ãªãããåãã¦é³å£°ãµã³ãã«ãå¾ããç¨åº¦ã®ãã¨ã¯è©¦ãã¾ããããåãã³ã¼ãã¬ãã«ã§èª­ãã ã®ã¯ &lt;a href=&#34;https://github.com/keithito/tacotron&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;keithito/tacotron&lt;/a&gt; ã®ã¿ã§ããèª­ãã ã³ã¼ãã¯ãTensorFlowã«è©³ãããªãåã§ãèª­ãããã®ã§ãã¨ã¦ãæ§é åããã¦ãã¦èª­ã¿ãããã£ãã§ãã&lt;/p&gt;
&lt;h2 id=&#34;èªåå®è£&#34;&gt;èªåå®è£&lt;/h2&gt;
&lt;p&gt;åå¼·ãå¼ã­ã¦ãPyTorchã§ã¹ã¯ã©ããããæ¸ãã¾ããããã®çµæã &lt;a href=&#34;https://github.com/r9y9/tacotron_pytorch&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/r9y9/tacotron_pytorch&lt;/a&gt; ã§ãã&lt;/p&gt;
&lt;p&gt;åã«ããã¤ãçµè«ãæ¸ãã¦ããã¨ã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;é³ã®åè³ªã¯ã&lt;a href=&#34;https://github.com/keithito/tacotron&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;keithito/tacotron&lt;/a&gt; ã®æ¹ãè¯ãæãã¾ããï¼åãã¢ãã«ã®å®è£ãå¿ãããã®ã«â¦ã¤ããâ¦ï¼ããã ããã¼ã¿ã»ããã®é³å£°ã«ã¯æ®é¿ãä¹ã£ã¦ãã¦ãçæãããé³å£°ãåé³å£°ã«è¿ãã®ãã¨ããã®ã¯ãåã«ã¯å¤æ­ãã¤ãã«ããã§ããè¨äºã®å¾åã«æ¯è¼ã§ããããã«ãµã³ãã«ãè²¼ã£ã¦ããã¾ãã®ã§ãæ°ã«ãªãæ¹ã¯ãã§ãã¯ãã¦ã¿ã¦ãã ãã&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/keithito/tacotron&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;keithito/tacotron&lt;/a&gt; ã§ã¯é·ãå¥åã ã¨åæã«å¤±æããä¸æ¹ã§&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;ãåã®å®è£ã§ã¯æ¯è¼çé·ãã¦ãããç¨åº¦åæã§ããããã§ãããªãã®ããçªãè©°ããã«ã¯ãTensorFlowã®seq2seq APIã® &lt;strong&gt;ã³ã¼ã&lt;/strong&gt; (APIã¯æ½è±¡åããããã¦ãã¦docstringããã§ã¯ããããããªãã®ã§â¦) ãèª­ã¿ã¨ãå¿è¦ãããããªã¨æã£ã¦ãã¾ãï¼ãã£ã¦ãã¾ããããã¾ãã&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;å®é¨&#34;&gt;å®é¨&lt;/h2&gt;
&lt;p&gt;åºæ¬çã«ã¯ &lt;a href=&#34;https://github.com/keithito/tacotron&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;keithito/tacotron&lt;/a&gt; ã®å­¦ç¿ã¹ã¯ãªããã¨åãã§ã&lt;a href=&#34;https://keithito.com/LJ-Speech-Dataset/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;LJ Speech Dataset&lt;/a&gt; ãä½¿ã£ã¦å­¦ç¿ããã¾ããããã­ã¹ãå¦çãé³å£°å¦ç (Griffin limç­) ã«ã¯æ¢å­ã®ã³ã¼ãããã®ã¾ã¾ä½¿ç¨ããã¢ãã«é¨åã®ã¿èªåã§ç½®ãæãã¾ãããå®é¨ã§ã¯ã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;attentionä»ãseq2seqã®èã§ãããã¢ã©ã¤ã¡ã³ããã©ã®ããã«å­¦ç¿ããã¦ããã®ã&lt;/li&gt;
&lt;li&gt;å­¦ç¿ãé²ãã«ã¤ãã¦ãçæãããé³å£°ã¯ã©ã®ããã«å¤ãã£ã¦ããã®ã&lt;/li&gt;
&lt;li&gt;å­¦ç¿ãããã¢ãã«ã¯ãæ±åæ§è½ã¯ã©ã®ç¨åº¦ãªã®ãï¼æªç¥æç« ãé·ãæç« ãã¹ãã«ãã¹ã«å¯¾ãã¦ããã©ã¼ãã³ã¹ã¯ã©ãå¤ããã®ããç­ï¼&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ãæ¢ã£ã¦ããã¾ããã&lt;/p&gt;
&lt;h3 id=&#34;ã¢ã©ã¤ã¡ã³ãã®å­¦ç¿éç¨ã®å¯è¦å&#34;&gt;ã¢ã©ã¤ã¡ã³ãã®å­¦ç¿éç¨ã®å¯è¦å&lt;/h3&gt;
&lt;p&gt;éå¸¸ã®seq2seqã¯ãã¨ã³ã³ã¼ãRNNã«ãã£ã¦å¾ãæå¾ã®ã¿ã¤ã ã¹ãããã«ãããé ãå±¤ã®ç¶æãããã³ã¼ãã®RNNã®åæç¶æã¨ãã¦æ¸¡ãã¾ããä¸æ¹attentiontä»ãã®seq2seqã¢ãã«ã§ã¯ããã³ã¼ãRNNã¯åã¿ã¤ã ã¹ãããã§ãã¨ã³ã³ã¼ãRNNã®åã¿ã¤ã ã¹ãããã«ãããé ãå±¤ã®ç¶æãéã¿ã¥ãã¦ä½¿ç¨ãããã®éã¿ãå­¦ç¿ãã¾ããattentionä»ãã®seq2seqã§ã¯ãã¢ã©ã¤ã¡ã³ãããã¡ãã¨ï¼ææ§ãªè¡¨ç¾ã§ããï¼å­¦ç¿ããã¦ããããå¯è¦åãã¦ãã§ãã¯ããã®ããå­¦ç¿ããã¡ãã¨é²ãã§ããã®ãç¢ºèªããã®ã«ä¾¿å©ã§ãã&lt;/p&gt;
&lt;p&gt;ä»¥ä¸ã«ã47000 step (epochã§ã¯ããã¾ãããåã®è¨ç®ç°å¢ GTX 1080Ti ã§åæ¥ããããªãããã) iterationããã¨ãã®ã¢ã©ã¤ã¡ã³ãçµæã¨ã47000 stepã®æç¹ã§ã®äºæ¸¬ãããé³å£°ãµã³ãã«ãç¤ºãã¾ãããªããgifã«ãããåç»åã¯ããã¼ã¿ã»ãããã©ã³ãã ã«ãµã³ãã«ããéã®ã¢ã©ã¤ã¡ã³ãã§ãããããåãé³å£°ã«å¯¾ããã¢ã©ã¤ã¡ã³ãã§ã¯ããã¾ãããTacotronè«æã«ã¯ãBahdanau Attentionãä½¿ç¨ããã¨ããã¾ããã&lt;a href=&#34;https://github.com/keithito/tacotron/issues/24&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;keithito/tacotron #24 Try Monotonic Attention&lt;/a&gt; ã«ããã¨ãTacotronè«æã®ç¬¬ä¸èèã¯æ°ãããã¼ã¸ã§ã³ã®Tacotronã§ã¯ Monotonic attentionãä½¿ç¨ãã¦ãããããã¨ãããã¨ãããMonotonic Attentionã§ãè©¦ãã¦ã¿ã¾ããããã¨ã§ããã£ãã®ã§ãããé·æï¼200æå­ãæ°æã¨ãï¼ãåæãããã¨ããã¨éä¸­ã§ã¢ã©ã¤ã¡ã³ããã¹ã­ãããããã¨ãå¤ãè¦åããããã®ã§ããããã£ãå ´åã«ãmonotonicã¨ããå¶ç´ãä¸æãåãã®ã ã¨æãã¾ãã&lt;/p&gt;
&lt;p&gt;ä»¥ä¸ã®é ã§gifãè²¼ãã¾ãã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/keithito/tacotron&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;keithito/tacotron&lt;/a&gt;, Bahdanau attention&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/keithito/tacotron&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;keithito/tacotron&lt;/a&gt;, Bahdanau-style monotonic attention&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/r9y9/tacotron_pytorch&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;r9y9/tacotron_pytorch&lt;/a&gt;, Bahdanau attention&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;keithito: Bahdanau Attention&lt;/strong&gt;&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/images/tacotron-tf-alignment_47000steps.gif&#34; /&gt;&lt;/div&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/step-47000-audio-tf.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;&lt;strong&gt;keithito: (Bahdanau-style) Monotonic Attention&lt;/strong&gt;&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/images/tacotron-tf-monotonic-alignment_47000steps.gif&#34; /&gt;&lt;/div&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/step-47000-audio-tf-monotonic.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;&lt;strong&gt;èªåå®è£: Bahdanau Attention&lt;/strong&gt;&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/images/tacotron-alignment_47000steps.gif&#34; /&gt;&lt;/div&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/step-47000-audio-pt.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;Monotonicãã©ããã§æ¯è¼ããã¨ãMonotonic attentionã®æ¹ãã¢ã©ã¤ã¡ã³ããããªãå®å®ãã¦ããããã«è¦ãã¾ããããããGithubã®ã¹ã¬ããã«ãã£ãé³å£°ãµã³ãã«ãè´ãã¨ãé³è³ªçãªæå³ã§ã¯å¤§ããªéãããªãããã«æã£ãã®ã¨ãåæéåº¦ï¼ç°¡åã«è©¦ããã¨ãããã¢ã©ã¤ã¡ã³ããã¾ã¨ãã«ãªãã ãstepã¯20000ãããã§ãã»ã¼åãã§ããï¼ãåãã«æãã¾ãããä¸æ¹ã§èªåå®è£ã¯ãã¢ã©ã¤ã¡ã³ããã¾ã¨ãã«ãªãstepã10000ãããã¨ããæ©ããã¾ãã·ã£ã¼ãã«è¦ãã¾ãã&lt;/p&gt;
&lt;p&gt;é³å£°ãµã³ãã«ã®æ¹ã§ãããæ¢å­å®è£ã¯ä¸¡èã¨ããããªãã«ã¾ã¨ãã§ããä¸æ¹èªåå®è£ã§ã¯ãã¾ã ããªããã¤ã¸ã¼ã§ããã§ããã ãtfå®è£ã¨åãããã«ã¤ãããå®é¨æ¡ä»¶ãåãã«ããã¤ããã§ãããä½ãééã£ã¦ããããããã¾ãããããã¤ãã¬ã¼ã·ã§ã³ãååã«åãã¨ãä¸å¿é³å£°ã¯ãããªãã«åºãããã«ãªãã¾ãã&lt;/p&gt;
&lt;p&gt;é³å£°ãµã³ãã«ã«é¢ããæ³¨æç¹ã¨ãã¦ã¯ãããã¯ãã³ã¼ãã®éã«æå¸«ãã¼ã¿ãä½¿ã£ã¦ããã®ã§ããã®æç¹ã§ã®ã¢ãã«ä½¿ã£ã¦ãåç­ã®é³è³ªã®é³å£°ãçæã§ããã¨ã¯éãã¾ãããå­¦ç¿æã«ã¯ããã³ã¼ãã®åã¿ã¤ã ã¹ãããã§æå¸«ãã¼ã¿ã®ã¹ãã¯ãã­ã°ã©ã ï¼æ­£ç¢ºã«ã¯ããã³ã¼ãã®åºåã¯ã¡ã«å¨æ³¢æ°ã¹ãã¯ãã­ã°ã©ã ï¼ãå¥åã¨ããä¸æ¹ã§ãè©ä¾¡æã«ã¯ããã³ã¼ãèªèº«ãåºåããã¹ãã¯ãã­ã°ã©ã ãæ¬¡ã®ã¿ã¤ã ã¹ãããã®å¥åã«ç¨ãã¾ããè©ä¾¡æã«ã¯ãä¸åº¦å¤ãªã¹ãã¯ãã­ã°ã©ã ãåºåãã¦ãã¾ã£ãããã¨ã©ã¼ãèç©ãã¦ãã£ã¦ã©ãã©ãå¤ãªåºåãããããã«ãªã£ã¦ãã¾ããã¨ã¯æ³åã«é£ãããªãã¨æãã¾ããseq2seqã¢ãã«ã®ãã³ã¼ãã«ã¯ãã¼ã ãµã¼ããä»£è¡¨çãªãã®ã¨ãã¦ããã¾ãããTacotronã§ã¯åç´ã«greedy decodingããã¾ãã&lt;/p&gt;
&lt;h3 id=&#34;å­¦ç¿ãé²ãã«ã¤ãã¦çæãããé³å£°ã¯ã©ã®ããã«å¤ãã£ã¦ããã®ã&#34;&gt;å­¦ç¿ãé²ãã«ã¤ãã¦ãçæãããé³å£°ã¯ã©ã®ããã«å¤ãã£ã¦ããã®ã&lt;/h3&gt;
&lt;p&gt;ãã¦ãããããã¯èªåå®è£ã®ã¿ã§ã®å®é¨çµæã§ããç´10æ¥ã70ä¸stepç¨åº¦å­¦ç¿ããã¾ããã®ã§ã5000, 10000, 50000, ãã®ãã¨ã¯10ä¸ãã10ä¸ã¹ããããã¨ã«70ä¸ã¹ãããã¾ã§ããããã§é³å£°ãçæãã¦ãã©ã®ããã«ãªã£ã¦ããã®ããè¦ã¦ããã¾ãã&lt;/p&gt;
&lt;h4 id=&#34;ä¾æ1&#34;&gt;ä¾æ1&lt;/h4&gt;
&lt;p&gt;Hi, my name is Tacotron. I&amp;rsquo;m still learning a lot from data.&lt;/p&gt;
&lt;p&gt;(56 chars, 14 words)&lt;/p&gt;
&lt;p&gt;step 5000&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/progress/0_step5000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;step 10000&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/progress/0_step10000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;step 50000&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/progress/0_step50000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;step 100000&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/progress/0_step100000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;step 200000&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/progress/0_step200000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;step 300000&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/progress/0_step300000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;step 400000&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/progress/0_step400000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;step 500000&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/progress/0_step500000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;step 600000&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/progress/0_step600000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;step 700000&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/progress/0_step700000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;ã ããã20ä¸ã¹ãããï¼å­¦ç¿äºæ¥ãããï¼ãããã¾ã¨ããªé³å£°ã«ãªã£ã¦ããããã«æãã¾ããç´°ããã¨ããã§ã¯ã&lt;code&gt;Hi,&lt;/code&gt; &lt;code&gt;Tacotron&lt;/code&gt; ã¨ããé¨åãå°ãçºé³ãã«ãããã§ãããã¼ã¿ã»ããã«ã¯ãã®ãããªè©±ãè¨èã®ãããªãã®ãå°ãªãã®ã¨ã&lt;code&gt;Tacotron&lt;/code&gt; ã¨ããåèªãè±èªãããçãªæå³ã§æªããããï¼é èªã§ããã­ããã¶ãï¼ã¨èãããã¾ãã&lt;/p&gt;
&lt;h4 id=&#34;ä¾æ2&#34;&gt;ä¾æ2&lt;/h4&gt;
&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Python_%28programming_language%29&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://en.wikipedia.org/wiki/Python_(programming_language)&lt;/a&gt; ããå¼ç¨ï¼&lt;/p&gt;
&lt;p&gt;Python is a widely used high-level programming language for general-purpose programming, created by Guido van Rossum and first released in 1991.&lt;/p&gt;
&lt;p&gt;(144 chars, 23 words)&lt;/p&gt;
&lt;p&gt;step 5000&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/progress/1_step5000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;step 10000&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/progress/1_step10000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;step 50000&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/progress/1_step50000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;step 100000&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/progress/1_step100000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;step 200000&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/progress/1_step200000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;step 300000&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/progress/1_step300000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;step 400000&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/progress/1_step400000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;step 500000&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/progress/1_step500000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;step 600000&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/progress/1_step600000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;step 700000&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/progress/1_step700000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;ã ããã20ä¸ã¹ããããããã¾ã¨ããªé³å£°ã«ãªã£ã¦ããããã«æãã¾ãã&lt;/p&gt;
&lt;h3 id=&#34;ã¢ãã«ã®æ±åæ§è½ã«ã¤ãã¦èª¿æ»&#34;&gt;ã¢ãã«ã®æ±åæ§è½ã«ã¤ãã¦èª¿æ»&lt;/h3&gt;
&lt;p&gt;ä»¥ä¸ã72ä¸ã¹ãããï¼ä¸é±éãããï¼å­¦ç¿ãããã¢ãã«ãä½¿ã£ã¦ãããããªå¥åã§ãã¹ãããçµæã§ããé³å£°ã¨åããã¦ã¢ã©ã¤ã¡ã³ããè²¼ã£ã¦ããã¾ãã&lt;/p&gt;
&lt;h4 id=&#34;é©å½ãªæªç¥å¥å&#34;&gt;é©å½ãªæªç¥å¥å&lt;/h4&gt;
&lt;p&gt;ãã¼ã¿ã»ããã«ã¯å­å¨ããªãæç« ãä½¿ã£ã¦ãã¹ããã¦ã¿ã¾ãããã¨ããã©ããï¼éãã¤ãã£ãã®åã«ã§ãï¼ä¸èªç¶ã ã¨æããã¨ãããè¦ããã¾ãããã¨ã¯ããã¾ãã¾ãããæãã§ã¯ãªãã§ããããã(google translateã§åãæç« ãåæãã¦ã¿ã¦æ¯ã¹ã¦ãããããªã«æªããªãæ°ããã¾ãã)&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/PyPy&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://en.wikipedia.org/wiki/PyPy&lt;/a&gt; ããï¼&lt;/p&gt;
&lt;p&gt;PyPy is an alternate implementation of the Python programming language written in Python.&lt;/p&gt;
&lt;p&gt;(89 chars, 14 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/0_unknown/0_step720000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/tacotron/0_unknown/0_step720000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/NumPy&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://en.wikipedia.org/wiki/NumPy&lt;/a&gt; ããï¼&lt;/p&gt;
&lt;p&gt;NumPy is a library for the Python programming language, adding support for large, multi-dimensional arrays and matrices, along with a large collection of high-level mathematical functions to operate on these arrays.&lt;/p&gt;
&lt;p&gt;(215 chars, 35 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/0_unknown/1_step720000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/tacotron/0_unknown/1_step720000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;&lt;a href=&#34;https://numba.pydata.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://numba.pydata.org/&lt;/a&gt; ããï¼&lt;/p&gt;
&lt;p&gt;Numba gives you the power to speed up your applications with high performance functions written directly in Python.&lt;/p&gt;
&lt;p&gt;(115 chars, 19 words)&lt;/p&gt;
&lt;p&gt;&lt;audio controls=&#34;controls&#34; &gt;ã¯&lt;/p&gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/0_unknown/2_step720000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/tacotron/0_unknown/2_step720000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;h4 id=&#34;ã¹ãã«ãã¹&#34;&gt;ã¹ãã«ãã¹&lt;/h4&gt;
&lt;p&gt;ã¹ãã«ãã¹ãããå ´åã«ãåæçµæã¯ã©ããªãã®ããã¨ãã£ããã¹ãã§ãã&lt;a href=&#34;https://google.github.io/tacotron/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Googleã®ãã¢&lt;/a&gt;ã«ããããã«ãããç¨åº¦ã­ãã¹ãï¼å°ãªãã¨ãå¨ä½ãç ´ç¶»ããã¨ãã£ããã¨ã¯ãªãï¼ã®ããã«æãã¾ããã&lt;/p&gt;
&lt;p&gt;Thisss isrealy awhsome.&lt;/p&gt;
&lt;p&gt;(23 chars, 4 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/1_spell/0_step720000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/tacotron/1_spell/0_step720000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;This is really awesome.&lt;/p&gt;
&lt;p&gt;(23 chars, 5 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/1_spell/1_step720000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/tacotron/1_spell/1_step720000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;I cannnnnot believe it.&lt;/p&gt;
&lt;p&gt;(23 chars, 5 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/1_spell/2_step720000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/tacotron/1_spell/2_step720000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;I cannot believe it.&lt;/p&gt;
&lt;p&gt;(20 chars, 6 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/1_spell/3_step720000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/tacotron/1_spell/3_step720000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;h4 id=&#34;ä¸­å°ãé·ãã®æç« &#34;&gt;ä¸­ãå°ãé·ãã®æç« &lt;/h4&gt;
&lt;p&gt;ã ããã250æå­ãè¶ãããããã§ãåèªãã¹ã­ããããããªã©ã®ç¾è±¡ãå¤ãç¢ºèªããã¾ããããã¼ã¿ã»ããã¯åºæ¬çã«ç­ãæç« ã®éã¾ããªã®ãçç±ã«æãã¾ããåè¿°ã®éããmonotonic attentionãä½¿ãã°ãåççã«ã¯ã¹ã­ããããã«ãããªãã¨æãã¾ãã&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/1703.10135&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://arxiv.org/abs/1703.10135&lt;/a&gt; ããå¼ç¨ï¼&lt;/p&gt;
&lt;p&gt;A text-to-speech synthesis system typically consists of multiple stages, such as a text analysis frontend, an acoustic model and an audio synthesis module.&lt;/p&gt;
&lt;p&gt;(155 chars, 26 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/2_long/1_step720000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/tacotron/2_long/1_step720000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;&lt;a href=&#34;https://americanliterature.com/childrens-stories/little-red-riding-hood&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://americanliterature.com/childrens-stories/little-red-riding-hood&lt;/a&gt; ããå¼ç¨ï¼&lt;/p&gt;
&lt;p&gt;Once upon a time there was a dear little girl who was loved by every one who looked at her, but most of all by her grandmother, and there was nothing that she would not have given to the child.&lt;/p&gt;
&lt;p&gt;(193 chars, 43 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/2_long/0_step720000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/tacotron/2_long/0_step720000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/1703.10135&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://arxiv.org/abs/1703.10135&lt;/a&gt; ããå¼ç¨ï¼&lt;/p&gt;
&lt;p&gt;A text-to-speech synthesis system typically consists of multiple stages, such as a text analysis frontend, an acoustic model and an audio synthesis module. Building these components often requires extensive domain expertise and may contain brittle design choices.&lt;/p&gt;
&lt;p&gt;(263 chars, 41 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/2_long/2_step720000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/tacotron/2_long/2_step720000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;&lt;a href=&#34;https://americanliterature.com/childrens-stories/little-red-riding-hood&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://americanliterature.com/childrens-stories/little-red-riding-hood&lt;/a&gt; ããå¼ç¨ï¼&lt;/p&gt;
&lt;p&gt;Once upon a time there was a dear little girl who was loved by every one who looked at her, but most of all by her grandmother, and there was nothing that she would not have given to the child. Once she gave her a little cap of red velvet, which suited her so well
that she would never wear anything else. So she was always called Little Red Riding Hood.&lt;/p&gt;
&lt;p&gt;(354 chars, 77 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/2_long/3_step720000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/tacotron/2_long/3_step720000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;h3 id=&#34;googleã®ãã¢ã¨æ¯è¼&#34;&gt;Googleã®ãã¢ã¨æ¯è¼&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://google.github.io/tacotron/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://google.github.io/tacotron/&lt;/a&gt; ã®é³å£°ãµã³ãã«ã¨åãæç« ã§è©¦ãã¾ããå¤§æå­å°æå­ã®åºå¥ã¯ä»åå­¦ç¿ããã¢ãã«ã§ã¯åºå¥ããªãã®ã§ãä¸é¨ä¾æã¯é¤ãã¦ãã¾ããããã¤ãæ°ã¥ãããã¨ãæãã¦ããã¨ã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;He has read the whole thing. / He reads book. ã®ããã«ãreadã®èª­ã¿ãåè©ã®æ´»ç¨å½¢ã«ãã£ã¦å¤ãããããªå ´åãªã®ã§ãããä¸æãè¡ãã¨ãã¨ãããªãã¨ããããã¾ãããã¤ãã¬ã¼ã·ã§ã³ãé²ãã¦ããä¸ã§ãã­ã¹ã¯ä¸ããç¶ããä¸æ¹ã§ããã¡ãã¨åºå¥ãã¦çºé³ã§ããããã«ãªã£ããã§ããªããªã£ã¦ãã¾ã£ãããã¨ããã®ãç¹°ãè¿ãã¦ãã¾ããã&lt;/li&gt;
&lt;li&gt;&lt;code&gt;?&lt;/code&gt; ãææ«ã«ã¤ããã¨ã§ãã¤ã³ããã¼ã·ã§ã³ãå¤ãã£ã¦ããããã¨ãæå¾ãã¾ãããããã¼ã¿ã»ããä¸­ã« &lt;code&gt;?&lt;/code&gt; ãå°ãªãããã®ãããã¾ããã¾ããããªãã£ãããã«æãã¾ãã&lt;/li&gt;
&lt;li&gt;out-of-domainã®æç« ã«ãã­ãã¹ãã®ããã«æãã¾ããããäºåç®ã®ä¾æã®ãããªãï¼è¤éãªï¼ï¼å°éç¨èªã®çºé³ã¯ãå³ããæãããã¾ããã&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Generative adversarial network or variational auto-encoder.&lt;/p&gt;
&lt;p&gt;(59 chars, 7 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/4_google_demo/0_step720000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/tacotron/4_google_demo/0_step720000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;Basilar membrane and otolaryngology are not auto-correlations.&lt;/p&gt;
&lt;p&gt;(62 chars, 8 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/4_google_demo/1_step720000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/tacotron/4_google_demo/1_step720000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;He has read the whole thing.&lt;/p&gt;
&lt;p&gt;(28 chars, 7 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/4_google_demo/2_step720000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/tacotron/4_google_demo/2_step720000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;He reads books.&lt;/p&gt;
&lt;p&gt;(15 chars, 4 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/4_google_demo/3_step720000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/tacotron/4_google_demo/3_step720000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;Thisss isrealy awhsome.&lt;/p&gt;
&lt;p&gt;(23 chars, 4 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/4_google_demo/4_step720000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/tacotron/4_google_demo/4_step720000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;This is your personal assistant, Google Home.&lt;/p&gt;
&lt;p&gt;(45 chars, 9 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/4_google_demo/5_step720000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/tacotron/4_google_demo/5_step720000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;This is your personal assistant Google Home.&lt;/p&gt;
&lt;p&gt;(44 chars, 8 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/4_google_demo/6_step720000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/tacotron/4_google_demo/6_step720000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;The quick brown fox jumps over the lazy dog.&lt;/p&gt;
&lt;p&gt;(44 chars, 10 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/4_google_demo/7_step720000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/tacotron/4_google_demo/7_step720000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;Does the quick brown fox jump over the lazy dog?&lt;/p&gt;
&lt;p&gt;(51 chars, 11 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/4_google_demo/8_step720000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/tacotron/4_google_demo/8_step720000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;h3 id=&#34;keithitotacotron-ã¨ã®æ¯è¼&#34;&gt;keithito/tacotron ã¨ã®æ¯è¼&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://keithito.github.io/audio-samples/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://keithito.github.io/audio-samples/&lt;/a&gt; ã® audio samples ã§ä½¿ããã¦ããæç« ã«å¯¾ãããã¹ãã§ããæ¯è¼ããããããã«ãæ¯è¼å¯¾è±¡ã®é³å£°ãåããã¦è²¼ã£ã¦ããã¾ããèªåå®è£ã§çæãããã®ã&lt;a href=&#34;https://github.com/keithito/tacotron&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;keithito/tacotron&lt;/a&gt; ã§çæãããã®ãã®é ã§ãã&lt;/p&gt;
&lt;p&gt;Scientists at the CERN laboratory say they have discovered a new particle.&lt;/p&gt;
&lt;p&gt;(74 chars, 13 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/3_keithito/0_step720000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/keithito/eval-877000-0.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/tacotron/3_keithito/0_step720000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;There&amp;rsquo;s a way to measure the acute emotional intelligence that has never gone out of style.&lt;/p&gt;
&lt;p&gt;(91 chars, 18 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/3_keithito/1_step720000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/keithito/eval-877000-1.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/tacotron/3_keithito/1_step720000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;President Trump met with other leaders at the Group of 20 conference.&lt;/p&gt;
&lt;p&gt;(69 chars, 13 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/3_keithito/2_step720000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/keithito/eval-877000-2.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/tacotron/3_keithito/2_step720000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;The Senate&amp;rsquo;s bill to repeal and replace the Affordable Care Act is now imperiled.&lt;/p&gt;
&lt;p&gt;(81 chars, 16 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/3_keithito/3_step720000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/keithito/eval-877000-3.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/tacotron/3_keithito/3_step720000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;Generative adversarial network or variational auto-encoder.&lt;/p&gt;
&lt;p&gt;(59 chars, 7 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/3_keithito/4_step720000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/keithito/eval-877000-4.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/tacotron/3_keithito/4_step720000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;The buses aren&amp;rsquo;t the problem, they actually provide a solution.&lt;/p&gt;
&lt;p&gt;(63 chars, 13 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/3_keithito/5_step720000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/keithito/eval-877000-5.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/tacotron/3_keithito/5_step720000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;h3 id=&#34;ground-truth-ã¨ã®æ¯è¼&#34;&gt;Ground truth ã¨ã®æ¯è¼&lt;/h3&gt;
&lt;p&gt;æå¾ã«ãåã®ãã¼ã¿ã»ããã¨ã®æ¯è¼ã§ããå­¦ç¿ãã¼ã¿ãããµã³ãã«ãåã£ã¦ãã¦æ¯è¼ãã¾ããèªåå®è£ã§çæãããã®ãground truthã®é ã«è²¼ãã¾ãã&lt;/p&gt;
&lt;p&gt;Printing, in the only sense with which we are at present concerned, differs from most if not from all the arts and crafts represented in the Exhibition.&lt;/p&gt;
&lt;p&gt;(152 chars, 30 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/5_ljspeech_sample/0_step720000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/lj/LJ001-0001.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/tacotron/5_ljspeech_sample/0_step720000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;in being comparatively modern.&lt;/p&gt;
&lt;p&gt;(30 chars, 5 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/5_ljspeech_sample/1_step720000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/lj/LJ001-0002.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/tacotron/5_ljspeech_sample/1_step720000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;For although the Chinese took impressions from wood blocks engraved in relief for centuries before the woodcutters of the Netherlands, by a similar process.&lt;/p&gt;
&lt;p&gt;(156 chars, 26 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/5_ljspeech_sample/2_step720000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/lj/LJ001-0003.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/tacotron/5_ljspeech_sample/2_step720000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;produced the block books, which were the immediate predecessors of the true printed book,&lt;/p&gt;
&lt;p&gt;(89 chars, 16 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/5_ljspeech_sample/3_step720000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/lj/LJ001-0004.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/tacotron/5_ljspeech_sample/3_step720000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;the invention of movable metal letters in the middle of the fifteenth century may justly be considered as the invention of the art of printing.&lt;/p&gt;
&lt;p&gt;(143 chars, 26 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/5_ljspeech_sample/4_step720000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/lj/LJ001-0005.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/tacotron/5_ljspeech_sample/4_step720000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;åé³å£°ããã¾ãè¯ãã¯ãªã¼ã³ãªé³å£°ã§ã¯ãªãã¨ã¯ãããã¾ã¼åé³å£°ã¨ã¯å¤§ããªéããããã¾ãã­ã¼ããå³ããã§ããã¹ãã¯ãã­ã°ã©ã ãè¦ã¦ããéãã§ã¯ï¼è²¼ã£ã¦ãªãã§ãããããã¾ããï¼ãæããã«é«å¨æ³¢æ°æåã®äºæ¸¬ãä¸æãè¨ã£ã¦ããªããã¨ã¯ããã£ã¦ãã¾ãããã¤ã¼ããªã¢ã¤ãã¢ã§ã¯ããã¾ãããGANãå°å¥ããã¨è¯ããªãã®ã§ã¯ãªããã¨æã£ã¦ãã¾ãã&lt;/p&gt;
&lt;h3 id=&#34;ãã¾ãçæããåº¦ã«å¤ããé³å£°&#34;&gt;ãã¾ãï¼çæããåº¦ã«å¤ããé³å£°&lt;/h3&gt;
&lt;p&gt;å®é¨ããéç¨ã§å¯æ¬¡çã«å¾ãããçµæã§ã¯ããã®ã§ããããã¹ãæã«ä¸é¨dropoutãæå¹ã«ãã¦ããã¨&lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;ãçæããåº¦ã«é³å£°ãç°ãªãï¼é»å¾ãå¾®å¦ã«å¤ããï¼ãã¨ãã£ãç¾è±¡ãçµé¨ãã¦ãã¾ããä»¥ä¸ãåã«æ¤è¨¼ããéã®å®é¨ãã¼ãã®ãªã³ã¯ãè²¼ã£ã¦ããã¾ãã&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://nbviewer.jupyter.org/gist/r9y9/fe1945b73cd5b98e97c61410fe26a851#Try-same-input-multiple-times&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://nbviewer.jupyter.org/gist/r9y9/fe1945b73cd5b98e97c61410fe26a851#Try-same-input-multiple-times&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;ã¾ã¨ã--ææ³ãªã©&#34;&gt;ã¾ã¨ã &amp;amp; ææ³ãªã©&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Tacotronãå®è£ãã¾ãã &lt;a href=&#34;https://github.com/r9y9/tacotron_pytorch&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/r9y9/tacotron_pytorch&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;24æéã®ãã¼ã¿ã»ããã«å¯¾ãã¦ã20ä¸ã¹ãããç¨åº¦ï¼æ°æ¥ãããï¼å­¦ç¿ãããããããªãã«ã¾ã¨ããªé³å£°ãçæã§ããããã«ãªãã¾ããã70ä¸ã¹ãããï¼ä¸é±éã¨å°ããããï¼å­¦ç¿ããã¾ãããããã£ã¨ã­ã¹ã¯ä¸ããç¶ããä¸æ¹ã§ã50ä¸ãããããã¯ãã¾ãå¤§ããªåè³ªæ¹åã¯è¦ãããªãã£ãããã«æãã¾ãã&lt;/li&gt;
&lt;li&gt;Googleã®è«æã¨ï¼ã»ã¼&lt;sup id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;ï¼åãããã«å®è£ããã¤ããã§ãããåè³ªã¯ããã¾ã§é«ããªããªãã£ãããã«æãã¾ããEnd-to-end ã§ã¯ã &lt;strong&gt;ãã¼ã¿ã®éã¨åè³ª&lt;/strong&gt; ãããªãéè¦ãªã®ã§ããããä¸»ãªåå ã ã¨æã£ã¦ãã¾ããï¼åã®å®è£ã«ãå¤å°ãã°ãããããããã¾ãããããã&lt;/li&gt;
&lt;li&gt;EOS (End-of-sentence) ã§ã¯ãçæ³çã«ã¯è¦ç´ ããã¹ã¦0ã®ã¹ãã¯ãã­ã°ã©ã ãåºåãããã¯ããªã®ã§ãããå®éã«ã¯ãã¯ãããããããªãã®ã§ãå¤å®ã«ã¯ä»¥ä¸ã®ãããªãããå¤å¦çãç¨ãã¾ãããããã§è²¼ã£ãé³å£°ã¯å¨é¨ãã®ä»çµã¿ã§åãã¦ãããåç´ã§ãããããªãã«ä¸æãæ©è½ãã¦ããããã§ãã&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;def is_end_of_frames(output, eps=0.2):
    return (output.data &amp;lt;= eps).all()
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;è«æããã¯éèªæãªç¹ã®ä¸ã¤ã¨ãã¦ãã¨ã³ã³ã¼ãã®åºåã®ãã¡ãå¥åã®ã¼ã­è©°ãããé¨åããã¹ã­ã³ã°ãããã©ãããã¨ãã£ãç¹ãããã¾ããããã¯ãæ¢å­å®è£ã«ãã£ã¦ãã¾ã¡ã¾ã¡ã§ãä¾ãã° &lt;a href=&#34;https://github.com/keithito/tacotron&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;keithito/tacotron&lt;/a&gt; ã§ã¯ãã¹ã­ã³ã°ãã¦ãã¾ãããã&lt;a href=&#34;https://github.com/barronalex/Tacotron/blob/2de9e507456cbe2b680cbc6b2beb6a761bd2eebd/models/tacotron.py#L51&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;barronalex/Tacotron&lt;/a&gt; ã§ã¯ãã¹ã¯ãã¦ãã¾ããåã¯ãã¹ã¯ããå ´åã¨ããªãå ´åã¨ä¸¡æ¹è©¦ããã®ã§ããï¼ããã«è²¼ã£ãçµæã¯ããã¹ã¯ãã¦ããªãå ´åã®ãã®ã§ãï¼ããã¹ã¯ããªãã»ããè¥å¹²è¯ããªã£ããããªæ°ããã¾ããçæ³çã«ã¯ãã¹ã¯ããã¹ãã ã¨æã£ãã®ã§ãããå®éã«è©¦ããã¨ããã©ã¡ãããå§åçã«æªãã¨ããçµæã§ã¯ããã¾ããã§ãããçºè¦ããå¤§ããªéãã®ä¸ã¤ã¯ããã¹ã¯ãªãã®å ´åã¯ã¢ãã³ã·ã§ã³ã¯å¤§ã¾ãã«monotonicã«ãªãä¸æ¹ã§ããã¹ã¯ããã®å ´åã¯ãç¡é³åºéã§ã¯ã¨ã³ã³ã¼ãåºåã®åé ­ã«ã¢ãã³ã·ã§ã³ã®éã¿ãå¤§ãããªãï¼ã®ã§ãmonotonicã§ã¯ãªãï¼ãã¨è¨ã£ããã¨ãããã¾ããããã¹ã¯ããã®é³å£°ãµã³ãã«ãã¢ã©ã¤ã¡ã³ãã®å¯è¦åã¯ãï¼å°ãå¤ãã§ããï¼&lt;a href=&#34;http://nbviewer.jupyter.org/github/r9y9/tacotron_pytorch/blob/bdad19fdff22016c7457a979707655bb7a605cd8/notebooks/Test%20Tacotron.ipynb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ãã&lt;/a&gt; ã«ããã¾ããåèã¾ã§ã«ãTensorflowã§ã¨ã³ã³ã¼ãã®åºåãã¹ã¯ããå ´åã¯ã&lt;code&gt;memory_sequence_length&lt;/code&gt; ãæå®ãã¾ã &lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/BahdanauAttention&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/BahdanauAttention&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;æ¥æ¬èªã§ãã£ãããmulti-speaker ã§ãã£ãããããã£ãã®ã§ãããã¨ã«ããå®é¨ã«æéããããã®ã§ãä»ã®ã¨ããåã®ä¸­ã§ã¯åªååº¦ãä½ãã«ãªã£ã¦ãã¾ãã¾ãããæéã¨è¨ç®è³æºã«ä½è£ãããã°ãããããã®ã§ããâ¦&lt;/li&gt;
&lt;li&gt;æ¥æ¬èªã§ããã«ã¯ãè±èªã¨åãããã«ã¯ããã¾ãããã¨ããã®ããchar-levelã§èããéã«ãèªå½ãå¤§ããããã®ã§ããããªãã°ãååå¤§ããªæ¥æ¬èªãã­ã¹ãã³ã¼ãã¹ããembeddingãå¥éå­¦ç¿ãã¦ï¼Tacotronã§ã¯ãã¢ãã«èªä½ã«embeddingãå¥ã£ã¦ãã¾ãï¼ããã®ä»ã®é¨åãé³å£°ã¤ãã³ã¼ãã¹ã§å­¦ç¿ãããã¨ãã£ãæ¹æ³ãè¯ãããªã¨æãã¾ããCSJã³ã¼ãã¹ã¯çµæ§åãã¦ããããããªããã¨æã£ã¦ãã¾ãã&lt;/li&gt;
&lt;li&gt;multi-speakerã¢ãã«ãèããå ´åãã©ãã«embeddingãå·®ãè¾¼ãã®ããã¨ãã£ããã¨ãéè¦ã«ãªã£ã¦ãã¾ããã&lt;a href=&#34;https://github.com/keithito/tacotron/issues/18&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;keithito/tacotron/issues/18&lt;/a&gt; ã &lt;a href=&#34;https://github.com/keithito/tacotron/issues/24&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;keithito/tacotron/issues/24&lt;/a&gt; ã«å°ãè­°è«ãããã®ã§ãèå³ã®ããäººã¯è¦ã¦ã¿ãã¨ããããããã¾ãããDeepVoiceã®è«æãåèã«ãªããã¨æãã¾ã&lt;/li&gt;
&lt;li&gt;ææ°ã®TensorFlowã§ã¯ãgriffin lim ã stftï¼GPUã§èµ°ããå¾éãæ±ããããï¼ãå®è£ããã¦ããã®ã§ãtacotronã¢ãã«ãå°ãæ¡å¼µãã¦ããµã³ãã«ã¬ãã«ã§ã­ã¹ãèãããã¨ãã£ããã¨ãç°¡åã«è©¦ããã¨æãã¾ãï¼ããæå³WaveNetã§ãï¼ããã ãããã®ãããè¨ç®ãªã½ã¼ã¹ãå¿è¦ã¨ããã®ãå®¹æã«æ³åãã¤ãã®ã§ãåã¯ãã£ã¦ãã¾ãããGPUè½ã¡ã¦ããªãããªããã&lt;/li&gt;
&lt;li&gt;Tacotronã®æ¡å¼µã¨ãã¦ãspeaker embeddingä»¥å¤ã«ããããããªæ½å¨å¤æ°ãåãè¾¼ãã§ã¿ãã¨ãæ¥½ãããã«æãã¾ãããä¾ãã°è©±éãææã¨ãã&lt;/li&gt;
&lt;li&gt;TensorFlowã®seq2seqãããã®ãã­ã¥ã¡ã³ã/ã³ã¼ããããèª­ãã§ããã®ã§ãããAPIãæ½è±¡åããããã¦ãã¦ã¤ãããªã¨æãã¾ãããä¾ãã°AttentionWrapperãã³ã¼ããèª­ã¾ãã«æåãçè§£ããã®ã¯ç¡çãªã®ã§ã¯ã¨æãã¾ãã &lt;a href=&#34;https://github.com/r9y9/tacotron_pytorch/issues/2#issuecomment-334255759&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/r9y9/tacotron_pytorch/issues/2#issuecomment-334255759&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/keithito/tacotron&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;keithito/tacotron&lt;/a&gt; ã¯æ¬å½ã«ããæ¸ããã¦ãããªã¨æã£ãã®ã§ãTensorFlowã«é·ãã¦ããæ¹ã«ã¯ãããããã§ã&lt;/li&gt;
&lt;li&gt;åã®å®è£ã§ã¯ãããããµã¤ãº32ã§GPUã¡ã¢ãª5GBç¨åº¦ããé£ããªãã®ã§ãTacotronã¯æ¯è¼çè»½ãã¢ãã«ãªã®ã ãªã¼ã¨æãã¾ãããç©ä½æ¤åºã§æåãª single shot multibox detector (éç§°SSD) ãªããã¯ãããããµã¤ãº16ã¨ãã§ãå¹³æ°ã§12GBã¨ãä½¿ã£ã¦ããã®ã§ï¼ä¸å¹´è¿ãåã®çµé¨ã§ããï¼ãç¡éã«GPUãªã½ã¼ã¹ãã»ãããªã£ã¦ãã¾ã&lt;/li&gt;
&lt;li&gt;ãããåã«ã¨ã£ã¦ãã¯ããã¦ã¾ã¨ãã«seq2seqãå®è£ããçµé¨ã§ãããè²ãåå¼·ããã®ã§ãããAttention mechanism ã«é¢ãã¦ã¯ã &lt;a href=&#34;http://colinraffel.com/blog/online-and-linear-time-attention-by-enforcing-monotonic-alignments.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://colinraffel.com/blog/online-and-linear-time-attention-by-enforcing-monotonic-alignments.html&lt;/a&gt; ãã¨ã¦ãåèã«ãªãã¾ããããã¨ã§ç¥ã£ãã®ã§ãããmonotonic attentionã®èèã¯åãæããä½¿ã£ã¦ããé³æ¥½ä¿¡å·å¦çã®ã©ã¤ãã©ãª &lt;a href=&#34;https://github.com/librosa/librosa&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;librosa&lt;/a&gt; ã®ã³ããã¿ã§ããï¼åãå¼±å°ã³ããã¿ã®ä¸äººï¼ãã¨ã¦ãä¾¿å©ã§ããããã¹ãããã¦ããã®ã§ãããããã§ãããªã¼ãã³ã½ã¼ã¹ã®Tacotronå®è£ã§ããé³å£°å¦çã«ãä½¿ããã¦ãã¾ã&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;ãããã«&#34;&gt;ãããã«&lt;/h2&gt;
&lt;p&gt;End-to-End é³å£°åæã¯ãè¨èªå¦çã®ãã­ã³ãã¨ã³ããï¼æä½éã®åå¦çãé¤ãï¼å¿è¦ã¨ããªãã¨ããç´ æ´ããããããã¾ããSampleRNNãChar2wavã¨ä»ã«ãè²ãããã¾ãããä»å¾ãã£ã¨çºå±ãã¦ããã®ã§ã¯ãªããã¨æã£ã¦ãã¾ããããã¾ãã&lt;/p&gt;
&lt;h2 id=&#34;åè&#34;&gt;åè&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1703.10135&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Tacotron: Towards End-to-End Speech Synthesis / arXiv:1703.10135&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;URLã«ã¯ç¾æç¹ã®gitã®ã³ãããããã·ã¥ãå¥ã£ã¦ãã¾ããææ°çã¯ã &lt;a href=&#34;https://github.com/r9y9/tacotron_pytorch&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/r9y9/tacotron_pytorch&lt;/a&gt; ããç´æ¥è¾¿ã£ã¦ãã ããã&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/keithito/tacotron/pull/43#issuecomment-332068107&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/keithito/tacotron/pull/43#issuecomment-332068107&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;dropoutãåã£ã¦ãã¾ãã¨ãã¢ã©ã¤ã¡ã³ããæ­»ãã§ãã¾ãã¨ãããã°ï¼ã«è¦ããã§ããâ¦æªã åå ãçªãæ­¢ãããã¦ãã¾ãã&amp;#160;&lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:4&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;ãã¨ãã°ã­ã¹ã¯ã¡ãã£ã¨éã£ã¦ãé«å¨æ³¢æ°å¸¯åã«æ¯ã¹ã¦ä½å¨æ³¢æ°å¸¯åã®éã¿ãå°ãå¤§ãããã¦ããããã¦ãã¾ããããã¯æ¢å­ã®tfå®è£ã«å¾ãã¾ããã&amp;#160;&lt;a href=&#34;#fnref:4&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
    </item>
    
    <item>
      <title>GAN æ¥æ¬èªé³å£°åæ [arXiv:1709.08041]</title>
      <link>https://r9y9.github.io/blog/2017/10/10/gantts-jp/</link>
      <pubDate>Tue, 10 Oct 2017 11:45:32 +0900</pubDate>
      <guid>https://r9y9.github.io/blog/2017/10/10/gantts-jp/</guid>
      <description>&lt;p&gt;&lt;strong&gt;10/11 è¿½è¨&lt;/strong&gt;: IEEE TASLPã®ãã¼ãã¼ (Open access) ãå¬éããããããªã®ã§ããªã³ã¯ãè²¼ã£ã¦ããã¾ã: &lt;a href=&#34;https://ieeexplore.ieee.org/document/8063435/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://ieeexplore.ieee.org/document/8063435/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;arXivè«æãªã³ã¯: &lt;a href=&#34;https://arxiv.org/abs/1709.08041&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;arXiv:1709.08041&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://r9y9.github.io/blog/2017/10/09/gantts/&#34;&gt;ååã®è¨äº&lt;/a&gt; ã®ç¶ãã§ããããã§ãã®ã·ãªã¼ãºã¯çµããã®äºå®ã§ãã&lt;/p&gt;
&lt;p&gt;ååã¯è±èªé³å£°åæã§ããããä»¥åæ¸ãã &lt;a href=&#34;https://r9y9.github.io/blog/2017/08/16/japanese-dnn-tts/&#34;&gt;DNNæ¥æ¬èªé³å£°åæã®è¨äº&lt;/a&gt; ã§ä½¿ã£ããã¼ã¿ã¨åããã®ãä½¿ããæ¥æ¬èªé³å£°åæããã£ã¦ã¿ã¾ããã®ã§ãçµæãæ®ãã¦ããã¾ãã&lt;/p&gt;
&lt;h2 id=&#34;å®é¨&#34;&gt;å®é¨&lt;/h2&gt;
&lt;h3 id=&#34;å®é¨æ¡ä»¶&#34;&gt;å®é¨æ¡ä»¶&lt;/h3&gt;
&lt;p&gt;HTSã®NIT-ATR503ã®ãã¢ãã¼ã¿ (&lt;a href=&#34;https://github.com/r9y9/nnmnkwii_gallery/blob/4899437e22528399ca50c34097a2db2bed782f8b/data/NIT-ATR503_COPYING&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ã©ã¤ã»ã³ã¹&lt;/a&gt;) ãããwavãã¼ã¿503çºè©±ãç¨ãã¾ãã442ãå­¦ç¿ç¨ã56ãè©ä¾¡ç¨ãæ®ã5ããã¹ãç¨ã«ãã¾ãï¼â»è±èªé³å£°ã¨train/evalã®æ¯çã¯åãã§ãï¼ãç¶ç¶é·ã¢ãã«ã¯ãstate-levelã§ã¯ãªãphone-levelã§ãããµã³ããªã³ã°å¨æ³¢æ°ã48kHzãªã®ã§ãmgcã®æ¬¡åã25ãã60ã«å¢ããã¾ãããã¢ãã«æ§é ã¯ããã¹ã¦è±èªé³å£°åæã®å ´åã¨åãã§ããADV loss ã¯0æ¬¡ãé¤ãmgcãç¨ãã¦è¨ç®ãã¾ãããF0ã¯å¥ãã¦ãã¾ããã&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/r9y9/gantts&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;gantts&lt;/a&gt; ã® &lt;a href=&#34;https://github.com/r9y9/gantts/tree/jp&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;jpãã©ã³ã&lt;/a&gt; ããã§ãã¯ã¢ã¦ããã¦ãä»¥ä¸ã®ã·ã§ã«ãå®è¡ããã¨ãããã«è²¼ã£ãçµæãå¾ããã¾ãã&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; ./jp_tts_demo.sh jp_tts_order59
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;ãã ããã·ã§ã«ä¸­ã«ã&lt;code&gt;HTS_ROOT&lt;/code&gt; ã¨ããå¤æ°ããããã·ã§ã«å®è¡åã«ãç°å¢ã«åããã¦ãã£ã¬ã¯ããªãæå®ããå¿è¦ãããã¾ãã&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt;diff --git a/jp_tts_demo.sh b/jp_tts_demo.sh
index 7a8f12c..b18e604 100755
--- a/jp_tts_demo.sh
+++ b/jp_tts_demo.sh
@@ -8,7 +8,7 @@ experiment_id=$1
 fs=48000

 # Needs adjastment
-HTS_DEMO_ROOT=~/local/HTS-demo_NIT-ATR503-M001
+HTS_DEMO_ROOT=HTSæ¥æ¬èªãã¢ã®å ´æãæå®ãã¦ãã ãã

 # Flags
 run_duration_training=1
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;å¤æé³å£°ã®æ¯è¼&#34;&gt;å¤æé³å£°ã®æ¯è¼&lt;/h3&gt;
&lt;h4 id=&#34;é³é¿ã¢ãã«ã®ã¿é©ç¨&#34;&gt;é³é¿ã¢ãã«ã®ã¿é©ç¨&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;èªç¶é³å£°&lt;/li&gt;
&lt;li&gt;ãã¼ã¹ã©ã¤ã³&lt;/li&gt;
&lt;li&gt;GAN&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;ã®é ã«é³å£°ãè²¼ãã¾ããè´ããããããã«ãsoxã§é³éãæ­£è¦åãã¦ãã¾ãã&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;nitech_jp_atr503_m001_j49&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/nit-atr503/nitech_jp_atr503_m001_j49.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-gantts/jp_tts_order59/acoustic_only/baseline/test/nitech_jp_atr503_m001_j49.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-gantts/jp_tts_order59/acoustic_only/gan/test/nitech_jp_atr503_m001_j49.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;&lt;strong&gt;nitech_jp_atr503_m001_j50&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/nit-atr503/nitech_jp_atr503_m001_j50.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-gantts/jp_tts_order59/acoustic_only/baseline/test/nitech_jp_atr503_m001_j50.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-gantts/jp_tts_order59/acoustic_only/gan/test/nitech_jp_atr503_m001_j50.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;&lt;strong&gt;nitech_jp_atr503_m001_j51&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/nit-atr503/nitech_jp_atr503_m001_j51.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-gantts/jp_tts_order59/acoustic_only/baseline/test/nitech_jp_atr503_m001_j51.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-gantts/jp_tts_order59/acoustic_only/gan/test/nitech_jp_atr503_m001_j51.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;&lt;strong&gt;nitech_jp_atr503_m001_j52&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/nit-atr503/nitech_jp_atr503_m001_j52.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-gantts/jp_tts_order59/acoustic_only/baseline/test/nitech_jp_atr503_m001_j52.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-gantts/jp_tts_order59/acoustic_only/gan/test/nitech_jp_atr503_m001_j52.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;&lt;strong&gt;nitech_jp_atr503_m001_j53&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/nit-atr503/nitech_jp_atr503_m001_j53.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-gantts/jp_tts_order59/acoustic_only/baseline/test/nitech_jp_atr503_m001_j53.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-gantts/jp_tts_order59/acoustic_only/gan/test/nitech_jp_atr503_m001_j53.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;h4 id=&#34;é³é¿ã¢ãã«ç¶ç¶é·ã¢ãã«ãé©ç¨&#34;&gt;é³é¿ã¢ãã«ï¼ç¶ç¶é·ã¢ãã«ãé©ç¨&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;nitech_jp_atr503_m001_j49&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/nit-atr503/nitech_jp_atr503_m001_j49.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-gantts/jp_tts_order59/duration_acoustic/baseline/test/nitech_jp_atr503_m001_j49.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-gantts/jp_tts_order59/duration_acoustic/gan/test/nitech_jp_atr503_m001_j49.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;&lt;strong&gt;nitech_jp_atr503_m001_j50&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/nit-atr503/nitech_jp_atr503_m001_j50.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-gantts/jp_tts_order59/duration_acoustic/baseline/test/nitech_jp_atr503_m001_j50.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-gantts/jp_tts_order59/duration_acoustic/gan/test/nitech_jp_atr503_m001_j50.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;&lt;strong&gt;nitech_jp_atr503_m001_j51&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/nit-atr503/nitech_jp_atr503_m001_j51.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-gantts/jp_tts_order59/duration_acoustic/baseline/test/nitech_jp_atr503_m001_j51.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-gantts/jp_tts_order59/duration_acoustic/gan/test/nitech_jp_atr503_m001_j51.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;&lt;strong&gt;nitech_jp_atr503_m001_j52&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/nit-atr503/nitech_jp_atr503_m001_j52.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-gantts/jp_tts_order59/duration_acoustic/baseline/test/nitech_jp_atr503_m001_j52.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-gantts/jp_tts_order59/duration_acoustic/gan/test/nitech_jp_atr503_m001_j52.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;&lt;strong&gt;nitech_jp_atr503_m001_j53&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/nit-atr503/nitech_jp_atr503_m001_j53.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-gantts/jp_tts_order59/duration_acoustic/baseline/test/nitech_jp_atr503_m001_j53.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-gantts/jp_tts_order59/duration_acoustic/gan/test/nitech_jp_atr503_m001_j53.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;ã©ãã§ãããããã¡ãã£ã¨æ©å£ã«ãªã£ã¦ãã¾ã£ã¦ããç®æãããã¾ãããå¨ä½çã«ã¯æç­æ§ãä¸ãã£ã¦ãåè³ªãæ¹åããããããªæãããã¾ããè¥å¹²ãã¤ã¸ã¼ãªæãã¯ãé³é¿ã¢ãã«ã«RNNãä½¿ãã°æ¹åãããã®ã§ãããä»åã¯è¨ç®ãªã½ã¼ã¹ã®é½åä¸ãFeed-forwardåã®ãµã³ãã«ã¨ãªã£ã¦ãã¾ãã&lt;/p&gt;
&lt;h3 id=&#34;gv&#34;&gt;GV&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;nitech_jp_atr503_m001_j49&lt;/code&gt; ã«å¯¾ãã¦è¨ç®ããçµæã§ãã&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/images/jp-gantts/nitech_jp_atr503_m001_j49_gv.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;è±èªé³å£°åæã®å®é¨ã§ãç¢ºèªãã¦ããã®ã§ãããmgcã®æ¬¡åãå¤§ããåãã¨ãé«æ¬¡åã§GVãè¥å¹²è½ã¡ãå¾åã«ããã¾ãããã ãã&lt;a href=&#34;https://twitter.com/r9y9/status/915213687891169280&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ä¸é±éåã®åã®ãã¤ã¼ã&lt;/a&gt; ã«ããã¨ããªãããããªãã¨ããªãï¼å½æã°ãã°ãã®ãã­ãã¿ã¤ãã³ã°ã®ææã ã£ãã®ã§ãã³ã¼ããæ®ã£ã¦ãããããã¾ã¯åç¾ã§ããªãã¨ããããããã¾ããï¼ãåãä½ããã¹ããã¦ããå¯è½æ§ãããã¾ãããã ãåè³ªã¯ãããªã«æªããªãããã«æãã¾ãã&lt;/p&gt;
&lt;h3 id=&#34;å¤èª¿ã¹ãã¯ãã«&#34;&gt;å¤èª¿ã¹ãã¯ãã«&lt;/h3&gt;
&lt;p&gt;è©ä¾¡ç¨ã»ããã§å¹³åãåã£ããã®ã§ãã&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/images/jp-gantts/ms.png&#34; /&gt;&lt;/div&gt;
&lt;h3 id=&#34;ç¹å¾´éã®åå¸&#34;&gt;ç¹å¾´éã®åå¸&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;nitech_jp_atr503_m001_j49&lt;/code&gt; ã«å¯¾ãã¦è¨ç®ããçµæã§ãã&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/images/jp-gantts/nitech_jp_atr503_m001_j49_scatter.png&#34; /&gt;&lt;/div&gt;
&lt;h3 id=&#34;ãã¾ã-htsãã¢ã¨è´ãæ¯ã¹&#34;&gt;ãã¾ã: HTSãã¢ã¨è´ãæ¯ã¹&lt;/h3&gt;
&lt;p&gt;HTSãã¢ãå®è¡ããã¨çæããããµã³ãã«ã¨ã®è´ãæ¯ã¹ã§ããæ³¨æäºé ã§ããã&lt;strong&gt;å®é¨æ¡ä»¶ãã¾ã£ããç°ãªãã¾ã&lt;/strong&gt;ãããã¾ã§åèç¨åº¦ã«ã©ããã&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;HTSãã¢&lt;/li&gt;
&lt;li&gt;ãã¼ã¹ã©ã¤ã³&lt;/li&gt;
&lt;li&gt;GAN&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;ã®é ã«é³å£°ãè²¼ãã¾ãã&lt;/p&gt;
&lt;p&gt;1 ããã«ã¡ã¯&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/hts_nit_atr503_2mix/phrase01.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-gantts/test/baseline/phrase01.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-gantts/test/gan/phrase01.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;2 ããã§ã¯ããããªã&lt;/p&gt;
&lt;p&gt;HTS&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/hts_nit_atr503_2mix/phrase02.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-gantts/test/baseline/phrase02.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-gantts/test/gan/phrase02.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;3 ã¯ããã¾ãã¦&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/hts_nit_atr503_2mix/phrase03.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-gantts/test/baseline/phrase03.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-gantts/test/gan/phrase03.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;4 ããããåå¤å±å·¥æ¥­å¤§å­¦ã¸&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/hts_nit_atr503_2mix/phrase04.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-gantts/test/baseline/phrase04.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-gantts/test/gan/phrase04.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;5 ä»å¤ã®åå¤å±ã®å¤©æ°ã¯é¨ã§ã&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/hts_nit_atr503_2mix/phrase05.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-gantts/test/baseline/phrase05.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-gantts/test/gan/phrase05.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;h2 id=&#34;ãããã«&#34;&gt;ãããã«&lt;/h2&gt;
&lt;p&gt;ã¢ã¤ãã¢ã¯ã·ã³ãã«ãå¹æã¯ç´ æ´ãããã¨ãããåã®å¥½ããªï¼è©¦ããããªãï¼ç ç©¶ã®ç´¹ä»ã§ããããããã¨ããããã¾ããã&lt;/p&gt;
&lt;p&gt;GANã·ãªã¼ãºã®ãã®ä»è¨äºã¸ã®ãªã³ã¯ã¯ä»¥ä¸ã®éãã§ãã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://r9y9.github.io/blog/2017/10/05/ganvc/&#34;&gt;GAN å£°è³ªå¤æ (en) ç·¨ã¯ãã¡ã&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://r9y9.github.io/blog/2017/10/09/gantts/&#34;&gt;GAN é³å£°åæ (en) ç·¨ã¯ãã¡ã&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;è¿½è¨: å³ãä½ãã®ã«ä½¿ã£ããã¼ãããã¯ã¯ &lt;a href=&#34;http://nbviewer.jupyter.org/gist/r9y9/185a56417cee27d9f785b8caf1c9f5ec&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ãã¡ã&lt;/a&gt; ã«ããã¦ããã¾ããã&lt;/p&gt;
&lt;h2 id=&#34;åè&#34;&gt;åè&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1709.08041&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Yuki Saito, Shinnosuke Takamichi, Hiroshi Saruwatari, &amp;ldquo;Statistical Parametric Speech Synthesis Incorporating Generative Adversarial Networks&amp;rdquo;, arXiv:1709.08041 [cs.SD], Sep. 2017&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>ãé³å£°åæç·¨ãStatistical Parametric Speech Synthesis Incorporating Generative Adversarial Networks [arXiv:1709.08041]</title>
      <link>https://r9y9.github.io/blog/2017/10/09/gantts/</link>
      <pubDate>Mon, 09 Oct 2017 02:00:00 +0900</pubDate>
      <guid>https://r9y9.github.io/blog/2017/10/09/gantts/</guid>
      <description>&lt;p&gt;&lt;strong&gt;10/11 è¿½è¨&lt;/strong&gt;: IEEE TASLPã®ãã¼ãã¼ (Open access) ãå¬éããããããªã®ã§ããªã³ã¯ãè²¼ã£ã¦ããã¾ã: &lt;a href=&#34;https://ieeexplore.ieee.org/document/8063435/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://ieeexplore.ieee.org/document/8063435/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;arXivè«æãªã³ã¯: &lt;a href=&#34;https://arxiv.org/abs/1709.08041&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;arXiv:1709.08041&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://r9y9.github.io/blog/2017/10/05/ganvc/&#34;&gt;ååã®è¨äº&lt;/a&gt; ã®ç¶ãã§ããé³é¿ã¢ãã«ã®å­¦ç¿ã«GANãä½¿ãã¨ããã¢ã¤ãã¢ã¯ãå£°è³ªå¤æã ãã§ãªãé³å£°åæã«ãå¿ç¨ã§ãã¾ãã&lt;a href=&#34;http://festvox.org/cmu_arctic/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CMU ARCTIC&lt;/a&gt; ãä½¿ã£ãè±èªé³å£°åæã®å®é¨ãè¡ã£ã¦ãããç¨åº¦è¯ãçµæãã§ãã®ã§ãã¾ã¨ãããã¨æãã¾ããé³å£°ãµã³ãã«ã ãè´ãããæ¹ã¯çãä¸­ã®æ¹ã¾ã§èª­ã¿é£ã°ãã¦ãã ããã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ã³ã¼ãã¯ãã¡ã: &lt;a href=&#34;https:github.com/r9y9/gantts&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;r9y9/gantts | PyTorch implementation of GAN-based text-to-speech and voice conversion (VC) &lt;/a&gt; (VCã®ã³ã¼ããä¸ç·ã§ã)&lt;/li&gt;
&lt;li&gt;é³å£°ãµã³ãã«ä»ããã¢ãã¼ãããã¯ã¯ãã¡ã: &lt;a href=&#34;http://nbviewer.jupyter.org/github/r9y9/gantts/blob/master/notebooks/Test%20TTS.ipynb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;The effects of adversarial training in text-to-speech synthesis | nbviewer&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ååã®è¨äºã§ãæ¸ããæ³¨ææ¸ãã§ãããå³å¯ã«åãçµæãåç¾ãããã¨ã¯æã£ã¦ãã¾ãããåæ§ã®ã¢ã¤ãã¢ãè©¦ããã¨ãã£ããã¨ã«ä¸»ç¼ãç½®ãã¦ãã¾ãã&lt;/p&gt;
&lt;h2 id=&#34;å®é¨&#34;&gt;å®é¨&lt;/h2&gt;
&lt;h3 id=&#34;å®é¨æ¡ä»¶&#34;&gt;å®é¨æ¡ä»¶&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;http://festvox.org/cmu_arctic/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CMU ARCTIC&lt;/a&gt; ãããè©±è &lt;code&gt;slt&lt;/code&gt; ã®wavãã¼ã¿ãããã1131çºè©±ãã¹ã¦ãç¨ãã¾ãã
&lt;a href=&#34;https://github.com/CSTR-Edinburgh/merlin&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Merlin&lt;/a&gt;  ã® slt ãã¢ã®æ¡ä»¶ã¨åæ§ã«ã1000ãå­¦ç¿ç¨ã126ãè©ä¾¡ç¨ãæ®ã5ããã¹ãç¨ã«ãã¾ããç¶ç¶é·ã¢ãã«ï¼state-levelï¼ã«ã¯ &lt;strong&gt;Bidirectional-LSTM RNN&lt;/strong&gt; ããé³é¿ã¢ãã«ã«ã¯ &lt;strong&gt;Feed-forwardå&lt;/strong&gt; ã®ãã¥ã¼ã©ã«ããããä½¿ç¨ãã¾ãã&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;ãç¶ç¶é·ã¢ãã«ãé³é¿ã¢ãã«ã®ä¸¡æ¹ã«GANãåãå¥ãã¾ãããè«æã®èã§ãã &lt;strong&gt;ADV loss&lt;/strong&gt; ã«ã¤ãã¦ã§ãããmgcã®ã¿ï¼0æ¬¡ã¯é¤ãï¼ãä½¿ã£ã¦è¨ç®ãããã¿ã¼ã³ã¨ãmgc + lf0ã§è¨ç®ãããã¿ã¼ã³ã¨ã§æ¯è¼ãã¾ãã&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;ã&lt;/p&gt;
&lt;p&gt;å®é¨ã®çµæ (ADV loss: mgcã®ã¿) ã¯ã &lt;a href=&#34;https://github.com/r9y9/gantts/tree/a5ec247ba7ee1a160875661f8899f56f8010be5b&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;a5ec247&lt;/a&gt; ããã§ãã¯ã¢ã¦ããã¦ãä¸è¨ã®ã·ã§ã«ãå®è¡ããã¨åç¾ã§ãã¾ãã&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;./tts_demo.sh tts_test
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;ãã¼ã¿ã®ãã¦ã³ã­ã¼ããç¹å¾´æ½åºãã¢ãã«å­¦ç¿ãé³å£°ãµã³ãã«åæã¾ã§ä¸éãè¡ããã¾ãã&lt;code&gt;tts_test&lt;/code&gt; ã®é¨åã¯ä½ã§ãããã§ããtensorboardç¨ã«åãã­ã°ã¤ãã³ãåãã¢ãã«åºååãé³å£°ãµã³ãã«åºååã®æ±ºå®ã«ä½¿ããã¾ããè©³ç´°ã¯ã³ã¼ããåç§ãã ããã (ADV loss: mgc + lf0) ã®çµæã¯ã&lt;a href=&#34;https://github.com/r9y9/gantts/blob/a5ec247ba7ee1a160875661f8899f56f8010be5b/hparams.py&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ãã¤ãã¼ãã©ã¡ã¼ã¿&lt;/a&gt;ãä¸è¨ã®ããã«å¤æ´ãã¦ã·ã§ã«ãå®è¡ããã¨åç¾ã§ãã¾ãã&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt;diff --git a/hparams.py b/hparams.py
index d82296c..e73dc57 100644
--- a/hparams.py
+++ b/hparams.py
@@ -175,7 +175,7 @@ tts_acoustic = tf.contrib.training.HParams(
     # Streams used for computing adversarial loss
     # NOTE: you should probably change discriminator&#39;s `in_dim`
     # if you change the adv_streams
-    adversarial_streams=[True, False, False, False],
+    adversarial_streams=[True, True, False, False],
     # Don&#39;t switch this on unless you are sure what you are doing
     # If True, you will need to adjast `in_dim` for discriminator.
     # Rationale for this is that power coefficients are less meaningful
@@ -202,7 +202,7 @@ tts_acoustic = tf.contrib.training.HParams(
     # Discriminator
     discriminator=&amp;quot;MLP&amp;quot;,
     discriminator_params={
-        &amp;quot;in_dim&amp;quot;: 24,
+        &amp;quot;in_dim&amp;quot;: 25,
         &amp;quot;out_dim&amp;quot;: 1,
         &amp;quot;num_hidden&amp;quot;: 2,
         &amp;quot;hidden_dim&amp;quot;: 256,
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;å¤æé³å£°ã®æ¯è¼&#34;&gt;å¤æé³å£°ã®æ¯è¼&lt;/h3&gt;
&lt;h4 id=&#34;é³é¿ã¢ãã«ã®ã¿é©ç¨-adv-loss-mgcã®ã¿&#34;&gt;é³é¿ã¢ãã«ã®ã¿é©ç¨ (ADV loss: mgcã®ã¿)&lt;/h4&gt;
&lt;p&gt;ç¶ç¶é·ã¢ãã«ãé©ç¨ããªãããã¤ ADV lossã«mgcã®ã¿ãç¨ããå ´åã§ãã&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;èªç¶é³å£°&lt;/li&gt;
&lt;li&gt;ãã¼ã¹ã©ã¤ã³&lt;/li&gt;
&lt;li&gt;GAN&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;ã®é ã«é³å£°ãè²¼ãã¾ããè´ããããããã«ãsoxã§é³éãæ­£è¦åãã¦ãã¾ãã&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;arctic_b0535&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/slt/arctic_b0535.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/gantts/tts_order24/acoustic_only/baseline/test/arctic_b0535.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/gantts/tts_order24/acoustic_only/gan/test/arctic_b0535.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;&lt;strong&gt;arctic_b0536&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/slt/arctic_b0536.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/gantts/tts_order24/acoustic_only/baseline/test/arctic_b0536.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/gantts/tts_order24/acoustic_only/gan/test/arctic_b0536.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;&lt;strong&gt;arctic_b0537&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/slt/arctic_b0537.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/gantts/tts_order24/acoustic_only/baseline/test/arctic_b0537.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/gantts/tts_order24/acoustic_only/gan/test/arctic_b0537.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;&lt;strong&gt;arctic_b0538&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/slt/arctic_b0538.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/gantts/tts_order24/acoustic_only/baseline/test/arctic_b0538.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/gantts/tts_order24/acoustic_only/gan/test/arctic_b0538.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;&lt;strong&gt;arctic_b0539&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/slt/arctic_b0539.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/gantts/tts_order24/acoustic_only/baseline/test/arctic_b0539.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/gantts/tts_order24/acoustic_only/gan/test/arctic_b0539.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;VCã®å ´åã¨åãããã«ãé³å£°ã®æç­æ§ãä¸ãã£ãããã«æãã¾ãã&lt;/p&gt;
&lt;h4 id=&#34;é³é¿ã¢ãã«ç¶ç¶é·ã¢ãã«ãé©ç¨-adv-loss-mgcã®ã¿&#34;&gt;é³é¿ã¢ãã«ï¼ç¶ç¶é·ã¢ãã«ãé©ç¨ (ADV loss: mgcã®ã¿)&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;arctic_b0535&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/slt/arctic_b0535.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/gantts/tts_order24/duration_acoustic/baseline/test/arctic_b0535.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/gantts/tts_order24/duration_acoustic/gan/test/arctic_b0535.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;&lt;strong&gt;arctic_b0536&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/slt/arctic_b0536.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/gantts/tts_order24/duration_acoustic/baseline/test/arctic_b0536.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/gantts/tts_order24/duration_acoustic/gan/test/arctic_b0536.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;&lt;strong&gt;arctic_b0537&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/slt/arctic_b0537.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/gantts/tts_order24/duration_acoustic/baseline/test/arctic_b0537.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/gantts/tts_order24/duration_acoustic/gan/test/arctic_b0537.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;&lt;strong&gt;arctic_b0538&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/slt/arctic_b0538.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/gantts/tts_order24/duration_acoustic/baseline/test/arctic_b0538.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/gantts/tts_order24/duration_acoustic/gan/test/arctic_b0538.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;&lt;strong&gt;arctic_b0539&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/slt/arctic_b0539.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/gantts/tts_order24/duration_acoustic/baseline/test/arctic_b0539.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/gantts/tts_order24/duration_acoustic/gan/test/arctic_b0539.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;é³å£°ã®æç­æ§ãä¸ãã£ã¦ããã¨ã¯æãã¾ãããç¶ç¶é·ã«é¢ãã¦ã¯ããã¼ã¹ã©ã¤ã³/GANã§å·®ç°ãã»ã¨ãã©ãªãããã«æããããã¨æãã¾ããããã¯ãï¼åãå®é¨ããç¯å²ã§ã¯å°ãªãã¨ãï¼DiscriminatorãGeneartorã«åã¡ãããã¦ (é³é¿ã¢ãã«ã®å ´åã¯ããããªãã¨ã¯ãªã)ã ADV lossãä¸ããã©ãããä¸ãã£ã¦ãã¾ããçµæ MGE lossãæå°åããå ´åã¨ã»ã¨ãã©å¤ãã£ã¦ããªããã¨ããçµæã«ãªã£ã¦ãã¾ããè«æã«è¨è¼ã®åå®¹ã¨ã¯ç°ãªããstate-levelã®ç¶ç¶é·ã¢ãã«ã§ã¯ãããã®ã®ããã¤ãã¼ãã©ã¡ã¼ã¿ãªã©ãªã©ããããå¤ãã¦è©¦ããã®ã§ãããä¸æãããã¾ããã§ããã&lt;/p&gt;
&lt;h4 id=&#34;adv-loss-mgc-vs-mgc--lf0&#34;&gt;ADV loss: mgc vs mgc + lf0&lt;/h4&gt;
&lt;p&gt;æ¬¡ã«ãã­ã¹ã®æ¯è¼ã§ããF0ã®å¤åã«çç®ããããããã«ãç¶ç¶é·ã¢ãã«ãä½¿ãããé³é¿ã¢ãã«ã®ã¿ãé©ç¨ãã¾ãã&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;èªç¶é³å£°&lt;/li&gt;
&lt;li&gt;ADV loss (mgcã®ã¿, 24æ¬¡å)&lt;/li&gt;
&lt;li&gt;ADV loss (mgc + lf0, 25æ¬¡å)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;ã®é ã«é³å£°ãè²¼ãã¾ããã¾ããWORLD (dio + stonemask) ã§åæããF0ã®å¯è¦åçµæãä½µãã¦è²¼ã£ã¦ããã¾ãã&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;arctic_b0535&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/slt/arctic_b0535.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/gantts/tts_order24/acoustic_only/gan/test/arctic_b0535.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/gantts/tts_order24_advf0/acoustic_only/gan/test/arctic_b0535.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/images/gantts/arctic_b0535_f0.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;arctic_b0536&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/slt/arctic_b0536.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/gantts/tts_order24/acoustic_only/gan/test/arctic_b0536.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/gantts/tts_order24_advf0/acoustic_only/gan/test/arctic_b0536.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/images/gantts/arctic_b0536_f0.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;arctic_b0537&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/slt/arctic_b0537.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/gantts/tts_order24/acoustic_only/gan/test/arctic_b0537.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/gantts/tts_order24_advf0/acoustic_only/gan/test/arctic_b0537.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/images/gantts/arctic_b0537_f0.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;arctic_b0538&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/slt/arctic_b0538.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/gantts/tts_order24/acoustic_only/gan/test/arctic_b0538.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/gantts/tts_order24_advf0/acoustic_only/gan/test/arctic_b0538.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/images/gantts/arctic_b0538_f0.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;arctic_b0539&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/slt/arctic_b0539.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/gantts/tts_order24/acoustic_only/gan/test/arctic_b0539.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/gantts/tts_order24_advf0/acoustic_only/gan/test/arctic_b0539.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/images/gantts/arctic_b0539_f0.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;ã©ãã§ãããããä¸æããã£ã¦ããå ´åãï¼arctic_b537ã¨ãï¼ããã°ãä¸æããã£ã¦ããªãå ´å (arctic_b539ã¨ã) ãããããã«æãã¾ããåã«ã¯F0ãä¸èªç¶ã«æºãã¦ããããã«æãå ´åãå¤ãããã¾ãããããã§ã¯5ã¤ããé³å£°ãè²¼ã£ã¦ãã¾ãããããã®ä»126åã®è©ä¾¡ç¨é³å£°ã§ãè´ãæ¯ã¹ã¦ããã¨ãADV lossã«F0ãå¥ããªãæ¹ãããæ°ããã¾ããï¼ããã¾ã§åã®ä¸»è¦³ã§ãã&lt;/p&gt;
&lt;p&gt;ãã®ãããã¯ãF0ã®æ½åºæ³ãè£éæ³ã«å¼·ãä¾å­ãããã§ããä»åã¯ãF0æ½åºã®ãã©ã¡ã¼ã¿ãã¾ã£ãããã¥ã¼ãã³ã°ãã¦ããªãã®ã§ããã®ããããã£ãï¼f0åæã¨ã©ã¼ã«å¼ã£å¼µããã¦æªããªã£ãï¼ã®ããããã¾ããã&lt;/p&gt;
&lt;h3 id=&#34;global-variance-ã¯è£åããã¦ããã®ã&#34;&gt;Global variance ã¯è£åããã¦ããã®ãï¼&lt;/h3&gt;
&lt;p&gt;F0ã®è©±ã¯çµããã§ãã¹ãã¯ãã«ç¹å¾´éã«çç®ãã¦çµæãåæãã¦ããã¾ããä»¥ä¸ãADV loss (mgcã®ã¿)ãç¶ç¶é·ã¢ãã«ï¼é³é¿ã¢ãã«ãé©ç¨ãããµã³ãã«ã§ã®åæçµæã§ãã&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/images/gantts/arctic_b0537_gv.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;å¤§ã¾ãã«ãè«æã§ç¤ºããã¦ããã®ã¨åæ§ã®çµæãå¾ããã¾ããããªããããã¯ &lt;code&gt;arctic_b0537&lt;/code&gt; ã®ä¸çºè©±ã«å¯¾ãã¦è¨ç®ãããã®ã§ããã¹ãã»ããã®å¹³åã§ã¯ããã¾ããï¼ããã¾ããï¼ãã¾ããããã¯ãã¹ãã»ããä¸­ã®ãµã³ãã«ã®ä¸­ã§ãGVãè£åããã¦ãããã¨ãããããããä¾ãããã¯ã¢ãããã¾ããããã ããä»ã®ãã¹ããµã³ãã«ã«ããã¦ãåæ§ã®å¾åãè¦ãããã®ã¯ç¢ºèªãã¦ãã¾ãã&lt;/p&gt;
&lt;h3 id=&#34;modulation-spectrum-å¤èª¿ã¹ãã¯ãã«-ã¯è£åããã¦ããã®ã&#34;&gt;Modulation spectrum (å¤èª¿ã¹ãã¯ãã«) ã¯è£åããã¦ããã®ãï¼&lt;/h3&gt;
&lt;p&gt;è©ä¾¡ç¨ã®é³å£°126çºè©±ããããã§å¤èª¿ã¹ãã¯ãã«ãè¨ç®ãããããã®å¹³åãåããé©å½ãªç¹å¾´éã®æ¬¡åãããã¯ã¢ãããããã®ãç¤ºãã¾ããæ¨ªè»¸ã¯å¤èª¿å¨æ³¢æ°ã§ããä¸çªå³ç«¯ã50Hzã§ãã&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/images/gantts/ms.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;&lt;code&gt;arctic_b0537&lt;/code&gt; ã®ä¸çºè©±ã«å¯¾ãã¦è¨ç®ãããã®ã§ãã&lt;strong&gt;VCã®å ´åã¨ã¯ç°ãªã&lt;/strong&gt;ããã¼ã¹ã©ã¤ã³ãGANã¨ãã«ãä½æ¬¡åã§ãã£ã¦ã10Hzãè¶ããè¾ºãããèªç¶é³å£°ã¨ã¯å¤§ããç°ã£ã¦ãã¾ããããã¯ãªããªã®ããåã«ã¯ã¾ã ããã£ã¦ãã¾ãããã¾ããVCã®å ´åã¨åæ§ã«ãé«æ¬¡åã«ãªãã»ã©ãGANãã¼ã¹ã®æ¹ãå¤èª¿ã¹ãã¯ãã«ã¯èªç¶é³å£°ã«è¿ããã¨ããããã¾ããGANã«ãã£ã¦ãå¤èª¿ã¹ãã¯ãã«ã¯ããç¨åº¦è£åããã¦ããã¨è¨ããã¨æãã¾ãã&lt;/p&gt;
&lt;h3 id=&#34;ç¹å¾´éã®åå¸&#34;&gt;ç¹å¾´éã®åå¸&lt;/h3&gt;
 &lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/images/gantts/arctic_b0537_scatter.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;&lt;code&gt;arctic_b0537&lt;/code&gt; ã®ä¸çºè©±ã«å¯¾ãã¦è¨ç®ãããã®ã§ããè«æã§ç¤ºããã¦ããã»ã©é¡èã§ã¯ãªãæ°ããã¾ãããããã¾ãã«åæ§ã®çµæãå¾ããã¾ããã&lt;/p&gt;
&lt;h2 id=&#34;ææ³&#34;&gt;ææ³&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;GANã®ãã¥ã¼ãã³ã°ã¯é£ãããäººåï¼ç´æï¼ãã¤ãã¼ãã©ã¡ã¼ã¿ã®ãã¥ã¼ãã³ã°ãè©¦ãã¾ããããå¤§å¤ã§ãããããã¦ãã¾ããã¾ãã§ããèªä¿¡ãããã¾ãããæ½¤æ²¢ãªè¨ç®è³æºã§ãªãã¨ããããâ¦&lt;/li&gt;
&lt;li&gt;GANã®å­¦ç¿ã¯ä¸å®å®ï¼ã«æããï¼ããéå¸¸ã® MSE loss ã®å­¦ç¿ã¯å®å®ã§ããã¤Bidirectional LSTM RNNã¯å®å®ãã¦ããã§ãï¼çµæãããã«è²¼ã£ã¦ããªãã¦ç³ãè¨³ã§ããï¼ããã ããè¨ç®ã«ãã®ãããæéããããã®ã¨ãGPUã¡ã¢ãªãããªãä½¿ãã®ã§ãã¨ããããéå¸¸ã®feed forwardåã§å®é¨ããçµæãã¾ã¨ãã¾ãã&lt;/li&gt;
&lt;li&gt;state-levelã®ç¶ç¶é·ã¢ãã«ã«ãGANãä½¿ãã®ã¯ãã¾ãä¸æãã§ãã¾ããã§ãããããã«è²¼ã£ããµã³ãã«ããã¯ããããªãã®ã§ããï¼ããã¾ããï¼ãGã¨Dãä¸æãç«¶ãåãããDãåã£ã¦ãã¾ãå ´åãã»ã¨ãã©ã§ããï¼çµæãããä¸çªã¾ãï¼ãä¸æãç«¶ãåãããããã¨ããã¨ãæ©å£é³å£°ãçæããã¦ãã¾ã£ãããã¨å¤±æãããã¾ããã&lt;/li&gt;
&lt;li&gt;F0ã ADV lossã«å ããã¨ãããèªç¶é³å£°ã«è¿ã¥ãã¨æããå ´åãããããä¸æ¹ã§F0ãä¸èªç¶ã«æºãã¦ãã¾ãå ´åãããã¾ãããããã¯F0ã®æ½åºæ³ãè£éæ³ã«ãä¾å­ããã®ã§ãèª¿æ»ãå¿è¦ã§ã&lt;/li&gt;
&lt;li&gt;mgc, lf0, vuv, bapãã¹ã¦ã§ ADV lossã«å ããã¨ãæ®å¿µãªçµæãè¦ããã¨ã«ãªãã¾ãããçæ³çã«ã¯ããã§ãä¸æãããã¨æã£ã¦æåã«è©¦ããã®ã§ãããã ãã§ãããèå³ã®ããäººã¯ãããã¦ã¿ã¦ãã ãã&lt;/li&gt;
&lt;li&gt;mgcã®0æ¬¡ï¼ãã¯ã¼æåï¼ã¯ãADV lossã«å ããªãæ¹ããããèãã¦ã¿ãã¨ãç¹ã«ãã¬ã¼ã åä½ã®ã¢ãã«ã®å ´åï¼RNNã§ã¯ãªãï¼ããã¯ã¼æå ±ã¯natural/generated ã®è­å¥ã«ã¯ã»ã¨ãã©å¯ä¸ããªãããã§ããããã¯Arxivã®æ¹ã®è«æã«ã¯æ¸ãã¦ããªãã®ã§ããï¼åã®è¦éãã§ãªããã°ï¼ã&lt;a href=&#34;http://sython.org/papers/ASJ/saito2017asja.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ASJã®åç¨¿&lt;/a&gt; ã«ã¯æ¸ãã¦ãããã§ããã­ãä¸ã¤ã®ãããã©ããã§ãã&lt;/li&gt;
&lt;li&gt;Dã«RNNãä½¿ã£ãå®é¨ãå°ããã£ã¦ã¿ãã®ã§ããããã¾ãç«¶ãåãããã®ãé£ãããã§ãããDã«RNNãä½¿ãã®ã¯æ¬è³ªçã«ã¯è¯ãã¨æã£ã¦ããã®ã§ããã®è¾ºãã¯ããå°ãè²ãè©¦è¡é¯èª¤ãããã¨æã£ã¦ãã¾ã&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;ã¾ã¨ã&#34;&gt;ã¾ã¨ã&lt;/h2&gt;
&lt;p&gt;GANã®å­¦ç¿ã¯å¤§å¤ã§ããããä¸æãå­¦ç¿ã§ããã°åè³ªåä¸ã«ã¤ãªãããã¨ãç¢ºèªã§ãã¾ãããä»å¾ãè¨ç®ãªã½ã¼ã¹ãç©ºãæ¬¡ç¬¬ãRNNã§ã®å®é¨ãé²ãããã¨æãã®ã¨ãæ¥æ¬èªã§ãã£ã¦ã¿ããã¨æã£ã¦ãã¾ãã&lt;/p&gt;
&lt;p&gt;GANã·ãªã¼ãºã®ãã®ä»è¨äºã¸ã®ãªã³ã¯ã¯ä»¥ä¸ã®éãã§ãã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://r9y9.github.io/blog/2017/10/05/ganvc/&#34;&gt;GAN å£°è³ªå¤æ (en) ç·¨ã¯ãã¡ã&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://r9y9.github.io/blog/2017/10/10/gantts-jp/&#34;&gt;GAN é³å£°åæ (ja) ç·¨ã¯ãã¡ã&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;åè&#34;&gt;åè&lt;/h2&gt;
&lt;p&gt;Arxivã«ãããã¼ãã¼ã ãã§ãªãããã®ä»ããããåèã«ãã¾ããããããã¨ããããã¾ãã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1709.08041&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Yuki Saito, Shinnosuke Takamichi, Hiroshi Saruwatari, &amp;ldquo;Statistical Parametric Speech Synthesis Incorporating Generative Adversarial Networks&amp;rdquo;, arXiv:1709.08041 [cs.SD], Sep. 2017&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://sython.org/papers/SIG-SLP/saito201702slp.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Yuki Saito, Shinnosuke Takamichi, and Hiroshi Saruwatari, &amp;ldquo;Training algorithm to deceive anti-spoofing verification for DNN-based text-to-speech synthesis,&amp;rdquo; IPSJ SIG Technical Report, 2017-SLP-115, no. 1, pp. 1-6, Feb., 2017. (in Japanese)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.jstage.jst.go.jp/article/transinf/E100.D/8/E100.D_2017EDL8034/_article&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Yuki Saito, Shinnosuke Takamichi, and Hiroshi Saruwatari, &amp;ldquo;Voice conversion using input-to-output highway networks,&amp;rdquo; IEICE Transactions on Information and Systems, Vol.E100-D, No.8, pp.1925&amp;ndash;1928, Aug. 2017&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.slideshare.net/ShinnosukeTakamichi/dnnantispoofing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.slideshare.net/ShinnosukeTakamichi/dnnantispoofing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.slideshare.net/YukiSaito8/Saito2017icassp&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.slideshare.net/YukiSaito8/Saito2017icassp&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/SythonUK/whisperVC&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/SythonUK/whisperVC&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://sython.org/papers/ASJ/saito2017asja.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Yuki Saito, Shinnosuke Takamichi, and Hiroshi Saruwatari, &amp;ldquo;Experimental investigation of divergences in adversarial DNN-based speech synthesis,&amp;rdquo; Proc. ASJ, Spring meeting, 1-8-7, &amp;ndash;, Sep., 2017. (in Japanese)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;ç¶ç¶é·ã¢ãã«ãé³é¿ã¢ãã«ã¨ãã«RNNãä½¿ãã¨è¯ããªããã¨ãããã£ã¦ããã®ã§ãããè¨ç®ãªã½ã¼ã¹ã®é½åä¸ãä»åã¯é³é¿ã¢ãã«ã¯Feed-forwardã«ãã¾ãããFeed-forwardã ã¨30åã§çµããè¨ç®ããRNNã ã¨æ°æéããã£ã¦ãã¾ãã®ã§â¦&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;ä»ãè²ããã£ãã®ã§ãããã ãããå¤±æã§ããã&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
    </item>
    
    <item>
      <title>ãå£°è³ªå¤æç·¨ãStatistical Parametric Speech Synthesis Incorporating Generative Adversarial Networks [arXiv:1709.08041]</title>
      <link>https://r9y9.github.io/blog/2017/10/05/ganvc/</link>
      <pubDate>Thu, 05 Oct 2017 23:25:36 +0900</pubDate>
      <guid>https://r9y9.github.io/blog/2017/10/05/ganvc/</guid>
      <description>&lt;p&gt;&lt;strong&gt;10/11 è¿½è¨&lt;/strong&gt;: IEEE TASLPã®ãã¼ãã¼ (Open access) ãå¬éããããããªã®ã§ããªã³ã¯ãè²¼ã£ã¦ããã¾ã: &lt;a href=&#34;https://ieeexplore.ieee.org/document/8063435/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://ieeexplore.ieee.org/document/8063435/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;arXivè«æãªã³ã¯: &lt;a href=&#34;https://arxiv.org/abs/1709.08041&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;arXiv:1709.08041&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;2017å¹´9ææ«ã«ãè¡¨é¡ã® &lt;a href=&#34;https://arxiv.org/abs/1709.08041&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;è«æ&lt;/a&gt; ãå¬éãããã®ã¨ã&lt;a href=&#34;https://github.com/r9y9/nnmnkwii&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;nnmnkwii&lt;/a&gt; ã¨ãã designed for easy and fast prototyping ãç®æãã©ã¤ãã©ãªãä½ã£ãã®ãããã®ã§ãå®è£ãã¦ã¿ã¾ãããåãå®é¨ããéãã§ã¯ãå£°è³ªå¤æ (Voice conversion; VC) ã§ã¯å®å®ãã¦è¯ããªãã¾ããï¼é³å£°åæã§ã¯ã¾ã å®é¨ä¸­ã§ãï¼ããã®è¨äºã§ã¯ãå£°è³ªå¤æã«ã¤ãã¦åãå®é¨ããçµæãã¾ã¨ãããã¨æãã¾ããé³å£°åæã«ã¤ãã¦ã¯ãã¾ãå¾æ¥ã¾ã¨ãã¾ã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ã³ã¼ãã¯ãã¡ã: &lt;a href=&#34;https:github.com/r9y9/gantts&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;r9y9/gantts | PyTorch implementation of GAN-based text-to-speech and voice conversion (VC) &lt;/a&gt; (TTSã®ã³ã¼ããä¸ç·ã§ã)&lt;/li&gt;
&lt;li&gt;é³å£°ãµã³ãã«ãè´ãããæ¹ã¯ãã¡ã: &lt;a href=&#34;http://nbviewer.jupyter.org/github/r9y9/gantts/blob/master/notebooks/Test%20VC.ipynb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;The effects of adversarial training in voice conversion | nbviewer&lt;/a&gt; (â»è§£èª¬ã¯ã¾ã£ããããã¾ããã®ã§ããããã)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ãªããå³å¯ã«åãçµæãåç¾ãããã¨ã¯æã£ã¦ãã¾ãããåæ§ã®ã¢ã¤ãã¢ãè©¦ããã¨ãã£ããã¨ã«ä¸»ç¼ãç½®ãã¦ãã¾ããã³ã¼ãã«é¢ãã¦ã¯ãããã«è²¼ã£ãçµæãåç¾ã§ããããã«æ°ãã¤ãã¾ããã&lt;/p&gt;
&lt;h2 id=&#34;æ¦è¦&#34;&gt;æ¦è¦&lt;/h2&gt;
&lt;p&gt;ä¸è¨ã§ããã°ãé³é¿ã¢ãã«ã®å­¦ç¿ã« Generative Adversarial Net (&lt;strong&gt;GAN&lt;/strong&gt;) ãå°å¥ãããã¨ãã£ããã®ã§ããå°ãå·ä½çã«ã¯ã&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;é³é¿ã¢ãã«ï¼çæã¢ãã«ï¼ãçæããé³é¿ç¹å¾´éãå½ç©ãæ¬ç©ããè¦åãããã¨ããè­å¥ã¢ãã«ã¨ã&lt;/li&gt;
&lt;li&gt;çæèª¤å·®ãå°ãããã¤ã¤ (Minimum Generation Error loss; &lt;strong&gt;MGE loss&lt;/strong&gt; ã®æå°å) ãçæããç¹å¾´éãè­å¥ã¢ãã«ã«æ¬ç©ã ã¨èª¤èªè­ããããã¨ãã (Adversarial loss; &lt;strong&gt;ADV loss&lt;/strong&gt; ã®æå°å) çæã¢ãã«&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;ãäº¤äºã«å­¦ç¿ãããã¨ã§ãèªç¶é³å£°ã®ç¹å¾´éã¨çæããç¹å¾´éã®åå¸ãè¿ã¥ãããããªãããè¯ãé³é¿ã¢ãã«ãç²å¾ãããã¨ãã£ãæ¹æ³ã§ãã&lt;/p&gt;
&lt;h2 id=&#34;ãã¼ã¹ã©ã¤ã³&#34;&gt;ãã¼ã¹ã©ã¤ã³&lt;/h2&gt;
&lt;p&gt;ãã¼ã¹ã©ã¤ã³ã¨ãã¦ã¯ã &lt;strong&gt;MGE training&lt;/strong&gt; ãæãããã¦ãã¾ããDNNé³å£°åæã§ããããã­ã¹é¢æ°ã¨ãã¦ãé³é¿ç¹å¾´é (éçç¹å¾´é + åçç¹å¾´é) ã«å¯¾ãã Mean Squared Error (&lt;strong&gt;MSE loss&lt;/strong&gt;) ã¨ãããã®ãããã¾ããããã¯ãç¹å¾´éã®åæ¬¡åæ¯ã«èª¤å·®ã«æ­£è¦åå¸ãèãã¦ããã®å¯¾æ°å°¤åº¦ãæå¤§åãããã¨ãæå³ãã¾ãã
ãããã&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;éçç¹å¾´éã¨åçç¹å¾´éã®éã«ã¯æ¬æ¥ deterministic ãªé¢ä¿ããããã¨ãç¡è¦ããã¦ãããã¨&lt;/li&gt;
&lt;li&gt;ã­ã¹ããã¬ã¼ã åä½ã§è¨ç®ãããã®ã§ã (åçç¹å¾´éãå«ã¾ãã¦ããã¨ã¯ãã) æéæ§é ãç¡è¦ããã¦ãã¾ã£ã¦ãããã¨&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;ããããããã®åé¡ãè§£æ±ºããããã«ãç³»ååä½ã§ããã¤ãã©ã¡ã¼ã¿çæå¾ã®éçç¹å¾´éã®é åã§ã­ã¹ãè¨ç®ããæ¹æ³ãMGE training ãææ¡ããã¦ãã¾ãã&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;h2 id=&#34;å®é¨&#34;&gt;å®é¨&lt;/h2&gt;
&lt;h3 id=&#34;å®é¨æ¡ä»¶&#34;&gt;å®é¨æ¡ä»¶&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;http://festvox.org/cmu_arctic/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CMU ARCTIC&lt;/a&gt; ãããè©±è &lt;code&gt;clb&lt;/code&gt; ã¨ &lt;code&gt;slt&lt;/code&gt; ã®wavãã¼ã¿ãããã500çºè©±ãç¨ãã¾ãã439ãå­¦ç¿ç¨ã56ãè©ä¾¡ç¨ãæ®ã5ããã¹ãç¨ã«ãã¾ããé³é¿ç¹å¾´éã«ã¯ãWORLDãä½¿ã£ã¦59æ¬¡ã®ã¡ã«ã±ãã¹ãã©ã ãæ½åºãã0æ¬¡ãé¤ã59æ¬¡åã®ãã¯ãã«ãåãã¬ã¼ã æ¯ã®ç¹å¾´éã¨ãã¾ããF0ãéå¨ææ§ææ¨ã«é¢ãã¦ã¯ãåè©±èã®ãã®ããã®ã¾ã¾ä½¿ããå·®åã¹ãã¯ãã«æ³ãç¨ãã¦æ³¢å½¢åæãè¡ãã¾ãããF0ã®å¤æã¯ãã¦ãã¾ãããé³é¿ã¢ãã«ã«ã¯ã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.jstage.jst.go.jp/article/transinf/E100.D/8/E100.D_2017EDL8034/_article&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Yuki Saito, Shinnosuke Takamichi, and Hiroshi Saruwatari, &amp;ldquo;Voice conversion using input-to-output highway networks,&amp;rdquo; IEICE Transactions on Information and Systems, Vol.E100-D, No.8, pp.1925&amp;ndash;1928, Aug. 2017&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ã§è¿°ã¹ããã¦ãã highway network ãç¨ãã¾ãããã ããæ´»æ§åé¢æ°ãReLUããLeakyReLUã«ããããDropoutãå¥ããããã¢ã¼ã­ãã¯ãã£ã¯å¾®å¦ã«å¤ãã¦ãã¾ããåèã¯ãèª¿ã¹ããå¾éãæ¶ãã«ããã¦å­¦ç¿ã®ä¸å®å®ãªGANã«è¯ãã¨æ¸ãã¦ããè¨äºããã£ãã®ã§ï¼ã¡ããã¨çè§£ãã¦ãããå®ç´ã§ãããå®é¨ããã¨ããæªå½±é¿ã¯ãªãããã§ããã®ã§æ§å­è¦ï¼ãå¾èã¯ãGANã®å­¦ç¿ã®å®å®åã«ã¤ãªãã£ãæ°ããã¾ãï¼å°ãªãã¨ãTTSã§ã¯ï¼ãDiscriminatorã«ã¯ãDropoutä»ãã®å¤å±¤ãã¥ã¼ã©ã«ããããä½¿ãã¾ãããMGE loss ã¨ ADV loss ããã©ã³ã¹ããéã¿ &lt;code&gt;w_d&lt;/code&gt; ã¯ã 1.0 ã«ãã¾ãããå±¤ã®æ°ããã¥ã¼ã­ã³ã®æ°ç­ããã®ä»è©³ç´°ãç¥ãããæ¹ã¯ãã³ã¼ããåç§ãã¦ãã ãããå®é¨ã«ä½¿ç¨ããã³ã¼ãã®æ­£ç¢ºãªãã¼ã¸ã§ã³ã¯  &lt;a href=&#34;https://github.com/r9y9/gantts/tree/ccbb51b51634b272f0a71f29ad4c28edd8ce3429&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ccbb51b&lt;/a&gt; ã§ãããã¤ãã¼ãã©ã¡ã¼ã¿ã¯ &lt;a href=&#34;https://github.com/r9y9/gantts/blob/ccbb51b51634b272f0a71f29ad4c28edd8ce3429/hparams.py&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ãã¡ã&lt;/a&gt; ã§ãã&lt;/p&gt;
&lt;p&gt;ããã§ç¤ºãçµæãåç¾ãããå ´åã¯ã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ã³ã¼ãããã§ãã¯ã¢ã¦ã&lt;/li&gt;
&lt;li&gt;ããã±ã¼ã¸ã¨ä¾å­é¢ä¿ãã¤ã³ã¹ãã¼ã«&lt;/li&gt;
&lt;li&gt;&lt;code&gt;clb&lt;/code&gt; ã¨ &lt;code&gt;slt&lt;/code&gt; ã®ãã¼ã¿ããã¦ã³ã­ã¼ãï¼åã®å ´åã¯ã &lt;code&gt;~/data/cmu_arctic&lt;/code&gt; ã«ããã¾ã&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ããã¦ãä»¥ä¸ã®ã¹ã¯ãªãããå®è¡ããã°OKã§ãã&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;./vc_demo.sh ~/data/cmu_arctic
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;ãªãå®è¡ã«ã¯ãGPUã¡ã¢ãªã4GBãããã¯å¿è¦ã§ãï¼ããããµã¤ãº32ã®å ´åï¼ãGTX 1080Ti + i7-7700K ã®è¨ç®ç°å¢ã§ãç´1æéåãããã§çµããã¾ããã¹ã¯ãªããå®è¡ãå®äºããã°ã&lt;code&gt;generated&lt;/code&gt; ãã£ã¬ã¯ããªã«ããã¼ã¹ã©ã¤ã³/GAN ããããã§å¤æããé³å£°ãåºåããã¾ããä»¥ä¸ã«é ã«ç¤ºãå³ã«ã¤ãã¦ã¯ã&lt;a href=&#34;http://nbviewer.jupyter.org/github/r9y9/gantts/blob/master/notebooks/Test%20VC.ipynb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ãã¢ãã¼ãããã¯&lt;/a&gt; ãå®è¡ããã¨ä½ããã¨ãã§ãã¾ãã&lt;/p&gt;
&lt;h3 id=&#34;å¤æé³å£°ã®æ¯è¼&#34;&gt;å¤æé³å£°ã®æ¯è¼&lt;/h3&gt;
&lt;p&gt;ãã¹ãã»ããã®5ã¤ã®ãã¼ã¿ã«å¯¾ãã¦ã®å¤æé³å£°ãããã³ãã®åé³å£°ãã¿ã¼ã²ããé³å£°ãæ¯è¼ã§ããããã«è²¼ã£ã¦ããã¾ããä¸è¨ã®é çªã§ãã&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;åè©±èã®é³å£°&lt;/li&gt;
&lt;li&gt;ã¿ã¼ã²ããè©±èã®é³å£°&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;MGE Loss&lt;/strong&gt; ãæå°åãã¦å¾ãããã¢ãã«ã«ããå¤æé³å£°&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;MGE loss + ADV loss&lt;/strong&gt; ãæå°åãã¦å¾ãããã¢ãã«ã«ããå¤æé³å£°&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;æ¯è¼ããããããã«ãé³éã¯soxã§æ­£è¦åãã¾ããã&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;arctic_a0496&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/ganvc/src/arctic_a0496.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/ganvc/tgt/arctic_a0496.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/ganvc/baseline/test/arctic_a0496.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/ganvc/gan/test/arctic_a0496.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;&lt;strong&gt;arctic_a0497&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/ganvc/src/arctic_a0497.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/ganvc/tgt/arctic_a0497.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/ganvc/baseline/test/arctic_a0497.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/ganvc/gan/test/arctic_a0497.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;&lt;strong&gt;arctic_a0498&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/ganvc/src/arctic_a0498.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/ganvc/tgt/arctic_a0498.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/ganvc/baseline/test/arctic_a0498.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/ganvc/gan/test/arctic_a0498.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;&lt;strong&gt;arctic_a0499&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/ganvc/src/arctic_a0499.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/ganvc/tgt/arctic_a0499.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/ganvc/baseline/test/arctic_a0499.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/ganvc/gan/test/arctic_a0499.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;&lt;strong&gt;arctic_a0500&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/ganvc/src/arctic_a0500.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/ganvc/tgt/arctic_a0500.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/ganvc/baseline/test/arctic_a0500.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/ganvc/gan/test/arctic_a0500.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;&lt;code&gt;clb&lt;/code&gt;, &lt;code&gt;slt&lt;/code&gt; ã¯éãããããã«ããã¨ä»¥åèª°ãããææãããã®ã§ãããããã«æ£ãã¦ãã¾ãã¾ããããããã¥ããã£ããããã¾ãããåã®è³ã§ã¯ãæç­æ§ãä¸ãã£ã¦ãè¯ããªã£ã¦ããããã«æãã¾ãã&lt;/p&gt;
&lt;h3 id=&#34;global-variance-ã¯è£åããã¦ããã®ã&#34;&gt;Global variance ã¯è£åããã¦ããã®ãï¼&lt;/h3&gt;
&lt;p&gt;çµ±è¨ãã¼ã¹ã®ææ³ã§ã¯ãå¤æé³å£°ã® &lt;strong&gt;Global variance (GV)&lt;/strong&gt; ãè½ã¡ã¦ãã¾ããåè³ªãå£åãã¦ãã¾ãåé¡ãããç¥ããã¦ãã¾ããGANãã¼ã¹ã®ææ³ã«ãã£ã¦ããã®åé¡ã«å¯¾å¦ã§ãã¦ããã®ãã©ãããå®éã«ç¢ºèªãã¾ãããä»¥ä¸ã«ããã¼ã¿ã»ããä¸­ã®ä¸ãµã³ãã«ãé©å½ã«ããã¯ã¢ãããã¦ãGVãè¨ç®ãããã®ãç¤ºãã¾ããç¸¦è»¸ã¯å¯¾æ°ãæ¨ªè»¸ã¯ã¡ã«ã±ãã¹ãã©ã ã®æ¬¡åã§ãã&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/images/ganvc/gv.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;ãããã¾ããè«æã§ç¤ºããã¦ããã®ã¨åç­ã®çµæãå¾ããã¨ãã§ãã¾ããã&lt;/p&gt;
&lt;h3 id=&#34;modulation-spectrum-å¤èª¿ã¹ãã¯ãã«-ã¯è£åããã¦ããã®ã&#34;&gt;Modulation spectrum (å¤èª¿ã¹ãã¯ãã«) ã¯è£åããã¦ããã®ãï¼&lt;/h3&gt;
&lt;p&gt;GVãããä¸è¬åãã®ã¨ãã¦ãå¤èª¿ã¹ãã¯ãã«ã¨ããæ¦å¿µãããã¾ããç«¯çã«è¨ãã°ããã©ã¡ã¼ã¿ç³»åã®æéæ¹åã«å¯¾ããé¢æ£ãã¼ãªã¨å¤æã®äºä¹ï¼ã®å¯¾æ°â»å®ç¾©ã«ããããã§ãããããã§ã¯å¯¾æ°ãã¨ã£ããã®ï¼ã§ããçµ±è¨å¦çã«ãã£ã¦å£åããå¤æé³å£°ã¯ãå¤èª¿ã¹ãã¯ãã«ãèªç¶é³å£°ã¨æ¯ã¹ã¦å°ãããªã£ã¦ãããã¨ãç¥ããã¦ãã¾ããã¨ããããã§ãGANãã¼ã¹ã®æ¹æ³ã«ãã£ã¦ãå¤èª¿ã¹ãã¯ãã«ã¯è£åããã¦ããã®ãï¼ã¨ãããã¨ãèª¿ã¹ã¦ã¿ã¾ãããããã¯ãè«æã«ã¯æ¸ãã¦ãã¾ããï¼ãããã£ã¨ããã¦ããã¨æãã¾ãï¼ãä»¥ä¸ã«ãè©ä¾¡ç¨ã®é³å£°56çºè©±ããããã§å¤èª¿ã¹ãã¯ãã«ãè¨ç®ãããããã®å¹³åãåããé©å½ãªç¹å¾´éã®æ¬¡åãããã¯ã¢ãããããã®ãç¤ºãã¾ããæ¨ªè»¸ã¯å¤èª¿å¨æ³¢æ°ã§ããä¸çªå³ç«¯ã50Hzã§ãã&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/images/ganvc/ms.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;ç¹ã«é«æ¬¡åã®å¤èª¿ã¹ãã¯ãã«ã«å¯¾ãã¦ããã¼ã¹ã©ã¤ã³ã¯å¤§ããè½ã¡ã¦ããä¸æ¹ã§ãGANãã¼ã¹ã§ã¯æ¯è¼çèªç¶é³å£°ã¨è¿ããã¨ããããã¾ããããããé«æ¬¡åã«ãªãã»ã©ãèªç¶é³å£°ã¨GANãã¼ã¹ã§ãéããåºã¦ããã®ããããã¾ããæ¹åã®ä½å°ã¯ããããã§ãã­ã&lt;/p&gt;
&lt;h3 id=&#34;ç¹å¾´éã®åå¸&#34;&gt;ç¹å¾´éã®åå¸&lt;/h3&gt;
&lt;p&gt;è«æã§ç¤ºããã¦ããscatter plotã§ãããåããã¨ããã£ã¦ã¿ã¾ããã&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/images/ganvc/scatter.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;æ¦ã­ãè«æéãã®çµæã¨ãªã£ã¦ãã¾ãã&lt;/p&gt;
&lt;h3 id=&#34;è©ç§°çã«ã¤ãã¦&#34;&gt;è©ç§°çã«ã¤ãã¦&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;w_d&lt;/code&gt; ãå¤åããã¦ãè©ç§°çãã©ããªããã¯å®é¨ãã¦ããªãã®ã§ããã&lt;code&gt;w_d = 1.0&lt;/code&gt; ã®å ´åã«ãã ããã0.7 ~ 0.9 ãããã«åã¾ããã¨ãç¢ºèªãã¾ãããTTSã§ã¯0.99ãããã®ãè«æã¨åæ§ã®çµæãåºã¾ãããããããã¨ããã®ã¯ãã©ã®ããã Discriminator ãå­¦ç¿ãããããåæåã¨ãã¦ã®MGEå­¦ç¿ï¼ä¾ãã°25epochãããï¼ã®ãã¨çæãããç¹å¾´éã«å¯¾ãã¦å­¦ç¿ãããã®ããããã¨ãåæåã¨ã¯å¥ã§ãã¼ã¹ã©ã¤ã³ç¨ã®ã¢ãã«ï¼100epochã¨ãï¼ãä½¿ã£ã¦çæãããç¹å¾´éã«å¯¾ãã¦å­¦ç¿ãããã®ããã«ãã£ã¦å¤ãã£ã¦ããã®ã¨ããã®è¾ºããè«æããã§ã¯ãã¾ãããããªãã£ãã®ã¨ãå­¦ç¿çãæé©åã¢ã«ã´ãªãºã ããã¼ã¿ã«ãã£ã¦ãå¤ãã£ã¦ããã®ã¨ãè©ç§°çã®è¨ç®ã¯åè³ªã«ã¯ã¾ã£ããé¢ä¿ãªãã®ããã£ã¦ããã¾ãçé¢ç®ã«ãã£ã¦ãã¾ãããããã¾ãã&lt;/p&gt;
&lt;h2 id=&#34;ææ³&#34;&gt;ææ³&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;å¹æã¯åçãæããã«è¯ããªãã¾ãããç´ æ´ãããã§ãã­&lt;/li&gt;
&lt;li&gt;è«æã§æ¸ããã¦ããåå¾©åæ° (25epochã¨ã)ãããã100, 200ã¨å¤ãå­¦ç¿ãããæ¹ãããã£ãã§ãï¼ç¥è¦çãªå·®ã¯å¾®å¦ã§ããï¼ã­ã¹ã¯ä¸ããç¶ãã¦ãã¾ããã&lt;/li&gt;
&lt;li&gt;å®è£ã¯ãããªã«å¤§å¤ã§ã¯ãªãã£ãã§ãããGANã®å­¦ç¿ãé£ããæãããã¾ããï¼VCã§ã¯ãã¾ãå¤±æããªãããTTSã§ã¯ããå¤±æãããè½ã¨ãæãæ¢ãä¸­&lt;/li&gt;
&lt;li&gt;Adam ã¯å­¦ç¿ã¯éãããéå­¦ç¿ããããããGANãä¸å®å®ã«ãªããã¡ãªæ°ããã¾ãã&lt;/li&gt;
&lt;li&gt;Adagrad ã¯åæã¯éãããå®å®&lt;/li&gt;
&lt;li&gt;MGE loss ã¨ ADV loss ã®éã¿ã®è¨ç®ã¯ãé©å½ã«clipããããã«ãã¾ãããããªãã¦ãã ãããåæãã¾ããããã°ãããã¨ç°¡åã«çºæ£ãã¾ãã­ãhaha&lt;/li&gt;
&lt;li&gt;gradient clipping ãããã¾ãããTTSã§ã¯å°ãªãã¨ãè¯ããªã£ãæ°ããã¾ããVCã¯ãªãã§ãå®å®ãã¦ããããã§ãã&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;ã¾ã¨ã&#34;&gt;ã¾ã¨ã&lt;/h2&gt;
&lt;p&gt;ã¨ã¦ãè¯ããªãã¾ãããç´ æ´ãããã§ããä»åãWORLDã«ãä¸è©±ã«ãªãã¾ãããç¶ãã¦ãTTSã§ãå®é¨ãé²ãã¦ããã¾ãã&lt;/p&gt;
&lt;p&gt;GANã·ãªã¼ãºã®ãã®ä»è¨äºã¸ã®ãªã³ã¯ã¯ä»¥ä¸ã®éãã§ãã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://r9y9.github.io/blog/2017/10/09/gantts/&#34;&gt;GAN é³å£°åæ (en) ç·¨ã¯ãã¡ã&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://r9y9.github.io/blog/2017/10/10/gantts-jp/&#34;&gt;GAN é³å£°åæ (ja) ç·¨ã¯ãã¡ã&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;åè&#34;&gt;åè&lt;/h2&gt;
&lt;p&gt;Arxivã«ãããã¼ãã¼ã ãã§ãªãããã®ä»ããããåèã«ãã¾ããããããã¨ããããã¾ãã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1709.08041&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Yuki Saito, Shinnosuke Takamichi, Hiroshi Saruwatari, &amp;ldquo;Statistical Parametric Speech Synthesis Incorporating Generative Adversarial Networks&amp;rdquo;, arXiv:1709.08041 [cs.SD], Sep. 2017&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://sython.org/papers/SIG-SLP/saito201702slp.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Yuki Saito, Shinnosuke Takamichi, and Hiroshi Saruwatari, &amp;ldquo;Training algorithm to deceive anti-spoofing verification for DNN-based text-to-speech synthesis,&amp;rdquo; IPSJ SIG Technical Report, 2017-SLP-115, no. 1, pp. 1-6, Feb., 2017. (in Japanese)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.jstage.jst.go.jp/article/transinf/E100.D/8/E100.D_2017EDL8034/_article&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Yuki Saito, Shinnosuke Takamichi, and Hiroshi Saruwatari, &amp;ldquo;Voice conversion using input-to-output highway networks,&amp;rdquo; IEICE Transactions on Information and Systems, Vol.E100-D, No.8, pp.1925&amp;ndash;1928, Aug. 2017&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.slideshare.net/ShinnosukeTakamichi/dnnantispoofing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.slideshare.net/ShinnosukeTakamichi/dnnantispoofing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.slideshare.net/YukiSaito8/Saito2017icassp&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.slideshare.net/YukiSaito8/Saito2017icassp&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/SythonUK/whisperVC&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/SythonUK/whisperVC&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Kobayashi, Kazuhiro, et al. &amp;ldquo;Statistical Singing Voice Conversion with Direct Waveform Modification based on the Spectrum Differential.&amp;rdquo; Fifteenth Annual Conference of the International Speech Communication Association. 2014.&lt;/li&gt;
&lt;/ul&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;è«æã§ã¯æå¹æ§ãç¤ºããã¦ãã¾ãããåãè©¦ããç¯å²åã§ããã¤åã®è³ã«ã«ããã°ããã¾ãå¤§ããªæ¹åã¯ç¢ºèªã§ãã¦ãã¾ãããå®¢è¦³çãªè©ä¾¡ã¯ããã®ãã¡ããäºå®ã§ãã&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
    </item>
    
    <item>
      <title>DNNé³å£°åæã®ããã®ã©ã¤ãã©ãªã®ç´¹ä»ã¨DNNæ¥æ¬èªé³å£°åæã®å®è£ä¾</title>
      <link>https://r9y9.github.io/blog/2017/08/16/japanese-dnn-tts/</link>
      <pubDate>Wed, 16 Aug 2017 23:10:56 +0900</pubDate>
      <guid>https://r9y9.github.io/blog/2017/08/16/japanese-dnn-tts/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://github.com/r9y9/nnmnkwii&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;nnmnkwii&lt;/a&gt; ã¨ããDNNé³å£°åæã®ããã®ã©ã¤ãã©ãªãå¬éãã¾ããã®ã§ããã®ç´¹ä»ããã¾ãã&lt;/p&gt;
&lt;blockquote class=&#34;twitter-tweet&#34; data-lang=&#34;en&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;&lt;a href=&#34;https://t.co/p8MnOxkVoH&#34;&gt;https://t.co/p8MnOxkVoH&lt;/a&gt; Library to build speech synthesis systems designed for easy and fast prototyping. Open sourced:)&lt;/p&gt;&amp;mdash; å±±æ¬ããããã¡ (@r9y9) &lt;a href=&#34;https://twitter.com/r9y9/status/897117170265501696&#34;&gt;August 14, 2017&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;//platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;p&gt;ãã­ã¥ã¡ã³ãã®ææ°çã¯ &lt;a href=&#34;https://r9y9.github.io/nnmnkwii/latest/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://r9y9.github.io/nnmnkwii/latest/&lt;/a&gt; ã§ããä»¥ä¸ã«ãããã¤ããªã³ã¯ãè²¼ã£ã¦ããã¾ãã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://r9y9.github.io/nnmnkwii/v0.0.1/design_jp.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ãªãä½ã£ãã®ãããã®èæ¯ã®èª¬æã¨è¨­è¨ (æ¥æ¬èª)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://r9y9.github.io/nnmnkwii/v0.0.1/nnmnkwii_gallery/notebooks/00-Quick%20start%20guide.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ã¯ã¤ãã¯ã¬ã¤ã&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://r9y9.github.io/nnmnkwii/v0.0.1/nnmnkwii_gallery/notebooks/tts/01-DNN-based%20statistical%20speech%20synthesis%20%28en%29.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;DNNè±èªé³å£°åæã®ãã¥ã¼ããªã¢ã«&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ãããããã°ãè¦§ãã ãã&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;ã&lt;/p&gt;
&lt;p&gt;ãã­ã¥ã¡ã³ãã¯ãã ãããè±èªã§ãç¡¬ãé°å²æ°ã§æ¸ããã®ã§ããã®è¨äºã§ã¯ãæ¥æ¬èªã§ã«ã¸ã¥ã¢ã«ã«èæ¯ãªã©ãèª¬æãããã¨æãã®ã¨ãï¼ãã­ã¥ã¡ã³ãã«ã¯è±èªé³å£°åæã®ä¾ãããªãã®ã§ï¼HTSã®ãã¢ã«åæ¢±ã®ATR503æã®ãã¼ã¿ã»ãããä½¿ã£ã¦ã&lt;strong&gt;DNNæ¥æ¬èªé³å£°åæ&lt;/strong&gt; ãå®è£ããä¾ãç¤ºãããã¨æãã¾ããçµæã ãç¥ãããæ¹ã¯ãé³å£°ãµã³ãã«ãä¸ã®æ¹ã«ããã®ã§ãé©å½ã«èª­ã¿é£ã°ãã¦ãã ããã&lt;/p&gt;
&lt;h2 id=&#34;ãªãä½ã£ãã®ã&#34;&gt;ãªãä½ã£ãã®ã&lt;/h2&gt;
&lt;p&gt;ä¸çªå¤§ããªçç±ã¯ãåã &lt;strong&gt;å¯¾è©±ç°å¢ï¼Jupyter, IPythonç­ï¼&lt;/strong&gt; ã§ä½¿ãããã¼ã«ãã»ããã£ãããã§ã&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;ã
åã¯çµæ§åããREPL (Read-Eval-Print-Loop) ä¿¡èã§ããã­ã°ã©ãã³ã°ã®ãããªãã®æéãREPLã§éããã¾ãã
IDEãå¥½ãã§ãããemacsãå¥½ããªã®ã§ãããåããããJupyterã&lt;a href=&#34;https://github.com/JuliaLang/julia&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Julia&lt;/a&gt;ã®REPLãå¥½ãã§ãã
ç¨éã«å¿ãã¦ä½¿ãåãã¾ãããç¹ã«ä½ããã¼ã¿ãåæããå¿è¦ããããããªæã«ãå³åº§ã«ãã¼ã¿ãå¯è¦åã§ããJupyter notebookã¯ãåã«ã¨ã£ã¦ãã­ã°ã©ãã³ã°ã«æ¬ ãããªããã®ã«ãªã£ã¦ãã¾ãã&lt;/p&gt;
&lt;p&gt;ã¨ããããHTSã®å¾ç¶ã¨ãã¦çã¾ããDNNé³å£°åæãã¼ã«ã§ãã &lt;a href=&#34;https://github.com/CSTR-Edinburgh/merlin&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Merlin&lt;/a&gt; ã¯ãã³ãã³ãã©ã¤ã³ãã¼ã«ã¨ãã¦ä½¿ãããæ³å®ã®ãã®ã§ãåã®è¦æãæºããã¦ããããã®ã§ã¯ããã¾ããã§ããã
ã¨ã¯ãããMerlinã¯åªç§ãªé³å£°ç ç©¶èãã¡ã®ç£ç©ã§ãããå½ç¶å½¹ã«ç«ã¤é¨åãå¤ããä½¿ã£ã¦ãã¾ããããããããã¨ãã­ãã¿ã¤ãã³ã°ã«ããã¦ã¯ããã¯ãå¯¾è©±ç°å¢ã§ãããããªãã¨ããæããå¼·ã¾ã£ã¦ããã¾ããã&lt;/p&gt;
&lt;p&gt;æ°ããä½ãã®ã§ã¯ãªããMerlinãä½¿ãç¶ãããMerlinãæ¹åããæ¹éãèãã¾ãããåãMerlinãä½¿ãå§ããé ãMerlinã¯python3ã§åããªãã£ãã®ã§ãåãããã« &lt;a href=&#34;https://github.com/CSTR-Edinburgh/merlin/pull/141&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ãã«ãªã¯&lt;/a&gt; ãåºãããã¨ãããã®ã§ãããã¾ãã¬ãã¥ã¼ã«æ°ã«æãããã£ã¦ãã¾ã£ãã®ã§ãããã¯æ°ãããã®ãä½ã£ãæ¹ããããªãã¨æãã«è³ãã¾ããã&lt;/p&gt;
&lt;p&gt;ä»¥ä¸ããåãæ°ãããã¼ã«ä½ããã¨æã£ãçç±ã§ãã&lt;/p&gt;
&lt;h2 id=&#34;ç¹å¾´&#34;&gt;ç¹å¾´&lt;/h2&gt;
&lt;p&gt;ãã¦ãMerlinã«å¯¾ããæ¬æã¨ä¸æºããçã¾ãããã¼ã«ã§ããã¾ããããã®ç¹å¾´ãç°¡åã«ã¾ã¨ãã¾ãã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;å¯¾è©±ç°å¢&lt;/strong&gt; ã§ã®ä½¿ç¨ãåæã«ãè¨­è¨ããã¦ãã¾ããã³ãã³ãã©ã¤ã³ãã¼ã«ã¯ããã¾ãããã¦ã¼ã¶ãå¿è¦ã«å¿ãã¦ä½ãã°ãããã¨ããèãã§ãã&lt;/li&gt;
&lt;li&gt;DNNé³å£°åæã®ãã¢ããã¼ãããã¯å½¢å¼ã§æä¾ãã¦ãã¾ãã&lt;/li&gt;
&lt;li&gt;å¤§è¦æ¨¡ãã¼ã¿ã§ãæ±ããããã«ããã¼ã¿ã»ããã¨ãã¼ã¿ã»ããã®ã¤ãã¬ã¼ã·ã§ã³ï¼ãã¬ã¼ã æ¯ãçºè©±æ¯ã®ä¸¡æ¹ï¼ã®ã¦ã¼ãã£ãªãã£ãæä¾ããã¦ãã¾ã&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Merlinã¨ã¯ç°ãªããé³é¿ã¢ãã«ã¯æä¾ãã¾ãã&lt;/strong&gt;ãèªåã§å®è£ããå¿è¦ãããã¾ãï¼ããä»ã®æä»£ç°¡åã§ããã­ãlstmã§ãæ°è¡ã§æ¸ããã®ã§&lt;/li&gt;
&lt;li&gt;ä»»æã®æ·±å±¤å­¦ç¿ãã¬ã¼ã ã¯ã¼ã¯ã¨ä½µãã¦ä½¿ããããã«ãè¨­è¨ããã¦ãã¾ã&lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;ï¼&lt;a href=&#34;https://r9y9.github.io/nnmnkwii/latest/references/autograd.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;autogradããã±ã¼ã¸&lt;/a&gt;ã®ã¿ãä»ã®ã¨ããPyTorchä¾å­ã§ã&lt;/li&gt;
&lt;li&gt;è¨èªç¹å¾´éã®æ½åºã®é¨åã¯ãMerlinã®ã³ã¼ãããªãã¡ã¯ã¿ãã¦ç¨ãã¦ãã¾ãããã®ããããã£ã¦ãMerlinã®ãã¢ã¨åç­ã®ããã©ã¼ãã³ã¹ãç°¡åã«å®ç¾ã§ãã¾ãã&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;å¯¾è±¡ã¦ã¼ã¶&#34;&gt;å¯¾è±¡ã¦ã¼ã¶&lt;/h2&gt;
&lt;p&gt;ã¾ãã¯ããã«ãå¤§éæã«ãã£ã¦ãé³å£°åæã®ç ç©¶ï¼or ãã®çä¼¼äºï¼ããã¦ã¿ããäººãä¸»ãªå¯¾è±¡ã§ãã
èªåã®ãã¼ã¿ãåã«ããã©ãã¯ããã¯ã¹ã§ããã®ã§é³å£°åæã¨ã³ã¸ã³ãä½ããããã¨ããäººã«ã¯å³ããããããã¾ããããã®åæãåã«ãå°ãæ´çãã¾ãã&lt;/p&gt;
&lt;h3 id=&#34;ãããªäººã«ããããã§ã&#34;&gt;ãããªäººã«ããããã§ã&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Jupyter notebookãå¥½ããªäºº&lt;/li&gt;
&lt;li&gt;REPLãå¥½ããªäºº&lt;/li&gt;
&lt;li&gt;Pythonã§å¦çãå®çµããããäºº&lt;/li&gt;
&lt;li&gt;ãªã¼ãã³ã½ã¼ã¹ã®æåã«å¯å®¹ãªäºº&lt;sup id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;
&lt;li&gt;é³å£°åæã®ç ç©¶ãå§ãã¦ã¿ããäºº&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;ãããªäººã«ã¯åããªããã&#34;&gt;ãããªäººã«ã¯åããªããã&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;ã³ãã³ãã©ã¤ã³ãã¼ã«ããè³é«ãªäºº&lt;/li&gt;
&lt;li&gt;ãã¤ãã©ã¤ã³å¦çããè³é«ãªäºº&lt;/li&gt;
&lt;li&gt;SPTKã®ã³ãã³ãã©ã¤ã³ãã¼ã«è³é«ãªäºº&lt;/li&gt;
&lt;li&gt;ä¿¡é ¼ã®ããæ©é¢ãä½ã£ããã¼ã«ããä½¿ããªãäºº&lt;sup id=&#34;fnref:5&#34;&gt;&lt;a href=&#34;#fn:5&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;5&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;
&lt;li&gt;é³å£°ç ç©¶èã¬ãå¢ã§ãèªåã®ãã¼ã«ã§æºè¶³ãã¦ããäºº&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;dnnæ¥æ¬èªé³å£°åæã®å®è£ä¾&#34;&gt;DNNæ¥æ¬èªé³å£°åæã®å®è£ä¾&lt;/h2&gt;
&lt;p&gt;ãã¦ãåç½®ãã¯ãã®ãããã«ãã¦ãæ¥æ¬èªé³å£°åæã®å®è£ä¾ãç¤ºãã¾ããã·ã³ãã«ãªFeed forwardãªãããã¯ã¼ã¯ã¨ãBi-directional LSTM RNNã®2ãã¿ã¼ã³ãããã¼ãããã¯å½¢å¼ã§ä½æãã¾ããã&lt;/p&gt;
&lt;p&gt;ã½ã¼ã¹ã³ã¼ãã¯ã &lt;a href=&#34;https://github.com/r9y9/nnmnkwii_gallery&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/r9y9/nnmnkwii_gallery&lt;/a&gt; ã«ããã¾ããä»¥ä¸ã«ãç¾ç¶ç¹ã§ã®ç´ãªã³ã¯ï¼gitã®ã³ãããããã·ã¥ãURLã«å¥ã£ã¦ãã¾ãï¼ãè²¼ã£ã¦ããã¾ããnbviewerã«é£ã³ã¾ãã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://nbviewer.jupyter.org/github/r9y9/nnmnkwii_gallery/blob/bd4bd260eb22d0000ac2776b204b3a5afb693c49/notebooks/tts/jp-01-DNN-based%20statistical%20speech%20synthesis.ipynb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Feed forwardãªãããã¯ã¼ã¯ãä½¿ã£ãé³å£°åæã®ãã¼ãããã¯ã¸ã®ç´ãªã³ã¯&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://nbviewer.jupyter.org/github/r9y9/nnmnkwii_gallery/blob/bd4bd260eb22d0000ac2776b204b3a5afb693c49/notebooks/tts/jp-02-Bidirectional-LSTM%20based%20RNNs%20for%20speech%20synthesis.ipynb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Bi-directional LSTM RNNãä½¿ã£ãé³å£°åæã®ãã¼ãããã¯ã¸ã®ç´ãªã³ã¯&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;èå³ã®ããäººã¯ãã­ã¼ã«ã«ã«è½ã¨ãã¦å®è¡ãã¦ã¿ã¦ãã ãããCUDAç°å¢ããããã¨ãåæã§ãããéå¸¸ã®Feed forwardã®ãããã¯ã¼ã¯ãç¨ãããã¢ã¯ã
ç¹å¾´æ½åºã®æéï¼ååå®è¡æã«å¿è¦ï¼ãé¤ãã°ã5åã§å­¦ç¿&amp;amp;æ³¢å½¢çæãçµããã¾ããBi-directional LSTMã®ãã¢ã¯ãåã®ç°å¢ (i7-7700K, GTX 1080Ti) ã§ã¯ãç´2æéã§çµããã¾ããGPUã¡ã¢ãªãå°ãªãå ´åã¯ãããããµã¤ãºãå°ããããªããã°ãªãããããæéããããããããã¾ããã&lt;/p&gt;
&lt;h3 id=&#34;ãã¼ã¿ã»ãã&#34;&gt;ãã¼ã¿ã»ãã&lt;/h3&gt;
&lt;p&gt;ä»åã¯ãHTSã®NIT-ATR503ã®ãã¢ãã¼ã¿ (&lt;a href=&#34;https://github.com/r9y9/nnmnkwii_gallery/blob/4899437e22528399ca50c34097a2db2bed782f8b/data/NIT-ATR503_COPYING&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ã©ã¤ã»ã³ã¹&lt;/a&gt;) ãæåãã¾ããã©ã¤ãã©ãªãä½¿ã£ã¦é³å£°åæãå®ç¾ããããã®ãã¼ã¿ã¨ãã¦ãæä½éä»¥ä¸ãå¿è¦ã§ãã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;(state or phone level) ãã«ã³ã³ãã­ã¹ãã©ãã«&lt;/li&gt;
&lt;li&gt;Wavãã¡ã¤ã«&lt;/li&gt;
&lt;li&gt;è³ªåãã¡ã¤ã«ï¼è¨èªç¹å¾´éã®æ½åºã«å¿è¦ï¼&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ä¸2ã¤ã¯ãä»åã¯HTSã®ãã¢ã¹ã¯ãªããããã¾ãã¾ããã®ã¾ã¾ä½¿ãã¾ãï¼â»HTSã®ãã¢ã¹ã¯ãªãããåãå¿è¦ã¯ããã¾ããï¼ãè³ªåãã¡ã¤ã«ã¯ãã³ã³ãã­ã¹ãã¯ã©ã¹ã¿ãªã³ã°ã«ä½¿ãããè³ªåãã¡ã¤ã«ãåã«ãè³ªåæ°ãï¼æ¬å½ã«ï¼é©å½ã«æ¸ããã¦ãMerlinã®ãã¢ã®è³ªåãã¡ã¤ã«ããCQSã«è©²å½ããè³ªåãå ãã¦ãä½æãã¾ããã
ãã«ã³ã³ãã­ã¹ãã©ãã«ã«ã¯ãphone-levelã§ã¢ã©ã¤ã¡ã³ãããããã®ãä½¿ãã¾ããã
state-levelã§ã¢ã©ã¤ã¡ã³ãããããã®ãä½¿ãã°ãæ§è½ã¯ä¸ããã¨æãã¾ããä»åã¯ç°¡åã®ããã«phone-levelã®ã¢ã©ã¤ã¡ã³ããä½¿ãã¾ãã&lt;/p&gt;
&lt;p&gt;è³ªåã®é¸å®ã«ã¯ãæ¹åã®ä½å°ããããã¨ãããã£ã¦ãã¾ãããããã¾ã§ãã¢ã¨ãããã¨ã§ããäºæ¿ãã ããã&lt;/p&gt;
&lt;h3 id=&#34;é³å£°åæã®çµæ&#34;&gt;é³å£°åæã®çµæ&lt;/h3&gt;
&lt;p&gt;å¨ä½ã®å¦çã«èå³ãããå ´åã¯å¥éãã¼ãããã¯ãè¦ã¦ãããã¨ãã¦ãããã§ã¯çµæã ãè²¼ã£ã¦ããã¾ãã
HTSã®ãã¢ããã¨ã£ã¦ããä¾æ5ã¤ã«å¯¾ãã¦ããããã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Feed forward neural networks (MyNetã¨ãã¾ã) ã§çæãããã®&lt;/li&gt;
&lt;li&gt;Bi-directional LSTM recurrent neural networks (MyRNNã¨ãã¾ã)ã§çæãããã®&lt;/li&gt;
&lt;li&gt;HTSãã¢ã§çæãããã® (HTSã¨ãã¾ã)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ã®é çªã«ãé³å£°ãã¡ã¤ã«ãæ·»ä»ãã¦ããã¾ããè´ããããããã«ãsoxã§æ­£è¦åãã¦ãã¾ããããã§ã¯ã©ããã&lt;/p&gt;
&lt;p&gt;1 ããã«ã¡ã¯&lt;/p&gt;
&lt;p&gt;MyNet&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-01-tts/phrase01.wav&#34; type=&#34;audio/wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;MyRNN&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-02-tts/phrase01.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;HTS&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/hts_nit_atr503_2mix/phrase01.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;2 ããã§ã¯ããããªã&lt;/p&gt;
&lt;p&gt;MyNet&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-01-tts/phrase02.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;MyRNN&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-02-tts/phrase02.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;HTS&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/hts_nit_atr503_2mix/phrase02.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;3 ã¯ããã¾ãã¦&lt;/p&gt;
&lt;p&gt;MyNet&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-01-tts/phrase03.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;MyRNN&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-02-tts/phrase03.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;HTS&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/hts_nit_atr503_2mix/phrase03.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;4 ããããåå¤å±å·¥æ¥­å¤§å­¦ã¸&lt;/p&gt;
&lt;p&gt;MyNet&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-01-tts/phrase04.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;MyRNN&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-02-tts/phrase04.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;HTS&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/hts_nit_atr503_2mix/phrase04.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;5 ä»å¤ã®åå¤å±ã®å¤©æ°ã¯é¨ã§ã&lt;/p&gt;
&lt;p&gt;MyNet&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-01-tts/phrase05.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;MyRNN&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-02-tts/phrase05.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;HTS&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/hts_nit_atr503_2mix/phrase05.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;ä¸å¿HTSã§çæãããé³å£°ãè²¼ãã¾ããããããããå®é¨æ¡ä»¶ãéãããã&lt;sup id=&#34;fnref:6&#34;&gt;&lt;a href=&#34;#fn:6&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;6&lt;/a&gt;&lt;/sup&gt;ã®ã§ãåç´ã«æ¯è¼ãããã¨ã¯ã§ãã¾ããã
ããã¦ HTS ï¼ STRAIGHTã¨æ¯è¼ãããã£ãã¨ããã§ãããåã¯STRAIGHTãæã£ã¦ããªãã®ã§ãæ®å¿µãªããã§ãã¾ãããæ²ãã¿ã&lt;/p&gt;
&lt;p&gt;ãããããããªãã«ã¾ã¨ããªé³å£°ãåºã¦ãããããªæ°ããã¾ãã&lt;/p&gt;
&lt;h2 id=&#34;ãããã«&#34;&gt;ãããã«&lt;/h2&gt;
&lt;p&gt;ãã¾ã¾ã§ãããããæ±ç¨æ§ã¨ã¯ç¨é ãã¯ã½ã³ã¼ããæ¸ãã¦ãã¾ããããä»åããã¯å°ãã¯ãã·ãªãã®ãä½ããã¨æã£ã¦ä½ãã¾ãããåä»¥å¤ã®äººã«ãå½¹ã«ç«ã¦ã°å¹¸ãã§ãããã¨ããã®è¨äºãæ¸ããç®çã¯ãããããªäººã«ä½¿ã£ã¦ã¿ã¦ã»ããã®ã¨ãä½¿ã£ã¦ã¿ãçµæã®ãã£ã¼ãããã¯ãã»ããï¼ãã°è¦ã¤ãããããããã¨ã©ã¼ã§åããããããã¯ã½ãç­ï¼ã¨ãããã¨ãªã®ã§ããã£ã¼ãããã¯ããã ããã¨å©ããã¾ãããããããé¡ããã¾ãã&lt;/p&gt;
&lt;p&gt;ã¡ãªã¿ã«ååã§ããããªãªã¿ or ãã¡ã¿ã¨èª­ãã§ãã ãããä½ã§ãããã®ã§ãããå¸¸è­çã«èãã¦ããç¢ºãã«èª­ããªããªãã¨æãã¾ããï¼å°ä¸¦æï¼ããã­ã¥ã¡ã³ãã«ããã­ã´ã¯ãæä¸æ¬¡åç©ä½è¿½è·¡ã®å®é¨ããã¦ããã¨ãã«æ®ã£ããæã¢ã³ã®ãã¤ã³ãã¯ã©ã¦ãã§ããããã®ãã¡ä¸å³çãªç»åã«å¤ãããã¨æã£ã¦ãã¾ããé©å½ã§ããã¾ãã&lt;/p&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;ãªã³ã¯åããæãã®ã§ãv0.0.1ã®ãªã³ã¯ãè²¼ãã¾ãããã§ããã°ãææ°çããè¦§ãã ããã &lt;a href=&#34;https://r9y9.github.io/nnmnkwii/latest/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://r9y9.github.io/nnmnkwii/latest/&lt;/a&gt; ãã¡ããããã©ãã¾ã&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;ç¥ã£ã¦ããäººã«ã¯ã¾ãããã¨è¨ãããã&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;é³é¿ã¢ãã«ã®æä¾ãã©ã¤ãã©ãªã®ç¯å²å¤ã¨ãããã¨ã§ãéæ¥çã«éæããã¦ãã¾ã&amp;#160;&lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:4&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;ãã°ã«ã¨ã³ã«ã¦ã³ããããããã«ä½¿ãã®ãããã¦ãã¾ãäººã«ã¯ãåãã¦ããªãããããã¾ããã&amp;#160;&lt;a href=&#34;#fnref:4&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:5&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Merlinã¯ãã¨ã¸ã³ãã©å¤§å­¦ã®åªç§ãªç ç©¶èã®æ¹ãã«ãã£ã¦ä½ããã¦ãã¾ã&amp;#160;&lt;a href=&#34;#fnref:5&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:6&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;f0åæãã¹ãã¯ãã«åçµ¡æ½åºãéå¨ææ§æåã®æ½åºæ³ããã¹ã¦ãã¨ãªããã¾ããã¹ããã£ã«ã¿ã®ç¨®é¡ãç°ãªããæ¡ä»¶ãããç¨åº¦æãã¦æ¯è¼ããã®ãé¢åããã ã£ãã®ã§ï¼ãªã«ãHTSãä½¿ã£ãã¢ãã«ã®å­¦ç¿ã¯æ°æéããããâ¦ï¼ãæãæãã¾ãããããã¾ãã&amp;#160;&lt;a href=&#34;#fnref:6&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
    </item>
    
    <item>
      <title>DNNçµ±è¨çé³å£°åæãã¼ã«ã­ãã Merlin ã®ä¸­èº«ãçè§£ããã</title>
      <link>https://r9y9.github.io/blog/2017/08/16/trying-to-understand-merlin/</link>
      <pubDate>Wed, 16 Aug 2017 03:00:00 +0900</pubDate>
      <guid>https://r9y9.github.io/blog/2017/08/16/trying-to-understand-merlin/</guid>
      <description>&lt;p&gt;ãã®è¨äºã§ã¯ãé³å£°åæãã¼ã«ã­ããã§ããMerlinããå·ä½çã«ä½ããã¦ããã®ãï¼ç¹å¾´éã®æ­£è¦åãç¡é³åºéã®åé¤ããã¹ããã£ã«ã¿ãªã©ãã³ã¼ããèª­ã¾ãªãã¨ããããªããã¨ï¼ããã®ä¸­èº«ãåãçè§£ããç¯å²ã§ã¾ã¨ãã¾ãã
ãªããHMMé³å£°åæã«ã¤ãã¦ç°¡åã«çè§£ãã¦ãããã¨ï¼HMMã¨ã¯ãç¶æã¨ã¯ããã«ã³ã³ãã­ã¹ãã©ãã«ã¨ã¯ããããï¼ãåæã¨ãã¾ãã&lt;/p&gt;
&lt;h2 id=&#34;ã¯ããã«&#34;&gt;ã¯ããã«&lt;/h2&gt;
&lt;p&gt;Merlinã®æ¦è¦ã«ã¤ãã¦ã¯ä»¥ä¸ããè¦§ãã ããã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://ssw9.net/papers/ssw9_PS2-13_Wu.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Wu, Zhizheng, Oliver Watts, and Simon King. &amp;ldquo;Merlin: An open source neural network speech synthesis system.&amp;rdquo; Proc. SSW, Sunnyvale, USA (2016).&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://ssw9.net/papers/ssw9_DS-3_Ronanki.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&amp;ldquo;A Demonstration of the
Merlin Open Source Neural Network Speech Synthesis System&amp;rdquo;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://cstr-edinburgh.github.io/merlin/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;å¬å¼ãã­ã¥ã¡ã³ã&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Merlinã«ã¯ãã¢ã¹ã¯ãªãããã¤ãã¦ãã¾ããåºæ¬çã«ã¦ã¼ã¶ãä½¿ãã¤ã³ã¿ãã§ã¼ã¹ã¯run_merlin.pyã¨ããã³ãã³ãã©ã¤ã³ã¹ã¯ãªããã§ã
ãã¢ã¹ã¯ãªããã§ã¯run_merlin.pyã«ç¨éã«å¿ããè¨­å®ãã¡ã¤ã«ãä¸ãããã¨ã§ãç¶ç¶é·ã¢ãã«ã®å­¦ç¿/é³é¿ã¢ãã«ã®å­¦ç¿/ãã©ã¡ã¼ã¿çæãªã©ãé³å£°åæã«å¿è¦ãªã¹ããããå®ç¾ãã¦ãã¾ãã&lt;/p&gt;
&lt;p&gt;ãã¢ã¹ã¯ãªãããå®è¡ããã¨ãé³å£°ãã¼ã¿ (wav) ã¨è¨èªç¹å¾´éï¼HTSã®ãã«ã³ã³ãã­ã¹ãã©ãã«ï¼ãããå¤æé³å£°ãåæãããã¨ããã¾ã§ã¾ãã£ã¨ãã£ã¦ãããã®ã§ãããããã ãã§ã¯åé¨ã§ä½ããã£ã¦ããã®ããçè§£ãããã¨ã¯ã§ãã¾ããã
ãã¼ã«ã­ãããä½¿ãç®çããèªåãç¨æãããã¼ã¿ã»ããã§é³å£°åæå¨ãä½ããããã¨ãã£ãå ´åã«ã¯ãç¹ã«åé¨ãç¥ãå¿è¦ã¯ããã¾ããã
ã¾ããè¨­å®ãã¡ã¤ã«ãã¡ããã£ã¨ãããã ãã§ãã¨æ¸ãã®ã§ããã°ãç¥ãå¿è¦ã¯ãªãããããã¾ããã
ããããã¢ãã«æ§é ãå¤ããããå­¦ç¿ã¢ã«ã´ãªãºã ãå¤ãããããã¹ããã£ã«ã¿ãå¥ããããã¨ãã£ãããã«ãå°ãé²ãã ä½¿ãæ¹ããããã¨ããã°ãåé¨æ§é ãçè§£ããªãã¨ã§ããªããã¨ãå¤ãã¨æãã¾ãã&lt;/p&gt;
&lt;p&gt;run_merlin.py ã¯ããããå¦ç (å·ä½çã«ã¯ãã¨ã§è¿°ã¹ã¾ã) ã®ã¨ã³ããªã¼ãã¤ã³ãã«ãªã£ã¦ãããããã«ãã³ã¼ãã¯ãªããªãã«è¤éã«ãªã£ã¦ãã¾ã&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;ããã®è¨äºã§ã¯ãrun_merlin.pyããã£ããä½ããã¦ããã®ããèª­ã¿è§£ããçµæãã¾ã¨ãã¾ãã&lt;/p&gt;
&lt;h2 id=&#34;merlinã§ã¯æä¾ããªããã¨&#34;&gt;Merlinã§ã¯æä¾ããªããã¨&lt;/h2&gt;
&lt;p&gt;Merlinãä½ãæä¾ãã¦ãããã®ããçè§£ããåã«ãä½ãæä¾ããªãã®ããããã£ããã¨æ´çãã¾ããä»¥ä¸ã®ã¨ããã§ãã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Text-processing (&lt;strong&gt;Frontend&lt;/strong&gt;)&lt;/li&gt;
&lt;li&gt;Speech analysis/synthesis (&lt;strong&gt;Backend&lt;/strong&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;HTSã¨åæ§ã«ãfrontend, backendã¨ãã£ãé¨åã¯æä¾ãã¦ãã¾ãããMerlinã®è«æã«ãããããã«ãHTSã®å½±é¿ãåãã¦ããããã§ãã&lt;/p&gt;
&lt;p&gt;Frontendã«ã¯ãè±èªãªãFestivalãBackendã«ã¯WORLDãSTRAIGHTãä½¿ã£ã¦ãããããã£ã¦ã­ãã¨ããã¹ã¿ã³ã¹ã§ãã
Backendã«é¢ãã¦ã¯ãMerlinã®ã¤ã³ã¹ãã¼ã«ã¬ã¤ãã«ããããã«ãWOLRDãã¤ã³ã¹ãã¼ã«ããããã«ä¿ããã¾ãã&lt;/p&gt;
&lt;p&gt;ãã¢ã¹ã¯ãªããã§ã¯ãFrontendã«ãã£ã¦çæããããã«ã³ã³ãã­ã¹ãã©ãã«ï¼HTSæ¸å¼ï¼ãäºåã«åæ¢±ããã¦ããã®ã§ãFestivalãã¤ã³ã¹ãã¼ã«ããå¿è¦ã¯ããã¾ããã
miscä»¥ä¸ã«ãFestivalãä½¿ã£ã¦ãã«ã³ã³ãã­ã¹ãã©ãã«ãä½ãã¹ã¯ãªãã (make_labels) ãããã®ã§ããã¢ãã¼ã¿ä»¥å¤ã®ãã¼ã¿ã»ãããä½¿ãå ´åã¯ããããä½¿ãã¾ãã&lt;/p&gt;
&lt;h2 id=&#34;steps&#34;&gt;Steps&lt;/h2&gt;
&lt;p&gt;æ¬ç·¨ã§ããslt_arcticã®ãã¢ã¹ã¯ãªããã«å¾ããããããã®ã¹ãããã«åãã¦ãè©³ç´°ã«è¦ã¦ããã¾ãããªããä»¥ä¸ãã¢ã¹ã¯ãªããã¨æ¸ããéã«ã¯ãslt_arcticã®ãã¢ã¹ã¯ãªãããæããã®ã¨ãã¾ãã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ç¶ç¶é·ã¢ãã«ã®å­¦ç¿&lt;/li&gt;
&lt;li&gt;é³é¿ã¢ãã«ã®å­¦ç¿&lt;/li&gt;
&lt;li&gt;å¤æé³å£°ã®åæ&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ãªããMerlinã®ã¹ã¯ãªããã«ãã£ã¦ã¯ããããã¼ã¿ã¯ãåºæ¬çã«&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;x.astype(np.float32).tofile(&amp;quot;foobar.bin&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;ã¨ãã£ãæãã§ã32bitæµ®åå°æ°ç¹ã®numpyã®éåãããããªãã®ãã¤ããªãã©ã¼ãããã§ä¿å­ããã¦ãã¾ãããããã°æã«ã¯ã&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;np.fromfile(&amp;quot;foobar.bin&amp;quot;, dtype=np.float32)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;ã¨ãã¦ããã¡ã¤ã«ãèª­ã¿è¾¼ãã§ã¤ã³ã¹ãã¯ãããã®ãä¾¿å©ã§ããæ³¨æäºé ã¨ãã¦ãããããããã¨ã«ãæ¡å¼µå­ã¯ä¿¡é ¼ã§ãã¾ããã&lt;code&gt;.lab&lt;/code&gt; ã¨ããæ¡å¼µå­ã§ãã£ã¦ãããã«ã³ã³ãã­ã¹ãã©ãã«ã®ãã­ã¹ããã¡ã¤ã«ã§ããå ´åãããã°ãä¸è¿°ã®ããã«ãã¤ããªãã©ã¼ãããã§ããå¯è½æ§ãããã¾ããã¤ããã§ãã­ï¼&lt;/p&gt;
&lt;h3 id=&#34;ç¶ç¶é·ã¢ãã«ã®å­¦ç¿&#34;&gt;ç¶ç¶é·ã¢ãã«ã®å­¦ç¿&lt;/h3&gt;
&lt;p&gt;ç¶ç¶é·ã¢ãã«ã¨ã¯ãè¨èªç¹å¾´éãããç¶ç¶é·ãäºæ¸¬ããã¢ãã«ã§ããMerlinã§ã¯ãphone-level / state-level ã®ã©ã¡ãããé¸æå¯è½ã§ããMerlinã®æä¾ããDNNé³å£°åæã§ã¯ãç¶ç¶é·ã®äºæ¸¬âé³é¿ç¹å¾´éã®äºæ¸¬âåæãã¨ãã£ãã¹ã¿ã¤ã«ãã¨ãã¾ãã
ããã©ã«ãã§ã¯ãstate-levelã§ç¶ç¶é·ï¼å·ä½çã«ã¯ä¸ç¶æå½ããã®ç¶ç¶ãã¬ã¼ã æ°ï¼ãäºæ¸¬ãã¾ããç¶æã¬ãã«ã®ã¢ã©ã¤ã¡ã³ãã®ã»ãããæéè§£ååº¦ã®é«ãã³ã³ãã­ã¹ããå¾ãããçµæé³å£°åæã®åè³ªãè¯ããªãã®ã§ãããã©ã«ãã«ãªã£ã¦ããã®ã ã¨æãã¾ãã &lt;a href=&#34;https://github.com/CSTR-Edinburgh/merlin/issues/18&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/CSTR-Edinburgh/merlin/issues/18&lt;/a&gt; ã«å°ãè­°è«ãããã¾ãã&lt;/p&gt;
&lt;p&gt;ãã¢ã¹ã¯ãªãããå®è¡ããã¨ã &lt;code&gt;experiments/slt_arctic_demo/duration_model/&lt;/code&gt; ä»¥ä¸ã«ç¶ç¶é·ã¢ãã«ç¨ã®ãã¼ã¿ãã¯åºåããã¾ããããã¤ãéè¦ãªãã®ã«ã¤ãã¦ãä»¥ä¸ã«ç¤ºãã¾ãã&lt;/p&gt;
&lt;h4 id=&#34;data&#34;&gt;data&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;label_phone_align&lt;/code&gt;: é³ç´ ã¬ãã«ã§ã®ãã«ã³ã³ãã­ã¹ãã©ãã«ã§ã&lt;/li&gt;
&lt;li&gt;&lt;code&gt;dur&lt;/code&gt;: ç¶æå¥ç¶ç¶é·ã§ããæ­£ç¢ºã«ã¯ã&lt;code&gt;T&lt;/code&gt; ããã«ã³ã³ãã­ã¹ãã©ãã«ä¸­ã®é³ç´ æ°ã¨ãã¦ã&lt;code&gt;(T, 5)&lt;/code&gt; ã®éåãçºè©±ãã¨ã«ä¿å­ããã¾ãã5ã¯é³ç´ ãããã®HMMã®ç¶ææ°ã§ãæ£ä¾çã«ï¼5ãä½¿ç¨ããã¦ãããããªæ°ããã¾ãã&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;inter_module&#34;&gt;inter_module&lt;/h4&gt;
&lt;p&gt;ä¸­éçµæã®ãã¡ã¤ã«ç¾¤ã§ã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;binary_label_416/&lt;/code&gt;: HTSå½¢å¼ã®è³ªåãã¡ã¤ã«ãåã«çæãããè¨èªç¹å¾´éè¡åã§ãããã¢ã¹ã¯ãªããã§ã¯ã416åã®è³ªåãããã®ã§ãä¸ç¶æããã416æ¬¡åã®ç¹å¾´ãã¯ãã«ã«ãªãã¾ããbinaryãªç¹å¾´éï¼æ¯é³ãå¦ãï¼ã¨é£ç¶çãªç¹å¾´éï¼åèªä¸­ã®sylalbleã®æ°ç­ï¼ãããã¾ãã&lt;code&gt;(T, 416)&lt;/code&gt; ã®è¡åããçºè©±ãã¨ã«ä¿å­ããã¦ãã¾ãã&lt;/li&gt;
&lt;li&gt;&lt;code&gt;label_norm_HTS_416.dat&lt;/code&gt;: 416æ¬¡åã®ç¹å¾´ãã¯ãã«ã®æ­£è¦åã«å¿è¦ãªæå ±ã§ãããã¢ã¹ã¯ãªããã§ã¯ãè¨èªç¹å¾´éã«é¢ãã¦ã¯min/maxæ­£è¦åãè¡ãããã®ã§ãminããã³maxã®416æ¬¡åã®ãã¯ãã«ï¼è¨416*2æ¬¡åï¼ãä¿å­ããã¦ãã¾ãã&lt;/li&gt;
&lt;li&gt;&lt;code&gt;nn_dur_5/&lt;/code&gt;: ç¡é³åºéãé¤å»ããããç¶æå¥ç¶ç¶é·ã§ãããã©ã«ãåããã¯å¯ãããã¨ã¯é£ããã§ãããç¡é³åºéãé¤å»ããã¦ãã¾ãã&lt;/li&gt;
&lt;li&gt;&lt;code&gt;nn_no_silence_lab_416/&lt;/code&gt;: ç¡é³åºéãé¤å»ããããè¨èªç¹å¾´éè¡åã§ãã&lt;/li&gt;
&lt;li&gt;&lt;code&gt;nn_no_silence_lab_norm_416/&lt;/code&gt;: ç¡é³åºéãé¤å»ããããmin/maxæ­£è¦åãããè¨èªç¹å¾´éè¡åã§ãã&lt;/li&gt;
&lt;li&gt;&lt;code&gt;nn_norm_dur_5/&lt;/code&gt; ç¡é³åºéãé¤å»ããããmean/varianceæ­£è¦åãããç¶æå¥ç¶ç¶é·ã§ãã&lt;/li&gt;
&lt;li&gt;&lt;code&gt;norm_info_dur_5_MVN.dat&lt;/code&gt;: ç¶ç¶é·ã®æ­£è¦åã«å¿è¦ãªæå ±ã§ããå·ä½çã«ã¯ãMean-varianceæ­£è¦åï¼N(0, 1)ã«ãªãããã«ããï¼ãè¡ãããã®ã§ãå¹³åã¨æ¨æºåå·®ï¼not åæ£ï¼ãå¥ã£ã¦ãã¾ããç¶æã¬ãã«ã§ã®ã¢ã©ã¤ã¡ã³ããä½¿ç¨ããå ´åã¯ã5*2ã§è¨10æ¬¡åã®ãã¯ãã«ã§ãã&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ref_data/&lt;/code&gt;: RMSEãªã©ã®è©ä¾¡åºæºãè¨ç®ããéã«ä½¿ãããç¶ç¶é·ã®ãã¹ããã¼ã¿ã§ãã&lt;code&gt;data/dur&lt;/code&gt; ãã£ã¬ã¯ããªã®ç¶ç¶é·ãã¼ã¿ãåã«ãç¡é³åºéãé¤å»ããããã®ã§ã&lt;/li&gt;
&lt;li&gt;&lt;code&gt;var/&lt;/code&gt;: ç¶ç¶é·ã®åæ£ï¼not æ¨æºåå·®ï¼ã§ãããã©ã¡ã¼ã¿çæ (MLPG) ã«ä½¿ãããæ³å®ã®ãã¼ã¿ã§ã&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ãã£ããããããããã¾ãã­ãããã ãã§ããããã«å¤ãã®ãã¨ãrun_merlin.pyã«ãã£ã¦ãªããã¦ããããããããã¨æãã¾ãã&lt;/p&gt;
&lt;h4 id=&#34;å¥ååºå&#34;&gt;å¥å/åºå&lt;/h4&gt;
&lt;p&gt;ä¸­éãã¡ã¤ã«ããããããã£ã¦ãããããã§ãããæ´çããã¨ããããã¯ã¼ã¯å­¦ç¿ã«ç¨ããå¥åã¨åºåã¯ä»¥ä¸ã«ãªãã¾ãã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;å¥å: &lt;code&gt;nn_no_silence_lab_norm_416&lt;/code&gt;, ä¸çºè©±ãããã®ç¹å¾´éã®shape: &lt;code&gt;(T, 416)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;åºå: &lt;code&gt;nn_norm_dur_5&lt;/code&gt;, ä¸çºè©±ãããã®ç¹å¾´éã®shape: &lt;code&gt;(T, 5)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;å­¦ç¿ãããã¢ãã«ã¯ã &lt;code&gt;nnets_model&lt;/code&gt;ã¨ãããã©ã«ãã«ä¿å­ããã¾ãã&lt;/p&gt;
&lt;h3 id=&#34;é³é¿ã¢ãã«ã®å­¦ç¿&#34;&gt;é³é¿ã¢ãã«ã®å­¦ç¿&lt;/h3&gt;
&lt;p&gt;é³é¿ã¢ãã«ã¨ã¯ãè¨èªç¹å¾´éããã¡ã«ã±ãã¹ãã©ã ãF0ãéå¨ææ§æåãªã©ã®é³é¿ç¹å¾´éãäºæ¸¬ããã¢ãã«ã§ããMerlinã®ãã¢ã¹ã¯ãªããã§ã¯ã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ã¡ã«ã±ãã¹ãã©ã : 60æ¬¡åï¼åçç¹å¾´éãåãããã¨ã180æ¬¡å)&lt;/li&gt;
&lt;li&gt;å¯¾æ°F0: 1æ¬¡åï¼åçç¹å¾´éãåãããã¨ã3æ¬¡å)&lt;/li&gt;
&lt;li&gt;æå£° or ç¡å£°ãã©ã° (voiced/unvoiced; vuv): 1æ¬¡å&lt;/li&gt;
&lt;li&gt;éå¨ææ§æå: 1æ¬¡åï¼åçç¹å¾´éãåãããã¨ã3æ¬¡å)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ã®è¨187æ¬¡åã®é³é¿ç¹å¾´éãäºæ¸¬ããã¢ãã«ãèãã¾ããç¶ç¶é·ã¢ãã«ã®ã¨ãã¨åæ§ã«ãåºåããããã¡ã¤ã«ã«ã¤ãã¦ããããèª¬æãã¾ãã&lt;/p&gt;
&lt;h4 id=&#34;data-1&#34;&gt;data&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;bap&lt;/code&gt;: çºè©±æ¯ã«è¨ç®ãããéå¨ææ§æåãå¥ã£ã¦ãã¾ããbapã¯band averaged aperiodicityã®ç¥ã§ãï¼å°éå®¶ã®äººã«ã¨ã£ã¦ã¯å½ããåãã¨æãã¾ãããä¸å¿&lt;/li&gt;
&lt;li&gt;&lt;code&gt;label_phone_align&lt;/code&gt;: phone-levelã§ã¢ã©ã¤ã¡ã³ããããHTSã®ã³ã³ãã­ã¹ãã©ãã«ãå¥ã£ã¦ãã¾ããããã©ã«ãã®è¨­å®ã§ã¯ä½¿ãã¾ããã&lt;/li&gt;
&lt;li&gt;&lt;code&gt;label_state_align&lt;/code&gt;: state-levelã§ã¢ã©ã¤ã¡ã³ããããHTSã®ã³ã³ãã­ã¹ãã©ãã«ãå¥ã£ã¦ãã¾ã&lt;/li&gt;
&lt;li&gt;&lt;code&gt;lf0&lt;/code&gt;: å¯¾æ°F0ã§ãããªããWORLDã§ã¯ãããF0ã¯ç¡å£°åºéã§0ãåãã¾ãããç¡å£°åºéã®é¨åãç·å½¢è£éãããã¨ã«ãã£ã¦ãéã¼ã­ã®å¤ã§è£å®ãã¦ãã¾ãã&lt;/li&gt;
&lt;li&gt;&lt;code&gt;mgc&lt;/code&gt;: ã¡ã«ã±ãã¹ãã©ã ã§ãï¼ãã©ã«ãåã¯ãæ£ç¿çã«ã¡ã«ä¸è¬åã±ãã¹ãã©ã ãè¡¨ã &lt;code&gt;mgc&lt;/code&gt;ã¨ãªã£ã¦ãã¾ããããã¢ã¹ã¯ãªããã§ã¯å®éã«ã¯ã¡ã«ã±ãã¹ãã©ã ã§ãï¼&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;inter_module-1&#34;&gt;inter_module&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;binary_label_425/&lt;/code&gt;: è¨èªç¹å¾´éã®è¡åã§ããç¶ç¶é·ã¢ãã«ã®å ´åã¨éã£ã¦ããã¬ã¼ã åä½ã§çæããã¦ããã®ã¨ããã¬ã¼ã åä½ãªãã§ã¯ã®ç¹å¾´éï¼é³ç´ ä¸­ã®ä½ãã¬ã¼ã ç®ãªã®ããç­ï¼ãè¿½å ããã¦ãã¾ãããã¬ã¼ã æ°ã &lt;code&gt;T&lt;/code&gt; ã¨ãã¦ã &lt;code&gt;(T, 425)&lt;/code&gt; ã®éåãçºè©±ãã¨ã«ä¿å­ããã¦ãã¾ãã&lt;/li&gt;
&lt;li&gt;&lt;code&gt;label_norm_HTS_425.dat&lt;/code&gt;: è¨èªç¹å¾´éã®min/maxæ­£è¦åã«å¿è¦ãªmin/maxã®ãã¯ãã«ã§ãã&lt;/li&gt;
&lt;li&gt;&lt;code&gt;nn_mgc_lf0_vuv_bap_187/&lt;/code&gt;: mgc, lf0, vuv, bapãçµåããé³é¿ç¹å¾´éã§ããããcmp (composed featureããæ¥ã¦ããã¨æããã) ã¨è¡¨ããããã®ã§ãããã£ã¬ã¯ããªåããã¯å¤å¥ãä»ãã¾ããããç¡é³åºéã¯åé¤ããã¦ãã¾ããããããã&lt;/li&gt;
&lt;li&gt;&lt;code&gt;nn_no_silence_lab_425/&lt;/code&gt;: &lt;code&gt;binary_label_425&lt;/code&gt; ã®è¨èªç¹å¾´éããç¡é³åºéãåé¤ãããã®ã§ã&lt;/li&gt;
&lt;li&gt;&lt;code&gt;nn_no_silence_lab_norm_425/&lt;/code&gt;: ãããããã«min/maxæ­£è¦åãããã®ã§ã&lt;/li&gt;
&lt;li&gt;&lt;code&gt;nn_norm_mgc_lf0_vuv_bap_187/&lt;/code&gt;: &lt;code&gt;nn_mgc_lf0_vuv_bap_187/&lt;/code&gt;ã®é³é¿ç¹å¾´éãN(0, 1)ã«ãªãããã«mean/varianceæ­£è¦åãããã®ã§ã&lt;/li&gt;
&lt;li&gt;&lt;code&gt;norm_info_mgc_lf0_vuv_bap_187_MVN.dat&lt;/code&gt;: é³é¿ç¹å¾´éã®æ­£è¦åã«å¿è¦ãªãå¹³åã¨æ¨æºåå·®ã§ã&lt;/li&gt;
&lt;li&gt;&lt;code&gt;var/&lt;/code&gt;: mgc, lf0, bap, vuvããããã®åæ£ã§ãããã®ãã¡vuvã¯ããã©ã¡ã¼ã¿çææã«MLPGãè¡ãã¾ããããä¿å­ã¯ããã¦ãã¾ãã&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;å¥ååºå-1&#34;&gt;å¥å/åºå&lt;/h4&gt;
&lt;p&gt;ç¶ç¶é·ã¢ãã«ã®å ´åã¨åæ§ã®ä¸­éç¹å¾´éãåºåããã¦ãã¾ããæ¹ãã¦æ´çããã¨ãé³é¿ã¢ãã«ã®å­¦ç¿ã«ä½¿ç¨ããå¥åã¨åºåã¯ãä»¥ä¸ã®ã¨ããã§ãã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;å¥å: &lt;code&gt;nn_no_silence_lab_norm_425/&lt;/code&gt;, ä¸çºè©±ãããã®ç¹å¾´éã®shape: &lt;code&gt;(T, 425)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;åºå: &lt;code&gt;nn_norm_mgc_lf0_vuv_bap_187&lt;/code&gt;, ä¸çºè©±ãããã®ç¹å¾´éã®shape: &lt;code&gt;(T, 187)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;å­¦ç¿ãããã¢ãã«ã¯ã &lt;code&gt;nnets_model&lt;/code&gt;ã¨ãããã©ã«ãã«ä¿å­ããã¾ãã&lt;/p&gt;
&lt;h3 id=&#34;æ³¢å½¢çæ&#34;&gt;æ³¢å½¢çæ&lt;/h3&gt;
&lt;p&gt;å¾ãããç¶ç¶é·ã¢ãã«ã¨é³é¿ã¢ãã«ãããæ³¢å½¢ãçæããå¦çã¯ãå¤§éæã«ãã£ã¦ä»¥ä¸ã®æé ã§è¡ããã¾ãã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ãã«ã³ã³ãã­ã¹ãã©ãã«ããå¾ãããè¨èªç¹å¾´éãåã«ãç¶ç¶é·ã¢ãã«ãä½¿ã£ã¦ç¶ç¶é·ãäºæ¸¬ãã&lt;/li&gt;
&lt;li&gt;äºæ¸¬ãããç¶ç¶é·ãä½¿ã£ã¦ããã«ã³ã³ãã­ã¹ãã©ãã«ãæ¸ãæãããããå·ä½çã«ã¯ãç¶ææ¯ã® start_time, end_time ã®é¨åãæ¸ãæããã&lt;/li&gt;
&lt;li&gt;æ¸ãæãããããã«ã³ã³ãã­ã¹ãã©ãã«ãããé³é¿ã¢ãã«ç¨ã®ãã¬ã¼ã ã¬ãã«ã®è¨èªç¹å¾´éãè¨ç®ããé³é¿ã¢ãã«ãä½¿ã£ã¦é³é¿ç¹å¾´éãäºæ¸¬ãã&lt;/li&gt;
&lt;li&gt;äºæ¸¬ãããé³é¿ç¹å¾´éï¼static + delta + delta-delta) ãããéçç¹å¾´éãMLPGã«ãã£ã¦çæãããMLPGã«ãã£ã¦çæããã®ã¯ãmgc, lf0, bapã®ã¿ã§ãvuvã«ã¤ãã¦ã¯ãã®ã¾ã¾ä½¿ããæ³¢å½¢åæã«ã¯vuvãç´æ¥ä½¿ãã®ã§ã¯ãªããvuv &amp;lt; 0.5ä»¥ä¸ã®f0ã0ã¨ãã¦æ±ãã&lt;/li&gt;
&lt;li&gt;çæãããã¡ã«ã±ãã¹ãã©ã ã«å¯¾ãã¦ãMerlinãæè£½ãã¹ããã£ã«ã¿ãæãã&lt;/li&gt;
&lt;li&gt;å¾ãããé³é¿ç¹å¾´é (mgc, f0, bap) ãããWORLDãä½¿ã£ã¦æ³¢å½¢åæããã&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ä»¥ä¸ã§ããMerlinã®è¯ãæã®ä¸ã¤ã«ãã­ã°ãããããã¯ãã¦ãããã¨ããã®ãããã¾ãããããããã®ãã¡ãã¹ããã£ã«ã¿ï¼ããã©ã«ãã§ONã§ãï¼ã«é¢ãã¦ã¯ä¸åï¼ããã©ã«ãã§ã¯ï¼ã­ã°ãã¯ããããæ°ã¥ãã®ã«æéããããã¾ããã&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;ã¾ããåäººçãªæè¦ã§ããããã®ãã¹ããã£ã«ã¿ã®å½±é¿ã¯çµ¶å¤§ã«æãã¾ãããã³ã¼ããè¦ã¦ãä½ããã¦ããã®ãåã«ã¯çè§£ã§ãã¾ããã§ãããããã¥ã¼ãªã¹ãã£ãã¯ãªæ¹æ³ãå«ãã§ããããã«æãã¾ãããèå³ã®ããæ¹ã¯ã æ³¢å½¢åæç¨ã®confãã¡ã¤ã«ãéãã¦ã&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[Waveform]
do_post_filtering: False
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;ã®ããã«ã&lt;code&gt;[Waveform]&lt;/code&gt; ã»ã¯ã·ã§ã³ã« &lt;code&gt;do_post_filtering&lt;/code&gt; ã¨ããé ç®ãå ãã¦ãçæçµæãè´ãæ¯ã¹ã¦ã¿ããã¨ããããããã¾ãããã¹ããã£ã«ã¿ã«ãã£ã¦åçã«é³è³ªãæ¹åããã¦ããã®ããããã¨æãã¾ããããã«èå³ã®ããæ¹ã¯ãã³ã¼ããèª­ãã§ã¿ã¦ãã ãããåèæç®ãæ¢ãã¾ããããåã«ã¯è¦ã¤ããã¾ããã§ããããå­ç¥ã®æ¹ãããã°æãã¦ããã ãããã§ãã&lt;/p&gt;
&lt;h2 id=&#34;ãããã«&#34;&gt;ãããã«&lt;/h2&gt;
&lt;p&gt;Merlinãæåã¯ä½¿ãã«ãããªã¨æã£ã¦ãã¾ããããé å¼µã£ã¦èª­ãã§ã¿ãã°ãã¨ã¦ãåå¼·ã«ãªãã¾ããï¼ä½¿ããããã¨ã¯è¨ã£ã¦ããªãï¼ãå¾åã¯ã ãã¦ãé©å½ãªã¾ã¨ãã«ãªã£ã¦ãã¾ã£ãããããã¾ãããããã¾ãããããããã®ä¸æºãã&lt;a href=&#34;https://github.com/r9y9/nnmnkwii&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;æ°ãããã¼ã«&lt;/a&gt;ãä½ãã¾ããããããã¯ã¾ãå¥ã®æ©ä¼ã«ç´¹ä»ãããã¨æãã¾ãããããã¨ããããã¾ããã&lt;/p&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;&lt;a href=&#34;http://jrmeyer.github.io/merlin/2017/02/14/Installing-Merlin.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://jrmeyer.github.io/merlin/2017/02/14/Installing-Merlin.html&lt;/a&gt; ã«ããã°ãThis is a very clearly written Python script ã ããã§ãâ¦ãåã«èª­è§£åããªãã ãã®å¯è½æ§ãããã¾ã&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;èªåã§ä½ã£ãã¢ãã«ããã©ããã¦ãmerlinã«åã¦ãªãããªãã ãã¨æ©ãã§ããã¨ããMerlinã«è¨åãã¦ããè«æã®ä¸ã¤ã«ããã¹ããã£ã«ã¿ãä½¿ã£ã¦ããã¨ã®è¨è¿°ããããæ¢ã£ã¦ã¿ãã¨ãããã«ãã£ããã¨ããæãã§ããã&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
    </item>
    
    <item>
      <title>Pythonã«ãããã¥ã¼ã©ã«ãããã®Toyã³ã¼ã</title>
      <link>https://r9y9.github.io/blog/2014/05/11/python-feed-forward-neural-network-toy-code/</link>
      <pubDate>Sun, 11 May 2014 00:00:00 +0000</pubDate>
      <guid>https://r9y9.github.io/blog/2014/05/11/python-feed-forward-neural-network-toy-code/</guid>
      <description>&lt;p&gt;1000çªçãã ãã©ãç¥ãåãã«ãã¥ã¼ã©ã«ããããæãã¦ãã¦ããã®éç¨ã§æ¸ããã³ã¼ããããããããéè¦ã&lt;/p&gt;
&lt;p&gt;ãã®ããã«ãèª¤å·®ä¼æ­æ³ãnåå°åºãã¾ããï¼æè¨³ï¼ä½åãã¡ã¢ãªããã¾ããï¼&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;#!/usr/bin/python
# coding: utf-8

# ãã¥ã¼ã©ã«ãããã¯ã¼ã¯(Feed-Forward Neural Networks)ã®å­¦ç¿ãèªè­ã®
# ãã¢ã³ã¼ãã§ãã
# èª¤å·®ä¼æ¬æ³ã«ãã£ã¦ãã¥ã¼ã©ã«ããããå­¦ç¿ãã¾ãã
# XORã®å­¦ç¿ããã¹ãã®ç°¡åãªãã¢ã³ã¼ããã¤ãã¦ãã¾ã
# 2014/05/10 Ryuichi Yamamoto

import numpy as np

def sigmoid(x):
    return 1.0 / (1.0 + np.exp(-x))

def dsigmoid(y):
    return y * (1.0 - y)

class NeuralNet:
    def __init__(self, num_input, num_hidden, num_output):
        &amp;quot;&amp;quot;&amp;quot;
        ãã©ã¡ã¼ã¿ã®åæå
        &amp;quot;&amp;quot;&amp;quot;
        # å¥åå±¤ããé ãå±¤ã¸ã®éã¿è¡å
        self.W1 = np.random.uniform(-1.0, 1.0, (num_input, num_hidden))
        self.hidden_bias = np.ones(num_hidden, dtype=float)
        # é ãå±¤ããåºåå±¤ã¸ã®éã¿è¡å
        self.W2 = np.random.uniform(-1.0, 1.0, (num_hidden, num_output))
        self.output_bias = np.ones(num_output, dtype=float)

    def forward(self, x):
        &amp;quot;&amp;quot;&amp;quot;
        ååãä¼æ¬ã®è¨ç®
        &amp;quot;&amp;quot;&amp;quot;
        h = sigmoid(np.dot(self.W1.T, x) + self.hidden_bias)
        return sigmoid(np.dot(self.W2.T, h) + self.output_bias)

    def cost(self, data, target):
        &amp;quot;&amp;quot;&amp;quot;
        æå°åãããèª¤å·®é¢æ°
        &amp;quot;&amp;quot;&amp;quot;
        N = data.shape[0]
        E = 0.0
        for i in range(N):
            y, t = self.forward(data[i]), target[i]
            E += np.sum((y - t) * (y - t))
        return 0.5 * E / float(N)

    def train(self, data, target, epoches=30000, learning_rate=0.1,\
              monitor_period=None):
        &amp;quot;&amp;quot;&amp;quot;
        Stochastic Gradient Decent (SGD) ã«ããå­¦ç¿
        &amp;quot;&amp;quot;&amp;quot;
        for epoch in range(epoches):
            # å­¦ç¿ãã¼ã¿ãã1ãµã³ãã«ãã©ã³ãã ã«é¸ã¶
            index = np.random.randint(0, data.shape[0])
            x, t = data[index], target[index]

            # å¥åããåºåã¾ã§ååãã«ä¿¡å·ãä¼æ¬
            h = sigmoid(np.dot(self.W1.T, x) + self.hidden_bias)
            y = sigmoid(np.dot(self.W2.T, h) + self.output_bias)

            # é ãå±¤-&amp;gt;åºåå±¤ã®éã¿ã®ä¿®æ­£éãè¨ç®
            output_delta = (y - t) * dsigmoid(y)
            grad_W2 = np.dot(np.atleast_2d(h).T, np.atleast_2d(output_delta))

            # é ãå±¤-&amp;gt;åºåå±¤ã®éã¿ãæ´æ°
            self.W2 -= learning_rate * grad_W2
            self.output_bias -= learning_rate * output_delta

            # å¥åå±¤-&amp;gt;é ãå±¤ã®éã¿ã®ä¿®æ­£éãè¨ç®
            hidden_delta = np.dot(self.W2, output_delta) * dsigmoid(h)
            grad_W1 = np.dot(np.atleast_2d(x).T, np.atleast_2d(hidden_delta))

            # å¥åå±¤-&amp;gt;é ãå±¤ã®éã¿ãæ´æ°
            self.W1 -= learning_rate * grad_W1
            self.hidden_bias -= learning_rate * hidden_delta

            # ç¾å¨ã®ç®çé¢æ°ã®å¤ãåºå
            if monitor_period != None and epoch % monitor_period == 0:
                print &amp;quot;Epoch %d, Cost %f&amp;quot; % (epoch, self.cost(data, target))

        print &amp;quot;Training finished.&amp;quot;

    def predict(self, x):
        &amp;quot;&amp;quot;&amp;quot;
        åºåå±¤ã®æãåå¿ãããã¥ã¼ã­ã³ã®çªå·ãè¿ãã¾ã
        &amp;quot;&amp;quot;&amp;quot;
        return np.argmax(self.forward(x))

if __name__ == &amp;quot;__main__&amp;quot;:
    import argparse

    parser = argparse.ArgumentParser(description=&amp;quot;Specify options&amp;quot;)
    parser.add_argument(&amp;quot;--epoches&amp;quot;, dest=&amp;quot;epoches&amp;quot;, type=int, required=True)
    parser.add_argument(&amp;quot;--learning_rate&amp;quot;, dest=&amp;quot;learning_rate&amp;quot;,\
                        type=float, default=0.1)
    parser.add_argument(&amp;quot;--hidden&amp;quot;, dest=&amp;quot;hidden&amp;quot;, type=int, default=20)
    args = parser.parse_args()

    nn = NeuralNet(2, args.hidden, 1)

    data = np.array([[0, 0], [0 ,1], [1, 0], [1, 1]])
    target = np.array([0, 1, 1, 0])

    nn.train(data, target, args.epoches, args.learning_rate,\
             monitor_period=1000)

    for x in data:
        print &amp;quot;%s : predicted %s&amp;quot; % (x, nn.forward(x))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;#!/usr/bin/python
# coding: utf-8

# MNISTãç¨ãããã¥ã¼ã©ã«ãããã«ããææ¸ãæ°å­èªè­ã®ãã¢ã³ã¼ãã§ã
# å­¦ç¿æ¹æ³ããã©ã¡ã¼ã¿ã«ããã¾ãããã ããã 90 ~ 97% ãããã®ç²¾åº¦åºã¾ãã
# ä½¿ãæ¹ã¯ãã³ã¼ããèª­ããã
# python mnist_net.py -h
# ã¨ãã¦ãã ãã
# åèã¾ã§ã«ã
# python mnist_net.py --epoches 50000 --learning_rate 0.1 --hidden 100
# ã¨ããã¨ããã¹ãã»ããã«å¯¾ãã¦ã93.2%ã®æ­£è§£çã§ã
# åã®ç°å¢ã§ã¯ãå­¦ç¿ãèªè­åããã¦ï¼ã ãããï¼5åããããããã¾ããã
# 2014/05/10 Ryuichi Yamamoto

import numpy as np
from sklearn.externals import joblib
import cPickle
import gzip
import os

# ä½æãããã¥ã¼ã©ã«ãããã®ããã±ã¼ã¸
import net

def load_mnist_dataset(dataset):
    &amp;quot;&amp;quot;&amp;quot;
    MNISTã®ãã¼ã¿ã»ããããã¦ã³ã­ã¼ããã¾ã
    &amp;quot;&amp;quot;&amp;quot;
    # Download the MNIST dataset if it is not present
    data_dir, data_file = os.path.split(dataset)
    if (not os.path.isfile(dataset)) and data_file == &#39;mnist.pkl.gz&#39;:
        import urllib
        origin = &#39;http://www.iro.umontreal.ca/~lisa/deep/data/mnist/mnist.pkl.gz&#39;
        print &#39;Downloading data from %s&#39; % origin
        urllib.urlretrieve(origin, dataset)

    f = gzip.open(dataset, &#39;rb&#39;)
    train_set, valid_set, test_set = cPickle.load(f)
    f.close()

    return train_set, valid_set, test_set

def augument_labels(labels, order):
    &amp;quot;&amp;quot;&amp;quot;
    1æ¬¡åã®ã©ãã«ãã¼ã¿ããã©ãã«ã®ç¨®é¡æ°(order)æ¬¡åã«æ¡å¼µãã¾ã
    &amp;quot;&amp;quot;&amp;quot;
    new_labels = []
    for i in range(labels.shape[0]):
        v = np.zeros(order)
        v[labels[i]] = 1
        new_labels.append(v)

    return np.array(new_labels).reshape((labels.shape[0], order))

if __name__ == &amp;quot;__main__&amp;quot;:
    import argparse

    parser = argparse.ArgumentParser(description=&amp;quot;MNISTææ¸ãæ°å­èªè­ã®ãã¢&amp;quot;)
    parser.add_argument(&amp;quot;--epoches&amp;quot;, dest=&amp;quot;epoches&amp;quot;, type=int, required=True)
    parser.add_argument(&amp;quot;--learning_rate&amp;quot;, dest=&amp;quot;learning_rate&amp;quot;,\
                        type=float, default=0.1)
    parser.add_argument(&amp;quot;--hidden&amp;quot;, dest=&amp;quot;hidden&amp;quot;, type=int, default=100)
    args = parser.parse_args()

    train_set, valid_set, test_set = load_mnist_dataset(&amp;quot;mnist.pkl.gz&amp;quot;)
    n_labels = 10 # 0,1,2,3,4,5,6,7,9
    n_features = 28*28

    # ã¢ãã«ãæ°ããä½ã
    nn = net.NeuralNet(n_features, args.hidden, n_labels)

    # ã¢ãã«ãèª­ã¿è¾¼ã
    # nn = joblib.load(&amp;quot;./nn_mnist.pkl&amp;quot;)

    nn.train(train_set[0], augument_labels(train_set[1], n_labels),\
             args.epoches, args.learning_rate, monitor_period=2000)

    ## ãã¹ã
    test_data, labels = test_set
    results = np.arange(len(test_data), dtype=np.int)
    for n in range(len(test_data)):
        results[n] = nn.predict(test_data[n])
        # print &amp;quot;%d : predicted %s, expected %s&amp;quot; % (n, results[n], labels[n])
    print &amp;quot;recognition rate: &amp;quot;, (results == labels).mean()

    # ã¢ãã«ãä¿å­
    model_filename = &amp;quot;nn_mnist.pkl&amp;quot;
    joblib.dump(nn, model_filename, compress=9)
    print &amp;quot;The model parameters are dumped to &amp;quot; + model_filename
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/r9y9/python-neural-net-toy-codes&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/r9y9/python-neural-net-toy-codes&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;ä»¥ä¸ã®ãããªã³ãã³ããå©ãã¦ãæ­£è§£çã97%ãããã«ãªãã¾ã§å­¦ç¿ãã¦ããå¥åå±¤ããé ãå±¤ã¸ã®éã¿ãå¯è¦åãã¦ã¿ã&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# python mnist_net.py --epoches 50000 --learning_rate 0.1 --hidden 100 # epochesã¯é©å½ã«
&lt;/code&gt;&lt;/pre&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/images/nn_mnist_W1_100.png&#34; alt=&#34;Input to Hidden weight filters after trained on MNIST.&#34; class=&#34;image&#34;&gt;&lt;/div&gt;
&lt;p&gt;èå³æ·±ããã¨ã«ãRBMã¨éã£ã¦éã¿è¡åã®è§£éã¯ãã«ãããçæã¢ãã«ã®å°¤åº¦ãæå¤§åãããã¨ã¨ãèª¤å·®ãæå°åãããã¨ã¯ãããªã«ãéããã ãªãã¨ããããªã¿ãªææ³&lt;/p&gt;
&lt;p&gt;RBMã«ã¤ãã¦ã¯ãä»¥ä¸ã¸&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://r9y9.github.io/blog/2014/03/06/restricted-boltzmann-machines-mnist/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Restricted Boltzmann Machines with MNIST - LESS IS MORE&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;ããã&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Restricted Boltzmann Machines with MNIST</title>
      <link>https://r9y9.github.io/blog/2014/03/06/restricted-boltzmann-machines-mnist/</link>
      <pubDate>Thu, 06 Mar 2014 00:00:00 +0000</pubDate>
      <guid>https://r9y9.github.io/blog/2014/03/06/restricted-boltzmann-machines-mnist/</guid>
      <description>&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/images/RBM_mnist_Hidden_500_layers.png &#34;RBM training result on MNIST handwritten digit dataset. Each image represents a filter learned by RBM.&#34;&#34; class=&#34;image&#34;&gt;&lt;/div&gt;
&lt;p&gt;ãã£ã¼ãæãä½¿ã£ãç ç©¶ãåç¾ãã¦ã¿ããã¦ãæè¿æãã¥ã¼ã©ã«ãããã«æãåºãå§ãããã§ãæå§ãã«Restricted Boltzmann Machinesãå®è£ãã¦ã¿ãã®ã§ã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;MNISTãä½¿ã£ã¦å­¦ç¿ããçµæã®éã¿ï¼22*22=484åï¼ãè²¼ã£ã¨ãï¼âï¼&lt;/li&gt;
&lt;li&gt;å¾ãç¥è¦ãã¾ã¨ãã¨ã&lt;/li&gt;
&lt;li&gt;Goã®ã³ã¼ãè²¼ã£ã¨ã&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ã£ã¦ãªæãã§æ¸ãã¦ãã&lt;/p&gt;
&lt;p&gt;(æ¬å½ã¯RBMã«ã¤ãã¦èªåãªãã®è§£éãæ¸ããã¨æã£ãã®ã ãã©ãããã¯ã¾ãä»åº¦)&lt;/p&gt;
&lt;h2 id=&#34;å®é¨æ¡ä»¶&#34;&gt;å®é¨æ¡ä»¶&lt;/h2&gt;
&lt;p&gt;ãã¼ã¿ãã¼ã¹ã¯mnistãææ¸ãæ°å­èªè­ã§æåãªã¢ã¬ãå­¦ç¿ã®æ¡ä»¶ã¯ã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;é ãå±¤ã®ã¦ãããæ°: 500&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;mini-batch size: 20&lt;/li&gt;
&lt;li&gt;iterationã®åæ°: 15&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;å¯¾æ°å°¤åº¦ã®å¤å&#34;&gt;å¯¾æ°å°¤åº¦ã®å¤å&lt;/h2&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/images/RBM_mnist_Hidden_500_log_likelihood.png &#34;Pseudo log-likelihood on mnist databae.&#34;&#34; class=&#34;image&#34;&gt;&lt;/div&gt;
&lt;p&gt;ä»¥ä¸ã°ã©ãã«è¡¨ç¤ºãã¦ããçãã¼ã¿&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;0 -196.59046099622128
1 -70.31708616742365
2 -65.29499371647965
3 -62.37983267378022
4 -61.5359019358253
5 -60.917772257650164
6 -59.64207778426757
7 -59.42201674307857
8 -59.18497336138633
9 -58.277168243126305
10 -58.36279288392401
11 -58.57805165724595
12 -57.71043215987184
13 -58.17783142034138
14 -57.53629129936344
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;å°¤åº¦ä¸ããã¨å®å¿ãããå³å¯ã«å¯¾æ°å°¤åº¦ãè¨ç®ãããã¨ã¯é£ããã®ã§ã&lt;a href=&#34;http://deeplearning.net/tutorial/rbm.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Restricted Boltzmann Machines (RBM) | DeepLearning Tutorial&lt;/a&gt; ã«ããæ¬ä¼¼å°¤åº¦ãåèã«ãã&lt;/p&gt;
&lt;h2 id=&#34;å­¦ç¿æé&#34;&gt;å­¦ç¿æé&lt;/h2&gt;
&lt;p&gt;ãã¡ã®core2duoã®PCã§4æéå¼±ã ã£ãæ°ãããï¼ããè¦ã&lt;/p&gt;
&lt;p&gt;é ãå±¤ã®ã¦ãããæ°100ã ã¨ã40åã»ã©ã ã£ã&lt;/p&gt;
&lt;h2 id=&#34;ç¥è¦&#34;&gt;ç¥è¦&lt;/h2&gt;
&lt;p&gt;ä»ã®æãè©¦è¡é¯èª¤ãã¦èªåãå¾ãç¥è¦ã¯ã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;sample by sampleã®SGDããmini-batch SGDã®æ¹ãå®å®ãã¦å°¤åº¦ä¸ãã&lt;/li&gt;
&lt;li&gt;mini-batch sizeãå¤§ããããããã¨å­¦ç¿ãé²ã¾ãªãã20ããããã¡ããã©è¯ãã£ã&lt;/li&gt;
&lt;li&gt;k-CD ã®kãå¤§ãããã¦ããã»ã©å­¦ç¿çµæå¤ãããªãï¼è¨ç®ã³ã¹ãã¯ãã£ããå¢ããã©ï¼&lt;/li&gt;
&lt;li&gt;persistent CDãä½¿ã£ã¦ããã¾ããããªããªãï¼è¨ç®ã³ã¹ãã¯ãã£ããå¢ããã©ï¼&lt;/li&gt;
&lt;li&gt;ãã£ã±1-CDã§ååã ã£ã&lt;/li&gt;
&lt;li&gt;ãã¼ã¿ã®æ­£è¦åæ¹æ³ã«ãã£ã¦çµæ§çµæãå¤ããããã¤ãºãè¶³ããã©ãããã¨ã&lt;/li&gt;
&lt;li&gt;å­¦ç¿çè¶éè¦ããããããä»åã®å ´åã¯0.1ããããã¡ããã©è¯ãã£ã&lt;/li&gt;
&lt;li&gt;é ãå±¤ã®ã¦ãããæ°ãå¤§ããã»ã©å­¦ç¿ãä¸æãè¡ãã°ã¨å°¤åº¦ã¯ä¸ãã(?)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ã¾ãã ããã &lt;a href=&#34;http://www.cs.toronto.edu/~hinton/absps/guideTR.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;A Practical Guide to Training Restricted Boltzmann Machines (PDF)&lt;/a&gt; ã«æ¸ãã¦ãããã©ãå®éã«èã§æãã¦çè§£ãããpersistent CDã¯ããã¡ãã£ã¨ææåºã¦æ¬²ããããã¼ã¿å¤ããã¨ææåºããããªï¼&lt;/p&gt;
&lt;h2 id=&#34;ã³ã¼ã&#34;&gt;ã³ã¼ã&lt;/h2&gt;
&lt;p&gt;ã³ã¢ã®é¨åã ããä¸å¿&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;package rbm

import (
	&amp;quot;encoding/json&amp;quot;
	&amp;quot;errors&amp;quot;
	&amp;quot;fmt&amp;quot;
	&amp;quot;github.com/r9y9/nn&amp;quot; // sigmoid, matrix
	&amp;quot;math&amp;quot;
	&amp;quot;math/rand&amp;quot;
	&amp;quot;os&amp;quot;
	&amp;quot;time&amp;quot;
)

// References:
// [1] G. Hinton, &amp;quot;A Practical Guide to Training Restricted Boltzmann Machines&amp;quot;,
// UTML TR 2010-003.
// url: http://www.cs.toronto.edu/~hinton/absps/guideTR.pdf
//
// [2] A. Fischer and C. Igel. &amp;quot;An introduction to restricted Boltzmann machines&amp;quot;,
// Proc. of the 17th Iberoamerican Congress on Pattern Recognition (CIARP),
// Volume 7441 of LNCS, pages 14â36. Springer, 2012
// url: http://image.diku.dk/igel/paper/AItRBM-proof.pdf
//
// [3] Restricted Boltzmann Machines (RBM),  DeepLearning tutorial
// url: http://deeplearning.net/tutorial/rbm.html

// Notes about implementation:
// Notation used in this code basically follows [2].
// e.g. W for weight, B for bias of visible layer, C for bias of hidden layer.

// Graphical representation of Restricted Boltzmann Machines (RBM).
//
//     â â .... â  h(hidden layer), c(bias)
//     /\ /\ /    /\
//    â â â ... â v(visible layer), b(bias)
type RBM struct {
	W               [][]float64 // Weight
	B               []float64   // Bias of visible layer
	C               []float64   // Bias of hidden layer
	NumHiddenUnits  int
	NumVisibleUnits int
	Option          TrainingOption
}

type TrainingOption struct {
	LearningRate        float64
	OrderOfGibbsSamping int // It is known that 1 is enough for many cases.
	Epoches             int
	MiniBatchSize       int
	L2Regularization    bool
	RegularizationRate  float64
}

// NewRBM creates new RBM instance. It requires input data and number of
// hidden units to initialize RBM.
func NewRBM(numVisibleUnits, numHiddenUnits int) *RBM {
	rbm := new(RBM)
	rand.Seed(time.Now().UnixNano())

	rbm.W = nn.MakeMatrix(numHiddenUnits, numVisibleUnits)
	rbm.B = make([]float64, numVisibleUnits)
	rbm.C = make([]float64, numHiddenUnits)
	rbm.NumVisibleUnits = numVisibleUnits
	rbm.NumHiddenUnits = numHiddenUnits

	rbm.InitRBM()
	return rbm
}

// NewRBMWithParameters returns RBM instance given RBM parameters.
// This func will be used in Deep Belief Networks.
func NewRBMWithParameters(W [][]float64, B, C []float64) (*RBM, error) {
	rbm := new(RBM)

	rbm.NumVisibleUnits = len(B)
	rbm.NumHiddenUnits = len(C)

	if len(W) != rbm.NumHiddenUnits || len(W[0]) != rbm.NumVisibleUnits {
		return nil, errors.New(&amp;quot;Shape of weight matrix is wrong.&amp;quot;)
	}

	rand.Seed(time.Now().UnixNano())
	rbm.W = W
	rbm.B = B
	rbm.C = C

	return rbm, nil
}

// LoadRBM loads RBM from a dump file and return its instatnce.
func LoadRBM(filename string) (*RBM, error) {
	file, err := os.Open(filename)
	if err != nil {
		return nil, err
	}
	defer file.Close()

	decoder := json.NewDecoder(file)
	rbm := &amp;amp;RBM{}
	err = decoder.Decode(rbm)

	if err != nil {
		return nil, err
	}

	return rbm, nil
}

// Dump writes RBM parameters to file in json format.
func (rbm *RBM) Dump(filename string) error {
	file, err := os.Create(filename)
	if err != nil {
		return err
	}
	defer file.Close()

	encoder := json.NewEncoder(file)
	err = encoder.Encode(rbm)
	if err != nil {
		return err
	}

	return nil
}

// Heuristic initialization of visible bias.
func (rbm *RBM) InitVisibleBiasUsingTrainingData(data [][]float64) {
	// Init B (bias of visible layer)
	activeRateInVisibleLayer := rbm.getActiveRateInVisibleLayer(data)
	for j := 0; j &amp;lt; rbm.NumVisibleUnits; j++ {
		rbm.B[j] = math.Log(activeRateInVisibleLayer[j] / (1.0 - activeRateInVisibleLayer[j]))
	}
}

func (rbm *RBM) getActiveRateInVisibleLayer(data [][]float64) []float64 {
	rate := make([]float64, rbm.NumVisibleUnits)
	for _, sample := range data {
		for j := 0; j &amp;lt; rbm.NumVisibleUnits; j++ {
			rate[j] += sample[j]
		}
	}
	for j := range rate {
		rate[j] /= float64(len(data))
	}
	return rate
}

// InitRBM performes a heuristic parameter initialization.
func (rbm *RBM) InitRBM() {
	// Init W
	for i := 0; i &amp;lt; rbm.NumHiddenUnits; i++ {
		for j := 0; j &amp;lt; rbm.NumVisibleUnits; j++ {
			rbm.W[i][j] = 0.01 * rand.NormFloat64()
		}
	}

	for j := 0; j &amp;lt; rbm.NumVisibleUnits; j++ {
		rbm.B[j] = 0.0
	}

	// Init C (bias of hidden layer)
	for i := 0; i &amp;lt; rbm.NumHiddenUnits; i++ {
		rbm.C[i] = 0.0
	}
}

// P_H_Given_V returns the conditinal probability of a hidden unit given a set of visible units.
func (rbm *RBM) P_H_Given_V(hiddenIndex int, v []float64) float64 {
	sum := 0.0
	for j := 0; j &amp;lt; rbm.NumVisibleUnits; j++ {
		sum += rbm.W[hiddenIndex][j] * v[j]
	}
	return nn.Sigmoid(sum + rbm.C[hiddenIndex])
}

// P_V_Given_H returns the conditinal probability of a visible unit given a set of hidden units.
func (rbm *RBM) P_V_Given_H(visibleIndex int, h []float64) float64 {
	sum := 0.0
	for i := 0; i &amp;lt; rbm.NumHiddenUnits; i++ {
		sum += rbm.W[i][visibleIndex] * h[i]
	}
	return nn.Sigmoid(sum + rbm.B[visibleIndex])
}

// GibbsSampling performs k-Gibbs sampling algorithm,
// where k is the number of iterations in gibbs sampling.
func (rbm *RBM) GibbsSampling(v []float64, k int) []float64 {
	// Initial value is set to input
	vUsedInSamping := make([]float64, len(v))
	copy(vUsedInSamping, v)

	for t := 0; t &amp;lt; k; t++ {
		sampledH := make([]float64, rbm.NumHiddenUnits)
		for i := 0; i &amp;lt; rbm.NumHiddenUnits; i++ {
			p := rbm.P_H_Given_V(i, vUsedInSamping)
			if p &amp;gt; rand.Float64() {
				sampledH[i] = 1.0
			} else {
				sampledH[i] = 0.0
			}
		}
		for j := 0; j &amp;lt; rbm.NumVisibleUnits; j++ {
			p := rbm.P_V_Given_H(j, sampledH)
			if p &amp;gt; rand.Float64() {
				vUsedInSamping[j] = 1.0
			} else {
				vUsedInSamping[j] = 0.0
			}
		}
	}

	return vUsedInSamping
}

func flip(x []float64, bit int) []float64 {
	y := make([]float64, len(x))
	copy(y, x)
	y[bit] = 1.0 - x[bit]
	return y
}

// FreeEnergy returns F(v), the free energy of RBM given a visible vector v.
// refs: eq. (25) in [1].
func (rbm *RBM) FreeEnergy(v []float64) float64 {
	energy := 0.0

	for j := 0; j &amp;lt; rbm.NumVisibleUnits; j++ {
		energy -= rbm.B[j] * v[j]
	}

	for i := 0; i &amp;lt; rbm.NumHiddenUnits; i++ {
		sum := rbm.C[i]
		for j := 0; j &amp;lt; rbm.NumVisibleUnits; j++ {
			sum += rbm.W[i][j] * v[j]
		}
		energy -= math.Log(1 + math.Exp(sum))
	}

	return energy
}

// PseudoLogLikelihood returns pseudo log-likelihood for a given input data.
func (rbm *RBM) PseudoLogLikelihood(v []float64) float64 {
	bitIndex := rand.Int() % len(v)
	fe := rbm.FreeEnergy(v)
	feFlip := rbm.FreeEnergy(flip(v, bitIndex))
	cost := float64(rbm.NumVisibleUnits) * math.Log(nn.Sigmoid(feFlip-fe))
	return cost
}

// PseudoLogLikelihood returns pseudo log-likelihood for a given dataset (or mini-batch).
func (rbm *RBM) PseudoLogLikelihoodForAllData(data [][]float64) float64 {
	sum := 0.0
	for i := range data {
		sum += rbm.PseudoLogLikelihood(data[i])
	}
	cost := sum / float64(len(data))
	return cost
}

// ComputeGradient returns gradients of RBM parameters for a given (mini-batch) dataset.
func (rbm *RBM) ComputeGradient(data [][]float64) ([][]float64, []float64, []float64) {
	gradW := nn.MakeMatrix(rbm.NumHiddenUnits, rbm.NumVisibleUnits)
	gradB := make([]float64, rbm.NumVisibleUnits)
	gradC := make([]float64, rbm.NumHiddenUnits)

	for _, v := range data {
		// Gibbs Sampling
		gibbsStart := v
		vAfterSamping := rbm.GibbsSampling(gibbsStart, rbm.Option.OrderOfGibbsSamping)

		// pre-computation that is used in gradient computation
		p_h_given_v1 := make([]float64, rbm.NumHiddenUnits)
		p_h_given_v2 := make([]float64, rbm.NumHiddenUnits)
		for i := 0; i &amp;lt; rbm.NumHiddenUnits; i++ {
			p_h_given_v1[i] = rbm.P_H_Given_V(i, v)
			p_h_given_v2[i] = rbm.P_H_Given_V(i, vAfterSamping)
		}

		// Gompute gradient of W
		for i := 0; i &amp;lt; rbm.NumHiddenUnits; i++ {
			for j := 0; j &amp;lt; rbm.NumVisibleUnits; j++ {
				gradW[i][j] += p_h_given_v1[i]*v[j] - p_h_given_v2[i]*vAfterSamping[j]
			}
		}

		// Gompute gradient of B
		for j := 0; j &amp;lt; rbm.NumVisibleUnits; j++ {
			gradB[j] += v[j] - vAfterSamping[j]
		}

		// Gompute gradient of C
		for i := 0; i &amp;lt; rbm.NumHiddenUnits; i++ {
			gradC[i] += p_h_given_v1[i] - p_h_given_v2[i]
		}
	}

	return gradW, gradB, gradC
}

func (rbm *RBM) ParseTrainingOption(option TrainingOption) error {
	rbm.Option = option

	if rbm.Option.MiniBatchSize &amp;lt;= 0 {
		return errors.New(&amp;quot;Number of mini-batchs must be larger than zero.&amp;quot;)
	}
	if rbm.Option.Epoches &amp;lt;= 0 {
		return errors.New(&amp;quot;Epoches must be larger than zero.&amp;quot;)
	}
	if rbm.Option.OrderOfGibbsSamping &amp;lt;= 0 {
		return errors.New(&amp;quot;Order of Gibbs sampling must be larger than zero.&amp;quot;)
	}
	if rbm.Option.LearningRate == 0 {
		return errors.New(&amp;quot;Learning rate must be specified to train RBMs.&amp;quot;)
	}

	return nil
}

// Train performs Contrastive divergense learning algorithm to train RBM.
// The alrogithm is basedd on (mini-batch) Stochastic Gradient Ascent.
func (rbm *RBM) Train(data [][]float64, option TrainingOption) error {
	err := rbm.ParseTrainingOption(option)
	if err != nil {
		return err
	}

	numMiniBatches := len(data) / rbm.Option.MiniBatchSize

	for epoch := 0; epoch &amp;lt; option.Epoches; epoch++ {
		// Monitoring
		fmt.Println(epoch, rbm.PseudoLogLikelihoodForAllData(data))

		for m := 0; m &amp;lt; numMiniBatches; m++ {
			// Compute Gradient
			batch := data[m*rbm.Option.MiniBatchSize : (m+1)*rbm.Option.MiniBatchSize]
			gradW, gradB, gradC := rbm.ComputeGradient(batch)

			// Update W
			for i := 0; i &amp;lt; rbm.NumHiddenUnits; i++ {
				for j := 0; j &amp;lt; rbm.NumVisibleUnits; j++ {
					rbm.W[i][j] += rbm.Option.LearningRate * gradW[i][j] / float64(rbm.Option.MiniBatchSize)
					if rbm.Option.L2Regularization {
						rbm.W[i][j] *= (1.0 - rbm.Option.RegularizationRate)
					}
				}
			}

			// Update B
			for j := 0; j &amp;lt; rbm.NumVisibleUnits; j++ {
				rbm.B[j] += rbm.Option.LearningRate * gradB[j] / float64(rbm.Option.MiniBatchSize)
			}

			// Update C
			for i := 0; i &amp;lt; rbm.NumHiddenUnits; i++ {
				rbm.C[i] += rbm.Option.LearningRate * gradC[i] / float64(rbm.Option.MiniBatchSize)
			}
		}
	}

	return nil
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;ä½¿ãæ¹ã¨ãã¯å¯ãã¦ï¼ã©ããèª°ãä½¿ããªãã¯ã&lt;/p&gt;
&lt;p&gt;ä»ã¯ãéå¸¸ã®RBMã®visible layerãé£ç¶å¤ã«æ¡å¼µãã Gaussian Bernoulli RBMãå­¦ç¿ãããã¨ãã¦ããã ãã©ããããã ãºã¤ãå®è£ãã¹ãããããã ãã©ãå±æè§£ã«è½ã¡ã¾ãã£ã¦ãæ°ãããã&lt;/p&gt;
&lt;p&gt;Gaussian Bernoulli RBMãDeep Belief Networks, Deep Neural Networksã«ã¤ãã¦ã¯ã¾ãä»åº¦&lt;/p&gt;
&lt;p&gt;2014/05/11
è¦æããã£ãã®ã§ãããããã³ã¼ãããã¾ãã
&lt;a href=&#34;https://github.com/r9y9/nnet&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/r9y9/nnet&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;åèè³æ&#34;&gt;åèè³æ&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://image.diku.dk/igel/paper/AItRBM-proof.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;An Introduction to Restricted Boltzmann Machines (PDF)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.cs.toronto.edu/~hinton/absps/guideTR.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;A Practical Guide to Training Restricted Boltzmann Machines (PDF)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://mglab.blogspot.jp/2012/08/restricted-boltzmann-machine.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Restricted Boltzmann Machineã®å­¦ç¿ææ³ã«ã¤ãã¦ã®ç°¡åãªã¾ã¨ã | æ åå¥®éè¨&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://d.hatena.ne.jp/saket/20121212&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ãããµã Restricted Boltzmann Machine | Risky Dune&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://deeplearning.net/tutorial/rbm.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Restricted Boltzmann Machines (RBM) | DeepLearning Tutorial&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://imonad.com/rbm/restricted-boltzmann-machine/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Restricted Boltzmann Machine - Short Tutorial | iMonad&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://scikit-learn.org/stable/auto_examples/plot_rbm_logistic_classification.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Restricted Boltzmann Machine features for digit classification | scikit-learn&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>
