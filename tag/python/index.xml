<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Python | LESS IS MORE</title>
    <link>https://r9y9.github.io/tag/python/</link>
      <atom:link href="https://r9y9.github.io/tag/python/index.xml" rel="self" type="application/rss+xml" />
    <description>Python</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>Copyright Â© Ryuichi YAMAMOTO All rights reserved.</copyright><lastBuildDate>Tue, 18 Oct 2022 22:17:44 +0900</lastBuildDate>
    <image>
      <url>https://r9y9.github.io/media/icon_hu71488a41e9448d472219f1cc71ecc0ad_259818_512x512_fill_lanczos_center_3.png</url>
      <title>Python</title>
      <link>https://r9y9.github.io/tag/python/</link>
    </image>
    
    <item>
      <title>NNSVS: A Neural Network-Based Singing Voice Synthesis Toolkit</title>
      <link>https://r9y9.github.io/projects/nnsvs/</link>
      <pubDate>Tue, 18 Oct 2022 22:17:44 +0900</pubDate>
      <guid>https://r9y9.github.io/projects/nnsvs/</guid>
      <description>&lt;p&gt;Preprint: &lt;a href=&#34;https://arxiv.org/abs/2210.15987&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;arXiv:2210.15987&lt;/a&gt; (Submitted to &lt;a href=&#34;https://2023.ieeeicassp.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ICASSP 2023&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#updates&#34;&gt;Updates&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#authors&#34;&gt;Authors&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#abstract&#34;&gt;Abstract&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#systems&#34;&gt;Systems&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#samples&#34;&gt;Samples&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#svs&#34;&gt;SVS&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#as&#34;&gt;A/S&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#mixed-demo&#34;&gt;Mixed demo&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#sample-1&#34;&gt;Sample 1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#sample-2&#34;&gt;Sample 2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#sample-3&#34;&gt;Sample 3&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#bonus-samples&#34;&gt;Bonus samples&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#japanese&#34;&gt;Japanese&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#mandarin&#34;&gt;Mandarin&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#error-cases&#34;&gt;Error cases&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#unstable-pitch-of-diffsinger&#34;&gt;Unstable pitch of DiffSinger&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#acknowledgments&#34;&gt;Acknowledgments&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#appendix&#34;&gt;Appendix&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#note-pitch-distribution&#34;&gt;Note pitch distribution&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#references&#34;&gt;References&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;updates&#34;&gt;Updates&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;2023/02/27: Added error cases to address reviewer&amp;rsquo;s comments. See &lt;a href=&#34;#error-cases&#34;&gt;Error cases&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;2022/11/27: Added samples of diffusion-based acoustic models. See &lt;a href=&#34;#bonus-samples&#34;&gt;Bonus samples&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;2022/10/18: Created the demo page.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;authors&#34;&gt;Authors&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Ryuichi Yamamoto (LINE Corp., Nagoya University)&lt;/li&gt;
&lt;li&gt;Reo Yoneyama (Nagoya University)&lt;/li&gt;
&lt;li&gt;Tomoki Toda (Nagoya University)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;This paper describes the design of NNSVS, an open-source software for neural network-based singing voice synthesis research. NNSVS is inspired by Sinsy, an open-source pioneer in singing voice synthesis research, and provides many additional features such as multi-stream models, autoregressive fundamental frequency models, and neural vocoders. Furthermore, NNSVS provides extensive documentation and numerous scripts to build complete singing voice synthesis systems. Experimental results demonstrate that our best system significantly outperforms our reproduction of Sinsy and other baseline systems. The toolkit is available at &lt;a href=&#34;https://github.com/nnsvs/nnsvs&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/nnsvs/nnsvs&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;systems&#34;&gt;Systems&lt;/h2&gt;
&lt;p&gt;The following table summarizes the systems used in our experiments. All the models were trained on Namine Ritsu&amp;rsquo;s database [1].&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;System&lt;/th&gt;
&lt;th&gt;Acoustic Features&lt;/th&gt;
&lt;th&gt;Multi-stream Architecture&lt;/th&gt;
&lt;th&gt;Autoregressive streams&lt;/th&gt;
&lt;th&gt;Vocoder&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Sinsy [2]&lt;/td&gt;
&lt;td&gt;MGC, LF0, VUV, BAP&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;hn-uSFGAN  [5]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Sinsy (w/ pitch correction)&lt;/td&gt;
&lt;td&gt;MGC, LF0, VUV, BAP&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;hn-uSFGAN&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Sinsy (w/ vibrato modeling)&lt;/td&gt;
&lt;td&gt;MGC, LF0, VUV, BAP&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;hn-uSFGAN&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Muskits RNN [3]&lt;/td&gt;
&lt;td&gt;MEL&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;HiFi-GAN [6]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;DiffSinger [4]&lt;/td&gt;
&lt;td&gt;MEL, LF0, VUV&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;hn-HiFi-GAN&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;NNSVS-Mel v1&lt;/td&gt;
&lt;td&gt;MEL, LF0, VUV&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;hn-uSFGAN&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;NNSVS-Mel v2&lt;/td&gt;
&lt;td&gt;MEL, LF0, VUV&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;td&gt;LF0&lt;/td&gt;
&lt;td&gt;hn-uSFGAN&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;NNSVS-Mel v3&lt;/td&gt;
&lt;td&gt;MEL, LF0, VUV&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;td&gt;MEL, LF0&lt;/td&gt;
&lt;td&gt;hn-uSFGAN&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;NNSVS-WORLD v0 [1]&lt;/td&gt;
&lt;td&gt;MGC, LF0, VUV, BAP&lt;/td&gt;
&lt;td&gt;No&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;WORLD&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;NNSVS-WORLD v1&lt;/td&gt;
&lt;td&gt;MGC, LF0, VUV, BAP&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;hn-uSFGAN&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;NNSVS-WORLD v2&lt;/td&gt;
&lt;td&gt;MGC, LF0, VUV, BAP&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;td&gt;LF0&lt;/td&gt;
&lt;td&gt;hn-uSFGAN&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;NNSVS-WORLD v3&lt;/td&gt;
&lt;td&gt;MGC, LF0, VUV, BAP&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;td&gt;MGC, LF0&lt;/td&gt;
&lt;td&gt;hn-uSFGAN&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;NNSVS-WORLD v4&lt;/td&gt;
&lt;td&gt;MGC, LF0, VUV, BAP&lt;/td&gt;
&lt;td&gt;Yes&lt;/td&gt;
&lt;td&gt;MGC, LF0, BAP&lt;/td&gt;
&lt;td&gt;hn-uSFGAN&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;hn-HiFI-GAN (A/S)&lt;/td&gt;
&lt;td&gt;MEL, LF0, VUV&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;hn-HiFi-GAN&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;hn-uSFGAN-Mel (A/S)&lt;/td&gt;
&lt;td&gt;MEL, LF0, VUV&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;hn-uSFGAN&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;hn-uSFGAN-WORLD (A/S)&lt;/td&gt;
&lt;td&gt;MGC, LF0, VUV, BAP&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;hn-uSFGAN&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Notes on baselines&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Muskits and DiffSinger baseline systems were trained with thier offical code (&lt;a href=&#34;https://github.com/SJTMusicTeam/Muskits/tree/1f1855d914d2077f33ad9675866f474005cd8034/egs/namine_ritsu_utagoe_db/svs1&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Muskits&lt;/a&gt; and &lt;a href=&#34;https://github.com/MoonInTheRiver/DiffSinger&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;DiffSinger&lt;/a&gt;).&lt;/li&gt;
&lt;li&gt;hn-HiFi-GAN is the vocoder used by DiffSinger. The detail of its implementation can be found &lt;a href=&#34;https://github.com/nnsvs/ParallelWaveGAN/blob/5a1e0e0c6972cfa0efcbd17d4b42c453e611234d/parallel_wavegan/models/hnhifigan.py#L173&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Sinsy systems are based on NNSVS&amp;rsquo;s implementation.&lt;/li&gt;
&lt;li&gt;NNSVS-WORLD v0 uses the model trained with the earlier version of NNSVS (as of Nov. 2021) [1]. See &lt;a href=&#34;https://www.youtube.com/watch?v=pKeo9IE_L1I&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt; for details.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Notes on NNSVS systems&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The code for reproducing experiments are available &lt;a href=&#34;https://github.com/nnsvs/nnsvs/tree/master/recipes/namine_ritsu_utagoe_db/icassp2023-24k-world&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;samples&#34;&gt;Samples&lt;/h2&gt;
&lt;p&gt;The following samples are vocal only. Mixed demo can be found &lt;a href=&#34;#mixed-demo&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&#34;svs&#34;&gt;SVS&lt;/h3&gt;
&lt;p&gt;Samples generated from musical score.&lt;/p&gt;
&lt;p&gt;Sample 1: 1st color&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Recording&lt;/th&gt;&lt;th&gt;Sinsy&lt;/th&gt;&lt;th&gt;Sinsy (with pitch correction)&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test01]-Recording.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test01]-Sinsy.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test01]-Sinsy (with pitch correction).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Sinsy (with vibrato modeling)&lt;/th&gt;&lt;th&gt;Muskits RNN&lt;/th&gt;&lt;th&gt;DiffSinger&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test01]-Sinsy (with vibrato modeling).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test01]-Muskits RNN.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test01]-DiffSinger.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;NNSVS-Mel v1&lt;/th&gt;&lt;th&gt;NNSVS-Mel v2&lt;/th&gt;&lt;th&gt;NNSVS-Mel v3&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test01]-NNSVS-Mel v1.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test01]-NNSVS-Mel v2.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test01]-NNSVS-Mel v3.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;NNSVS-WORLD v0&lt;/th&gt;&lt;th&gt;NNSVS-WORLD v1&lt;/th&gt;&lt;th&gt;NNSVS-WORLD v2&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test01]-NNSVS-WORLD v0.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test01]-NNSVS-WORLD v1.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test01]-NNSVS-WORLD v2.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;NNSVS-WORLD v3&lt;/th&gt;&lt;th&gt;NNSVS-WORLD v4&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test01]-NNSVS-WORLD v3.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test01]-NNSVS-WORLD v4.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Sample 2: ARROW&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Recording&lt;/th&gt;&lt;th&gt;Sinsy&lt;/th&gt;&lt;th&gt;Sinsy (with pitch correction)&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test02]-Recording.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test02]-Sinsy (with vibrato modeling).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test02]-Sinsy (with pitch correction).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Sinsy (with vibrato modeling)&lt;/th&gt;&lt;th&gt;Muskits RNN&lt;/th&gt;&lt;th&gt;DiffSinger&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test02]-Sinsy (with vibrato modeling).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test02]-Muskits RNN.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test02]-DiffSinger.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;NNSVS-Mel v1&lt;/th&gt;&lt;th&gt;NNSVS-Mel v2&lt;/th&gt;&lt;th&gt;NNSVS-Mel v3&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test02]-NNSVS-Mel v1.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test02]-NNSVS-Mel v2.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test02]-NNSVS-Mel v3.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;NNSVS-WORLD v0&lt;/th&gt;&lt;th&gt;NNSVS-WORLD v1&lt;/th&gt;&lt;th&gt;NNSVS-WORLD v2&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test02]-NNSVS-WORLD v0.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test02]-NNSVS-WORLD v1.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test02]-NNSVS-WORLD v2.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;NNSVS-WORLD v3&lt;/th&gt;&lt;th&gt;NNSVS-WORLD v4&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test02]-NNSVS-WORLD v3.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test02]-NNSVS-WORLD v4.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Sample 3: BC&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Recording&lt;/th&gt;&lt;th&gt;Sinsy&lt;/th&gt;&lt;th&gt;Sinsy (with pitch correction)&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test03]-Recording.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test03]-Sinsy.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test03]-Sinsy (with pitch correction).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Sinsy (with vibrato modeling)&lt;/th&gt;&lt;th&gt;Muskits RNN&lt;/th&gt;&lt;th&gt;DiffSinger&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test03]-Sinsy (with vibrato modeling).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test03]-Muskits RNN.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test03]-DiffSinger.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;NNSVS-Mel v1&lt;/th&gt;&lt;th&gt;NNSVS-Mel v2&lt;/th&gt;&lt;th&gt;NNSVS-Mel v3&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test03]-NNSVS-Mel v1.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test03]-NNSVS-Mel v2.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test03]-NNSVS-Mel v3.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;NNSVS-WORLD v0&lt;/th&gt;&lt;th&gt;NNSVS-WORLD v1&lt;/th&gt;&lt;th&gt;NNSVS-WORLD v2&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test03]-NNSVS-WORLD v0.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test03]-NNSVS-WORLD v1.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test03]-NNSVS-WORLD v2.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;NNSVS-WORLD v3&lt;/th&gt;&lt;th&gt;NNSVS-WORLD v4&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test03]-NNSVS-WORLD v3.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test03]-NNSVS-WORLD v4.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Sample 4: Close to you&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Recording&lt;/th&gt;&lt;th&gt;Sinsy&lt;/th&gt;&lt;th&gt;Sinsy (with pitch correction)&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test04]-Recording.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test04]-Sinsy.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test04]-Sinsy (with pitch correction).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Sinsy (with vibrato modeling)&lt;/th&gt;&lt;th&gt;Muskits RNN&lt;/th&gt;&lt;th&gt;DiffSinger&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test04]-Sinsy (with vibrato modeling).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test04]-Muskits RNN.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test04]-DiffSinger.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;NNSVS-Mel v1&lt;/th&gt;&lt;th&gt;NNSVS-Mel v2&lt;/th&gt;&lt;th&gt;NNSVS-Mel v3&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test04]-NNSVS-Mel v1.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test04]-NNSVS-Mel v2.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test04]-NNSVS-Mel v3.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;NNSVS-WORLD v0&lt;/th&gt;&lt;th&gt;NNSVS-WORLD v1&lt;/th&gt;&lt;th&gt;NNSVS-WORLD v2&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test04]-NNSVS-WORLD v0.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test04]-NNSVS-WORLD v1.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test04]-NNSVS-WORLD v2.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;NNSVS-WORLD v3&lt;/th&gt;&lt;th&gt;NNSVS-WORLD v4&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test04]-NNSVS-WORLD v3.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test04]-NNSVS-WORLD v4.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Sample 5: ERROR&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Recording&lt;/th&gt;&lt;th&gt;Sinsy&lt;/th&gt;&lt;th&gt;Sinsy (with pitch correction)&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test05]-Recording.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test05]-Sinsy.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test05]-Sinsy (with pitch correction).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Sinsy (with vibrato modeling)&lt;/th&gt;&lt;th&gt;Muskits RNN&lt;/th&gt;&lt;th&gt;DiffSinger&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test05]-Sinsy (with vibrato modeling).wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test05]-Muskits RNN.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test05]-DiffSinger.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;NNSVS-Mel v1&lt;/th&gt;&lt;th&gt;NNSVS-Mel v2&lt;/th&gt;&lt;th&gt;NNSVS-Mel v3&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test05]-NNSVS-Mel v1.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test05]-NNSVS-Mel v2.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test05]-NNSVS-Mel v3.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;NNSVS-WORLD v0&lt;/th&gt;&lt;th&gt;NNSVS-WORLD v1&lt;/th&gt;&lt;th&gt;NNSVS-WORLD v2&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test05]-NNSVS-WORLD v0.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test05]-NNSVS-WORLD v1.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test05]-NNSVS-WORLD v2.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;NNSVS-WORLD v3&lt;/th&gt;&lt;th&gt;NNSVS-WORLD v4&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test05]-NNSVS-WORLD v3.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test05]-NNSVS-WORLD v4.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;h3 id=&#34;as&#34;&gt;A/S&lt;/h3&gt;
&lt;p&gt;Samples generated from extracted features (i.e., analysis-by-synthesis).&lt;/p&gt;
&lt;p&gt;Sample 1: 1st color&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Recording&lt;/th&gt;&lt;th&gt;hn-HiFi-GAN&lt;/th&gt;&lt;th&gt;hn-USFGAN-Mel&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/AnaSyn/[Test01]-Recording.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/AnaSyn/[Test01]-hn-HiFi-GAN.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/AnaSyn/[Test01]-hn-USFGAN-Mel.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;hn-USFGAN-WORLD&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/AnaSyn/[Test01]-hn-USFGAN-WORLD.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Sample 2: ARROW&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Recording&lt;/th&gt;&lt;th&gt;hn-HiFi-GAN&lt;/th&gt;&lt;th&gt;hn-USFGAN-Mel&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/AnaSyn/[Test02]-Recording.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/AnaSyn/[Test02]-hn-HiFi-GAN.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/AnaSyn/[Test02]-hn-USFGAN-Mel.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;hn-USFGAN-WORLD&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/AnaSyn/[Test02]-hn-USFGAN-WORLD.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Sample 3: BC&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Recording&lt;/th&gt;&lt;th&gt;hn-HiFi-GAN&lt;/th&gt;&lt;th&gt;hn-USFGAN-Mel&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/AnaSyn/[Test03]-Recording.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/AnaSyn/[Test03]-hn-HiFi-GAN.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/AnaSyn/[Test03]-hn-USFGAN-Mel.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;hn-USFGAN-WORLD&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/AnaSyn/[Test03]-hn-USFGAN-WORLD.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Sample 4: Close to you&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Recording&lt;/th&gt;&lt;th&gt;hn-HiFi-GAN&lt;/th&gt;&lt;th&gt;hn-USFGAN-Mel&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/AnaSyn/[Test04]-Recording.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/AnaSyn/[Test04]-hn-HiFi-GAN.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/AnaSyn/[Test04]-hn-USFGAN-Mel.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;hn-USFGAN-WORLD&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/AnaSyn/[Test04]-hn-USFGAN-WORLD.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Sample 5: ERROR&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Recording&lt;/th&gt;&lt;th&gt;hn-HiFi-GAN&lt;/th&gt;&lt;th&gt;hn-USFGAN-Mel&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/AnaSyn/[Test05]-Recording.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/AnaSyn/[Test05]-hn-HiFi-GAN.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/AnaSyn/[Test05]-hn-USFGAN-Mel.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;hn-USFGAN-WORLD&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/AnaSyn/[Test05]-hn-USFGAN-WORLD.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;h2 id=&#34;mixed-demo&#34;&gt;Mixed demo&lt;/h2&gt;
&lt;p&gt;System: NNSVS-WORLD v4&lt;/p&gt;
&lt;h3 id=&#34;sample-1&#34;&gt;Sample 1&lt;/h3&gt;
&lt;p&gt;ERROR (from test data)&lt;/p&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/u2210L3JXPo&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;h3 id=&#34;sample-2&#34;&gt;Sample 2&lt;/h3&gt;
&lt;p&gt;ARROW (from test data)&lt;/p&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/OqwVNUjzgAE&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;h3 id=&#34;sample-3&#34;&gt;Sample 3&lt;/h3&gt;
&lt;p&gt;WAVE (from training data)&lt;/p&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/_5T0HPfeGjs&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;h2 id=&#34;bonus-samples&#34;&gt;Bonus samples&lt;/h2&gt;
&lt;p&gt;We integrated the diffusion model for SVS [4] to improve naturalness of synthetic voice.
The following table summarizes the systems for bonus samples.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;System&lt;/th&gt;
&lt;th&gt;Acoustic Features&lt;/th&gt;
&lt;th&gt;Autoregressive streams&lt;/th&gt;
&lt;th&gt;Diffusion streams&lt;/th&gt;
&lt;th&gt;Vocoder&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;NNSVS-WORLD v4*&lt;/td&gt;
&lt;td&gt;MGC, LF0, VUV, BAP&lt;/td&gt;
&lt;td&gt;LF0, MGC, BAP&lt;/td&gt;
&lt;td&gt;-&lt;/td&gt;
&lt;td&gt;SiFi-GAN [7]&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;NNSVS-Mel v5&lt;/td&gt;
&lt;td&gt;MEL, lF0, VUV&lt;/td&gt;
&lt;td&gt;LF0&lt;/td&gt;
&lt;td&gt;MEL&lt;/td&gt;
&lt;td&gt;SiFi-GAN&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;NNSVS-WORLD v5&lt;/td&gt;
&lt;td&gt;MGC, LF0, VUV, BAP&lt;/td&gt;
&lt;td&gt;LF0&lt;/td&gt;
&lt;td&gt;MGC, BAP&lt;/td&gt;
&lt;td&gt;SiFi-GAN&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;NNSVS-WORLD v4* is the best model (as of 2022/09) reported in our paper with the following two changes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;sampling rate was changed from 24 kHz to 48 kHz&lt;/li&gt;
&lt;li&gt;the vocoder was changed from hn-uSFGAN to SiFI-GAN [7].&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;NNSVS-Mel v5 and NNSVS-WORLD v5 are the systems using diffusion-based multi-stream acoustic models.&lt;/p&gt;
&lt;p&gt;Note that we used 48 kHz sampling rate for the additional experiments.&lt;/p&gt;
&lt;h3 id=&#34;japanese&#34;&gt;Japanese&lt;/h3&gt;
&lt;p&gt;Sample 1: 1st color&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Recording&lt;/th&gt;&lt;th&gt;NNSVS-WORLD v4*&lt;/th&gt;&lt;th&gt;NNSVS-Mel v5&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202211_nnsvs/SVS/[Test01]-Recording.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202211_nnsvs/SVS/[Test01]-NNSVS-WORLD v4*.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202211_nnsvs/SVS/[Test01]-NNSVS-Mel v5.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;NNSVS-WORLD v5&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202211_nnsvs/SVS/[Test01]-NNSVS-WORLD v5.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Sample 2: ARROW&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Recording&lt;/th&gt;&lt;th&gt;NNSVS-WORLD v4*&lt;/th&gt;&lt;th&gt;NNSVS-Mel v5&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202211_nnsvs/SVS/[Test02]-Recording.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202211_nnsvs/SVS/[Test02]-NNSVS-WORLD v4*.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202211_nnsvs/SVS/[Test02]-NNSVS-Mel v5.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;NNSVS-WORLD v5&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202211_nnsvs/SVS/[Test02]-NNSVS-WORLD v5.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Sample 3: BC&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Recording&lt;/th&gt;&lt;th&gt;NNSVS-WORLD v4*&lt;/th&gt;&lt;th&gt;NNSVS-Mel v5&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202211_nnsvs/SVS/[Test03]-Recording.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202211_nnsvs/SVS/[Test03]-NNSVS-WORLD v4*.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202211_nnsvs/SVS/[Test03]-NNSVS-Mel v5.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;NNSVS-WORLD v5&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202211_nnsvs/SVS/[Test03]-NNSVS-WORLD v5.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Sample 4: Close to you&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Recording&lt;/th&gt;&lt;th&gt;NNSVS-WORLD v4*&lt;/th&gt;&lt;th&gt;NNSVS-Mel v5&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202211_nnsvs/SVS/[Test04]-Recording.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202211_nnsvs/SVS/[Test04]-NNSVS-WORLD v4*.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202211_nnsvs/SVS/[Test04]-NNSVS-Mel v5.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;NNSVS-WORLD v5&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202211_nnsvs/SVS/[Test04]-NNSVS-WORLD v5.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Sample 5: ERROR&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Recording&lt;/th&gt;&lt;th&gt;NNSVS-WORLD v4*&lt;/th&gt;&lt;th&gt;NNSVS-Mel v5&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202211_nnsvs/SVS/[Test05]-Recording.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202211_nnsvs/SVS/[Test05]-NNSVS-WORLD v4*.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202211_nnsvs/SVS/[Test05]-NNSVS-Mel v5.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;NNSVS-WORLD v5&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202211_nnsvs/SVS/[Test05]-NNSVS-WORLD v5.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;h3 id=&#34;mandarin&#34;&gt;Mandarin&lt;/h3&gt;
&lt;p&gt;We provide Mandarin SVS samples using &lt;a href=&#34;https://wenet.org.cn/opencpop/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Opencpop database&lt;/a&gt; [8].&lt;/p&gt;
&lt;p&gt;Sample 1: 2044001628&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Recording&lt;/th&gt;&lt;th&gt;NNSVS-Mel v5&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202211_nnsvs/SVS_opencpop/[Test01]-Recording.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202211_nnsvs/SVS_opencpop/[Test01]-NNSVS-Mel v5.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Sample 2: 2044001629&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Recording&lt;/th&gt;&lt;th&gt;NNSVS-Mel v5&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202211_nnsvs/SVS_opencpop/[Test02]-Recording.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202211_nnsvs/SVS_opencpop/[Test02]-NNSVS-Mel v5.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Sample 3: 2092003412&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Recording&lt;/th&gt;&lt;th&gt;NNSVS-Mel v5&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202211_nnsvs/SVS_opencpop/[Test03]-Recording.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202211_nnsvs/SVS_opencpop/[Test03]-NNSVS-Mel v5.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Sample 4: 2093003457&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Recording&lt;/th&gt;&lt;th&gt;NNSVS-Mel v5&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202211_nnsvs/SVS_opencpop/[Test04]-Recording.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202211_nnsvs/SVS_opencpop/[Test04]-NNSVS-Mel v5.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;p&gt;Sample 5: 2093003458&lt;/p&gt;
&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;Recording&lt;/th&gt;&lt;th&gt;NNSVS-Mel v5&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202211_nnsvs/SVS_opencpop/[Test05]-Recording.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202211_nnsvs/SVS_opencpop/[Test05]-NNSVS-Mel v5.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;h2 id=&#34;error-cases&#34;&gt;Error cases&lt;/h2&gt;
&lt;h3 id=&#34;unstable-pitch-of-diffsinger&#34;&gt;Unstable pitch of DiffSinger&lt;/h3&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/images/nnsvs/error_diffsinger_unstable_pitch.png&#34; width=&#34;100%&#34; /&gt;&lt;/div&gt;
&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;&lt;th&gt;DiffSinger&lt;/th&gt;&lt;th&gt;Recording&lt;/th&gt;&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test05]-DiffSinger.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;td&gt;&lt;audio controls=&#34;&#34;&gt;&lt;source src=&#34;https://r9y9.github.io/audio/202210_nnsvs/SVS/[Test05]-Recording.wav&#34; type=&#34;audio/wav&#34;&gt;&lt;/audio&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;
&lt;p&gt;As shown in the figure (blue: discontinous F0; green: unstable vibrato), the pitch contour of the DiffSinger is sometimes unstable.&lt;/p&gt;
&lt;h2 id=&#34;acknowledgments&#34;&gt;Acknowledgments&lt;/h2&gt;
&lt;p&gt;This work was partly supported by JST CREST Grant Number JPMJCR19A3.&lt;/p&gt;
&lt;h2 id=&#34;appendix&#34;&gt;Appendix&lt;/h2&gt;
&lt;h3 id=&#34;note-pitch-distribution&#34;&gt;Note pitch distribution&lt;/h3&gt;
&lt;p&gt;We selected test songs to cover a wide range of note pitches. Their distributions are shown in the following figure.&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/images/ritsu_pitch_dist.png&#34; width=&#34;100%&#34; /&gt;&lt;/div&gt;
&lt;p&gt;Pitch is presented as MIDI note number, where A4 (69) corresponds to 440 Hz.
The lowerest and highest notes of the test songs were D#4 (155.6 Hz) and A5 (880 Hz), whereas those of the training data were D#3 (146.8 Hz) and B5 (987.8 Hz).&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;[1] Canon, [NamineRitsu] Blue (YOASOBI) [ENUNU model Ver.2, Singing DBVer.2 release], &lt;a href=&#34;https://www.youtube.com/watch?v=pKeo9IE_L1I&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.youtube.com/watch?v=pKeo9IE_L1I&lt;/a&gt;, Accessed: 2022.10.06.&lt;/li&gt;
&lt;li&gt;[2] Y. Hono, K. Hashimoto, K. Oura, et al., âSinsy: A deep neural network-based singing voice synthesis system,â IEEE/ACM Trans. on Audio, Speech, and Language Processing, vol. 29, pp. 2803.&lt;/li&gt;
&lt;li&gt;[3] J. Shi, S. Guo, T. Qian, et al., âMuskits: an End-to-end Music Processing Toolkit for Singing Voice Synthesis,â in Proc. Interspeech, 2022, pp. 4277â4281.&lt;/li&gt;
&lt;li&gt;[4] J. Liu, C. Li, Y. Ren, et al., âDiffSinger: Singing Voice Synthesis via Shallow Diffusion Mechanismâ, AAAI, vol. 36, no. 10, pp. 11020-11028, Jun. 2022.&lt;/li&gt;
&lt;li&gt;[5] R. Yoneyama, Y.-C. Wu, and T. Toda, âUnified Source-Filter GAN with Harmonic-plus-Noise Source Excitation Generation,â in Proc. Interspeech, 2022, pp. 848â852.&lt;/li&gt;
&lt;li&gt;[6] J. Kong, J. Kim, and J. Bae, âHiFi-GAN: Generative adversarial networks for efficient and high fidelity speech synthesis,â NeurIPS, vol. 33, pp. 17 022â17 033, 2020.&lt;/li&gt;
&lt;li&gt;[7] R. Yoneyama, Y.-C. Wu, and T. Toda, âSource-Filter HiFi-GAN: Fast and Pitch Controllable High-Fidelity Neural Vocoder.&amp;quot; arXiv preprint arXiv:2210.15533, 2022.&lt;/li&gt;
&lt;li&gt;[8] Y. Wang, X. Wang, P. Zhu, et al., âOpencpop: a high-quality open source chinese popular song corpus for singing voice synthesis,&amp;quot; arXiv:2201.07429, 2022.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Non-parallel High-Quality Audio Super Resolution with Domain Adaptation and Resampling CycleGANs</title>
      <link>https://r9y9.github.io/projects/dualcyclegan/</link>
      <pubDate>Tue, 18 Oct 2022 21:17:44 +0900</pubDate>
      <guid>https://r9y9.github.io/projects/dualcyclegan/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Lightweight and High-Fidelity End-to-End Text-to-Speech with Multi-Band Generation and Inverse Short-Time Fourier Transform</title>
      <link>https://r9y9.github.io/projects/lvits/</link>
      <pubDate>Mon, 17 Oct 2022 19:22:30 +0900</pubDate>
      <guid>https://r9y9.github.io/projects/lvits/</guid>
      <description></description>
    </item>
    
    <item>
      <title>ttslearn: Library for Pythonã§å­¦ã¶é³å£°åæ (Text-to-speech with Python)</title>
      <link>https://r9y9.github.io/projects/ttslearn/</link>
      <pubDate>Wed, 11 Aug 2021 16:27:22 +0900</pubDate>
      <guid>https://r9y9.github.io/projects/ttslearn/</guid>
      <description></description>
    </item>
    
    <item>
      <title> WN-based TTSããã¾ãã / Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions [arXiv:1712.05884]</title>
      <link>https://r9y9.github.io/blog/2018/05/20/tacotron2/</link>
      <pubDate>Sun, 20 May 2018 14:21:30 +0900</pubDate>
      <guid>https://r9y9.github.io/blog/2018/05/20/tacotron2/</guid>
      <description>&lt;h2 id=&#34;summary&#34;&gt;Summary&lt;/h2&gt;
&lt;p&gt;Thank you for coming to see my blog post about WaveNet text-to-speech.&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron2/intro.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;ul&gt;
&lt;li&gt;è«æãªã³ã¯: &lt;a href=&#34;https://arxiv.org/abs/1712.05884&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://arxiv.org/abs/1712.05884&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;ãªã³ã©ã¤ã³ãã¢: &lt;a href=&#34;https://colab.research.google.com/github/r9y9/Colaboratory/blob/master/Tacotron2_and_WaveNet_text_to_speech_demo.ipynb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Tacotron2: WaveNet-based text-to-speech demo&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;ã³ã¼ã &lt;a href=&#34;https://github.com/r9y9/wavenet_vocoder&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;r9y9/wavenet_vocoder&lt;/a&gt;, &lt;a href=&#34;https://github.com/Rayhane-mamah/Tacotron-2&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Rayhane-mamah/Tacotron-2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;é³å£°ãµã³ãã«: &lt;a href=&#34;https://r9y9.github.io/wavenet_vocoder/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://r9y9.github.io/wavenet_vocoder/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;ä¸è¡ã¾ã¨ã&#34;&gt;ä¸è¡ã¾ã¨ã&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;èªä½WaveNet (&lt;strong&gt;WN&lt;/strong&gt;) ã¨æ¢å­å®è£Tacotron 2 (WNãé¤ã) ãçµã¿åããã¦ãè±èªTTSãä½ãã¾ãã&lt;/li&gt;
&lt;li&gt;LJSpeechãå­¦ç¿ãã¼ã¿ã¨ããå ´åãèªåå²ä¸ &lt;strong&gt;æé«åè³ª&lt;/strong&gt; ã®TTSãã§ããã¨æãã¾ã&lt;/li&gt;
&lt;li&gt;Tacotron 2ã¨ Deep Voice 3 ã®abstractãèª­ã¾ããé³å£°ãµã³ãã«ãè²¼ã£ã¦ããã¾ãã®ã§ãèå³ã®ããæ¹ã¯ã©ãã&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ãªããTacotron 2 ã®è§£èª¬ã¯ãã¾ãããç³ãè¨³ããã¾ããï¼ãªããªãåãã¾ã ååã«èª­ã¿è¾¼ãã§ããªãããï¼&lt;/p&gt;
&lt;h2 id=&#34;èæ¯&#34;&gt;èæ¯&lt;/h2&gt;
&lt;p&gt;éå»ã«ãWaveNetãå®è£ãã¾ããï¼åè: &lt;a href=&#34;https://r9y9.github.io/blog/2018/01/28/wavenet_vocoder/&#34;&gt;WaveNet vocoder ããã£ã¦ã¿ã¾ããã®ã§ããã®è¨é²ã§ã / WaveNet: A Generative Model for Raw Audio [arXiv:1609.03499]&lt;/a&gt;ï¼ãéå»è¨äºããå¼ç¨ãã¾ãã&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Tacotron2 ã¯ããã¨ã¯ããã°ã»ã¼ã§ããæãã§ãããç´è¿ã§ã¯åã®ä¸­ã§åªååº¦ãä½ãã®ããããã°ããå®é¨ãããäºå®ã¯ããã¾ãããèå³ã®ããæ¹ã¯ãã£ã¦ã¿ã¦ãã ããã&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;ãããããã¨ã®ä¸ã¤ã¨ãã¦ãã£ãã¨ã¯ãããå½åã®äºå®éããã¹ã¯ã©ããã§Tacotron 2ãå®è£ããæéã¯åããªãã£ãã®ã§ãããæ¢å­å®è£ãä½¿ã£ã¦ã¿ãã¨ããååã«ä¸æãåãã¦ããããã«æããã®ã§ããããããä½¿ããã¦ããã ããWaveNet TTSãå®ç¾ãããã¨ãã§ãã¾ãããã¨ããããã§ãçµæãããã«ã«ã¸ã¥ã¢ã«ã«æ®ãã¦ãããã¨ããè¶£æ¨ã®è¨äºã«ãªãã¾ãã&lt;/p&gt;
&lt;p&gt;ãªã¼ãã³ãªãã¼ã¿ã»ãããã³ã¼ããä½¿ã£ã¦ãå®éã©ã®ç¨åº¦ã®åè³ªãå¾ãããã®ãï¼å­¦ç¿/æ¨è«ã«ã©ã®ãããæéããããã®ãï¼ããã®ãæ°ã«ãªãæ¹ã«ã¯ãåèã«ãªãããããã¾ããã®ã§ããããããã°ç¶ããã©ããã&lt;/p&gt;
&lt;h2 id=&#34;å®é¨æ¡ä»¶&#34;&gt;å®é¨æ¡ä»¶&lt;/h2&gt;
&lt;p&gt;ç´°ããåå®¹ã¯ã³ã¼ãã«è­²ãã¨ãã¦ãéè¦ãªç¹ã ããªã¹ãã¢ãããã¾ã&lt;/p&gt;
&lt;h3 id=&#34;pre-trained-modelshyper-parameters-ã¸ã®ãªã³ã¯&#34;&gt;Pre-trained modelsãhyper parameters ã¸ã®ãªã³ã¯&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Tacotron2 (mel-spectrogram prediction part): trained 189k steps on LJSpeech dataset (&lt;a href=&#34;https://www.dropbox.com/s/vx7y4qqs732sqgg/pretrained.tar.gz?dl=0&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Pre-trained model&lt;/a&gt;, &lt;a href=&#34;https://github.com/r9y9/Tacotron-2/blob/9ce1a0e65b9217cdc19599c192c5cd68b4cece5b/hparams.py&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Hyper params&lt;/a&gt;).&lt;/li&gt;
&lt;li&gt;WaveNet: trained over 1000k steps on LJSpeech dataset (&lt;a href=&#34;https://www.dropbox.com/s/zdbfprugbagfp2w/20180510_mixture_lj_checkpoint_step000320000_ema.pth?dl=0&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Pre-trained model&lt;/a&gt;, &lt;a href=&#34;https://www.dropbox.com/s/0vsd7973w20eskz/20180510_mixture_lj_checkpoint_step000320000_ema.json?dl=0&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Hyper params&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;wavenet&#34;&gt;WaveNet&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;1000k stepä»¥ä¸è¨ç·´ãããã¢ãã« (2018/1/27ã«ä½ã£ããã®ã10æ¥ããã&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;å­¦ç¿ããï¼ããã¼ã¹ã«ãããã« 320k stepå­¦ç¿ï¼ç´3æ¥ï¼ãã¾ãããåå­¦ç¿ããã®ã¯ãä»¥åã®ã³ã¼ãã«ã¯ &lt;a href=&#34;https://github.com/r9y9/wavenet_vocoder/issues/33&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;wavenet_vocoder/issues/33&lt;/a&gt; ãããªãã°ããã£ãããã§ãã&lt;/li&gt;
&lt;li&gt;è©ä¾¡ã«ã¯ãexponential moving averagingããããã©ã¡ã¼ã¿ãä½¿ãã¾ãããdecay ãã©ã¡ã¼ã¿ã¯Taco2è«æã¨åã 0.9999&lt;/li&gt;
&lt;li&gt;å­¦ç¿ã«ã¯ãMel-spectrogram prediction networkã«ããåºåããã Ground-truth-aligned (GTA) ãªã¡ã«ã¹ãã¯ãã­ã°ã©ã ã§ã¯ãªããçé³å£°ããè¨ç®ãããã¡ã«ã¹ãã¯ãã­ã°ã©ã ãä½¿ãã¾ãããæéã®é½åä¸ãããã¾ããããGTAãä½¿ãã¨ããåè³ªãåä¸ããã¨èãããã¾ã&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;tacotron-2-mel-spectrogram-prediction&#34;&gt;Tacotron 2 (mel-spectrogram prediction)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/Rayhane-mamah/Tacotron-2&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/Rayhane-mamah/Tacotron-2&lt;/a&gt; ã«ã¯WaveNetå®è£ãå«ã¾ãã¦ãã¾ãããmel-spectrogram prediction ã®é¨åã ãä½¿ç¨ãã¾ãã&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/Rayhane-mamah/Tacotron-2/issues/30#issue-317360759&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/Rayhane-mamah/Tacotron-2/issues/30#issue-317360759&lt;/a&gt; ã§å¬éããã¦ãã 182k stepå­¦ç¿ãããã¢ãã«ããããã«7k stepã»ã©ï¼æ°æéãããï¼å­¦ç¿ããã¾ãããåå­¦ç¿ãããçç±ã¯ãèªåã®å®è£ã¨Rayhaneæ°ã®å®è£ã§æ³å®ããã¡ã«ã¹ãã¯ãã­ã°ã©ã ã®ã¬ã³ã¸ãç°ãªã£ã¦ããããã§ãï¼å: &lt;code&gt;[0, 1]&lt;/code&gt;, Rayhane: &lt;code&gt;[-4, 4]&lt;/code&gt;ï¼ãããããçµç·¯ããã&lt;code&gt;[-4, 4]&lt;/code&gt; ã®ã¬ã³ã¸ã§ãã£ãã¨ããï¼&lt;code&gt;[0, 4]&lt;/code&gt; ã«ãã¦å­¦ç¿ããªããã¾ãããç´æ¥ &lt;code&gt;[0, 1]&lt;/code&gt; ã«ãã¦å­¦ç¿ããªãã£ãã®ã¯ï¼ããã§ãåããã¨åã¯æã£ã¦ããã®ã§ããï¼ãmel-spectrogram ã®ã¬ã³ã¸ãå¤§ããåã£ãæ¹ãè¯ããã¨ããå ±åãããã¤ããã£ãããã§ãï¼ä¾ãã° &lt;a href=&#34;https://github.com/Rayhane-mamah/Tacotron-2/issues/4#issuecomment-377728945&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/Rayhane-mamah/Tacotron-2/issues/4#issuecomment-377728945&lt;/a&gt; )ãAttention seq2seq ã¯çµé¨ä¸å­¦ç¿ãé£ããã®ã§ãåã®ç´æãããåäººã®ç¥æµãåªåãããã¨ã«ããæ¬¡ç¬¬ã§ããWNã«å¥åããã¨ãã«ã¯ã Taco2ãåºåããã¡ã«ã¹ãã¯ãã­ã°ã©ã ã &lt;code&gt;c = np.interp(c, (0, 4), (0, 1))&lt;/code&gt; ã¨ã¬ã³ã¸ãå¤æãã¦ä¸ãã¾ãã&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;ãã¢é³å£°&#34;&gt;ãã¢é³å£°&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://r9y9.github.io/wavenet_vocoder/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://r9y9.github.io/wavenet_vocoder/&lt;/a&gt; ã«ãµã³ãã«ã¯ããããããã¾ããããããã§ã¯éããµã³ãã«ãã¨æããTacotron 2 ã¨ Deep Voice 3ã® abstract ãèª­ã¾ãã¦ã¿ã¾ããã
å­¦ç¿ãã¼ã¿ã«è¥å¹²æ®é¿ãä¹ã£ã¦ããã®ã§ï¼ãã¤ãºã£ã½ãï¼ãããåæ ããã¦ãã¾ã£ã¦ããã®ã§ãããåäººçã«ã¯ã¾ãã¾ãããçµæãå¾ãããã¨æã£ã¦ãã¾ããèå³ãããæ¹ã¯ãDeepVoice3ãªã©åã®éå»è¨äºã§è§¦ãã¦ããTTSçµæã¨æ¯ã¹ã¦ã¿ã¦ãã ããã&lt;/p&gt;
&lt;p&gt;ãªããæ¨è«ã®è¨ç®éåº¦ã¯,ãåã®ã­ã¼ã«ã«ç°å¢ï¼GTX 1080Ti, i7-7700Kï¼ã§ãã£ã¨ 170 timesteps / second ã¨ãã£ãæãã§ãããããã¯ãParallel WaveNet ã®è«æã§è§¦ãããã¦ããæ°å­ã¨ããã¾ãã«ä¸è´ãã¾ãã&lt;/p&gt;
&lt;p&gt;This paper describes Tacotron 2, a neural network architecture for speech synthesis directly from text.&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron2/20180510_mixture_lj_checkpoint_step000320000_ema_speech-mel-00001.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;The system is composed of a recurrent sequence-to-sequence feature prediction network that maps character embeddings to mel-scale spectrograms, followed by a modified WaveNet model acting as a vocoder to synthesize timedomain waveforms from those spectrograms.&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron2/20180510_mixture_lj_checkpoint_step000320000_ema_speech-mel-00002.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;Our model achieves a mean opinion score of 4.53 comparable to a MOS of 4.58 for professionally recorded speech.&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron2/20180510_mixture_lj_checkpoint_step000320000_ema_speech-mel-00003.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;To validate our design choices, we present ablation studies of key components of our system and evaluate the impact of using mel spectrograms as the input to WaveNet instead of linguistic, duration, and F0 features.&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron2/20180510_mixture_lj_checkpoint_step000320000_ema_speech-mel-00004.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;We further demonstrate that using a compact acoustic intermediate representation enables significant simplification of the WaveNet architecture.&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron2/20180510_mixture_lj_checkpoint_step000320000_ema_speech-mel-00005.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;We present Deep Voice 3, a fully-convolutional attention-based neural text-to-speech system.&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron2/20180510_mixture_lj_checkpoint_step000320000_ema_speech-mel-00006.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;Deep Voice 3 matches state-of-the-art neural speech synthesis systems in naturalness while training ten times faster.&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron2/20180510_mixture_lj_checkpoint_step000320000_ema_speech-mel-00007.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;We scale Deep Voice 3 to data set sizes unprecedented for TTS, training on more than eight hundred hours of audio from over two thousand speakers.&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron2/20180510_mixture_lj_checkpoint_step000320000_ema_speech-mel-00008.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;In addition, we identify common error modes of attention-based speech synthesis networks, demonstrate how to mitigate them, and compare several different waveform synthesis methods.&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron2/20180510_mixture_lj_checkpoint_step000320000_ema_speech-mel-00009.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;We also describe how to scale inference to ten million queries per day on one single-GPU server.&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron2/20180510_mixture_lj_checkpoint_step000320000_ema_speech-mel-00010.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;h2 id=&#34;ãªã³ã©ã¤ã³ãã¢&#34;&gt;ãªã³ã©ã¤ã³ãã¢&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://colab.research.google.com/github/r9y9/Colaboratory/blob/master/Tacotron2_and_WaveNet_text_to_speech_demo.ipynb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Tacotron2: WaveNet-based text-to-speech demo&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Google Colabã§åãããããã«ãã¢ãã¼ãããã¯ãä½ãã¾ãããç°å¢æ§ç¯ãä¸è¦ãªã®ã§ãæè»½ã«ãè©¦ãã§ãããã¨æãã¾ãã&lt;/p&gt;
&lt;h2 id=&#34;éè¨&#34;&gt;éè¨&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;WaveNetãå­¦ç¿ããã¨ãã«ãMel-spectrogram precition networkã®GTAãªåºåã§ãªããçã¡ã«ã¹ãã¯ãã­ã°ã©ã ããã®ã¾ã¾ä½¿ã£ã¦ãåè³ªã®è¯ãé³å£°åæãã§ããã®ã¯åäººçã«é©ãã§ãããããã¯ã¤ã¾ããTaco2ãã(non teacher-forcingãªæ¡ä»¶ã§) ååè¯ãã¡ã«ã¹ãã¯ãã­ã°ã©ã ãäºæ¸¬ã§ãã¦ãããã¨ãããã¨ãªã®ã ã¨æãã¾ãã&lt;/li&gt;
&lt;li&gt;åææ§ãåä¸ãããããã«ãåºåã127.5 åããã¨ãããã¨ããä»¶ã§ãããåã¯ãã£ã¦ãã¾ããããªããªããåãã¾ã ãã®æ¹æ³ã®å¦¥å½æ§ãçè§£ã§ãã¦ããªãããã§ãã&lt;a href=&#34;https://twitter.com/__dhgrs__/status/995962302896599040&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;@__dhgrs__ããã®å ±å&lt;/a&gt; ã«ããã¨ããã¯ãæå¹ã«åãããã§ãã­â¦&lt;/li&gt;
&lt;li&gt;ããã¾ã &lt;a href=&#34;http://www.monthly-hack.com/entry/2018/02/23/203208&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;@__dhgrs__ããã®ãã­ã°è¨äº&lt;/a&gt; ã«ãæ¸ããã¦ãã¾ãããMixture of Logistic distributions (MoLã¨ãã¾ã) ãä½¿ã£ãå ´åã¯ãcategoricalãèãã¦softmaxãä½¿ãå ´åã«æ¯ã¹ãã¨ååãªåè³ªãå¾ãã®ã«å¤§å¹ã«è¨ç®æéãå¿è¦ã«ãªãã¾ãã­ããä½é¨çã«ã¯10åç¨åº¦ã§ããè¨ç®ã«ãã¾ãã«æéããããã®ã§ãã¹ã¯ã©ããã§ä½åº¦ãå­¦ç¿ããã®ã¯å³ãããå­¦ç¿æ¸ã¿ã¢ãã«ãä½åº¦ãç¹°ãè¿ãfine turningãã¦ããã¨ãããç§ä¼ã®ã¿ã¬æ¹å¼ã§å­¦ç¿ãè¡ãã¾ããï¼åç¾æ§ãªãã§ããæºæï¼&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/Rayhane-mamah/Tacotron-2&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/Rayhane-mamah/Tacotron-2&lt;/a&gt; ä»åä½¿ããã¦ããã£ãTaco2å®è£ã¯ãåã®å®è£ãä¸é¨ä½¿ããã¦ããããã§ãããããã¨ã¯å¥ã® NVIDIA ããåºã &lt;a href=&#34;https://github.com/NVIDIA/tacotron2&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/NVIDIA/tacotron2&lt;/a&gt; ã®è¬è¾ã«ã¯åã®ååãå¥ãã¦ããã ãã¦ããããä»ã«ãããããã±ã¼ã¹ããããªãã«ãã£ã¦ãç«¯çã«ãã£ã¦åæ ã§ããããããããæãã§ãã&lt;/li&gt;
&lt;li&gt;éå¬éã®ãã¼ã¿ã»ãããä½¿ã£ã¦å­¦ç¿/çæããWaveNet TTS ã®ãµã³ãã«ãããã¾ããå¬éã§ããªãã®ã§ããã«ã¯ããã¦ãã¾ããããã¨ã¦ãé«åè³ªãªé³å£°åæï¼ä¸»è¦³ã§ããï¼ãã§ãããã¨ãç¢ºèªãã¦ãã¾ã&lt;/li&gt;
&lt;li&gt;ãã®ãã­ã¸ã§ã¯ããã¯ããããã¨ã§ããªãã¨åæ ã«ã&lt;a href=&#34;http://www.nict.go.jp/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;NICT&lt;/a&gt;ã§ã®ãã¼ã¯ã®æ©ä¼ãããããã¨ãã§ãã¾ããããªã¼ãã½ã¼ã¹ã«ã¤ãã¦æ¯éã¯ããã¨æãã¾ãããåäººçã«ã¯è¯ããã¨ãã¨ã¦ãå¤ããªã¨æãã¾ãããã¬ã¼ã³è³æã¯ãhttps://github.com/r9y9/wavenet_vocoder/issues/57 ã«ç½®ãã¦ããã¾ãï¼ããã¹ã©ã¤ãã ãã§èª­ã¿ç©ã¨ãã¦æç«ãããã®ã§ã¯ãªãã¨æãã¾ãããã¿ã¾ããï¼&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;ãããã«&#34;&gt;ãããã«&lt;/h2&gt;
&lt;p&gt;WaveNet TTSãããããä½ããã¨ãã§ãã¾ãããSample-levelã§autoregressive modelãèããã¨ããã¢ãã­ã¼ããæ¬å½ã«åããã®ãçåã ã£ãã®ã§ãããå®éã«ä½ã£ã¦ã¿ã¦ãä¸æãè¡ãã¨ãããã¨ãä½æãããã¨ãã§ãã¾ããããã§ããã&lt;/p&gt;
&lt;p&gt;Googleã®ç ç©¶èãã¾ãç´ æ´ãããç ç©¶ããããã¨ããããã¾ããWaveNetã¯æ¬å½ã«ãããã£ã&lt;/p&gt;
&lt;h2 id=&#34;åè&#34;&gt;åè&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1609.03499&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Aaron van den Oord, Sander Dieleman, Heiga Zen, et al, &amp;ldquo;WaveNet: A Generative Model for Raw Audio&amp;rdquo;, 	arXiv:1609.03499, Sep 2016.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1711.10433&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Aaron van den Oord, Yazhe Li, Igor Babuschkin, et al, &amp;ldquo;Parallel WaveNet: Fast High-Fidelity Speech Synthesis&amp;rdquo;, 	arXiv:1711.10433, Nov 2017.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.isca-speech.org/archive/Interspeech_2017/pdfs/0314.PDF&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Tamamori, Akira, et al. &amp;ldquo;Speaker-dependent WaveNet vocoder.&amp;rdquo; Proceedings of Interspeech. 2017.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1712.05884&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Jonathan Shen, Ruoming Pang, Ron J. Weiss, et al, &amp;ldquo;Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions&amp;rdquo;, arXiv:1712.05884, Dec 2017.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1710.07654&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Wei Ping, Kainan Peng, Andrew Gibiansky, et al, &amp;ldquo;Deep Voice 3: 2000-Speaker Neural Text-to-Speech&amp;rdquo;, arXiv:1710.07654, Oct. 2017.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1611.09482&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Tom Le Paine, Pooya Khorrami, Shiyu Chang, et al, &amp;ldquo;Fast Wavenet Generation Algorithm&amp;rdquo;, arXiv:1611.09482, Nov. 2016&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.monthly-hack.com/entry/2018/02/23/203208&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;VQ-VAEã®è¿½è©¦ã§å¾ãWaveNetã®ãã¦ãã¦ãã¾ã¨ãã¦ã¿ãã - Monthly Hacker&amp;rsquo;s Blog&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;ææ§ãªè¡¨ç¾ã§ç³ãè¨³ãããã¾ãã&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34;&gt;
&lt;p&gt;åãä½¿ã£ãå½æã¯ãWNã®é¨åã¯ååã«ãã¹ãããã¦ããªãã£ãã®ã¨ãWNã®ã³ã¼ãã¯åã®ã³ã¼ããtfã«translateããæããªï¼èèããããã£ã¦ã¾ãï¼ã®ã§ãWNã¯èªåã®å®è£ãä½¿ã£ãæ¬¡ç¬¬ã§ã&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</description>
    </item>
    
    <item>
      <title>ã108 è©±èç·¨ãDeep Voice 3: 2000-Speaker Neural Text-to-Speech / arXiv:1710.07654 [cs.SD]</title>
      <link>https://r9y9.github.io/blog/2017/12/22/deepvoice3_multispeaker/</link>
      <pubDate>Fri, 22 Dec 2017 15:30:00 +0900</pubDate>
      <guid>https://r9y9.github.io/blog/2017/12/22/deepvoice3_multispeaker/</guid>
      <description>&lt;h2 id=&#34;summary&#34;&gt;Summary&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;è«æãªã³ã¯: &lt;a href=&#34;https://arxiv.org/abs/1710.07654&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;arXiv:1710.07654&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;ã³ã¼ã: &lt;a href=&#34;https://github.com/r9y9/deepvoice3_pytorch&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/r9y9/deepvoice3_pytorch&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;VCTK: &lt;a href=&#34;https://datashare.ed.ac.uk/handle/10283/2950&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://datashare.ed.ac.uk/handle/10283/2950&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;é³å£°ãµã³ãã«ã¾ã¨ã: &lt;a href=&#34;https://r9y9.github.io/deepvoice3_pytorch/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://r9y9.github.io/deepvoice3_pytorch/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;ä¸è¡ã¾ã¨ã&#34;&gt;ä¸è¡ã¾ã¨ã&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1710.07654&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;arXiv:1710.07654: Deep Voice 3: 2000-Speaker Neural Text-to-Speech&lt;/a&gt; ãèª­ãã§ãè¤æ°è©±èã®å ´åã®ã¢ãã«ãå®è£ãã¾ãã&lt;/li&gt;
&lt;li&gt;è«æã®ã¿ã¤ãã«éãã®2000è©±èã¨ã¯ããã¾ãããã&lt;a href=&#34;https://datashare.ed.ac.uk/handle/10283/2950&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;VCTK&lt;/a&gt; ãä½¿ã£ã¦ã108 è©±èå¯¾å¿ã®è±èªTTSã¢ãã«ãä½ãã¾ããï¼å­¦ç¿æé1æ¥ãããï¼&lt;/li&gt;
&lt;li&gt;å¥åããè©±èIDãå¤ãããã¨ã§ãä¸ã¤ã®ã¢ãã«ã§ããªã¨ã¼ã·ã§ã³ã«å¯ãã é³å£°ãµã³ãã«ãçæã§ãããã¨ãç¢ºèªãã¾ãã&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;æ¦è¦&#34;&gt;æ¦è¦&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://r9y9.github.io/blog/2017/12/13/deepvoice3/&#34;&gt;ãåä¸è©±èç·¨ãDeep Voice 3: 2000-Speaker Neural Text-to-Speech / arXiv:1710.07654 [cs.SD]&lt;/a&gt; ã®ç¶ç·¨ã§ãã&lt;/p&gt;
&lt;p&gt;è«ææ¦è¦ã¯ååç´¹ä»ãããã®ã¨åããªã®ã§ãè©±èã®æ¡ä»¶ä»ãã®é¨åã«ã¤ãã¦ã®ã¿ç°¡åã«è¿°ã¹ã¾ãããªããè©±èã®æ¡ä»¶ä»ãã«é¢ãã¦ã¯ãDeepVoice2ã®è«æ (&lt;a href=&#34;https://arxiv.org/abs/1705.08947&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;arXiv:1705.08947 [cs.CL]&lt;/a&gt;) ã®æ¹ãè©³ããã§ãã&lt;/p&gt;
&lt;p&gt;ã¾ãåºæ¬çã«ãè©±èã®æå ±ã¯ trainable embedding ã¨ãã¦ã¢ãã«ã«çµã¿è¾¼ã¿ã¾ããtext embeddingã®ãããã«ãããã¯ã¼ã¯ã®å¥åã®ä¸ç®æã«å¥ãããããªè¨­è¨ã§ã¯å­¦ç¿ãä¸æãããªãï¼è©±èæå ±ãç¡è¦ããããã«ãªã£ã¦ãã¾ãã®ã ã¨æãã¾ãï¼ããããããã¯ã¼ã¯ã®ããããã¨ããã«å¥ããã®ããã¤ã³ãã®ããã§ããå·ä½çã«ã¯ãEncoder, Decoder (+ Attention), Converterã®ãã¹ã¦ã«å¥ãã¾ããããã«å·ä½çã«ã¯ããããã¯ã¼ã¯ã®åºæ¬è¦ç´ ã§ãã Gated linear unit + Conv1d ã®ãã¹ã¦ã«å¥ãã¾ããè©³ç´°ã¯è«æã«è¨è¼ã®architectureã®å³ãåç§ãã¦ãã ããã&lt;/p&gt;
&lt;p&gt;è©±èã®æ¡ä»¶ä»ãã«é¢ãã¦ãä¸ã¤æ³¨æãå ããã¨ããã°ãæ¬è«æã«ã¯æç¤ºçã«æ¸ããã¦ãã¾ãããã speaker embeddingã¯åæéstepãã¹ã¦ã«expandãã¦ç¨ããã®ã ã¨æãã¾ãï¼ã§ãªãã¨å®è£ããã¨ãã«å°ãï¼ãDeepVoice2ã®è«æã«ã¯ãã®æ¨ãæç¤ºçã«æ¸ããã¦ãã¾ãã&lt;/p&gt;
&lt;h2 id=&#34;vctk-ã®åå¦ç&#34;&gt;VCTK ã®åå¦ç&lt;/h2&gt;
&lt;p&gt;å®é¨ã«å¥ãåã«ãVCTKã®åå¦çã«ã¤ãã¦ãç°¡åã«ã¾ã¨ãããã¨æãã¾ããVCTKã®é³å£°ãã¼ã¿ã«ã¯ãæ°ç§ã«æ¸¡ãç¡é³åºéããããªãã«å¥ã£ã¦ããã®ã§ããããåãé¤ãå¿è¦ãããã¾ããä»¥åã&lt;a href=&#34;https://r9y9.github.io/blog/2017/11/12/jsut_ver1/&#34;&gt;æ¥æ¬èª End-to-end é³å£°åæã«ä½¿ããã³ã¼ãã¹ JSUT ã®åå¦ç&lt;/a&gt; ã§æ¸ããåå®¹ã¨åãããã«ãé³ç´ ã¢ã©ã¤ã¡ã³ããåã£ã¦ç¡é³åºéãé¤å»ãã¾ããåã¯ä»¥ä¸ã®äºã¤ã®æ¹æ³ããããã¾ããã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/lowerquality/gentle&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Gentle&lt;/a&gt; (&lt;a href=&#34;https://github.com/kaldi-asr/kaldi&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Kaldi&lt;/a&gt;ãã¼ã¹)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/CSTR-Edinburgh/merlin&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Merlin&lt;/a&gt; ä»å±ã®ã¢ã©ã¤ã¡ã³ããã¼ã« (&lt;a href=&#34;http://festvox.org/cmu_arctic/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;festvox&lt;/a&gt;ãã¼ã¹) (&lt;a href=&#34;https://gist.github.com/kastnerkyle/cc0ac48d34860c5bb3f9112f4d9a0300&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ä¾¿å©ã¹ã¯ãªãã&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;è«æä¸­ã«ã¯ãï¼ç¡é³é¤å»ã®ãããã¨ããæèã§ã¯ãªãã®ã§ãã&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;ï¼Gentleãä½¿ã£ãæ¨ãæ¸ããã¦ãã¾ããããããè©¦ããã¨ããã¢ã©ã¤ã¡ã³ããå¤±æããã±ã¼ã¹ããããªãã«ããã&lt;a href=&#34;https://github.com/facebookresearch/loop&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;loop&lt;/a&gt; ã¯å¾èã®æ¹æ³ãç¨ãã¦ããè¯ãçµæãåºã¦ãããã¨ãããçµè«ã¨ãã¦ã¯åã¯å¾èãæ¡ç¨ãã¾ããããªããä¸¡æ¹ã®ã³ã¼ãã¯æ®ãã¦ããã®ã§ãæ°ã«ãªãæ¹ã¯ä¸¡æ¹ãããã¦ã¿ã¦ãã ããã&lt;/p&gt;
&lt;h2 id=&#34;å®é¨&#34;&gt;å®é¨&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://datashare.ed.ac.uk/handle/10283/2950&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;VCTK&lt;/a&gt; ã®108è©±èåã®ãã¹ã¦&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;ãä½¿ç¨ãã¦ã20æéãããï¼30ä¸ã¹ããã x 2ï¼å­¦ç¿ãã¾ããã30ä¸ã¹ãããå­¦ç¿ããå¾ã§ããã¢ãã«ããã¼ã¹ã«ãããã«30ä¸ã¹ãããå­¦ç¿ãã¾ãã&lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;ãã¢ãã«ã¯ãåä¸è©±èã®å ´åã¨ã»ã¨ãã©åãã§ãããå¤æ´ãå ããç¹ãä»¥ä¸ã«ã¾ã¨ãã¾ãã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;å±é&lt;/strong&gt;: Speaker embedding ãè¿½å ãã¾ããã&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;å±é&lt;/strong&gt;: Speaker embeddingããã¹ã¦ã®æéã¹ãããã«expandãããã¨ãDropoutãé©ç¨ããããã«ãã¾ããï¼è«æã«ã¯æ¸ãã¦ãã¾ããããçµè«ããè¨ãã°éè¦ã§ããâ¦ï¼&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Decoder&lt;/strong&gt;: ã¢ãã³ã·ã§ã³ã®ã¬ã¤ã¤ã¼æ°ã2ãã1ã«æ¸ããã¾ãã&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;è¨ç®éåº¦ã¯ãããããµã¤ãº16ã§ã8.6 step/sec ãããã§ãããGPUã¡ã¢ãªã®ä½¿ç¨éã¯9GBç¨åº¦ã§ãããConvolution Blockãã¨ã«Linearã¬ã¤ã¤ã¼ãè¿½å ãããã®ã§ããããªãã«ã¡ã¢ãªä½¿ç¨éãå¢ãã¾ããPyTorch v0.3.0ãä½¿ãã¾ããã&lt;/p&gt;
&lt;p&gt;å­¦ç¿ã«ä½¿ç¨ããã³ãã³ãã¯ä»¥ä¸ã§ãã&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-sh&#34;&gt;python train.py --data-root=./data/vctk --checkpoint-dir=checkpoints_vctk \
   --hparams=&amp;quot;preset=deepvoice3_vctk,builder=deepvoice3_multispeaker&amp;quot; \
   --log-event-path=log/deepvoice3_multispeaker_vctk_preset \
   --load-embedding=20171221_deepvoice3_checkpoint_step000300000.pth
 # &amp;lt;&amp;lt; 30ä¸ã¹ãããã§ä¸æ¦æã¡åã &amp;gt;&amp;gt;
 # ããä¸åº¦0ãã30ä¸ã¹ãããã¾ã§å­¦ç¿ããªãã
 python train.py --data-root=./data/vctk --checkpoint-dir=checkpoints_vctk_fineturn \
   --hparams=&amp;quot;preset=deepvoice3_vctk,builder=deepvoice3_multispeaker&amp;quot; \
   --log-event-path=log/deepvoice3_multispeaker_vctk_preset_fine \
   --restore-parts=./checkpoints_vctk/checkpont_step000300000.pth
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;å­¦ç¿ãé«éåãããããLJSpeechã§30ä¸ã¹ãããå­¦ç¿ããã¢ãã«ã®embeddingã®é¨åãåå©ç¨ãã¾ãããã¾ããcyclic annealingã®ãããªå¹æãå¾ããããã¨ãæå¾ãã¦ãä¸åº¦å­¦ç¿ãæã¡åã£ã¦ãããã«0stepãããã¡ã¤ã³ãã¥ã¼ãã³ã°ãã¦ã¿ã¾ããã&lt;/p&gt;
&lt;p&gt;ã³ã¼ãã®ã³ãããããã·ã¥ã¯ &lt;a href=&#34;https://github.com/r9y9/deepvoice3_pytorch/tree/0421749af908905d181f089f06956fddd0982d47&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;0421749&lt;/a&gt; ã§ããæ­£ç¢ºãªãã¤ãã¼ãã©ã¡ã¼ã¿ãç¥ãããå ´åã¯ãããããè¾¿ããã¨æãã¾ãã&lt;/p&gt;
&lt;h3 id=&#34;ã¢ã©ã¤ã¡ã³ãã®å­¦ç¿éç¨-30ä¸ã¹ããã&#34;&gt;ã¢ã©ã¤ã¡ã³ãã®å­¦ç¿éç¨ (~30ä¸ã¹ããã)&lt;/h3&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/images/deepvoice3_multispeaker/alignments.gif&#34; /&gt;&lt;/div&gt;
&lt;h3 id=&#34;å­¦ç¿ããã-speaker-embedding-ã®å¯è¦å&#34;&gt;å­¦ç¿ããã Speaker embedding ã®å¯è¦å&lt;/h3&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/images/deepvoice3_multispeaker/speaker_embedding.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;è«æã®appendixã«æ¸ããã¦ããã®ã¨åãããã«ãå­¦ç¿ãããEmbeddingã«å¯¾ãã¦PCAãããã¦å¯è¦åãã¾ãããè«æã®å³ã¨ã¯å°ãç°ãªãã¾ãããæå¾éããç·å¥³ã¯ã»ã¼ç·å½¢åé¢ã§ããããã«ãªã£ã¦ãããã¨ã¯ç¢ºèªã§ãã¾ããã&lt;/p&gt;
&lt;h3 id=&#34;é³å£°ãµã³ãã«&#34;&gt;é³å£°ãµã³ãã«&lt;/h3&gt;
&lt;p&gt;æåã«åã®ææ³ãè¿°ã¹ã¦ããã¨ãLJSpeechã§åä¸è©±èã¢ãã«ãå­¦ç¿ããå ´åã¨æ¯ã¹ãã¨ãæ±åãã«ããå°è±¡ãããã¾ãããæå­ãã¹ã­ãããããã¨ãã£ãã¨ã©ã¼ã±ã¼ã¹ãæ¯è¼ãã¦å¤ãããã«æãã¾ããã
ãããããµã³ãã«ãè²¼ãã®ã¯å¤§å¤ãªã®ã§ãèå³ã®ããæ¹ã¯èªåã§é©å½ãªæªç¥ãã­ã¹ããä¸ãã¦åæãã¦ã¿ã¦ãã ãããå­¦ç¿æ¸ã¿ã¢ãã«ã¯ &lt;a href=&#34;https://github.com/r9y9/deepvoice3_pytorch#pretrained-models&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;deepvoice3_pytorch#pretrained-models&lt;/a&gt; ãããã¦ã³ã­ã¼ãã§ããããã«ãã¦ããã¾ãã&lt;/p&gt;
&lt;h3 id=&#34;loophttpsytaigmangithubioloopnetwork-3-multiple-speakers-from-vctk-ã¨åãæç« &#34;&gt;&lt;a href=&#34;https://ytaigman.github.io/loop/#network-3-multiple-speakers-from-vctk&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Loop&lt;/a&gt; ã¨åãæç« &lt;/h3&gt;
&lt;p&gt;Some have accepted this as a miracle without any physical explanation&lt;/p&gt;
&lt;p&gt;(69 chars, 11 words)&lt;/p&gt;
&lt;p&gt;speaker IDãè¥ãé ã«12ãµã³ãã«ã®è©±èID ãä¸ãã¦ãåæããçµæãè²¼ã£ã¦ããã¾ãã&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;225, 23,  F,    English,    Southern,  England&lt;/strong&gt; (ID, AGE,  GENDER,  ACCENTS,  REGION)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/deepvoice3_multispeaker/loop/0_20171222_deepvoice3_vctk108_checkpoint_step000300000_speaker0.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;&lt;strong&gt;226,  22,  M,    English,    Surrey&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/deepvoice3_multispeaker/loop/0_20171222_deepvoice3_vctk108_checkpoint_step000300000_speaker1.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;&lt;strong&gt;227,  38,  M,    English,    Cumbria&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/deepvoice3_multispeaker/loop/0_20171222_deepvoice3_vctk108_checkpoint_step000300000_speaker2.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;&lt;strong&gt;228,  22,  F,    English,    Southern  England&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/deepvoice3_multispeaker/loop/0_20171222_deepvoice3_vctk108_checkpoint_step000300000_speaker3.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;&lt;strong&gt;229,  23,  F,    English,    Southern  England&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/deepvoice3_multispeaker/loop/0_20171222_deepvoice3_vctk108_checkpoint_step000300000_speaker4.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;&lt;strong&gt;230,  22,  F,    English,    Stockton-on-tees&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/deepvoice3_multispeaker/loop/0_20171222_deepvoice3_vctk108_checkpoint_step000300000_speaker5.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;&lt;strong&gt;231,  23,  F,    English,    Southern  England&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/deepvoice3_multispeaker/loop/0_20171222_deepvoice3_vctk108_checkpoint_step000300000_speaker6.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;&lt;strong&gt;232,  23,  M,    English,    Southern  England&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/deepvoice3_multispeaker/loop/0_20171222_deepvoice3_vctk108_checkpoint_step000300000_speaker7.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;&lt;strong&gt;233,  23,  F,    English,    Staffordshire&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/deepvoice3_multispeaker/loop/0_20171222_deepvoice3_vctk108_checkpoint_step000300000_speaker8.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;&lt;strong&gt;234,  22,  F,    Scottish,  West  Dumfries&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/deepvoice3_multispeaker/loop/0_20171222_deepvoice3_vctk108_checkpoint_step000300000_speaker9.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;&lt;strong&gt;236,  23,  F,    English,    Manchester&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/deepvoice3_multispeaker/loop/0_20171222_deepvoice3_vctk108_checkpoint_step000300000_speaker10.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;&lt;strong&gt;237,  22,  M,    Scottish,  Fife&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/deepvoice3_multispeaker/loop/0_20171222_deepvoice3_vctk108_checkpoint_step000300000_speaker11.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;å£°è³ªã ãã§ãªããè©±éã«ãããªã¨ã¼ã·ã§ã³ãåºã¦ããã®ããããã¾ãã&lt;code&gt;231&lt;/code&gt; ã®æåã§ä¸é¨é³ãæ¶ãã¦ãã¾ãï¼ãããã£ãã¨ã©ã¼ã±ã¼ã¹ã¯ããããã¾ãï¼ã&lt;/p&gt;
&lt;h4 id=&#34;keithitotacotron-ã®ãµã³ãã«httpskeithitogithubioaudio-samples-ã¨åãæç« &#34;&gt;&lt;a href=&#34;https://keithito.github.io/audio-samples/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;keithito/tacotron ã®ãµã³ãã«&lt;/a&gt; ã¨åãæç« &lt;/h4&gt;
&lt;p&gt;ç°¡åã«æ±åæ§è½ããã§ãã¯ããããã«ãæªç¥æç« ã§ãã¹ããã¾ãã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ç·æ§ (292,  23,  M,    NorthernIrish,  Belfast)&lt;/li&gt;
&lt;li&gt;å¥³æ§ (288,  22,  F,    Irish,  Dublin)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ã®äºã¤ã®ãµã³ãã«ãè²¼ã£ã¦ããã¾ãã&lt;/p&gt;
&lt;p&gt;Scientists at the CERN laboratory say they have discovered a new particle.&lt;/p&gt;
&lt;p&gt;(74 chars, 13 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/deepvoice3_multispeaker/3_keithito/0_20171222_deepvoice3_vctk108_checkpoint_step000300000_speaker62.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/deepvoice3_multispeaker/3_keithito/0_20171222_deepvoice3_vctk108_checkpoint_step000300000_speaker62_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/deepvoice3_multispeaker/3_keithito/0_20171222_deepvoice3_vctk108_checkpoint_step000300000_speaker61.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/deepvoice3_multispeaker/3_keithito/0_20171222_deepvoice3_vctk108_checkpoint_step000300000_speaker61_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;There&amp;rsquo;s a way to measure the acute emotional intelligence that has never gone out of style.&lt;/p&gt;
&lt;p&gt;(91 chars, 18 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/deepvoice3_multispeaker/3_keithito/1_20171222_deepvoice3_vctk108_checkpoint_step000300000_speaker62.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/deepvoice3_multispeaker/3_keithito/1_20171222_deepvoice3_vctk108_checkpoint_step000300000_speaker62_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/deepvoice3_multispeaker/3_keithito/1_20171222_deepvoice3_vctk108_checkpoint_step000300000_speaker61.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/deepvoice3_multispeaker/3_keithito/1_20171222_deepvoice3_vctk108_checkpoint_step000300000_speaker61_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;President Trump met with other leaders at the Group of 20 conference.&lt;/p&gt;
&lt;p&gt;(69 chars, 13 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/deepvoice3_multispeaker/3_keithito/2_20171222_deepvoice3_vctk108_checkpoint_step000300000_speaker62.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/deepvoice3_multispeaker/3_keithito/2_20171222_deepvoice3_vctk108_checkpoint_step000300000_speaker62_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/deepvoice3_multispeaker/3_keithito/2_20171222_deepvoice3_vctk108_checkpoint_step000300000_speaker61.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/deepvoice3_multispeaker/3_keithito/2_20171222_deepvoice3_vctk108_checkpoint_step000300000_speaker61_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;The Senate&amp;rsquo;s bill to repeal and replace the Affordable Care Act is now imperiled.&lt;/p&gt;
&lt;p&gt;(81 chars, 16 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/deepvoice3_multispeaker/3_keithito/3_20171222_deepvoice3_vctk108_checkpoint_step000300000_speaker62.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/deepvoice3_multispeaker/3_keithito/3_20171222_deepvoice3_vctk108_checkpoint_step000300000_speaker62_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/deepvoice3_multispeaker/3_keithito/3_20171222_deepvoice3_vctk108_checkpoint_step000300000_speaker61.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/deepvoice3_multispeaker/3_keithito/3_20171222_deepvoice3_vctk108_checkpoint_step000300000_speaker61_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;Generative adversarial network or variational auto-encoder.&lt;/p&gt;
&lt;p&gt;(59 chars, 7 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/deepvoice3_multispeaker/3_keithito/4_20171222_deepvoice3_vctk108_checkpoint_step000300000_speaker62.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/deepvoice3_multispeaker/3_keithito/4_20171222_deepvoice3_vctk108_checkpoint_step000300000_speaker62_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/deepvoice3_multispeaker/3_keithito/4_20171222_deepvoice3_vctk108_checkpoint_step000300000_speaker61.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/deepvoice3_multispeaker/3_keithito/4_20171222_deepvoice3_vctk108_checkpoint_step000300000_speaker61_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;The buses aren&amp;rsquo;t the problem, they actually provide a solution.&lt;/p&gt;
&lt;p&gt;(63 chars, 13 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/deepvoice3_multispeaker/3_keithito/5_20171222_deepvoice3_vctk108_checkpoint_step000300000_speaker62.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/deepvoice3_multispeaker/3_keithito/5_20171222_deepvoice3_vctk108_checkpoint_step000300000_speaker62_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/deepvoice3_multispeaker/3_keithito/5_20171222_deepvoice3_vctk108_checkpoint_step000300000_speaker61.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/deepvoice3_multispeaker/3_keithito/5_20171222_deepvoice3_vctk108_checkpoint_step000300000_speaker61_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;ã¨ããã©ããé³ãæãã¦ããã®ãç®ç«ã¡ã¾ããè²ãå®é¨ãã¾ãããããã¯ãåä¸è©±è 24hã®ãã¼ã¿ã§å­¦ç¿ããã¢ãã«ã«æ¯ã¹ãã¨ãä¸è©±èããã30å~1hç¨åº¦ã®ãã¼ã¿ã§ã¯ãæ±åãããã®ãé£ããå°è±¡ãæã¡ã¾ããã&lt;/p&gt;
&lt;h2 id=&#34;ã¾ã¨ã&#34;&gt;ã¾ã¨ã&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;è¤æ°è©±èçã®DeepVoice3ãå®è£ãã¦ãå®éã«108è©±èã®ãã¼ã¿ã»ããã§å­¦ç¿ãããããªãã«åããã¨ãç¢ºèªã§ãã¾ãã&lt;/li&gt;
&lt;li&gt;è¤æ°è©±èçã®DeepVoice3ã§ã¯ãã¢ãã³ã·ã§ã³ã®å­¦ç¿ãåä¸è©±èã®å ´åã¨æ¯ã¹ã¦é£ããå°è±¡ã§ãããã¢ãã³ã·ã§ã³ã¬ã¤ã¤ã¼ã®æ°ã2ãã1ã«æ¸ããã¨ãã¢ã©ã¤ã¡ã³ãããã£ããããå¾åã«ãããã¨ãç¢ºèªãã¾ããã&lt;/li&gt;
&lt;li&gt;VCTKã®åå¦çå¤§äºããã¡ãã¨ãã¾ããã&lt;/li&gt;
&lt;li&gt;Speaker embedding ã«Dropoutããããã®ã¯ãè«æã«ã¯è¨è¼ããã¦ãã¾ããããçµæããè¨ã£ã¦éè¦ã§ããããªãã¨ãé³å£°ã®åè³ªä»¥åã®åé¡ã¨ãã¦ãæå­ãæ­£ããçºé³ãããªããã¨ãã£ãç¾è±¡ã«é­éãã¾ããã&lt;/li&gt;
&lt;li&gt;Speaker embedding ããã¹ã¦ã®æå»ã«åä¸ã®å¤ãexpandãã¦ãã¾ãã¨éå­¦ç¿ããããã®ã§ã¯ãªããããäºæ¸¬ãåã«ãåæå»ã§ã©ã³ãã æ§ãããããã¨ã§ãã®åé¡ãç·©åã§ããªããã¨èããDropoutãè¶³ãã¦ã¿ã¾ãããä¸æãè¨ã£ãããã«æãã¾ã&lt;/li&gt;
&lt;li&gt;è«æã®åå®¹ã«ã¤ãã¦è©³ããè§¦ãã¦ãã¾ããããå®ã¯ãã£ããéã¨ããããæç« ã¨å³ã«ä¸ä¸è´ããã£ãããã¾ãï¼ä¾ãã°å³1ã«ããEncoder PreNet/PostNet ã¯æç« ä¸­ã§èª¬æããªãï¼ãèèã«é£çµ¡ãã¦ç¢ºèªããã®ãä¸çªè¯ãã®ã§ãããã©ãããã¢ãã«ãªãä¸æããããèãã¦è©¦è¡é¯èª¤ããã®ãæ¥½ããã®ã§ãä»åã¯é°å²æ°ã§å®è£ãã¾ããããããªãã«ä¸æãåãã¦ããããã«æãã¾ã&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;æ¬¡ã¯ãDeepVoice3ãTacotron 2 (&lt;a href=&#34;https://arxiv.org/abs/1712.0588&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;arXiv:1712.05884 [cs.CL]&lt;/a&gt;) ã§æå¹æ§ãç¤ºããã¦ãã WaveNet Vocoder ãå®è£ãã¦ãåè³ªãæ¹åãã¦ã¿ããã¨æã£ã¦ãã¾ãã&lt;/p&gt;
&lt;h2 id=&#34;åè&#34;&gt;åè&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1710.07654&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Wei Ping, Kainan Peng, Andrew Gibiansky, et al, &amp;ldquo;Deep Voice 3: 2000-Speaker Neural Text-to-Speech&amp;rdquo;, arXiv:1710.07654, Oct. 2017.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1705.08947&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Sercan Arik, Gregory Diamos, Andrew Gibiansky,, et al, &amp;ldquo;Deep Voice 2: Multi-Speaker Neural Text-to-Speech&amp;rdquo;, arXiv:1705.08947, May 2017.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1712.05884&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Jonathan Shen, Ruoming Pang, Ron J. Weiss, et al, &amp;ldquo;Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions&amp;rdquo;, arXiv:1712.05884, Dec 2017.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;é¢é£è¨äº&#34;&gt;é¢é£è¨äº&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://r9y9.github.io/blog/2017/12/13/deepvoice3/&#34;&gt;ãåä¸è©±èç·¨ãDeep Voice 3: 2000-Speaker Neural Text-to-Speech / arXiv:1710.07654 [cs.SD] | LESS IS MORE&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://r9y9.github.io/blog/2017/11/23/dctts/&#34;&gt;Efficiently Trainable Text-to-Speech System Based on Deep Convolutional Networks with Guided Attention. [arXiv:1710.08969] | LESS IS MORE&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://r9y9.github.io/blog/2017/11/12/jsut_ver1/&#34;&gt;æ¥æ¬èª End-to-end é³å£°åæã«ä½¿ããã³ã¼ãã¹ JSUT ã®åå¦ç | LESS IS MORE&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;VCTKã®ç¡é³åºéé¤å»ã®ããã¨ããæèã§ã¯ãªãããã­ã¹ãã«short pause / long pause ãæ¿å¥ããããã§ã&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34;&gt;
&lt;p&gt;transcriptionããªã1è©±è (p315) ã®ãã¼ã¿ã¯é¤ãã¦ãã¾ã&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34;&gt;
&lt;p&gt;Dropoutããã¤ãããã¨ã­ã¹ãä¸ããã«ãããä¸æ¹ã§ãããããã¨æ±åãã«ããå°è±¡ãããã¾ãããã®ã§ãDropoutãã¤ãã§ããç¨åº¦æ±åããããã¨ãDropoutããããã«ãã¦fine turningãããã¨ãã£ãæ¦ç¥ãåã£ã¦ã¿ã¾ããã&amp;#160;&lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>ãã¥ã¼ã©ã«ãããã®å­¦ç¿éç¨ã®å¯è¦åãé¡æã«ãJupyter &#43; Bokeh ã§åçãªæç»ãè¡ãæ¹æ³ã®ç´¹ä» [Jupyter Advent Calendar 2017]</title>
      <link>https://r9y9.github.io/blog/2017/12/14/jupyter-bokeh/</link>
      <pubDate>Thu, 14 Dec 2017 00:00:30 +0900</pubDate>
      <guid>https://r9y9.github.io/blog/2017/12/14/jupyter-bokeh/</guid>
      <description>&lt;p&gt;Line &lt;a href=&#34;https://bokeh.pydata.org/en/latest/docs/reference/models/glyphs/line.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://bokeh.pydata.org/en/latest/docs/reference/models/glyphs/line.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://r9y9.github.io/images/jupyter_with_bokeh_files/jupyter_with_bokeh_3_1.png&#34; alt=&#34;png&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;VBar &lt;a href=&#34;https://bokeh.pydata.org/en/latest/docs/reference/models/glyphs/vbar.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://bokeh.pydata.org/en/latest/docs/reference/models/glyphs/vbar.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://r9y9.github.io/images/jupyter_with_bokeh_files/jupyter_with_bokeh_3_3.png&#34; alt=&#34;png&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;HBar &lt;a href=&#34;https://bokeh.pydata.org/en/latest/docs/reference/models/glyphs/hbar.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://bokeh.pydata.org/en/latest/docs/reference/models/glyphs/hbar.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://r9y9.github.io/images/jupyter_with_bokeh_files/jupyter_with_bokeh_3_5.png&#34; alt=&#34;png&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;ImageRGBA &lt;a href=&#34;https://bokeh.pydata.org/en/latest/docs/reference/models/glyphs/image_rgba.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://bokeh.pydata.org/en/latest/docs/reference/models/glyphs/image_rgba.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://r9y9.github.io/images/jupyter_with_bokeh_files/jupyter_with_bokeh_3_7.png&#34; alt=&#34;png&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;ImageRGBA &lt;a href=&#34;https://bokeh.pydata.org/en/latest/docs/reference/models/glyphs/image_rgba.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://bokeh.pydata.org/en/latest/docs/reference/models/glyphs/image_rgba.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://r9y9.github.io/images/jupyter_with_bokeh_files/jupyter_with_bokeh_3_9.png&#34; alt=&#34;png&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h2 id=&#34;åç½®ã&#34;&gt;åç½®ã&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://qiita.com/advent-calendar/2017/jupyter&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Jupyter Advent Calendar 2017&lt;/a&gt; 14æ¥ç®ã®è¨äºã§ãããã®è¨äºã¯ãJupyter notebookã§ä½æãããã®ãnbconvertã§markdownã«å¤æããæã§å°ãä¿®æ­£ãã¦ä½ãã¾ãããèª­ã¿ç©ã¨ãã¦ã¯ãã®è¨äºããå®è¡ããã«ã¯ãã¼ãããã¯ã®æ¹ãåç§ãã¦ããã ãã®ãè¯ããã¨æãã¾ãã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://gist.github.com/r9y9/d57e797c28f6cdc4e44264411c21b76f&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ãã¼ãããã¯ (gist)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://nbviewer.jupyter.org/gist/r9y9/d57e797c28f6cdc4e44264411c21b76f&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;nbviewer&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;æ¦è¦&#34;&gt;æ¦è¦&lt;/h2&gt;
&lt;p&gt;é©å½ãªãã¥ã¼ã©ã«ãããã®å­¦ç¿éç¨ã®å¯è¦åï¼ã­ã¹ãæ­£è§£çã®é·ç§»ç­ï¼ãé¡æã«ãã¦ã&lt;a href=&#34;https://bokeh.pydata.org/en/latest/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Bokeh&lt;/a&gt;ãä½¿ã£ã¦åçã«ã°ã©ããæ´æ°ãã¦ãããã¨ã«ããå¯è¦åã®å®ç¨ä¾ãç´¹ä»ãã¾ãããã®ãã¼ãããã¯ã®åé ­ã«ãæå¾ã¾ã§å®è¡ããã¨å¾ãããã°ã©ãä¸è¦§ãã¾ã¨ãã¾ãããã©ããã£ã¦ã°ã©ããä½ãã®ãç¥ãããæ¹ã¯ç¶ããèª­ãã§ããããã°ã¨æãã¾ããBokehã®è©³ç´°ãªä½¿ãæ¹ã¯ãå¬å¼ãã­ã¥ã¡ã³ããåèã«ãã¦ãã ããã&lt;/p&gt;
&lt;p&gt;ãªããããã§ç´¹ä»ããä¾ã¯ãåãéå»ã«åºãæ©æ¢°å­¦ç¿ã®ã³ã³ã (&lt;a href=&#34;https://deepanalytics.jp/compe/36?tab=compedetail&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://deepanalytics.jp/compe/36?tab=compedetail&lt;/a&gt;) ã§å®éã«ä½¿ç¨ããã³ã¼ãããã»ã¼åã£ã¦ãã¾ããï¼8/218ä½ã§ããï¼ãã°ã©ããåçã«æ´æ°ããæ¹æ³ã¯ &lt;a href=&#34;https://bokeh.pydata.org/en/latest/docs/user_guide/notebook.html#notebook-handles&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;å¬å¼ãã­ã¥ã¡ã³ã&lt;/a&gt; ã«è¨è¿°ããã¦ãã¾ããããã®ãµã³ãã«ã®åå®¹ã¯ãåãæç»ãã¦è²ãå¤ãããã¨ãã£ãå®ç¨æ§çç¡ã®ãã®ã§ãããã¨ãã¾ãã°ã°ã£ã¦ãä¾ãå¤ãè¦ã¤ãããªããã¨ããããã®ãããªç´¹ä»è¨äºãæ¸ããã¨ã«ãã¾ãããåèã«ãªãã°å¹¸ãã§ãã&lt;/p&gt;
&lt;p&gt;ä½è«ã§ã¯ããã¾ããããã¨æ©æ¢°å­¦ç¿ã«é¢ãã¦ã¯ãtensorboardãä½¿ã£ãã»ããç°¡åã§è¯ãã¨æãã¾ããåã¯æè¿ãããã¦ãã¾ãã &lt;a href=&#34;https://qiita.com/r9y9/items/d54162d37ec4f110f4b4&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://qiita.com/r9y9/items/d54162d37ec4f110f4b4&lt;/a&gt;. è²ãªãä½ç½®ãªãå¤§ãããªããæè»ã«ã«ã¹ã¿ãã¤ãºãããããããã¯ãã¼ãããã¯ã§å¦çãå®çµãããããã¨è¨ã£ãå ´åã«ã¯ãããã§ç´¹ä»ããæ¹æ³ãè¯ãããããã¾ããã&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;%pylab inline
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Populating the interactive namespace from numpy and matplotlib
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from IPython.display import HTML, Image
import IPython
from os.path import exists

def summary():
    baseurl = &amp;quot;https://bokeh.pydata.org/en/latest/docs/reference/models/glyphs/&amp;quot;
    for (name, figname, url) in [
        (&amp;quot;Line&amp;quot;, &amp;quot;line&amp;quot;, &amp;quot;line.html&amp;quot;),
        (&amp;quot;VBar&amp;quot;, &amp;quot;vbar&amp;quot;, &amp;quot;vbar.html&amp;quot;),
        (&amp;quot;HBar&amp;quot;, &amp;quot;hbar&amp;quot;, &amp;quot;hbar.html&amp;quot;),
        (&amp;quot;ImageRGBA&amp;quot;, &amp;quot;gray_image&amp;quot;, &amp;quot;image_rgba.html&amp;quot;),
        (&amp;quot;ImageRGBA&amp;quot;, &amp;quot;inferno_image&amp;quot;, &amp;quot;image_rgba.html&amp;quot;),
        ]:
        gif = &amp;quot;./fig/{}.gif&amp;quot;.format(figname)
        print(&amp;quot;\n&amp;quot;,name, baseurl + url)
        if exists(gif):
            with open(gif, &#39;rb&#39;) as f:
                IPython.display.display(Image(data=f.read()), format=&amp;quot;gif&amp;quot;)

summary()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;(â»ãã­ã°åé ­ã«è²¼ã£ãã®ã§çç¥ãã¾ã)&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# True ã«ãã¦ãã¼ãããã¯ãå®è¡ããã¨ãä¸è¨gifã®åã¨ãªãç»åãä¿å­ããæå¾ã«gifãçæãã
save_img = False
if save_img:
    import os
    from os.path import exists
    if not exists(&amp;quot;./fig&amp;quot;):
        os.makedirs(&amp;quot;./fig&amp;quot;)
    toolbar_location = None
else:
    toolbar_location = &amp;quot;above&amp;quot;

# bokehã§æç»ããã°ã©ãã¯notebookã«æ®ããªãã®ã§ãTrueã®å ´åã¯ä»£ããã«äºåã«ä¿å­ãã¦ããgifãæç»ãã
# ããã­ã¼ã«ã«ã§å®è¡ããã¨ãã¯ãFalseã«ãã¦ãã ãã
show_static = True
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;æºå&#34;&gt;æºå&lt;/h2&gt;
&lt;p&gt;åè¿°ã®éãããã¥ã¼ã©ã«ãããã®å­¦ç¿éç¨ã®å¯è¦åãé¡æã¨ãã¦ãJupyterä¸ã§ã®Bokehã®ä½¿ãæ¹ãç´¹ä»ãã¦ããããã¨æãã¾ããä»åã¯ãPyTorch (v0.3.0) ãä½¿ã£ã¦ãã¥ã¼ã©ã«ãããã®å­¦ç¿ã®ã³ã¼ããæ¸ãã¾ããã&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/pytorch/examples/tree/master/mnist&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/pytorch/examples/tree/master/mnist&lt;/a&gt; ããã¼ã¹ã«ãå¯è¦åããããããã«å°ããããã¾ããã&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import datasets, transforms
from torch.autograd import Variable
import numpy as np
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;data&#34;&gt;Data&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;use_cuda = torch.cuda.is_available()

batch_size = 128

kwargs = {&#39;num_workers&#39;: 1, &#39;pin_memory&#39;: True} if use_cuda else {}
train_loader = torch.utils.data.DataLoader(
    datasets.MNIST(&#39;./data&#39;, train=True, download=True,
                   transform=transforms.Compose([
                       transforms.ToTensor()
                   ])),
    batch_size=batch_size, shuffle=True, **kwargs)
test_loader = torch.utils.data.DataLoader(
    datasets.MNIST(&#39;./data&#39;, train=False, transform=transforms.Compose([
                       transforms.ToTensor(),
                   ])),
    batch_size=batch_size, shuffle=False, **kwargs)

data_loaders = {&amp;quot;train&amp;quot;: train_loader, &amp;quot;test&amp;quot;:test_loader}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;model&#34;&gt;Model&lt;/h3&gt;
&lt;p&gt;ç°¡åãªç³ã¿è¾¼ã¿ãã¥ã¼ã©ã«ãããã§ãã&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)
        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)
        self.conv2_drop = nn.Dropout2d()
        self.fc1 = nn.Linear(320, 50)
        self.fc2 = nn.Linear(50, 10)

    def forward(self, x):
        x = F.relu(F.max_pool2d(self.conv1(x), 2))
        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))
        x = x.view(-1, 320)
        x = F.relu(self.fc1(x))
        x = F.dropout(x, training=self.training)
        x = self.fc2(x)
        return F.log_softmax(x, dim=-1)
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;train-loop&#34;&gt;Train loop&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from tqdm import tnrange
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;epochs = 20

def __train_loop(model, data_loaders, optimizer, epoch, phase):
    model = model.train() if phase == &amp;quot;train&amp;quot; else model.eval()
    running_loss = 0
    running_corrects = 0
    corrects = [0]*10
    counts = [0]*10
    for batch_idx, (x, y) in enumerate(data_loaders[phase]):
        x = x.cuda() if use_cuda else x
        y = y.cuda() if use_cuda else y
        x, y = Variable(x), Variable(y)
        optimizer.zero_grad()
        y_hat = model(x)

        # loss
        loss = F.nll_loss(y_hat, y)

        # update
        if phase == &amp;quot;train&amp;quot;:
            loss.backward()
            optimizer.step()
        running_loss += loss.data[0]

        # predict
        preds = torch.max(y_hat.data, 1)[1]
        match = (preds == y.data).cpu()
        running_corrects += match.sum()

        # ã«ãã´ãªãã¨ã®æ­£è§£çãåºãã®ã«ã»ãã
        for i in range(len(match)):
            if match.view(-1)[i] &amp;gt; 0:
                corrects[y.data.view(-1)[i]] += 1
        for i in range(len(match)):
            counts[y.data.view(-1)[i]] += 1

    # epoch-wise metrics
    l = running_loss / len(data_loaders[phase])
    acc = running_corrects / len(data_loaders[phase].dataset)
    return {&amp;quot;loss&amp;quot;: l, &amp;quot;acc&amp;quot;: acc, &amp;quot;corrects&amp;quot;: corrects, &amp;quot;counts&amp;quot;: counts}

def train_loop(model, data_loaders, optimizer, epochs=12, callback=None):
    history = {&amp;quot;train&amp;quot;: {}, &amp;quot;test&amp;quot;: {}}
    for epoch in tnrange(epochs):
        for phase in [&amp;quot;train&amp;quot;, &amp;quot;test&amp;quot;]:
            d = __train_loop(model, data_loaders, optimizer, epoch, phase)
            for k,v in d.items():
                try:
                    history[phase][k].append(v)
                except KeyError:
                    history[phase][k] = [v]

            # ããã§ã°ã©ãã®æ´æ°ãå¼ã¶æ³å®ã§ã
            if callback is not None:
                callback.on_epoch_end(epoch, phase, history)
    return history
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;æ¬ç·¨&#34;&gt;æ¬ç·¨&lt;/h2&gt;
&lt;h3 id=&#34;0-matplotlib&#34;&gt;0. Matplotlib&lt;/h3&gt;
&lt;p&gt;ã¾ãã¯ããã«ãåçã§ã¯ãªãï¼éçãªï¼ã°ã©ãã®ä¾ãç¤ºãã¾ããææ¸ãæ°å­èªè­ã®ãããªè­å¥ã¿ã¹ã¯ã«ããã¦ãæãä¸è¬çã§ããã¨æãããè©ä¾¡å°ºåº¦ã¨ãã¦ãã­ã¹ã¨æ­£è§£çãå¯è¦åãã¾ãã&lt;code&gt;train_loop&lt;/code&gt;é¢æ°ã¯ãè¿ãå¤ã«ã­ã¹ã¨æ­£è§£çã®historyãè¿ãããã«ããã®ã§ããããä½¿ã£ã¦ã°ã©ããä½ãã¾ãã&lt;/p&gt;
&lt;p&gt;å³ã®ä½æã«ã¯ããããªãã¼ã«ãããã¨æãã®ã§ãããmatplotlibãå®çªã§ï¼åã¯ï¼å¤§ããªä¸æºããªãã®ã§ãããä½¿ã£ã¦ãã¾ãã&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;model = Net().cuda() if use_cuda else Net()
optimizer = optim.Adadelta(model.parameters())
history = train_loop(model, data_loaders, optimizer, epochs)
print(&amp;quot;Test loss: {:.3f}&amp;quot;.format(history[&amp;quot;train&amp;quot;][&amp;quot;loss&amp;quot;][-1]))
print(&amp;quot;Test acc: {:.3f}&amp;quot;.format(history[&amp;quot;test&amp;quot;][&amp;quot;acc&amp;quot;][-1]))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Test loss: 0.111
Test acc: 0.989
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;matplotlib.pyplot.figure(figsize=(16,6))
subplot(1,2,1)
plot(history[&amp;quot;train&amp;quot;][&amp;quot;loss&amp;quot;], linewidth=3, color=&amp;quot;red&amp;quot;, label=&amp;quot;train loss&amp;quot;)
plot(history[&amp;quot;test&amp;quot;][&amp;quot;loss&amp;quot;], linewidth=3, color=&amp;quot;blue&amp;quot;, label=&amp;quot;test lsos&amp;quot;)
xlabel(&amp;quot;epoch&amp;quot;, fontsize=16)
legend(prop={&amp;quot;size&amp;quot;: 16})
subplot(1,2,2)
plot(history[&amp;quot;train&amp;quot;][&amp;quot;acc&amp;quot;], linewidth=3, color=&amp;quot;red&amp;quot;, label=&amp;quot;train acc&amp;quot;)
plot(history[&amp;quot;test&amp;quot;][&amp;quot;acc&amp;quot;], linewidth=3, color=&amp;quot;blue&amp;quot;, label=&amp;quot;test acc&amp;quot;)
xlabel(&amp;quot;epoch&amp;quot;, fontsize=16)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;matplotlib.text.Text at 0x7f16fa9ca438&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://r9y9.github.io/images/jupyter_with_bokeh_files/jupyter_with_bokeh_16_1.png&#34; alt=&#34;png&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h3 id=&#34;1-line&#34;&gt;1. Line&lt;/h3&gt;
&lt;p&gt;æ¬¡ã«ãä¸è¨ã®ç·ã°ã©ãããBokehãä½¿ã£ã¦ä½ã£ã¦ã¿ã¾ããããã«ã¯ã &lt;a href=&#34;https://bokeh.pydata.org/en/latest/docs/reference/models/glyphs/line.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://bokeh.pydata.org/en/latest/docs/reference/models/glyphs/line.html&lt;/a&gt; ãä½¿ãã¾ãã&lt;/p&gt;
&lt;p&gt;bokehã§ä½ã£ãã°ã©ããnotebookã«inline plotããããã«ã¯ã&lt;a href=&#34;https://bokeh.pydata.org/en/latest/docs/reference/io.html#bokeh.io.output_notebook&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;bokeh.io.output_notebook&lt;/a&gt; ãå¼ã³åºãã¦ããå¿è¦ãããã¾ãã&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import bokeh
import bokeh.io
from bokeh.io import push_notebook, show, output_notebook
from bokeh.plotting import figure
try:
    # å°ãå¤ãbokehã ã¨ãã£ã¡
    from bokeh.io import gridplot
except ImportError:
    from bokeh.layouts import gridplot

output_notebook()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;æ¬¡ã«å®ç¾©ãã &lt;code&gt;LinePlotsCallback&lt;/code&gt; ã¯ãã°ã©ãã®æå ±ããã­ããã£ã«ä¿æãã&lt;code&gt;on_epoch_end&lt;/code&gt; ã§å­¦ç¿çµæã®hisotoryãåãåã£ã¦ãã­ã¹ã¨æ­£è§£çã®ã°ã©ããæ´æ°ãã¾ãã historyã«ã¯ãä»åã®å ´åã¯ã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ã­ã¹ (float)&lt;/li&gt;
&lt;li&gt;æ­£è§£ç (float)&lt;/li&gt;
&lt;li&gt;ã«ãã´ãªæ¯ã®ç·ãµã³ãã«æ° (list)&lt;/li&gt;
&lt;li&gt;ã«ãã´ãªæ¯ã®æ­£è§£ãµã³ãã«æ° (list)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ã®4ã¤ãå«ããããã«å®è£ãã¾ãã (&lt;code&gt;train_loop&lt;/code&gt; é¢æ°ãåç§)ã&lt;code&gt;LinePlotsCallback&lt;/code&gt; ã§ã¯ããã®ãã¡ã­ã¹ã¨æ­£è§£çãéæåãåã£ã¦ãã°ã©ããæ´æ°ãã¾ãã&lt;code&gt;Line&lt;/code&gt; ãªãã¸ã§ã¯ãã®æ´æ°ã«ã¯ã&lt;code&gt;data_source.data[&amp;quot;x&amp;quot;]&lt;/code&gt;, &lt;code&gt;data_source.data[&amp;quot;y&amp;quot;]&lt;/code&gt; ã«éæå¤ãè¿½å ãã¦ãããã¨ã§è¡ãã¾ãã&lt;/p&gt;
&lt;p&gt;ä»¥éç¤ºãã°ã©ãã§ãåããªã®ã§ãããã°ã©ããçæããåºæ¬çãªæé ãã¾ã¨ããã¨ã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://bokeh.pydata.org/en/latest/docs/reference/plotting.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;bokeh.plotting.figure&lt;/a&gt; ã«ãããfigureãªãã¸ã§ã¯ããçæãã&lt;/li&gt;
&lt;li&gt;çæããfigureãªãã¸ã§ã¯ãã«å¯¾ãã¦ãç·ã°ã©ããæ£ã°ã©ãã¨ãã£ããã¼ã (ã¬ã³ãã©ãbokehã§ã¯&lt;a href=&#34;https://bokeh.pydata.org/en/latest/docs/reference/models/glyphs.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;glyphs&lt;/a&gt;ã¨å¼ã¶) ãçæãã&lt;/li&gt;
&lt;li&gt;(ä»åã¯æ ¼å­ç¶ã«å³ãéç½®ãããã£ãã®ã§ï¼è¤æ°ã®figureãªãã¸ã§ã¯ããgridä¸ã«ã¬ã¤ã¢ã¦ããã&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ã¨ãªã£ã¦ãã¾ããæ ¼å­ç¶ã«éç½®ããªãå ´åã¯æå¾ã®ã¹ãããã¯ä¸è¦ã§ãããä¾¿å©ãªã®ã§ä½¿ãã¾ãã&lt;/p&gt;
&lt;p&gt;ã°ã©ãã®æ´æ°ã¯ãã¬ã³ãã©ã«å¤ãã»ãããããã¨ã«ã&lt;a href=&#34;https://bokeh.pydata.org/en/latest/docs/reference/io.html#bokeh.io.push_notebook&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;bokeh.io.push_notebook&lt;/a&gt; ãå¼ã³åºããã¨ã§è¡ãã¾ãã&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;class LinePlotsCallback(object):
    def __init__(self, epochs=epochs, batch_size=batch_size):
        # Epochæ¯
        p1 = figure(title=&amp;quot;Loss&amp;quot;, plot_height=300, plot_width=350,
                        y_range=(0, 0.5), x_range=(-1, epochs+1))
        p2 = figure(title=&amp;quot;Acc&amp;quot;, plot_height=300, plot_width=350,
                        y_range=(0.8, 1.0), x_range=(-1, epochs+1))

        self.renderers = {&amp;quot;train&amp;quot;:{}, &amp;quot;test&amp;quot;:{}}

        # èµ¤: train, é: ãã¹ã
        for phase, c in [(&amp;quot;train&amp;quot;, &amp;quot;red&amp;quot;), (&amp;quot;test&amp;quot;, &amp;quot;blue&amp;quot;)]:
            for (p, key) in [(p1, &amp;quot;loss&amp;quot;), (p2, &amp;quot;acc&amp;quot;)]:
                self.renderers[phase][key] = p.line([], [], color=c, line_width=3)

        self.graph = gridplot([p1, p2], ncols=2, toolbar_location=toolbar_location)


    def on_epoch_end(self, epoch, phase, history):
        for key in [&amp;quot;loss&amp;quot;, &amp;quot;acc&amp;quot;]:
            self.renderers[phase][key].data_source.data[&amp;quot;x&amp;quot;].append(epoch)
            self.renderers[phase][key].data_source.data[&amp;quot;y&amp;quot;].append(history[phase][key][-1])
        push_notebook()
        if save_img:
            bokeh.io.export_png(self.graph, &amp;quot;fig/{:02d}_line.png&amp;quot;.format(epoch))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;callback = LinePlotsCallback()
if show_static:
    if exists(&amp;quot;fig/line.gif&amp;quot;):
        with open(&amp;quot;fig/line.gif&amp;quot;, &#39;rb&#39;) as f:
            IPython.display.display(Image(data=f.read()), format=&amp;quot;gif&amp;quot;)
else:
    bokeh.io.show(callback.graph, notebook_handle=True)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://r9y9.github.io/images/jupyter_with_bokeh_files/jupyter_with_bokeh_21_0.png&#34; alt=&#34;png&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;model = Net().cuda() if use_cuda else Net()
optimizer = optim.Adadelta(model.parameters())
history = train_loop(model, data_loaders, optimizer, epochs, callback=callback)
print(&amp;quot;Test loss: {:.3f}&amp;quot;.format(history[&amp;quot;train&amp;quot;][&amp;quot;loss&amp;quot;][-1]))
print(&amp;quot;Test acc: {:.3f}&amp;quot;.format(history[&amp;quot;test&amp;quot;][&amp;quot;acc&amp;quot;][-1]))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Test loss: 0.113
Test acc: 0.990
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;2-vbar&#34;&gt;2. VBar&lt;/h3&gt;
&lt;p&gt;ãã¼ã¿ã»ããå¨ä½ã®æ­£è§£çã ãã§ãªããã«ãã´ãªæ¯ã®æ­£è§£çãªã©ã®å°ºåº¦ãç¥ãããæãããããã¾ããæ¬¡ã¯ãæ°å­ã®åã«ãã´ãªãã¨ã«ã©ã®ãããæ­£è§£ãã¦ããã®ããã¨ãã£ãå°ºåº¦ãå¯è¦åããããã«ãç¸¦æ£ã°ã©ããä½ã£ã¦ã¿ã¾ããããã«ã¯ã &lt;a href=&#34;https://bokeh.pydata.org/en/latest/docs/reference/models/glyphs/vbar.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://bokeh.pydata.org/en/latest/docs/reference/models/glyphs/vbar.html&lt;/a&gt; ãä½¿ãã¾ããon_epoch_endã§æ¸¡ãããhistoryã®ãã¡ã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ã«ãã´ãªæ¯ã®ç·ãµã³ãã«æ° (list)&lt;/li&gt;
&lt;li&gt;ã«ãã´ãªæ¯ã®æ­£è§£ãµã³ãã«æ° (list)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ã®äºã¤ãä½¿ã£ã¦åçã«ã°ã©ããæ´æ°ãã¾ãã&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Line&lt;/code&gt; ãªãã¸ã§ã¯ãã®æ´æ°ã¯ã&lt;code&gt;data_source.data[&amp;quot;x&amp;quot;]&lt;/code&gt;, &lt;code&gt;data_source.data[&amp;quot;y&amp;quot;]&lt;/code&gt; ã«å¤ãè¿½å ãã¦ãããã¨ã§è¡ãã¾ãããã&lt;code&gt;VBar&lt;/code&gt;ãªãã¸ã§ã¯ãã®å ´åã¯ã&lt;code&gt;data_source.data[&amp;quot;top&amp;quot;]&lt;/code&gt; ã«å¤ãã»ãããã¾ããä¸åãã®æ£ã°ã©ããä½ãããå ´åã¯ã&lt;code&gt;data_source.data[&amp;quot;bottom&amp;quot;]&lt;/code&gt; ã«å¤ãã»ããããã°OKã§ãã&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;class VBarPlotsCallback(object):
    def __init__(self, epochs=epochs, batch_size=batch_size):
        # Epochæ¯
        p1 = figure(title=&amp;quot;Category-wise correctness (train)&amp;quot;,
                    plot_height=300, plot_width=350, y_range=(0, 7000))
        p2 = figure(title=&amp;quot;Category-wise correctness (test)&amp;quot;,
                    plot_height=300, plot_width=350, y_range=(0, 1500))

        self.renderers = {&amp;quot;train&amp;quot;:{}, &amp;quot;test&amp;quot;:{}}

        bar_opts = dict(width=0.8, alpha=0.5)
        for phase, p in [(&amp;quot;train&amp;quot;, p1), (&amp;quot;test&amp;quot;, p2)]:
            for (key, c) in [(&amp;quot;corrects&amp;quot;, &amp;quot;blue&amp;quot;), (&amp;quot;counts&amp;quot;, &amp;quot;red&amp;quot;)]:
                self.renderers[phase][key] = p.vbar(
                    x=np.arange(0,10), top=[0]*10, name=&amp;quot;test&amp;quot;, color=c, **bar_opts)

        self.graph = gridplot([p1, p2], ncols=2, toolbar_location=toolbar_location)

    def on_epoch_end(self, epoch, phase, history):
        for key in [&amp;quot;counts&amp;quot;, &amp;quot;corrects&amp;quot;]:
            self.renderers[phase][key].data_source.data[&amp;quot;top&amp;quot;] = history[phase][key][-1]
            push_notebook()
        if save_img:
            bokeh.io.export_png(self.graph, &amp;quot;fig/{:02d}_vbar.png&amp;quot;.format(epoch))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;callback = VBarPlotsCallback()
if show_static:
    if exists(&amp;quot;fig/vbar.gif&amp;quot;):
        with open(&amp;quot;fig/vbar.gif&amp;quot;, &#39;rb&#39;) as f:
            IPython.display.display(Image(data=f.read()), format=&amp;quot;gif&amp;quot;)
else:
    bokeh.io.show(callback.graph, notebook_handle=True)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://r9y9.github.io/images/jupyter_with_bokeh_files/jupyter_with_bokeh_25_0.png&#34; alt=&#34;png&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;model = Net().cuda() if use_cuda else Net()
optimizer = optim.Adadelta(model.parameters())
history = train_loop(model, data_loaders, optimizer, epochs, callback=callback)
print(&amp;quot;Test loss: {:.3f}&amp;quot;.format(history[&amp;quot;train&amp;quot;][&amp;quot;loss&amp;quot;][-1]))
print(&amp;quot;Test acc: {:.3f}&amp;quot;.format(history[&amp;quot;test&amp;quot;][&amp;quot;acc&amp;quot;][-1]))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Test loss: 0.115
Test acc: 0.989
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;3-hbar&#34;&gt;3. HBar&lt;/h3&gt;
&lt;p&gt;HBarã¨éå¸¸ã«ä¼¼ãã°ã©ãã¨ãã¦ãæ¨ªåãã®æ£ã°ã©ãã§ãã &lt;a href=&#34;https://bokeh.pydata.org/en/latest/docs/reference/models/glyphs/hbar.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://bokeh.pydata.org/en/latest/docs/reference/models/glyphs/hbar.html&lt;/a&gt; ãããã¾ããVBarã®å ´åã¨åæ§ã«ãã«ãã´ãªæ¯ã®æ­£è§£ãµã³ãã«æ°ãå¯è¦åãã¦ã¿ã¾ããæ¬è³ªçã«å¯è¦åããæå ±ã¯å¤ããã¾ããããããã¾ã§ãã¢ã¨ãããã¨ã§ã&lt;/p&gt;
&lt;p&gt;&lt;code&gt;HBar&lt;/code&gt;ãªãã¸ã§ã¯ãã®æ´æ°ã¯ã&lt;code&gt;data_source.data[&amp;quot;right&amp;quot;]&lt;/code&gt; or &lt;code&gt;data_source.data[&amp;quot;left&amp;quot;]&lt;/code&gt; ã«å¤ãã»ããããã°OKã§ãã&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;class HBarPlotsCallback(object):
    def __init__(self, epochs=epochs, batch_size=batch_size):
        # Epochæ¯
        p1 = figure(title=&amp;quot;Category-wise correctness (train)&amp;quot;,
                    plot_height=300, plot_width=350, x_range=(0, 7000))
        p2 = figure(title=&amp;quot;Category-wise correctness (test)&amp;quot;,
                    plot_height=300, plot_width=350, x_range=(0, 1500))

        self.renderers = {&amp;quot;train&amp;quot;:{}, &amp;quot;test&amp;quot;:{}}

        bar_opts = dict(height=0.8, alpha=0.5)
        for phase, p in [(&amp;quot;train&amp;quot;, p1), (&amp;quot;test&amp;quot;, p2)]:
            for (key, c) in [(&amp;quot;corrects&amp;quot;, &amp;quot;blue&amp;quot;), (&amp;quot;counts&amp;quot;, &amp;quot;green&amp;quot;)]:
                self.renderers[phase][key] = p.hbar(
                    y=np.arange(0,10), right=[0]*10, name=&amp;quot;test&amp;quot;, color=c, **bar_opts)

        self.graph = gridplot([p1, p2], ncols=2, toolbar_location=toolbar_location)

    def on_epoch_end(self, epoch, phase, history):
        for key in [&amp;quot;counts&amp;quot;, &amp;quot;corrects&amp;quot;]:
            self.renderers[phase][key].data_source.data[&amp;quot;right&amp;quot;] = history[phase][key][-1]
            push_notebook()
        if save_img:
            bokeh.io.export_png(self.graph, &amp;quot;fig/{:02d}_hbar.png&amp;quot;.format(epoch))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;callback = HBarPlotsCallback()
if show_static:
    if exists(&amp;quot;fig/hbar.gif&amp;quot;):
        with open(&amp;quot;fig/hbar.gif&amp;quot;, &#39;rb&#39;) as f:
            IPython.display.display(Image(data=f.read()), format=&amp;quot;gif&amp;quot;)
else:
    bokeh.io.show(callback.graph, notebook_handle=True)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://r9y9.github.io/images/jupyter_with_bokeh_files/jupyter_with_bokeh_29_0.png&#34; alt=&#34;png&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;model = Net().cuda() if use_cuda else Net()
optimizer = optim.Adadelta(model.parameters())
history = train_loop(model, data_loaders, optimizer, epochs, callback=callback)
print(&amp;quot;Test loss: {:.3f}&amp;quot;.format(history[&amp;quot;train&amp;quot;][&amp;quot;loss&amp;quot;][-1]))
print(&amp;quot;Test acc: {:.3f}&amp;quot;.format(history[&amp;quot;test&amp;quot;][&amp;quot;acc&amp;quot;][-1]))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Test loss: 0.116
Test acc: 0.989
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;5-image&#34;&gt;5. Image&lt;/h3&gt;
&lt;p&gt;æå¾ã«ãhttps://bokeh.pydata.org/en/latest/docs/reference/models/glyphs/image_rgba.html ãä½¿ã£ã¦ãç»åãå¯è¦åããä¾ãç´¹ä»ãã¾ããä¾ãã°çæã¢ãã«ãå­¦ç¿ããã¨ããªã©ãå­¦ç¿ã®éç¨ã§ããã®çæãµã³ãã«ãå¯è¦åãããå ´åãããããã®ã§ããããã£ãå ´åã«ä½¿ãã¾ãã&lt;/p&gt;
&lt;p&gt;æåã«å®è£ããã¢ãã«ã¯ææ¸ãæ°å­èªè­ã®ããã®è­å¥ã¢ãã«ã ã£ããããè¶£åãå¤ãã¦ãçæã¢ãã«ã§ãã Variational Auto-encoder (VAE) ãä½¿ãã¾ããè­å¥ã¢ãã«ã®å­¦ç¿ã¨çæã¢ãã«ã®å­¦ç¿ã¯å°ãæ¯è²ãéãã®ã§ãï¼ã»ã¨ãã©åãã§ãããç°¡åã®ããï¼ä½µãã¦å­¦ç¿ç¨ã®ã³ã¼ããæ¸ãæãã¾ããã&lt;/p&gt;
&lt;h4 id=&#34;vae&#34;&gt;VAE&lt;/h4&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/pytorch/examples/tree/master/vae&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/pytorch/examples/tree/master/vae&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;class VAE(nn.Module):
    def __init__(self):
        super(VAE, self).__init__()

        self.fc1 = nn.Linear(784, 400)
        self.fc21 = nn.Linear(400, 20)
        self.fc22 = nn.Linear(400, 20)
        self.fc3 = nn.Linear(20, 400)
        self.fc4 = nn.Linear(400, 784)

        self.relu = nn.ReLU()
        self.sigmoid = nn.Sigmoid()

    def encode(self, x):
        h1 = self.relu(self.fc1(x))
        return self.fc21(h1), self.fc22(h1)

    def reparameterize(self, mu, logvar):
        if self.training:
            std = logvar.mul(0.5).exp_()
            eps = Variable(std.data.new(std.size()).normal_())
            return eps.mul(std).add_(mu)
        else:
            return mu

    def decode(self, z):
        h3 = self.relu(self.fc3(z))
        return self.sigmoid(self.fc4(h3))

    def forward(self, x):
        mu, logvar = self.encode(x.view(-1, 784))
        z = self.reparameterize(mu, logvar)
        return self.decode(z), mu, logvar

def loss_function(recon_x, x, mu, logvar):
    BCE = F.binary_cross_entropy(recon_x, x.view(-1, 784))

    # see Appendix B from VAE paper:
    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014
    # https://arxiv.org/abs/1312.6114
    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)
    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())
    # Normalise by same number of elements as in reconstruction
    KLD /= batch_size * 784

    return BCE + KLD
&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&#34;training-loop&#34;&gt;Training loop&lt;/h4&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def __train_loop_vae(model, data_loaders, optimizer, epoch, phase):
    model = model.train() if phase == &amp;quot;train&amp;quot; else model.eval()
    running_loss = 0
    recon_batch_first, target = None, None
    for batch_idx, (x, _) in enumerate(data_loaders[phase]):
        x = x.cuda() if use_cuda else x
        x = Variable(x)
        optimizer.zero_grad()
        y_hat = model(x)

        # loss
        recon_batch, mu, logvar = model(x)
        loss = loss_function(recon_batch, x, mu, logvar)

        # update
        if phase == &amp;quot;train&amp;quot;:
            loss.backward()
            optimizer.step()
        running_loss += loss.data[0]

        if target is None:
            target = x
            recon_batch_first = recon_batch

    # epoch-wise metrics
    l = running_loss / len(data_loaders[phase])
    return {&amp;quot;loss&amp;quot;: l, &amp;quot;recon&amp;quot;: recon_batch_first.data.cpu(), &amp;quot;target&amp;quot;: target.data.cpu()}

def train_loop_vae(model, data_loaders, optimizer, epochs=12, callback=None):
    history = {&amp;quot;train&amp;quot;: {}, &amp;quot;test&amp;quot;: {}}
    for epoch in tnrange(epochs):
        for phase in [&amp;quot;train&amp;quot;, &amp;quot;test&amp;quot;]:
            d = __train_loop_vae(model, data_loaders, optimizer, epoch, phase)
            for k,v in d.items():
                try:
                    history[phase][k].append(v)
                except KeyError:
                    history[phase][k] = [v]

            if callback is not None:
                callback.on_epoch_end(epoch, phase, history)
    return history
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;ãã¦ãæºåã¯çµããã§ãã&lt;/p&gt;
&lt;p&gt;æ¬¡ã«ç¤ºã &lt;code&gt;ImagePlotsCallback&lt;/code&gt; ã¯ã&lt;code&gt;on_epoch_end&lt;/code&gt; ã§å­¦ç¿çµæã®hisotoryãåãåã£ã¦ãVAEãéãã¦å¾©åããç»åã¨ãå¾©åãããå¯¾è±¡ã®ç»åãåçã«æ´æ°ãã¾ããImageRGBA ã®å ´åã¯ã&lt;code&gt;data_source.data[&amp;quot;image&amp;quot;]&lt;/code&gt; ã«éåãã»ãããããã¨ã§ãæ´æ°ãããã¨ãã§ãã¾ãã&lt;/p&gt;
&lt;p&gt;æ³¨æäºé ã¨ãã¦ãã¢ãã¯ã­ç»åãæç»ããéã«ã¯ãé©å½ãªã«ã©ã¼ããããããã¦ã(w, h) -&amp;gt; (w, h, 4) ã®éåã«ãã¦ããå¿è¦ãããã¾ãã&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from torchvision.utils import make_grid
from matplotlib.pyplot import cm

def _to_img(batch, cmap=cm.gray):
    # 128ã¯å¤ãã£ãã®ã§ååã«ãã¾ã
    _batch_size = batch_size // 2
    batch = batch[:_batch_size]

    batch = batch.view(-1,1,28,28)
    grid = make_grid(batch, nrow=int(np.sqrt(_batch_size)))[0].numpy()
    # Force squared
    l = np.min(grid.shape)
    grid = grid[:l, :l]
    img = np.uint8(cmap(grid) * 255)
    return img

class ImagePlotsCallback(object):
    def __init__(self, epochs=epochs, batch_size=batch_size, cmap=cm.gray):
        x_range, y_range = (-0.5, 10.5), (-0.5, 10.5)
        p1 = figure(title=&amp;quot;Reconstructed (train)&amp;quot;,
                    plot_height=350, plot_width=350, x_range=x_range, y_range=y_range)
        p2 = figure(title=&amp;quot;Target (train)&amp;quot;,
                    plot_height=350, plot_width=350, x_range=x_range, y_range=y_range)
        p3 = figure(title=&amp;quot;Reconstructed (test)&amp;quot;,
                    plot_height=350, plot_width=350, x_range=x_range, y_range=y_range)
        p4 = figure(title=&amp;quot;Target (test)&amp;quot;,
                    plot_height=350, plot_width=350, x_range=x_range, y_range=y_range)
        self.cmap = cmap

        self.renderers = {&amp;quot;train&amp;quot;:{}, &amp;quot;test&amp;quot;:{}}
        empty = torch.zeros(batch_size,1,28,28)
        empty = _to_img(empty, self.cmap)
        # to adjast aspect ratio
        r = empty.shape[0]/empty.shape[1]

        # https://github.com/bokeh/bokeh/issues/1666
        for k, p in [(&amp;quot;recon&amp;quot;, p1), (&amp;quot;target&amp;quot;, p2)]:
            self.renderers[&amp;quot;train&amp;quot;][k] = p.image_rgba(image=[empty[::-1]], x=[0], y=[0], dw=[10], dh=[r*10])
        for k, p in [(&amp;quot;recon&amp;quot;, p3), (&amp;quot;target&amp;quot;, p4)]:
            self.renderers[&amp;quot;test&amp;quot;][k] = p.image_rgba(image=[empty[::-1]], x=[0], y=[0], dw=[10], dh=[r*10])

        self.graph = gridplot([p1, p2, p3, p4], ncols=2, toolbar_location=toolbar_location)

    def on_epoch_end(self, epoch, phase, history):
        for k in [&amp;quot;recon&amp;quot;, &amp;quot;target&amp;quot;]:
            self.renderers[phase][k].data_source.data[&amp;quot;image&amp;quot;] = [_to_img(history[phase][k][-1], self.cmap)[::-1]]
        push_notebook()

        if save_img:
            bokeh.io.export_png(self.graph, &amp;quot;fig/{:02d}_{}_image.png&amp;quot;.format(epoch, self.cmap.name))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# ã°ã¬ã¼ã¹ã±ã¼ã«
callback = ImagePlotsCallback(cmap=cm.gray)
if show_static:
    if exists(&amp;quot;fig/gray_image.gif&amp;quot;):
        with open(&amp;quot;fig/gray_image.gif&amp;quot;, &#39;rb&#39;) as f:
            IPython.display.display(Image(data=f.read()), format=&amp;quot;gif&amp;quot;)
else:
    bokeh.io.show(callback.graph, notebook_handle=True)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://r9y9.github.io/images/jupyter_with_bokeh_files/jupyter_with_bokeh_38_0.png&#34; alt=&#34;png&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# gifãä½ã£ãã¨ãã«è¦ãããããã«ãshuffle=Falseã«ãã
kwargs = {&#39;num_workers&#39;: 1, &#39;pin_memory&#39;: True} if use_cuda else {}
train_loader = torch.utils.data.DataLoader(
    datasets.MNIST(&#39;./data&#39;, train=True, download=True,
                   transform=transforms.Compose([
                       transforms.ToTensor()
                   ])),
    batch_size=batch_size, shuffle=False, **kwargs)
test_loader = torch.utils.data.DataLoader(
    datasets.MNIST(&#39;./data&#39;, train=False, transform=transforms.Compose([
                       transforms.ToTensor(),
                   ])),
    batch_size=batch_size, shuffle=False, **kwargs)

data_loaders = {&amp;quot;train&amp;quot;: train_loader, &amp;quot;test&amp;quot;:test_loader}
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;model = VAE().cuda() if use_cuda else VAE()
optimizer = optim.Adam(model.parameters(), lr=1e-3)
history = train_loop_vae(model, data_loaders, optimizer, epochs, callback=callback)
print(&amp;quot;Test loss: {:.3f}&amp;quot;.format(history[&amp;quot;train&amp;quot;][&amp;quot;loss&amp;quot;][-1]))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Test loss: 0.133
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;æ¬è³ªçãªéãã¯ããã¾ããããç°ãªãã«ã©ã¼ããããè©¦ãã¦ã¿ã¾ãã&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;gradient = np.linspace(0,1,256)
gradient = np.vstack((gradient, gradient))
pyplot.figure(figsize=(16,0.5))
imshow(gradient, aspect=&amp;quot;auto&amp;quot;, cmap=cm.inferno)
axis(&amp;quot;off&amp;quot;);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://r9y9.github.io/images/jupyter_with_bokeh_files/jupyter_with_bokeh_42_0.png&#34; alt=&#34;png&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;callback = ImagePlotsCallback(cmap=cm.inferno)
if show_static:
    if exists(&amp;quot;fig/inferno_image.gif&amp;quot;):
        with open(&amp;quot;fig/inferno_image.gif&amp;quot;, &#39;rb&#39;) as f:
            IPython.display.display(Image(data=f.read()), format=&amp;quot;gif&amp;quot;)
else:
    bokeh.io.show(callback.graph, notebook_handle=True)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://r9y9.github.io/images/jupyter_with_bokeh_files/jupyter_with_bokeh_43_0.png&#34; alt=&#34;png&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;model = VAE().cuda() if use_cuda else VAE()
optimizer = optim.Adam(model.parameters(), lr=1e-3)
history = train_loop_vae(model, data_loaders, optimizer, epochs, callback=callback)
print(&amp;quot;Test loss: {:.3f}&amp;quot;.format(history[&amp;quot;train&amp;quot;][&amp;quot;loss&amp;quot;][-1]))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Test loss: 0.133
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;ãããã«&#34;&gt;ãããã«&lt;/h2&gt;
&lt;p&gt;Bokehã«ããã°ã©ãä½æã¯ãå°ãã¨ã£ã¤ãã«ããããããã¾ãããï¼matplotlibã¨ãã§ã¯ã¬ã³ãã©ã¨ãæè­ããªãã§ããã­ï¼ãæ£ããã°æè»æ§ãé«ããä¾¿å©ãªã®ã§ã¯ãªããã¨æãã¾ãã&lt;/p&gt;
&lt;p&gt;ä»åã®è¨äºãæ¸ãã«ããã£ã¦ã¯ãbokeh v0.12.9 ãä½¿ãã¾ãããããã­ã¼ã«ã«ã§notebookãå®è¡ããå ´åã¯ããã¼ã¸ã§ã³ãæãããã¨ããããããã¾ãã&lt;/p&gt;
&lt;h2 id=&#34;åè&#34;&gt;åè&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://qiita.com/driller/items/0730325bf5c1cd689979&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ipywidgetsã¨Bokehä½¿ã£ã¦ã¤ã³ã¿ã©ã¯ãã£ããªå¯è¦åããã - Qiita&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://qiita.com/y__sama/items/654ed8ab7464718876f9&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Jupyter Notebookãåçã«ä½¿ã£ã¦ã¿ã - Qiita&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://bokeh.pydata.org/en/latest/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Welcome to Bokeh â Bokeh 0.12.12 documentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://qiita.com/r9y9/items/d54162d37ec4f110f4b4&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;PyTorchã§å­¦ç¿ã®éç¨ãç¢ºèªãããã¨ãã¯tensorboardXãä½¿ãã®ãè¯ãã£ãã§ã -ãQiita&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>ãåä¸è©±èç·¨ãDeep Voice 3: 2000-Speaker Neural Text-to-Speech / arXiv:1710.07654 [cs.SD]</title>
      <link>https://r9y9.github.io/blog/2017/12/13/deepvoice3/</link>
      <pubDate>Wed, 13 Dec 2017 12:15:00 +0900</pubDate>
      <guid>https://r9y9.github.io/blog/2017/12/13/deepvoice3/</guid>
      <description>&lt;h2 id=&#34;summary&#34;&gt;Summary&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;è«æãªã³ã¯: &lt;a href=&#34;https://arxiv.org/abs/1710.07654&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;arXiv:1710.07654&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;ã³ã¼ã: &lt;a href=&#34;https://github.com/r9y9/deepvoice3_pytorch&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/r9y9/deepvoice3_pytorch&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;ä¸è¡ã¾ã¨ã&#34;&gt;ä¸è¡ã¾ã¨ã&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1710.07654&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;arXiv:1710.07654: Deep Voice 3: 2000-Speaker Neural Text-to-Speech&lt;/a&gt; ãèª­ãã§ãåä¸è©±èã®å ´åã®ã¢ãã«ãå®è£ãã¾ããï¼è¤æ°è©±èã®å ´åã¯ãä»å®é¨ä¸­ã§ã (&lt;a href=&#34;https://github.com/r9y9/deepvoice3_pytorch/pull/6&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;deepvoice3_pytorch/#6&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1710.08969&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;arXiv:1710.08969&lt;/a&gt; ã¨åãããRNNã§ã¯ãªãCNNãä½¿ãã®ãèã§ã&lt;/li&gt;
&lt;li&gt;ä¾ã«ãã£ã¦ &lt;a href=&#34;https://keithito.com/LJ-Speech-Dataset/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;LJSpeech Dataset&lt;/a&gt; ãä½¿ã£ã¦ãè±èªTTSã¢ãã«ãä½ãã¾ããï¼å­¦ç¿æéåæ¥ãããï¼ãè«æã«è¨è¼ã®ãã¤ãã¼ãã©ã¡ã¼ã¿ã§ã¯è¯ãçµæãå¾ãããªãã£ãã®ã§ããã&lt;a href=&#34;https://arxiv.org/abs/1710.08969&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;arXiv:1710.08969&lt;/a&gt; ã®ã¢ã¤ãã¢ãããã¤ãåãããã¨ã§ãè¯ãçµæãå¾ããã¨ãã§ãã¾ããã&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;æ¦è¦&#34;&gt;æ¦è¦&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://r9y9.github.io/blog/2017/11/23/dctts/&#34;&gt;Efficiently Trainable Text-to-Speech System Based on Deep Convolutional Networks with Guided Attention. [arXiv:1710.08969]&lt;/a&gt; ã§ç´¹ä»ããæ¹æ³ã¨ãã¢ããã¼ã·ã§ã³ãåºæ¬çãªæ¹æ³è«ã¯ã¾ã£ããåãã®ããçç¥ãã¾ããã¢ãã«ã®ã¢ã¼ã­ãã¯ãã£ãç°ãªãã¾ããããã®ç¹ã«ã¤ãã¦ãååè¿°ã¹ãã®ã§ããã¡ããåç§ãã ããã
ä»åã®è¨äºã§ã¯ãDeepVoice3ã®ã¢ã¼ã­ãã¯ãã£ããã¼ã¹ã«ããæ¹æ³ã§ã®å®é¨çµæãã¾ã¨ãã¾ãã&lt;/p&gt;
&lt;h2 id=&#34;äºåå®é¨&#34;&gt;äºåå®é¨&lt;/h2&gt;
&lt;p&gt;ã¯ããã«ãå¯è½ãªéãè«æã«å¿ å®ã«ãè«æã«è¨è¼ã®ã¢ãã«ã¢ã¼ã­ãã¯ãã£ããã¤ãã¼ãã©ã¡ã¼ã¿ã§ãã¬ã¤ã¤ã¼æ°ãConvã¬ã¤ã¤ã¼ã®ã«ã¼ãã«æ°ãè¥å¹²å¢ãããã¢ãã«ã§è©¦ãã¾ãããï¼å¢ãããªãã¨ãLJSpeechã§ã¯ã¤ã³ããã¼ã·ã§ã³ãæªããé³å£°ãçæããã¦ãã¾ãã¾ããï¼ãããããã©ããããã©ã¼ããããã£ããããªé³å£°ãçæãããå¾åã«ããã¾ãããè²ãè©¦è¡é¯èª¤ãã¦æ¹è¯ããã®ã§ãããè©³ç´°ã¯å¾è¿°ããã¨ãã¦ãæ¹è¯å/æ¹è¯å¾ã®é³å£°ãµã³ãã«ãä»¥ä¸ã«ç¤ºãã¾ãã&lt;/p&gt;
&lt;p&gt;Generative adversarial network or variational auto-encoder.&lt;/p&gt;
&lt;p&gt;(59 chars, 7 words)&lt;/p&gt;
&lt;p&gt;æ¹è¯åï¼&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/deepvoice3/yobi/3_checkpoint_step000530000.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;æ¹è¯å¾ï¼&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/deepvoice3/yobi/4_checkpoint_step000210000.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;ãããã§ãããããçµæ§éãã¾ããã­ããªããæ¹è¯åã®ã¢ãã«ã¯53ä¸ã¤ãã¬ã¼ã·ã§ã³ãæ¹è¯å¾ã¯21ä¸ã¤ãã¬ã¼ã·ã§ã³å­¦ç¿ãã¾ãããåæ°ãå¢ããã°ããã¨ãããã®ã§ã¯ãªãããã§ãï¼å½ããåã§ããï¼ãçµè«ããããã¨ãã¢ãã«ã®èªç±åº¦ãè¶³ããªãã£ãã®ãåè³ªãåä¸ãã«ããã£ãåå ã§ã¯ãªããã¨èãã¦ãã¾ãã&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2017/12/21 è¿½è¨&lt;/strong&gt;ï¼ããã¾ããã21ä¸ã¤ãã¬ã¼ã·ã§ã³ã®ã¢ãã«ã¯ãä½ãããå¥ã®äºåå­¦ç¿ããã¢ãã«ãããããã«å­¦ç¿ãããããªæ°ããã¦ãã¾ããâ¦ããã ãåè¨ã§53ä¸ãã¤ãã¬ã¼ã·ã§ã³ãã¦ããªãã®ã¯ééããªãã¨æãã¾ãç³ãè¨³ãããã¾ãã&lt;/p&gt;
&lt;h2 id=&#34;å®é¨&#34;&gt;å®é¨&lt;/h2&gt;
&lt;p&gt;ååã¨åãã &lt;a href=&#34;https://keithito.com/LJ-Speech-Dataset/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;LJSpeech Dataset&lt;/a&gt; ãä½¿ã£ã¦ã11æéãããï¼21ä¸ã¹ãããï¼å­¦ç¿ãã¾ãããã¢ãã«ã¯ãDeepVoice3ã§ææ¡ããã¦ãããã®ãå°ããããã¾ãããã©ã®ãããªå¤æ´ãããã®ããä»¥ä¸ã«ã¾ã¨ãã¾ãã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Encoder&lt;/strong&gt;: ã¬ã¤ã¤ã¼æ°ãå¢ããããã£ã³ãã«æ°ãå¤§ãããã¾ãããä»£ããã«ã«ã¼ãã«æ°ã¯7ãã3ã«æ¸ããã¾ãã&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Decoder&lt;/strong&gt;: ã¡ã«å¨æ³¢æ°ã¹ãã¯ãã­ã°ã©ã ã®è¤æ°ãã¬ã¼ã ãDecoderã®1-stepã§äºæ¸¬ããã®ã§ã¯ãªãã&lt;a href=&#34;https://arxiv.org/abs/1710.08969&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;arXiv:1710.08969&lt;/a&gt; ã§è¿°ã¹ããã¦ããããã«ã1-stepã§ï¼ç²ãï¼1ãã¬ã¼ã ãäºæ¸¬ãã¦ãConvTransposed1d ã«ããåã®æéè§£ååº¦ã¾ã§ã¢ãããµã³ããªã³ã°ããï¼è¦ã¯æéæ¹åã®ã¢ãããµã³ããªã³ã°ãã¢ãã«ã§å­¦ç¿ããï¼ããã«ãã¾ãã&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Decoder&lt;/strong&gt;: ã¢ãã³ã·ã§ã³ã®åã«ãããã¤ãConv1d + ReLUãè¶³ãã¾ãã&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Converter&lt;/strong&gt;: ConvTransposed1dãäºã¤å¥ãã¦ãæéè§£ååº¦ã4åã«ã¢ãããµã³ããªã³ã°ããããã«ãã¾ãã&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Converter&lt;/strong&gt;: ãã£ã³ãã«æ°ãå¤§ãããã¾ãã&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Decoder/Converter&lt;/strong&gt;: ã¬ã¤ã¤ã¼ã®æå¾ã«Sigmoidãè¿½å ãã¾ãã&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Loss&lt;/strong&gt;: Guided attention lossãå ãã¾ãã&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Loss&lt;/strong&gt;: Binary divergenceãå ãã¾ãã&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;å±é&lt;/strong&gt;: Linearã1x1 convolutionã«å¤ãã¾ãããDilationãå¤§ããã¨ãã¾ãã&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ä¸è¨å¤æ´ç¹ã«ã¤ãã¦ãæ¬æ¥ãªãã°ãExtensiveã«å®é¨ãã¦ãã©ããã©ã®ç¨åº¦æå¹ãèª¿ã¹ãã®ãä¸çªè¯ãã®ã§ãããè¨ç®è³æºã®é½åã«ãããé¨åçã«ãããã£ã¦ãã¾ããï¼ããã¾ããï¼ãé¨åçã¨ã¯ãããããã£ããã¨ã¯æå¾ã«ã¾ã¨ãã¦ããã¾ãã&lt;/p&gt;
&lt;p&gt;è¨ç®éåº¦ã¯ãããããµã¤ãº16ã§ã5.3 step/sec ãããã®è¨ç®éåº¦ã§ããã&lt;a href=&#34;https://arxiv.org/abs/1710.08969&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;arXiv:1710.08969&lt;/a&gt; ããã¯è¥å¹²éããããã§ããGPUã¡ã¢ãªã®ä½¿ç¨éã¯5 ~ 6GBç¨åº¦ã§ãããPyTorch v0.3.0ãä½¿ãã¾ããã&lt;/p&gt;
&lt;p&gt;å­¦ç¿ã«ä½¿ç¨ããã³ãã³ãã¯ä»¥ä¸ã§ãã&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;python train.py --checkpoint-dir=checkpoints_deepvoice3 \
    --hparams=&amp;quot;use_preset=True,builder=deepvoice3&amp;quot; \
    --log-event-path=log/deepvoice3_preset
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;ã³ã¼ãã®ã³ãããããã·ã¥ã¯ &lt;a href=&#34;https://github.com/r9y9/deepvoice3_pytorch/tree/7bcf1d070448b4127b41bdf3a1e34c9fea382054&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;7bcf1d0704&lt;/a&gt; ã§ããæ­£ç¢ºãªãã¤ãã¼ãã©ã¡ã¼ã¿ãç¥ãããå ´åã¯ãããããè¾¿ããã¨æãã¾ãã&lt;/p&gt;
&lt;h3 id=&#34;ã¢ã©ã¤ã¡ã³ãã®å­¦ç¿éç¨&#34;&gt;ã¢ã©ã¤ã¡ã³ãã®å­¦ç¿éç¨&lt;/h3&gt;
&lt;p&gt;ä»åã®å®é¨ã§ã¯ã¢ãã³ã·ã§ã³ã¬ã¤ã¤ã¼ã¯äºã¤ï¼æåã¨æå¾ï¼ããã¾ãããä»¥ä¸ã«å¹³åãåã£ããã®ãç¤ºãã¾ãã&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/images/deepvoice3/alignment.gif&#34; /&gt;&lt;/div&gt;
&lt;h3 id=&#34;åç¨®ã­ã¹ã®é·ç§»&#34;&gt;åç¨®ã­ã¹ã®é·ç§»&lt;/h3&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/images/deepvoice3/deepvoice3_tensorboard.png&#34; /&gt;&lt;/div&gt;
&lt;h3 id=&#34;é³å£°ãµã³ãã«&#34;&gt;é³å£°ãµã³ãã«&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://r9y9.github.io/blog/2017/11/23/dctts/&#34;&gt;ååã®è¨äº&lt;/a&gt; ã§è²¼ã£ããµã³ãã«ã¨ã¾ã£ããåãæç« ãç¨ãã¾ãããèå³ã®ããæ¹ã¯è´ãæ¯ã¹ã¦ã¿ã¦ãã ããã&lt;/p&gt;
&lt;h4 id=&#34;httpstachi-higithubiotts_samples-ãã&#34;&gt;&lt;a href=&#34;https://tachi-hi.github.io/tts_samples/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://tachi-hi.github.io/tts_samples/&lt;/a&gt; ãã&lt;/h4&gt;
&lt;p&gt;icassp stands for the international conference on acoustics, speech and signal processing.&lt;/p&gt;
&lt;p&gt;(90 chars, 14 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/deepvoice3/nyanko/0_checkpoint_step000210000.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/deepvoice3/nyanko/0_checkpoint_step000210000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;a matrix is positive definite, if all eigenvalues are positive.&lt;/p&gt;
&lt;p&gt;(63 chars, 12 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/deepvoice3/nyanko/2_checkpoint_step000210000.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/deepvoice3/nyanko/2_checkpoint_step000210000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;a spectrogram is obtained by applying es-tee-ef-tee to a signal.&lt;/p&gt;
&lt;p&gt;(64 chars, 11 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/deepvoice3/nyanko/6_checkpoint_step000210000.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/deepvoice3/nyanko/6_checkpoint_step000210000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;h4 id=&#34;keithitotacotron-ã®ãµã³ãã«httpskeithitogithubioaudio-samples-ã¨åãæç« &#34;&gt;&lt;a href=&#34;https://keithito.github.io/audio-samples/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;keithito/tacotron ã®ãµã³ãã«&lt;/a&gt; ã¨åãæç« &lt;/h4&gt;
&lt;p&gt;Scientists at the CERN laboratory say they have discovered a new particle.&lt;/p&gt;
&lt;p&gt;(74 chars, 13 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/deepvoice3/3_keithito/0_checkpoint_step000210000.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/deepvoice3/3_keithito/0_checkpoint_step000210000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;There&amp;rsquo;s a way to measure the acute emotional intelligence that has never gone out of style.&lt;/p&gt;
&lt;p&gt;(91 chars, 18 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/deepvoice3/3_keithito/1_checkpoint_step000210000.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/deepvoice3/3_keithito/1_checkpoint_step000210000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;President Trump met with other leaders at the Group of 20 conference.&lt;/p&gt;
&lt;p&gt;(69 chars, 13 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/deepvoice3/3_keithito/2_checkpoint_step000210000.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/deepvoice3/3_keithito/2_checkpoint_step000210000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;The Senate&amp;rsquo;s bill to repeal and replace the Affordable Care Act is now imperiled.&lt;/p&gt;
&lt;p&gt;(81 chars, 16 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/deepvoice3/3_keithito/3_checkpoint_step000210000.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/deepvoice3/3_keithito/3_checkpoint_step000210000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;Generative adversarial network or variational auto-encoder.&lt;/p&gt;
&lt;p&gt;(59 chars, 7 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/deepvoice3/3_keithito/4_checkpoint_step000210000.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/deepvoice3/3_keithito/4_checkpoint_step000210000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;The buses aren&amp;rsquo;t the problem, they actually provide a solution.&lt;/p&gt;
&lt;p&gt;(63 chars, 13 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/deepvoice3/3_keithito/5_checkpoint_step000210000.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/deepvoice3/3_keithito/5_checkpoint_step000210000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;h2 id=&#34;ã¾ã¨ã&#34;&gt;ã¾ã¨ã&lt;/h2&gt;
&lt;p&gt;ä»¥ä¸ãç¥è¦ãã¾ã¨ãã¾ãããããã¾ã§ãã®å¾åããããã¨ããç¨åº¦ã«åãæ­¢ãã¦ãã ããã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Tacotron, DeepVoice3ã§è¿°ã¹ããã¦ããããã«ã¡ã«å¨æ³¢æ°ã¹ãã¯ãã­ã°ã©ã ã®è¤æ°ãã¬ã¼ã ãDecoderã®1-stepã§äºæ¸¬ãããããã&lt;a href=&#34;https://arxiv.org/abs/1710.08969&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;arXiv:1710.08969&lt;/a&gt; ã§è¿°ã¹ããã¦ããããã«ã1-stepã§ï¼ç²ãï¼1ãã¬ã¼ã ãäºæ¸¬ãã¦ãConvTransposed1d ã«ããåã®æéè§£ååº¦ã¾ã§ã¢ãããµã³ããªã³ã°ããæ¹ãè¯ããçæãããé³å£°ã®ããã©ã¼ãã®ãããªç¾è±¡ãç·©åãããããã«æãã&lt;/li&gt;
&lt;li&gt;Dilationãå¤§ãããã¦ããå¤§ããªåè³ªã®å¤åã¯ãªãããã«æãã&lt;/li&gt;
&lt;li&gt;Guided-attentionã¯ãã¢ãã³ã·ã§ã³ãæ©ãmonotonicã«ãªãã¨ããæå³ã§è¯ãããã ããåè³ªã«å¤§ããªå½±é¿ã¯ãªãããã«æãã&lt;/li&gt;
&lt;li&gt;Encoderã®ã¬ã¤ã¤ã¼æ°ãå¤§ããããã®ã¯å¹æãã&lt;/li&gt;
&lt;li&gt;Converterã®ãã£ã³ãã«æ°ãå¤§ããããã®ã¯å¹æãã&lt;/li&gt;
&lt;li&gt;Binary divergence lossã¯ãå­¦ç¿ãå®å®ãããããã«ãDeepVoice3é¢¨ã®ã¢ã¼ã­ãã¯ãã£ã§ãæå¹ã ã£ã&lt;/li&gt;
&lt;li&gt;Encoder/Converterã¯ &lt;a href=&#34;https://arxiv.org/abs/1710.08969&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;arXiv:1710.08969&lt;/a&gt; ã®ãã®ããDecoderã¯DeepVoice3ã®ãã®ããã¨ãããã¿ã¼ã³ã§è©¦ãããã¨ãããã¾ããã&lt;a href=&#34;https://arxiv.org/abs/1710.08969&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;arXiv:1710.08969&lt;/a&gt;ã«æ¯ã¹ã¦è¥å¹²åè³ªãè½ã¡ãããã«æãããã®ã®ãã»ã¼åç­ã¨è¨ãããããªåè³ªãå¾ããã¾ããã&lt;a href=&#34;https://arxiv.org/abs/1710.08969&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;arXiv:1710.08969&lt;/a&gt; ã§ã¯Decoderã«20ã¬ã¤ã¤ã¼ä»¥ä¸ä½¿ã£ã¦ãã¾ããã10æªæºã§ããããªãã®åè³ªã«ãªã£ãããã«æãã¾ãï¼ä¸ã§è²¼ã£ãé³å£°ãµã³ãã«ãã¾ãã«ãã®ä¾ã§ãï¼&lt;/li&gt;
&lt;li&gt;åè³ªãæ¹è¯ããããã«ã&lt;a href=&#34;https://arxiv.org/abs/1710.08969&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;arXiv:1710.08969&lt;/a&gt; ããè²ãã¢ã¤ãã¢ãåãã¾ããããéã«DeepVoice3ã®ã¢ã¤ãã¢ã§è¯ãã£ãã¨æãããã®ã«ãDecoderã®å¥åã«ã(ã¡ã«å¨æ³¢æ°ã®æ¬¡åã¾ã§å°ãããã¦ãSigmoidãéãã¦å¾ãããï¼ã¡ã«å¨æ³¢æ°ã¹ãã¯ãã­ã°ã©ã ãä½¿ãã®ã§ã¯ãªããã®åã®hidden stateãä½¿ããã¨ãã£ããã¨ãããã¾ãããå¾éããµãããããSigmoidããã¾ãªãããããã¹ãã¯ãã­ã°ã©ã ã«å¯¾ããL1 Lossã®æ¸å°ãç¢ºå®ã«éããªãã¾ãã (&lt;a href=&#34;https://github.com/r9y9/deepvoice3_pytorch/commit/22a674803f2994af2b818635a0501e4417834936&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;22a6748&lt;/a&gt;)ã&lt;/li&gt;
&lt;li&gt;ãã®è¨äºã«è²¼ã£ãé³å£°ãµã³ãã«ã«ããã¦ãåé ­ã®aãæãã¦ããä¾ãç®ç«ã¡ã¾ãããéå»ã«ãã£ãå®é¨ã§ã¯ããããä¾ã¯ç¨ã ã£ãã®ã§ãä½ããã¤ãã¼ãã©ã¡ã¼ã¿ãèª¤ã£ã¦ããã£ããã ã¨æãã¾ãï¼é&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;åè&#34;&gt;åè&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1710.07654&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Wei Ping, Kainan Peng, Andrew Gibiansky, et al, &amp;ldquo;Deep Voice 3: 2000-Speaker Neural Text-to-Speech&amp;rdquo;, arXiv:1710.07654, Oct. 2017.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1705.03122&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Jonas Gehring, Michael Auli, David Grangier, et al, &amp;ldquo;Convolutional Sequence to Sequence Learning&amp;rdquo;, arXiv:1705.03122, May 2017.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://r9y9.github.io/blog/2017/11/23/dctts/&#34;&gt;Efficiently Trainable Text-to-Speech System Based on Deep Convolutional Networks with Guided Attention. [arXiv:1710.08969] | LESS IS MORE&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;é¢é£è¨äº&#34;&gt;é¢é£è¨äº&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://r9y9.github.io/blog/2017/11/23/dctts/&#34;&gt;Efficiently Trainable Text-to-Speech System Based on Deep Convolutional Networks with Guided Attention. [arXiv:1710.08969] | LESS IS MORE&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Efficiently Trainable Text-to-Speech System Based on Deep Convolutional Networks with Guided Attention. [arXiv:1710.08969]</title>
      <link>https://r9y9.github.io/blog/2017/11/23/dctts/</link>
      <pubDate>Thu, 23 Nov 2017 19:30:00 +0900</pubDate>
      <guid>https://r9y9.github.io/blog/2017/11/23/dctts/</guid>
      <description>&lt;h2 id=&#34;summary&#34;&gt;Summary&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;è«æãªã³ã¯: &lt;a href=&#34;https://arxiv.org/abs/1710.08969&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;arXiv:1710.08969&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;ã³ã¼ã: &lt;a href=&#34;https://github.com/r9y9/deepvoice3_pytorch&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/r9y9/deepvoice3_pytorch&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;ä¸è¡ã¾ã¨ã&#34;&gt;ä¸è¡ã¾ã¨ã&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1710.08969&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;arXiv:1710.08969: Efficiently Trainable Text-to-Speech System Based on Deep Convolutional Networks with Guided Attention.&lt;/a&gt; ãèª­ãã§ãå®è£ãã¾ãã&lt;/li&gt;
&lt;li&gt;RNNã§ã¯ãªãCNNãä½¿ãã®ãèã§ããªã¼ãã³ã½ã¼ã¹Tacotronã¨åç­ä»¥ä¸ã®åè³ªã§ãããªããã&lt;strong&gt;é«éã« (ä¸æ¥ç¨åº¦ã§) å­¦ç¿ã§ãã&lt;/strong&gt; ã®ãå£²ãã®ããã§ãã&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://keithito.com/LJ-Speech-Dataset/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;LJSpeech Dataset&lt;/a&gt; ãä½¿ã£ã¦ãè±èªTTSã¢ãã«ãä½ãã¾ããï¼å­¦ç¿æéä¸æ¥ãããï¼ãå®å¨åç¾ã¨ã¾ã§ã¯ããã¾ããããå¤§ã¾ãã«è«æã®ä¸»å¼µãç¢ºèªã§ãã¾ããã&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;åç½®ã&#34;&gt;åç½®ã&lt;/h2&gt;
&lt;p&gt;æ¬å½ã¯ &lt;a href=&#34;https://arxiv.org/abs/1710.07654&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;DeepVoice3&lt;/a&gt; ã®å®è£ããã¦ããã®ã§ãããã©ããä¸æããããªãã£ãã®ã§æ°åãå¤ãã¦ãã£ã¦ã¿ã¾ããã
ä»¥å Tacotronã«é¢ããé·ããã­ã°è¨äº (&lt;a href=&#34;https://r9y9.github.io/blog/2017/10/15/tacotron/&#34;&gt;ãªã³ã¯&lt;/a&gt;) ãæ¸ãã¦ãã¾ã£ãã®ã§ãããèª­ãæ¹ãæ¸ãæ¹ãã¤ããã®ã§ãç°¡æ½ã«ã¾ã¨ãããã¨ã«ãã¾ãããèå³ã®ããäººã¯ç¶ããã©ããã&lt;/p&gt;
&lt;h2 id=&#34;æ¦è¦&#34;&gt;æ¦è¦&lt;/h2&gt;
&lt;p&gt;End-to-endãã­ã¹ãé³å£°åæ (Text-to-speech synthesis; TTS) ã®ããã® &lt;strong&gt;Attentionä»ãç³ã¿è¾¼ã¿ãã¥ã¼ã©ã«ããã (CNN)&lt;/strong&gt; ãææ¡ããã¦ãã¾ããSampleRNN, Char2Wav, Tacotronãªã©ã®å¾æ¥ææ¡ããã¦ããRNNããã¼ã¹ã¨ããæ¹æ³ã§ã¯ãã¢ãã«ã®æ§é ä¸è¨ç®ãä¸¦ååãã«ããã
å­¦ç¿/æ¨è«ã«æéãããããã¨ãåé¡ã¨ãã¦ããã¾ãããæ¬è«æã§ã¯ãä¸»ã«ä»¥ä¸ã®äºã¤ã®ã¢ã¤ãã¢ã«ãã£ã¦ãå¾æ¥æ³ããéãå­¦ç¿ã§ããã¢ãã«ãææ¡ãã¦ãã¾ãã&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;RNNã§ã¯ãªãCNNãä½¿ããã¨ (åèè«æ: &lt;a href=&#34;https://arxiv.org/abs/1705.03122&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;arXiv:1705.03122&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Attentionãmotonicã«ãªããããããå¹æãæã¤Lossãèãããã¨ (&lt;strong&gt;Guided attention&lt;/strong&gt;)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;å®é¨ã§ã¯ããªã¼ãã³ã½ã¼ã¹Tacotron (&lt;a href=&#34;https://github.com/keithito/tacotron&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;keithito/tacotron&lt;/a&gt;) ã®12æ¥å­¦ç¿ãããã¢ãã«ã¨æ¯è¼ããä¸»è¦³è©ä¾¡ã«ããåç­ä»¥ä¸ã®åè³ªãå¾ããããã¨ãç¤ºããã¦ãã¾ãã&lt;/p&gt;
&lt;h3 id=&#34;deepvoice3httpsarxivorgabs171007654-ã¨ã®éã&#34;&gt;&lt;a href=&#34;https://arxiv.org/abs/1710.07654&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;DeepVoice3&lt;/a&gt; ã¨ã®éã&lt;/h3&gt;
&lt;p&gt;ã»ã¼åææã«çºè¡¨ãããDeepVoice3ãåãããCNNããã¼ã¹ã¨ãããã®ã§ããè«æãèª­ã¿ã¾ããããã¢ããã¼ã·ã§ã³ã¨ã¢ãã­ã¼ãã®åºæ¬ã¯ DeepVoice3 ã¨åãã«æãã¾ããããããããããã¯ã¼ã¯æ§é ã¯ DeepVoice3ã¨ã¯å¤§ããç°ãªãã¾ããããã¤ãææ¡æ³ã®ç¹å¾´ãæããã¨ãä»¥ä¸ã®ã¨ããã§ãã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ãããã¯ã¼ã¯ãæ·±ãï¼DeepVoice3ã ã¨Encoder, Decoder, Converter ãããã10æªæºã§ããããã®è«æã§ã¯Decoderã ãã§20ä»¥ä¸ï¼ããã¹ã¦ã«ããã¦æ·±ãã§ããã«ã¼ãã«ãµã¤ãºã¯3ã¨å°ããã§ã&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;
&lt;li&gt;Fully-connected layer ã§ã¯ãªã1x1 convolutionãä½¿ã£ã¦ãã¾ã&lt;/li&gt;
&lt;li&gt;ãã£ã³ãã«æ°ãå¤§ããï¼256ã¨ã512ã¨ããããã«ãããã¯ã¼ã¯åã§äºåã«ãªã£ã¦ãããããï¼ãDeepVoice3ã ã¨Encoderã¯64ã§ã&lt;/li&gt;
&lt;li&gt;ã¬ã¤ã¤ã¼ã®æ·±ãã«å¯¾ãã¦ææ°ä¸ã«å¤§ãããªãDilationãä½¿ã£ã¦ãã¾ãï¼DeepVoiceã§ã¯ãã¹ã¦dilation=1ï¼&lt;/li&gt;
&lt;li&gt;ã¢ãã³ã·ã§ã³ã¬ã¤ã¤ã¼ã¯ä¸ã¤ï¼DeepVoice3ã¯è¤æ°&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;DeepVoice3ã¯ã&lt;a href=&#34;https://arxiv.org/abs/1705.03122&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;arXiv:1705.03122&lt;/a&gt; ã®ã¢ãã«æ§é ã¨ããªãä¼¼éã£ã¦ããä¸æ¹ã§ãæ¬è«æã§ã¯ï¼åèæç®ã¨ãã¦ããããã¦ãã¾ããï¼å½±ãå½¢ããªããããå¤ãã£ã¦ãããã¨ããå°è±¡ãåãã¾ãã&lt;/p&gt;
&lt;p&gt;ã­ã¹ã«é¢ãã¦ã¯ãGuided attentionã«é¢ããã­ã¹ãå ããã®ã«å ãã¦ãTacotronãDeepVoice3ã¨ã¯ç°ãªããã¹ãã¯ãã­ã°ã©ã /ã¡ã«ã¹ãã¯ãã­ã°ã©ã ã«é¢ãã¦ binary divergence (å®ç¾©ã¯è«æåç§) ãã­ã¹ã«å ãã¦ããã¨ããéããããã¾ãã&lt;/p&gt;
&lt;h2 id=&#34;å®é¨&#34;&gt;å®é¨&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://keithito.com/LJ-Speech-Dataset/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;LJSpeech Dataset&lt;/a&gt; ãä½¿ã£ã¦ã17æéãããï¼26.5ä¸ã¹ãããï¼å­¦ç¿ãã¾ãããè¨ç®è³æºã®é½åä¸ãSSRNã®ãã£ã³ãã«æ°ã¯512ã§ã¯ãªããã®ååã®256ã«ãã¾ããã&lt;/p&gt;
&lt;p&gt;ãªããå®è£ããã«ããã£ã¦ã¯ãå³å¯ã«åç¾ãããã¨ã¯ãããè²ãé°å²æ°ã§ãã¾ããã¾ããããã¨ãã¨DeepVoice3ã®å®è£ããã¦ããã®ããããã¢ã¤ãã¢ãããã¤ãåãã¦ãã¾ããä¾ãã°ããã³ã¼ãã®åºåããã¤æ­¢ããããã¨ããdone flag predictionããããã¯ã¼ã¯ã«å¥ãã¦ãã¾ããDropoutã«ã¤ãã¦è¨åãããã¾ãããããªãã¨æ±åãã«ããå°è±¡ããã£ãã®ã§&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;ãè¶³ãã¾ããã&lt;/p&gt;
&lt;p&gt;è¨ç®éåº¦ã¯ãããããµã¤ãº16ã§ã4.3 step/sec ãããã®è¨ç®éåº¦ã§ãããåã®ãã·ã³ã®GPUã¯GTX 1080Ti ã§ããä½¿ç¨ãããã¤ãã¼ãã©ã¡ã¼ã¿ã¯&lt;a href=&#34;https://github.com/r9y9/deepvoice3_pytorch/blob/70dc880fae185d96effaee97f0ce55b5c0d13b61/hparams.py&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ãã¡ã&lt;/a&gt;ã§ããå­¦ç¿ã«ä½¿ç¨ããã³ãã³ãã¯ä»¥ä¸ã§ãï¼ã¡ã¢ï¼ã&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;python train.py --data-root=./data/ljspeech --checkpoint-dir=checkpoints_nyanko \
    --hparams=&amp;quot;use_preset=True,builder=nyanko&amp;quot; \
    --log-event-path=log/nyanko_preset
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;ã¢ã©ã¤ã¡ã³ãã®å­¦ç¿éç¨&#34;&gt;ã¢ã©ã¤ã¡ã³ãã®å­¦ç¿éç¨&lt;/h3&gt;
&lt;p&gt;æ°ä¸ã¹ãããã§ãç¶ºéºã«monotonicã«ãªãã¾ãããGIFã¯ãåãé³å£°ã«å¯¾ããã¢ã©ã¤ã¡ã³ãã§ã¯ãªããæ¯åº¦éãï¼ã©ã³ãã ãªï¼é³å£°ãµã³ãã«ã«å¯¾ããã¢ã©ã¤ã¡ã³ããè¨ç®ãã¦ããã£ã¤ãããã®ã§ãï¼ããããããããã¾ãã&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/images/dctts/alignment.gif&#34; /&gt;&lt;/div&gt;
&lt;h3 id=&#34;åç¨®ã­ã¹ã®é·ç§»&#34;&gt;åç¨®ã­ã¹ã®é·ç§»&lt;/h3&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/images/dctts/dctts_tensorboard.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;è¦ã¥ããã¦ç³ãè¨³ããã¾ããã¨ããæãã§ãããåã®ããã®ç°¡æã­ã°ã¨ãããã¨ã§è²¼ã£ã¦ããã¾ããbinary divergenceã¯ãããã«åæããããã§ããã&lt;/p&gt;
&lt;h3 id=&#34;é³å£°ãµã³ãã«&#34;&gt;é³å£°ãµã³ãã«&lt;/h3&gt;
&lt;h4 id=&#34;å¬å¼é³å£°ãµã³ãã«httpstachi-higithubiotts_samples-ã¨åãæç« æç²&#34;&gt;&lt;a href=&#34;https://tachi-hi.github.io/tts_samples/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;å¬å¼é³å£°ãµã³ãã«&lt;/a&gt; ã¨åãæç« ï¼æç²ï¼&lt;/h4&gt;
&lt;p&gt;å¬å¼ãµã³ãã«ã¨ã®æ¯è¼ã§ãã11/23æç¹ã§ãå¬å¼ã®ãµã³ãã«æ°ã15åã¨å¤ãã®ã§ãé©å½ã«3ã¤é¸ã³ã¾ãããå¬å¼ã¨æ¯ã¹ãã¨å°ãç°ãªã£ã¦ããå°è±¡ãåãã¾ãããã¾ãã¾ãè¯ãããªã¨æãã¾ããï¼ææ§ã§ãã&lt;/p&gt;
&lt;p&gt;icassp stands for the international conference on acoustics, speech and signal processing.&lt;/p&gt;
&lt;p&gt;(90 chars, 14 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/nyanko/6_nyanko/0_checkpoint_step000265000.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/nyanko/6_nyanko/0_checkpoint_step000265000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;a matrix is positive definite, if all eigenvalues are positive.&lt;/p&gt;
&lt;p&gt;(63 chars, 12 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/nyanko/6_nyanko/2_checkpoint_step000265000.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/nyanko/6_nyanko/2_checkpoint_step000265000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;a spectrogram is obtained by applying es-tee-ef-tee to a signal.&lt;/p&gt;
&lt;p&gt;(64 chars, 11 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/nyanko/6_nyanko/6_checkpoint_step000265000.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/nyanko/6_nyanko/6_checkpoint_step000265000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;h4 id=&#34;keithitotacotron-ã®ãµã³ãã«httpskeithitogithubioaudio-samples-ã¨åãæç« &#34;&gt;&lt;a href=&#34;https://keithito.github.io/audio-samples/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;keithito/tacotron ã®ãµã³ãã«&lt;/a&gt; ã¨åãæç« &lt;/h4&gt;
&lt;p&gt;Scientists at the CERN laboratory say they have discovered a new particle.&lt;/p&gt;
&lt;p&gt;(74 chars, 13 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/nyanko/3_keithito/0_checkpoint_step000265000.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/nyanko/3_keithito/0_checkpoint_step000265000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;There&amp;rsquo;s a way to measure the acute emotional intelligence that has never gone out of style.&lt;/p&gt;
&lt;p&gt;(91 chars, 18 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/nyanko/3_keithito/1_checkpoint_step000265000.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/nyanko/3_keithito/1_checkpoint_step000265000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;President Trump met with other leaders at the Group of 20 conference.&lt;/p&gt;
&lt;p&gt;(69 chars, 13 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/nyanko/3_keithito/2_checkpoint_step000265000.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/nyanko/3_keithito/2_checkpoint_step000265000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;The Senate&amp;rsquo;s bill to repeal and replace the Affordable Care Act is now imperiled.&lt;/p&gt;
&lt;p&gt;(81 chars, 16 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/nyanko/3_keithito/3_checkpoint_step000265000.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/nyanko/3_keithito/3_checkpoint_step000265000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;Generative adversarial network or variational auto-encoder.&lt;/p&gt;
&lt;p&gt;(59 chars, 7 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/nyanko/3_keithito/4_checkpoint_step000265000.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/nyanko/3_keithito/4_checkpoint_step000265000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;The buses aren&amp;rsquo;t the problem, they actually provide a solution.&lt;/p&gt;
&lt;p&gt;(63 chars, 13 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/nyanko/3_keithito/5_checkpoint_step000265000.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/nyanko/3_keithito/5_checkpoint_step000265000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;h2 id=&#34;ã¾ã¨ã--ããã£ããã¨ãªã©&#34;&gt;ã¾ã¨ã &amp;amp; ããã£ããã¨ãªã©&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Tacotronã§ã¯å­¦ç¿ã«ä½æ¥ãããã£ã¦ãã¾ãããï¼è¨ç®ãéã1æ¥ã§10ä¸stepç¨åº¦ï¼ã1æ¥ã§ãããªãã®åè³ªã«ãªãã¾ããã&lt;/li&gt;
&lt;li&gt;Guided atetntionãããã¨ãç¢ºãã«éãattentionãmonotonicã«ãªãã¾ããã&lt;/li&gt;
&lt;li&gt;2æéç¨åº¦ã®å­¦ç¿ã§ã¯ &lt;a href=&#34;https://tachi-hi.github.io/tts_samples/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ãã&lt;/a&gt; ã«ããã®ã¨åç¨åº¦ã®åè³ªã«ã¯ãªãã¾ããã§ããâ¦&lt;/li&gt;
&lt;li&gt;DeepVoice3ã®ã¢ãã«ã¢ã¼ã­ãã¯ãã£ã§å­¦ç¿ããå ´åã¨æ¯ã¹ãã¨ãåè³ªã¯åä¸ãã¾ãã&lt;/li&gt;
&lt;li&gt;DeepVoice3ã¨æ¯ã¹ãã¨ãæ·±ããããªã®ãå­¦ç¿ãé£ããããã«æãã¾ãããéã¿ã®åæåã®ãã©ã¡ã¼ã¿ãã¡ãã£ã¨ãããã¨ãsigmoidã®åºåã0 or 1ã«ãªã£ã¦å­¦ç¿ãæ­¢ã¾ããã¨ãã£ããã¨ãããã¾ãããéã¿ã®åæåã¯ã¨ã¦ãéè¦ã§ãã&lt;/li&gt;
&lt;li&gt;ä¸è¨ã«ãé¢é£ãã¦ãå¾éã®ãã«ã ãççºçã«å¤§ãããªããã¨ããã°ãã°ãããã¯ãªããã³ã°ãå¥ãã¾ããï¼éè¦ã§ããï¼&lt;/li&gt;
&lt;li&gt;Binary divergenceãã­ã¹ã«ããã¦ãåè³ªã«ã¯å½±é¿ããªãããã«æãã¾ããããã ããªãã¨å­¦ç¿åæã«å¾éãççºããããã£ãã§ã&lt;/li&gt;
&lt;li&gt;ææ¡æ³ã¯è²ããªã¢ã¤ãã¢ãçãè¾¼ã¾ãã¦ããã®ã§ãããå®éã®ã¨ããã©ããéè¦ãªè¦ç´ ãªã®ããã¨ãã£ãç¹ã«é¢ãã¦ã¯ãè«æã§ã¯æããã«ããã¦ããªãã£ãããã«æãã¾ããä»å¾ãã®è¾ºããæããã«ããè«æããã£ã¦ãããã®ã§ã¯ãªããã¨æãã¾ããã&lt;/li&gt;
&lt;li&gt;å­¦ç¿ã«ä½¿ãGPUã¡ã¢ãªéãTacotronããå¤ãï¼SSRNã®ãã£ã³ãã«æ°512, ããããµã¤ãº16ã§ &lt;del&gt;8GBããã&lt;/del&gt; 5~6GB ãããã§ããï¼â¦â¦å³ããâ¦â¦&lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;
&lt;li&gt;2017/12/19è¿½è¨: Dropoutãªãã ã¨ãå¥åãã­ã¹ãã¨ã¯ç¡ç¸ã®è±èªãããä½ããçæãããããã«ãªã£ã¦ãã¾ãã¾ãããDropoutã¯ãã¯ãéè¦ã§ãã&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ä¸çªã®å­¦ã³ã¯ããããã¯ã¼ã¯ã®éã¿ã®åæåæ¹æ³ã¯éè¦ãã¨ãããã¨ã§ãããããã¾ã&lt;/p&gt;
&lt;h2 id=&#34;åè&#34;&gt;åè&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1710.08969&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Hideyuki Tachibana, Katsuya Uenoyama, Shunsuke Aihara, &amp;ldquo;Efficiently Trainable Text-to-Speech System Based on Deep Convolutional Networks with Guided Attention&amp;rdquo;. arXiv:1710.08969, Oct 2017.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1710.07654&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Wei Ping, Kainan Peng, Andrew Gibiansky, et al, &amp;ldquo;Deep Voice 3: 2000-Speaker Neural Text-to-Speech&amp;rdquo;, arXiv:1710.07654, Oct. 2017.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1705.03122&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Jonas Gehring, Michael Auli, David Grangier, et al, &amp;ldquo;Convolutional Sequence to Sequence Learning&amp;rdquo;, arXiv:1705.03122, May 2017.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/He_Delving_Deep_into_ICCV_2015_paper.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;He, Kaiming, et al. &amp;ldquo;Delving deep into rectifiers: Surpassing human-level performance on imagenet classification.&amp;rdquo; Proceedings of the IEEE international conference on computer vision. 2015.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;DeepVoice3ã§ã«ã¼ãã«ãµã¤ãº3ã§è©¦ãã¨ãå¨ç¶ãã¾ãããã¾ããã§ãã&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34;&gt;
&lt;p&gt;æ¨è«æã«ã¢ãã³ã·ã§ã³ã®å¶ç´ãããã¦ããããµããµããµããµããµããã¿ãããªç¹°ãè¿ããèµ·ãã¦ãã¾ãã¾ãã&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34;&gt;
&lt;p&gt;è«æã§ã¯ã¨ã³ã³ã¼ããã³ã¼ãã®å­¦ç¿ã¨SRNNã®å­¦ç¿ãå¥ãã§ãããªã£ã¦ãã¾ãããåã¯ä¸ç·ã«ããã¾ããããã®ãããããã¾ã&amp;#160;&lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Tacotron: Towards End-to-End Speech Synthesis / arXiv:1703.10135 [cs.CL]</title>
      <link>https://r9y9.github.io/blog/2017/10/15/tacotron/</link>
      <pubDate>Sun, 15 Oct 2017 14:00:00 +0900</pubDate>
      <guid>https://r9y9.github.io/blog/2017/10/15/tacotron/</guid>
      <description>&lt;p&gt;Googleã2017å¹´4æã«çºè¡¨ããEnd-to-Endã®é³å£°åæã¢ãã« &lt;a href=&#34;https://arxiv.org/abs/1703.10135&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Tacotron: Towards End-to-End Speech Synthesis / arXiv:1703.10135 [cs.CL]&lt;/a&gt; ã«èå³ããã£ãã®ã§ãèªåã§ãåæ§ã®ã¢ãã«ãå®è£ãã¦å®é¨ãã¦ã¿ã¾ãããçµæããã£ããã¨ãªã©ãã¾ã¨ãã¦ãããã¨æãã¾ãã&lt;/p&gt;
&lt;p&gt;Googleã«ããTacotronã®é³å£°ãµã³ãã«ã¯ã &lt;a href=&#34;https://google.github.io/tacotron/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://google.github.io/tacotron/&lt;/a&gt; ããè´ãã¾ããåã®å®è£ã«ããé³å£°ãµã³ãã«ã¯ãã®è¨äºã®çãä¸­ãããããããããã¯  &lt;a href=&#34;http://nbviewer.jupyter.org/github/r9y9/tacotron_pytorch/blob/f98eda7336726cdfe4ab97ae867cc7f71353de50/notebooks/Test%20Tacotron.ipynb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Test Tacotron.ipynb | nbviewer&lt;/a&gt;&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; ããè´ããã¨ãã§ãã¾ãã&lt;/p&gt;
&lt;p&gt;ã¨ã¦ãé·ãè¨äºã«ãªã£ã¦ãã¾ã£ãã®ã§ãçµè«ã®ã¿ç¥ãããæ¹ã¯ãä¸çªæå¾ã¾ã§é£ã°ãã¦ãã ãããæå¾ã®æ¹ã®ã¾ã¨ãã»ã¯ã·ã§ã³ã«ãå®é¨ããä¸ã§åãå¾ãç¥è¦ãã¾ã¨ã¾ã£ã¦ãã¾ãã&lt;/p&gt;
&lt;h2 id=&#34;æ¦è¦&#34;&gt;æ¦è¦&lt;/h2&gt;
&lt;p&gt;è«æã®ã¿ã¤ãã«ã«ãããéããEnd-to-Endãç®æãã¦ãã¾ããå¸åçãªï¼è¤éã«ããªããã¡ãªï¼é³å£°åæã·ã¹ãã ã®æ§æè¦ç´ ã§ããã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;è¨èªä¾å­ã®ãã­ã¹ãå¦çãã­ã³ãã¨ã³ã&lt;/li&gt;
&lt;li&gt;è¨èªç¹å¾´éã¨é³é¿ç¹å¾´éã®ãããã³ã° (HMMãªãDNNãªã)&lt;/li&gt;
&lt;li&gt;æ³¢å½¢åæã®ããã¯ã¨ã³ã&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ãä¸ã¤ã®ã¢ãã«ã§éæãããã¨ããã&lt;strong&gt;attentionä»ãseq2seqã¢ãã«&lt;/strong&gt; ãææ¡ãã¦ãã¾ãããã ãã&lt;strong&gt;Toward&lt;/strong&gt; ã¨ããããã«ãå®å¨ã«End-to-Endã§ã¯ãªãããããã¯ã¼ã¯ã¯æ³¢å½¢ã§ã¯ãªã &lt;strong&gt;æ¯å¹ã¹ãã¯ãã­ã°ã©ã &lt;/strong&gt; ãåºåããGriffin limã®æ¹æ³ã«ãã£ã¦ä½ç¸ãå¾©åããéç­æéãã¼ãªã¨å¤æããããã¨ã«ãã£ã¦ãæçµçãªæ³¢å½¢ãå¾ã¾ããæ ¹æ¬ã«ããã¢ã¤ãã¢èªä½ã¯ã·ã³ãã«ã§ããããã®ãããªEnd-to-Endã«è¿ãã¢ãã«ã§é«åè³ªãªé³å£°åæãå®ç¾ããã®ã¯å°é£ã§ãããããè«æã§ã¯å­¦ç¿ãä¸æãããããããããã®ããã¤ãã®ãã¯ããã¯ãææ¡ãããã¨ãã£ãä¸»å¼µã§ããä»¥ä¸ã«ããã¤ãããã¯ã¢ãããã¾ãã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ã¨ã³ã³ã¼ãã« &lt;strong&gt;CBFG&lt;/strong&gt; (1-D convolution bank + highway network + bidirectional GRU) ã¨ããã¢ã¸ã¥ã¼ã«ãä½¿ã&lt;/li&gt;
&lt;li&gt;ãã³ã¼ãã®åºåãã¹ãã¯ãã­ã°ã©ã ã§ã¯ãªãï¼ããä½æ¬¡åã®ï¼&lt;strong&gt;ã¡ã«å¨æ³¢æ°ã¹ãã¯ãã­ã°ã©ã &lt;/strong&gt; ã«ãããã¹ãã¯ãã­ã°ã©ã ã¯ã¢ã©ã¤ã¡ã³ããå­¦ç¿ããã«ã¯åé·ãªããã&lt;/li&gt;
&lt;li&gt;ã¹ãã¯ãã­ã°ã©ã ã¯ãã¡ã«å¨æ³¢æ°ã¹ãã¯ãã­ã°ã©ã ã«å¯¾ãã¦ &lt;strong&gt;CBFG&lt;/strong&gt; ãéãã¦å¾ã&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ãã®ä»ãBatchNormalizationãå¥ããããDropoutãå¥ããããGRUãã¹ã¿ãã¯ããããã¨è²ãããã¾ãããæ­£ç´ãªã¨ãããã©ããã©ã®ãããå¹æãããã®ãã¯ããã£ã¦ãã¾ããï¼èª¿ã¹ãã«ã¯ãéæ¹ããªãæéããããã¾ãï¼ããè«æã®ä¸»å¼µã«ããã¨ãããããæå¹ãªããã§ãã&lt;/p&gt;
&lt;h2 id=&#34;æ¢å­å®è£&#34;&gt;æ¢å­å®è£&lt;/h2&gt;
&lt;p&gt;Googleã¯å®è£ãå¬éãã¦ãã¾ãããããªã¼ãã³ã½ã¼ã¹å®è£ãããã¤ãããã¾ãã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/Kyubyong/tacotron&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/Kyubyong/tacotron&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/barronalex/Tacotron&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/barronalex/Tacotron&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/keithito/tacotron&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/keithito/tacotron&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;èªåã§å®è£ããåã«ãä¸è¨ããã¹ã¦ãç°¡åã«è©¦ããããçæãããé³å£°ãµã³ãã«ãæ¯è¼ããä¸ã§ãåã¯ &lt;a href=&#34;https://github.com/keithito/tacotron&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;keithito/tacotron&lt;/a&gt; ãä¸çªè¯ãããã«æãã¾ãããæãè¯ãã¨æã£ãç¹ã¯ãkeithito ããã¯ã&lt;a href=&#34;https://keithito.com/LJ-Speech-Dataset/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;LJ Speech Dataset&lt;/a&gt; ã¨ããåä¸è©±èã®è±èªèª­ã¿ä¸ãé³å£° &lt;strong&gt;ç´24æéã®ãã¼ã¿ã»ãããæ§ç¯&lt;/strong&gt; ããããã &lt;strong&gt;public domainã§å¬é&lt;/strong&gt; ãã¦ãããã¨ã§ãããã®ãã¼ã¿ã»ããã¯è²´éã§ãã&lt;a href=&#34;https://keithito.github.io/audio-samples/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ãã¢é³å£°ãµã³ãã«&lt;/a&gt;ã¯ããã®ãã¼ã¿ã»ãããä½¿ã£ãçµæã§ããããä»ã¨æ¯ã¹ã¦ã¨ã¦ãé«åè³ªã«æãã¾ãããèªåã§ãè©¦ãã¦ã¿ã¦ã1æéç¨åº¦ã§è±èªãããé³å£°ãçæã§ããããã«ãªã£ãã®ã¨ãããã«æ°æéã§ã¢ã©ã¤ã¡ã³ããå­¦ç¿ããããã¨ãç¢ºèªãã¾ããã&lt;/p&gt;
&lt;p&gt;ãªããä¸è¨3ã¤ãã¹ã¦ã§å­¦ç¿ã¹ã¯ãªãããåãã¦é³å£°ãµã³ãã«ãå¾ããç¨åº¦ã®ãã¨ã¯è©¦ãã¾ããããåãã³ã¼ãã¬ãã«ã§èª­ãã ã®ã¯ &lt;a href=&#34;https://github.com/keithito/tacotron&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;keithito/tacotron&lt;/a&gt; ã®ã¿ã§ããèª­ãã ã³ã¼ãã¯ãTensorFlowã«è©³ãããªãåã§ãèª­ãããã®ã§ãã¨ã¦ãæ§é åããã¦ãã¦èª­ã¿ãããã£ãã§ãã&lt;/p&gt;
&lt;h2 id=&#34;èªåå®è£&#34;&gt;èªåå®è£&lt;/h2&gt;
&lt;p&gt;åå¼·ãå¼ã­ã¦ãPyTorchã§ã¹ã¯ã©ããããæ¸ãã¾ããããã®çµæã &lt;a href=&#34;https://github.com/r9y9/tacotron_pytorch&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/r9y9/tacotron_pytorch&lt;/a&gt; ã§ãã&lt;/p&gt;
&lt;p&gt;åã«ããã¤ãçµè«ãæ¸ãã¦ããã¨ã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;é³ã®åè³ªã¯ã&lt;a href=&#34;https://github.com/keithito/tacotron&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;keithito/tacotron&lt;/a&gt; ã®æ¹ãè¯ãæãã¾ããï¼åãã¢ãã«ã®å®è£ãå¿ãããã®ã«â¦ã¤ããâ¦ï¼ããã ããã¼ã¿ã»ããã®é³å£°ã«ã¯æ®é¿ãä¹ã£ã¦ãã¦ãçæãããé³å£°ãåé³å£°ã«è¿ãã®ãã¨ããã®ã¯ãåã«ã¯å¤æ­ãã¤ãã«ããã§ããè¨äºã®å¾åã«æ¯è¼ã§ããããã«ãµã³ãã«ãè²¼ã£ã¦ããã¾ãã®ã§ãæ°ã«ãªãæ¹ã¯ãã§ãã¯ãã¦ã¿ã¦ãã ãã&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/keithito/tacotron&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;keithito/tacotron&lt;/a&gt; ã§ã¯é·ãå¥åã ã¨åæã«å¤±æããä¸æ¹ã§&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;ãåã®å®è£ã§ã¯æ¯è¼çé·ãã¦ãããç¨åº¦åæã§ããããã§ãããªãã®ããçªãè©°ããã«ã¯ãTensorFlowã®seq2seq APIã® &lt;strong&gt;ã³ã¼ã&lt;/strong&gt; (APIã¯æ½è±¡åããããã¦ãã¦docstringããã§ã¯ããããããªãã®ã§â¦) ãèª­ã¿ã¨ãå¿è¦ãããããªã¨æã£ã¦ãã¾ãï¼ãã£ã¦ãã¾ããããã¾ãã&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;å®é¨&#34;&gt;å®é¨&lt;/h2&gt;
&lt;p&gt;åºæ¬çã«ã¯ &lt;a href=&#34;https://github.com/keithito/tacotron&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;keithito/tacotron&lt;/a&gt; ã®å­¦ç¿ã¹ã¯ãªããã¨åãã§ã&lt;a href=&#34;https://keithito.com/LJ-Speech-Dataset/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;LJ Speech Dataset&lt;/a&gt; ãä½¿ã£ã¦å­¦ç¿ããã¾ããããã­ã¹ãå¦çãé³å£°å¦ç (Griffin limç­) ã«ã¯æ¢å­ã®ã³ã¼ãããã®ã¾ã¾ä½¿ç¨ããã¢ãã«é¨åã®ã¿èªåã§ç½®ãæãã¾ãããå®é¨ã§ã¯ã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;attentionä»ãseq2seqã®èã§ãããã¢ã©ã¤ã¡ã³ããã©ã®ããã«å­¦ç¿ããã¦ããã®ã&lt;/li&gt;
&lt;li&gt;å­¦ç¿ãé²ãã«ã¤ãã¦ãçæãããé³å£°ã¯ã©ã®ããã«å¤ãã£ã¦ããã®ã&lt;/li&gt;
&lt;li&gt;å­¦ç¿ãããã¢ãã«ã¯ãæ±åæ§è½ã¯ã©ã®ç¨åº¦ãªã®ãï¼æªç¥æç« ãé·ãæç« ãã¹ãã«ãã¹ã«å¯¾ãã¦ããã©ã¼ãã³ã¹ã¯ã©ãå¤ããã®ããç­ï¼&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ãæ¢ã£ã¦ããã¾ããã&lt;/p&gt;
&lt;h3 id=&#34;ã¢ã©ã¤ã¡ã³ãã®å­¦ç¿éç¨ã®å¯è¦å&#34;&gt;ã¢ã©ã¤ã¡ã³ãã®å­¦ç¿éç¨ã®å¯è¦å&lt;/h3&gt;
&lt;p&gt;éå¸¸ã®seq2seqã¯ãã¨ã³ã³ã¼ãRNNã«ãã£ã¦å¾ãæå¾ã®ã¿ã¤ã ã¹ãããã«ãããé ãå±¤ã®ç¶æãããã³ã¼ãã®RNNã®åæç¶æã¨ãã¦æ¸¡ãã¾ããä¸æ¹attentiontä»ãã®seq2seqã¢ãã«ã§ã¯ããã³ã¼ãRNNã¯åã¿ã¤ã ã¹ãããã§ãã¨ã³ã³ã¼ãRNNã®åã¿ã¤ã ã¹ãããã«ãããé ãå±¤ã®ç¶æãéã¿ã¥ãã¦ä½¿ç¨ãããã®éã¿ãå­¦ç¿ãã¾ããattentionä»ãã®seq2seqã§ã¯ãã¢ã©ã¤ã¡ã³ãããã¡ãã¨ï¼ææ§ãªè¡¨ç¾ã§ããï¼å­¦ç¿ããã¦ããããå¯è¦åãã¦ãã§ãã¯ããã®ããå­¦ç¿ããã¡ãã¨é²ãã§ããã®ãç¢ºèªããã®ã«ä¾¿å©ã§ãã&lt;/p&gt;
&lt;p&gt;ä»¥ä¸ã«ã47000 step (epochã§ã¯ããã¾ãããåã®è¨ç®ç°å¢ GTX 1080Ti ã§åæ¥ããããªãããã) iterationããã¨ãã®ã¢ã©ã¤ã¡ã³ãçµæã¨ã47000 stepã®æç¹ã§ã®äºæ¸¬ãããé³å£°ãµã³ãã«ãç¤ºãã¾ãããªããgifã«ãããåç»åã¯ããã¼ã¿ã»ãããã©ã³ãã ã«ãµã³ãã«ããéã®ã¢ã©ã¤ã¡ã³ãã§ãããããåãé³å£°ã«å¯¾ããã¢ã©ã¤ã¡ã³ãã§ã¯ããã¾ãããTacotronè«æã«ã¯ãBahdanau Attentionãä½¿ç¨ããã¨ããã¾ããã&lt;a href=&#34;https://github.com/keithito/tacotron/issues/24&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;keithito/tacotron #24 Try Monotonic Attention&lt;/a&gt; ã«ããã¨ãTacotronè«æã®ç¬¬ä¸èèã¯æ°ãããã¼ã¸ã§ã³ã®Tacotronã§ã¯ Monotonic attentionãä½¿ç¨ãã¦ãããããã¨ãããã¨ãããMonotonic Attentionã§ãè©¦ãã¦ã¿ã¾ããããã¨ã§ããã£ãã®ã§ãããé·æï¼200æå­ãæ°æã¨ãï¼ãåæãããã¨ããã¨éä¸­ã§ã¢ã©ã¤ã¡ã³ããã¹ã­ãããããã¨ãå¤ãè¦åããããã®ã§ããããã£ãå ´åã«ãmonotonicã¨ããå¶ç´ãä¸æãåãã®ã ã¨æãã¾ãã&lt;/p&gt;
&lt;p&gt;ä»¥ä¸ã®é ã§gifãè²¼ãã¾ãã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/keithito/tacotron&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;keithito/tacotron&lt;/a&gt;, Bahdanau attention&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/keithito/tacotron&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;keithito/tacotron&lt;/a&gt;, Bahdanau-style monotonic attention&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/r9y9/tacotron_pytorch&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;r9y9/tacotron_pytorch&lt;/a&gt;, Bahdanau attention&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;keithito: Bahdanau Attention&lt;/strong&gt;&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/images/tacotron-tf-alignment_47000steps.gif&#34; /&gt;&lt;/div&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/step-47000-audio-tf.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;&lt;strong&gt;keithito: (Bahdanau-style) Monotonic Attention&lt;/strong&gt;&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/images/tacotron-tf-monotonic-alignment_47000steps.gif&#34; /&gt;&lt;/div&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/step-47000-audio-tf-monotonic.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;&lt;strong&gt;èªåå®è£: Bahdanau Attention&lt;/strong&gt;&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/images/tacotron-alignment_47000steps.gif&#34; /&gt;&lt;/div&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/step-47000-audio-pt.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;Monotonicãã©ããã§æ¯è¼ããã¨ãMonotonic attentionã®æ¹ãã¢ã©ã¤ã¡ã³ããããªãå®å®ãã¦ããããã«è¦ãã¾ããããããGithubã®ã¹ã¬ããã«ãã£ãé³å£°ãµã³ãã«ãè´ãã¨ãé³è³ªçãªæå³ã§ã¯å¤§ããªéãããªãããã«æã£ãã®ã¨ãåæéåº¦ï¼ç°¡åã«è©¦ããã¨ãããã¢ã©ã¤ã¡ã³ããã¾ã¨ãã«ãªãã ãstepã¯20000ãããã§ãã»ã¼åãã§ããï¼ãåãã«æãã¾ãããä¸æ¹ã§èªåå®è£ã¯ãã¢ã©ã¤ã¡ã³ããã¾ã¨ãã«ãªãstepã10000ãããã¨ããæ©ããã¾ãã·ã£ã¼ãã«è¦ãã¾ãã&lt;/p&gt;
&lt;p&gt;é³å£°ãµã³ãã«ã®æ¹ã§ãããæ¢å­å®è£ã¯ä¸¡èã¨ããããªãã«ã¾ã¨ãã§ããä¸æ¹èªåå®è£ã§ã¯ãã¾ã ããªããã¤ã¸ã¼ã§ããã§ããã ãtfå®è£ã¨åãããã«ã¤ãããå®é¨æ¡ä»¶ãåãã«ããã¤ããã§ãããä½ãééã£ã¦ããããããã¾ãããããã¤ãã¬ã¼ã·ã§ã³ãååã«åãã¨ãä¸å¿é³å£°ã¯ãããªãã«åºãããã«ãªãã¾ãã&lt;/p&gt;
&lt;p&gt;é³å£°ãµã³ãã«ã«é¢ããæ³¨æç¹ã¨ãã¦ã¯ãããã¯ãã³ã¼ãã®éã«æå¸«ãã¼ã¿ãä½¿ã£ã¦ããã®ã§ããã®æç¹ã§ã®ã¢ãã«ä½¿ã£ã¦ãåç­ã®é³è³ªã®é³å£°ãçæã§ããã¨ã¯éãã¾ãããå­¦ç¿æã«ã¯ããã³ã¼ãã®åã¿ã¤ã ã¹ãããã§æå¸«ãã¼ã¿ã®ã¹ãã¯ãã­ã°ã©ã ï¼æ­£ç¢ºã«ã¯ããã³ã¼ãã®åºåã¯ã¡ã«å¨æ³¢æ°ã¹ãã¯ãã­ã°ã©ã ï¼ãå¥åã¨ããä¸æ¹ã§ãè©ä¾¡æã«ã¯ããã³ã¼ãèªèº«ãåºåããã¹ãã¯ãã­ã°ã©ã ãæ¬¡ã®ã¿ã¤ã ã¹ãããã®å¥åã«ç¨ãã¾ããè©ä¾¡æã«ã¯ãä¸åº¦å¤ãªã¹ãã¯ãã­ã°ã©ã ãåºåãã¦ãã¾ã£ãããã¨ã©ã¼ãèç©ãã¦ãã£ã¦ã©ãã©ãå¤ãªåºåãããããã«ãªã£ã¦ãã¾ããã¨ã¯æ³åã«é£ãããªãã¨æãã¾ããseq2seqã¢ãã«ã®ãã³ã¼ãã«ã¯ãã¼ã ãµã¼ããä»£è¡¨çãªãã®ã¨ãã¦ããã¾ãããTacotronã§ã¯åç´ã«greedy decodingããã¾ãã&lt;/p&gt;
&lt;h3 id=&#34;å­¦ç¿ãé²ãã«ã¤ãã¦çæãããé³å£°ã¯ã©ã®ããã«å¤ãã£ã¦ããã®ã&#34;&gt;å­¦ç¿ãé²ãã«ã¤ãã¦ãçæãããé³å£°ã¯ã©ã®ããã«å¤ãã£ã¦ããã®ã&lt;/h3&gt;
&lt;p&gt;ãã¦ãããããã¯èªåå®è£ã®ã¿ã§ã®å®é¨çµæã§ããç´10æ¥ã70ä¸stepç¨åº¦å­¦ç¿ããã¾ããã®ã§ã5000, 10000, 50000, ãã®ãã¨ã¯10ä¸ãã10ä¸ã¹ããããã¨ã«70ä¸ã¹ãããã¾ã§ããããã§é³å£°ãçæãã¦ãã©ã®ããã«ãªã£ã¦ããã®ããè¦ã¦ããã¾ãã&lt;/p&gt;
&lt;h4 id=&#34;ä¾æ1&#34;&gt;ä¾æ1&lt;/h4&gt;
&lt;p&gt;Hi, my name is Tacotron. I&amp;rsquo;m still learning a lot from data.&lt;/p&gt;
&lt;p&gt;(56 chars, 14 words)&lt;/p&gt;
&lt;p&gt;step 5000&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/progress/0_step5000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;step 10000&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/progress/0_step10000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;step 50000&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/progress/0_step50000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;step 100000&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/progress/0_step100000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;step 200000&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/progress/0_step200000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;step 300000&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/progress/0_step300000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;step 400000&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/progress/0_step400000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;step 500000&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/progress/0_step500000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;step 600000&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/progress/0_step600000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;step 700000&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/progress/0_step700000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;ã ããã20ä¸ã¹ãããï¼å­¦ç¿äºæ¥ãããï¼ãããã¾ã¨ããªé³å£°ã«ãªã£ã¦ããããã«æãã¾ããç´°ããã¨ããã§ã¯ã&lt;code&gt;Hi,&lt;/code&gt; &lt;code&gt;Tacotron&lt;/code&gt; ã¨ããé¨åãå°ãçºé³ãã«ãããã§ãããã¼ã¿ã»ããã«ã¯ãã®ãããªè©±ãè¨èã®ãããªãã®ãå°ãªãã®ã¨ã&lt;code&gt;Tacotron&lt;/code&gt; ã¨ããåèªãè±èªãããçãªæå³ã§æªããããï¼é èªã§ããã­ããã¶ãï¼ã¨èãããã¾ãã&lt;/p&gt;
&lt;h4 id=&#34;ä¾æ2&#34;&gt;ä¾æ2&lt;/h4&gt;
&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Python_%28programming_language%29&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://en.wikipedia.org/wiki/Python_(programming_language)&lt;/a&gt; ããå¼ç¨ï¼&lt;/p&gt;
&lt;p&gt;Python is a widely used high-level programming language for general-purpose programming, created by Guido van Rossum and first released in 1991.&lt;/p&gt;
&lt;p&gt;(144 chars, 23 words)&lt;/p&gt;
&lt;p&gt;step 5000&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/progress/1_step5000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;step 10000&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/progress/1_step10000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;step 50000&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/progress/1_step50000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;step 100000&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/progress/1_step100000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;step 200000&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/progress/1_step200000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;step 300000&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/progress/1_step300000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;step 400000&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/progress/1_step400000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;step 500000&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/progress/1_step500000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;step 600000&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/progress/1_step600000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;step 700000&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/progress/1_step700000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;ã ããã20ä¸ã¹ããããããã¾ã¨ããªé³å£°ã«ãªã£ã¦ããããã«æãã¾ãã&lt;/p&gt;
&lt;h3 id=&#34;ã¢ãã«ã®æ±åæ§è½ã«ã¤ãã¦èª¿æ»&#34;&gt;ã¢ãã«ã®æ±åæ§è½ã«ã¤ãã¦èª¿æ»&lt;/h3&gt;
&lt;p&gt;ä»¥ä¸ã72ä¸ã¹ãããï¼ä¸é±éãããï¼å­¦ç¿ãããã¢ãã«ãä½¿ã£ã¦ãããããªå¥åã§ãã¹ãããçµæã§ããé³å£°ã¨åããã¦ã¢ã©ã¤ã¡ã³ããè²¼ã£ã¦ããã¾ãã&lt;/p&gt;
&lt;h4 id=&#34;é©å½ãªæªç¥å¥å&#34;&gt;é©å½ãªæªç¥å¥å&lt;/h4&gt;
&lt;p&gt;ãã¼ã¿ã»ããã«ã¯å­å¨ããªãæç« ãä½¿ã£ã¦ãã¹ããã¦ã¿ã¾ãããã¨ããã©ããï¼éãã¤ãã£ãã®åã«ã§ãï¼ä¸èªç¶ã ã¨æããã¨ãããè¦ããã¾ãããã¨ã¯ããã¾ãã¾ãããæãã§ã¯ãªãã§ããããã(google translateã§åãæç« ãåæãã¦ã¿ã¦æ¯ã¹ã¦ãããããªã«æªããªãæ°ããã¾ãã)&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/PyPy&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://en.wikipedia.org/wiki/PyPy&lt;/a&gt; ããï¼&lt;/p&gt;
&lt;p&gt;PyPy is an alternate implementation of the Python programming language written in Python.&lt;/p&gt;
&lt;p&gt;(89 chars, 14 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/0_unknown/0_step720000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/tacotron/0_unknown/0_step720000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/NumPy&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://en.wikipedia.org/wiki/NumPy&lt;/a&gt; ããï¼&lt;/p&gt;
&lt;p&gt;NumPy is a library for the Python programming language, adding support for large, multi-dimensional arrays and matrices, along with a large collection of high-level mathematical functions to operate on these arrays.&lt;/p&gt;
&lt;p&gt;(215 chars, 35 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/0_unknown/1_step720000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/tacotron/0_unknown/1_step720000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;&lt;a href=&#34;https://numba.pydata.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://numba.pydata.org/&lt;/a&gt; ããï¼&lt;/p&gt;
&lt;p&gt;Numba gives you the power to speed up your applications with high performance functions written directly in Python.&lt;/p&gt;
&lt;p&gt;(115 chars, 19 words)&lt;/p&gt;
&lt;p&gt;&lt;audio controls=&#34;controls&#34; &gt;ã¯&lt;/p&gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/0_unknown/2_step720000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/tacotron/0_unknown/2_step720000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;h4 id=&#34;ã¹ãã«ãã¹&#34;&gt;ã¹ãã«ãã¹&lt;/h4&gt;
&lt;p&gt;ã¹ãã«ãã¹ãããå ´åã«ãåæçµæã¯ã©ããªãã®ããã¨ãã£ããã¹ãã§ãã&lt;a href=&#34;https://google.github.io/tacotron/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Googleã®ãã¢&lt;/a&gt;ã«ããããã«ãããç¨åº¦ã­ãã¹ãï¼å°ãªãã¨ãå¨ä½ãç ´ç¶»ããã¨ãã£ããã¨ã¯ãªãï¼ã®ããã«æãã¾ããã&lt;/p&gt;
&lt;p&gt;Thisss isrealy awhsome.&lt;/p&gt;
&lt;p&gt;(23 chars, 4 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/1_spell/0_step720000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/tacotron/1_spell/0_step720000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;This is really awesome.&lt;/p&gt;
&lt;p&gt;(23 chars, 5 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/1_spell/1_step720000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/tacotron/1_spell/1_step720000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;I cannnnnot believe it.&lt;/p&gt;
&lt;p&gt;(23 chars, 5 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/1_spell/2_step720000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/tacotron/1_spell/2_step720000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;I cannot believe it.&lt;/p&gt;
&lt;p&gt;(20 chars, 6 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/1_spell/3_step720000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/tacotron/1_spell/3_step720000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;h4 id=&#34;ä¸­å°ãé·ãã®æç« &#34;&gt;ä¸­ãå°ãé·ãã®æç« &lt;/h4&gt;
&lt;p&gt;ã ããã250æå­ãè¶ãããããã§ãåèªãã¹ã­ããããããªã©ã®ç¾è±¡ãå¤ãç¢ºèªããã¾ããããã¼ã¿ã»ããã¯åºæ¬çã«ç­ãæç« ã®éã¾ããªã®ãçç±ã«æãã¾ããåè¿°ã®éããmonotonic attentionãä½¿ãã°ãåççã«ã¯ã¹ã­ããããã«ãããªãã¨æãã¾ãã&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/1703.10135&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://arxiv.org/abs/1703.10135&lt;/a&gt; ããå¼ç¨ï¼&lt;/p&gt;
&lt;p&gt;A text-to-speech synthesis system typically consists of multiple stages, such as a text analysis frontend, an acoustic model and an audio synthesis module.&lt;/p&gt;
&lt;p&gt;(155 chars, 26 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/2_long/1_step720000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/tacotron/2_long/1_step720000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;&lt;a href=&#34;https://americanliterature.com/childrens-stories/little-red-riding-hood&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://americanliterature.com/childrens-stories/little-red-riding-hood&lt;/a&gt; ããå¼ç¨ï¼&lt;/p&gt;
&lt;p&gt;Once upon a time there was a dear little girl who was loved by every one who looked at her, but most of all by her grandmother, and there was nothing that she would not have given to the child.&lt;/p&gt;
&lt;p&gt;(193 chars, 43 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/2_long/0_step720000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/tacotron/2_long/0_step720000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/1703.10135&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://arxiv.org/abs/1703.10135&lt;/a&gt; ããå¼ç¨ï¼&lt;/p&gt;
&lt;p&gt;A text-to-speech synthesis system typically consists of multiple stages, such as a text analysis frontend, an acoustic model and an audio synthesis module. Building these components often requires extensive domain expertise and may contain brittle design choices.&lt;/p&gt;
&lt;p&gt;(263 chars, 41 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/2_long/2_step720000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/tacotron/2_long/2_step720000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;&lt;a href=&#34;https://americanliterature.com/childrens-stories/little-red-riding-hood&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://americanliterature.com/childrens-stories/little-red-riding-hood&lt;/a&gt; ããå¼ç¨ï¼&lt;/p&gt;
&lt;p&gt;Once upon a time there was a dear little girl who was loved by every one who looked at her, but most of all by her grandmother, and there was nothing that she would not have given to the child. Once she gave her a little cap of red velvet, which suited her so well
that she would never wear anything else. So she was always called Little Red Riding Hood.&lt;/p&gt;
&lt;p&gt;(354 chars, 77 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/2_long/3_step720000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/tacotron/2_long/3_step720000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;h3 id=&#34;googleã®ãã¢ã¨æ¯è¼&#34;&gt;Googleã®ãã¢ã¨æ¯è¼&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://google.github.io/tacotron/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://google.github.io/tacotron/&lt;/a&gt; ã®é³å£°ãµã³ãã«ã¨åãæç« ã§è©¦ãã¾ããå¤§æå­å°æå­ã®åºå¥ã¯ä»åå­¦ç¿ããã¢ãã«ã§ã¯åºå¥ããªãã®ã§ãä¸é¨ä¾æã¯é¤ãã¦ãã¾ããããã¤ãæ°ã¥ãããã¨ãæãã¦ããã¨ã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;He has read the whole thing. / He reads book. ã®ããã«ãreadã®èª­ã¿ãåè©ã®æ´»ç¨å½¢ã«ãã£ã¦å¤ãããããªå ´åãªã®ã§ãããä¸æãè¡ãã¨ãã¨ãããªãã¨ããããã¾ãããã¤ãã¬ã¼ã·ã§ã³ãé²ãã¦ããä¸ã§ãã­ã¹ã¯ä¸ããç¶ããä¸æ¹ã§ããã¡ãã¨åºå¥ãã¦çºé³ã§ããããã«ãªã£ããã§ããªããªã£ã¦ãã¾ã£ãããã¨ããã®ãç¹°ãè¿ãã¦ãã¾ããã&lt;/li&gt;
&lt;li&gt;&lt;code&gt;?&lt;/code&gt; ãææ«ã«ã¤ããã¨ã§ãã¤ã³ããã¼ã·ã§ã³ãå¤ãã£ã¦ããããã¨ãæå¾ãã¾ãããããã¼ã¿ã»ããä¸­ã« &lt;code&gt;?&lt;/code&gt; ãå°ãªãããã®ãããã¾ããã¾ããããªãã£ãããã«æãã¾ãã&lt;/li&gt;
&lt;li&gt;out-of-domainã®æç« ã«ãã­ãã¹ãã®ããã«æãã¾ããããäºåç®ã®ä¾æã®ãããªãï¼è¤éãªï¼ï¼å°éç¨èªã®çºé³ã¯ãå³ããæãããã¾ããã&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Generative adversarial network or variational auto-encoder.&lt;/p&gt;
&lt;p&gt;(59 chars, 7 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/4_google_demo/0_step720000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/tacotron/4_google_demo/0_step720000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;Basilar membrane and otolaryngology are not auto-correlations.&lt;/p&gt;
&lt;p&gt;(62 chars, 8 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/4_google_demo/1_step720000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/tacotron/4_google_demo/1_step720000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;He has read the whole thing.&lt;/p&gt;
&lt;p&gt;(28 chars, 7 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/4_google_demo/2_step720000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/tacotron/4_google_demo/2_step720000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;He reads books.&lt;/p&gt;
&lt;p&gt;(15 chars, 4 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/4_google_demo/3_step720000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/tacotron/4_google_demo/3_step720000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;Thisss isrealy awhsome.&lt;/p&gt;
&lt;p&gt;(23 chars, 4 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/4_google_demo/4_step720000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/tacotron/4_google_demo/4_step720000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;This is your personal assistant, Google Home.&lt;/p&gt;
&lt;p&gt;(45 chars, 9 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/4_google_demo/5_step720000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/tacotron/4_google_demo/5_step720000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;This is your personal assistant Google Home.&lt;/p&gt;
&lt;p&gt;(44 chars, 8 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/4_google_demo/6_step720000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/tacotron/4_google_demo/6_step720000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;The quick brown fox jumps over the lazy dog.&lt;/p&gt;
&lt;p&gt;(44 chars, 10 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/4_google_demo/7_step720000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/tacotron/4_google_demo/7_step720000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;Does the quick brown fox jump over the lazy dog?&lt;/p&gt;
&lt;p&gt;(51 chars, 11 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/4_google_demo/8_step720000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/tacotron/4_google_demo/8_step720000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;h3 id=&#34;keithitotacotron-ã¨ã®æ¯è¼&#34;&gt;keithito/tacotron ã¨ã®æ¯è¼&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://keithito.github.io/audio-samples/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://keithito.github.io/audio-samples/&lt;/a&gt; ã® audio samples ã§ä½¿ããã¦ããæç« ã«å¯¾ãããã¹ãã§ããæ¯è¼ããããããã«ãæ¯è¼å¯¾è±¡ã®é³å£°ãåããã¦è²¼ã£ã¦ããã¾ããèªåå®è£ã§çæãããã®ã&lt;a href=&#34;https://github.com/keithito/tacotron&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;keithito/tacotron&lt;/a&gt; ã§çæãããã®ãã®é ã§ãã&lt;/p&gt;
&lt;p&gt;Scientists at the CERN laboratory say they have discovered a new particle.&lt;/p&gt;
&lt;p&gt;(74 chars, 13 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/3_keithito/0_step720000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/keithito/eval-877000-0.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/tacotron/3_keithito/0_step720000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;There&amp;rsquo;s a way to measure the acute emotional intelligence that has never gone out of style.&lt;/p&gt;
&lt;p&gt;(91 chars, 18 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/3_keithito/1_step720000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/keithito/eval-877000-1.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/tacotron/3_keithito/1_step720000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;President Trump met with other leaders at the Group of 20 conference.&lt;/p&gt;
&lt;p&gt;(69 chars, 13 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/3_keithito/2_step720000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/keithito/eval-877000-2.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/tacotron/3_keithito/2_step720000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;The Senate&amp;rsquo;s bill to repeal and replace the Affordable Care Act is now imperiled.&lt;/p&gt;
&lt;p&gt;(81 chars, 16 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/3_keithito/3_step720000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/keithito/eval-877000-3.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/tacotron/3_keithito/3_step720000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;Generative adversarial network or variational auto-encoder.&lt;/p&gt;
&lt;p&gt;(59 chars, 7 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/3_keithito/4_step720000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/keithito/eval-877000-4.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/tacotron/3_keithito/4_step720000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;The buses aren&amp;rsquo;t the problem, they actually provide a solution.&lt;/p&gt;
&lt;p&gt;(63 chars, 13 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/3_keithito/5_step720000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/keithito/eval-877000-5.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/tacotron/3_keithito/5_step720000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;h3 id=&#34;ground-truth-ã¨ã®æ¯è¼&#34;&gt;Ground truth ã¨ã®æ¯è¼&lt;/h3&gt;
&lt;p&gt;æå¾ã«ãåã®ãã¼ã¿ã»ããã¨ã®æ¯è¼ã§ããå­¦ç¿ãã¼ã¿ãããµã³ãã«ãåã£ã¦ãã¦æ¯è¼ãã¾ããèªåå®è£ã§çæãããã®ãground truthã®é ã«è²¼ãã¾ãã&lt;/p&gt;
&lt;p&gt;Printing, in the only sense with which we are at present concerned, differs from most if not from all the arts and crafts represented in the Exhibition.&lt;/p&gt;
&lt;p&gt;(152 chars, 30 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/5_ljspeech_sample/0_step720000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/lj/LJ001-0001.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/tacotron/5_ljspeech_sample/0_step720000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;in being comparatively modern.&lt;/p&gt;
&lt;p&gt;(30 chars, 5 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/5_ljspeech_sample/1_step720000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/lj/LJ001-0002.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/tacotron/5_ljspeech_sample/1_step720000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;For although the Chinese took impressions from wood blocks engraved in relief for centuries before the woodcutters of the Netherlands, by a similar process.&lt;/p&gt;
&lt;p&gt;(156 chars, 26 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/5_ljspeech_sample/2_step720000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/lj/LJ001-0003.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/tacotron/5_ljspeech_sample/2_step720000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;produced the block books, which were the immediate predecessors of the true printed book,&lt;/p&gt;
&lt;p&gt;(89 chars, 16 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/5_ljspeech_sample/3_step720000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/lj/LJ001-0004.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/tacotron/5_ljspeech_sample/3_step720000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;the invention of movable metal letters in the middle of the fifteenth century may justly be considered as the invention of the art of printing.&lt;/p&gt;
&lt;p&gt;(143 chars, 26 words)&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/5_ljspeech_sample/4_step720000.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/tacotron/lj/LJ001-0005.mp3&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/audio/tacotron/5_ljspeech_sample/4_step720000_alignment.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;åé³å£°ããã¾ãè¯ãã¯ãªã¼ã³ãªé³å£°ã§ã¯ãªãã¨ã¯ãããã¾ã¼åé³å£°ã¨ã¯å¤§ããªéããããã¾ãã­ã¼ããå³ããã§ããã¹ãã¯ãã­ã°ã©ã ãè¦ã¦ããéãã§ã¯ï¼è²¼ã£ã¦ãªãã§ãããããã¾ããï¼ãæããã«é«å¨æ³¢æ°æåã®äºæ¸¬ãä¸æãè¨ã£ã¦ããªããã¨ã¯ããã£ã¦ãã¾ãããã¤ã¼ããªã¢ã¤ãã¢ã§ã¯ããã¾ãããGANãå°å¥ããã¨è¯ããªãã®ã§ã¯ãªããã¨æã£ã¦ãã¾ãã&lt;/p&gt;
&lt;h3 id=&#34;ãã¾ãçæããåº¦ã«å¤ããé³å£°&#34;&gt;ãã¾ãï¼çæããåº¦ã«å¤ããé³å£°&lt;/h3&gt;
&lt;p&gt;å®é¨ããéç¨ã§å¯æ¬¡çã«å¾ãããçµæã§ã¯ããã®ã§ããããã¹ãæã«ä¸é¨dropoutãæå¹ã«ãã¦ããã¨&lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;ãçæããåº¦ã«é³å£°ãç°ãªãï¼é»å¾ãå¾®å¦ã«å¤ããï¼ãã¨ãã£ãç¾è±¡ãçµé¨ãã¦ãã¾ããä»¥ä¸ãåã«æ¤è¨¼ããéã®å®é¨ãã¼ãã®ãªã³ã¯ãè²¼ã£ã¦ããã¾ãã&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://nbviewer.jupyter.org/gist/r9y9/fe1945b73cd5b98e97c61410fe26a851#Try-same-input-multiple-times&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://nbviewer.jupyter.org/gist/r9y9/fe1945b73cd5b98e97c61410fe26a851#Try-same-input-multiple-times&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;ã¾ã¨ã--ææ³ãªã©&#34;&gt;ã¾ã¨ã &amp;amp; ææ³ãªã©&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Tacotronãå®è£ãã¾ãã &lt;a href=&#34;https://github.com/r9y9/tacotron_pytorch&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/r9y9/tacotron_pytorch&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;24æéã®ãã¼ã¿ã»ããã«å¯¾ãã¦ã20ä¸ã¹ãããç¨åº¦ï¼æ°æ¥ãããï¼å­¦ç¿ãããããããªãã«ã¾ã¨ããªé³å£°ãçæã§ããããã«ãªãã¾ããã70ä¸ã¹ãããï¼ä¸é±éã¨å°ããããï¼å­¦ç¿ããã¾ãããããã£ã¨ã­ã¹ã¯ä¸ããç¶ããä¸æ¹ã§ã50ä¸ãããããã¯ãã¾ãå¤§ããªåè³ªæ¹åã¯è¦ãããªãã£ãããã«æãã¾ãã&lt;/li&gt;
&lt;li&gt;Googleã®è«æã¨ï¼ã»ã¼&lt;sup id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;ï¼åãããã«å®è£ããã¤ããã§ãããåè³ªã¯ããã¾ã§é«ããªããªãã£ãããã«æãã¾ããEnd-to-end ã§ã¯ã &lt;strong&gt;ãã¼ã¿ã®éã¨åè³ª&lt;/strong&gt; ãããªãéè¦ãªã®ã§ããããä¸»ãªåå ã ã¨æã£ã¦ãã¾ããï¼åã®å®è£ã«ãå¤å°ãã°ãããããããã¾ãããããã&lt;/li&gt;
&lt;li&gt;EOS (End-of-sentence) ã§ã¯ãçæ³çã«ã¯è¦ç´ ããã¹ã¦0ã®ã¹ãã¯ãã­ã°ã©ã ãåºåãããã¯ããªã®ã§ãããå®éã«ã¯ãã¯ãããããããªãã®ã§ãå¤å®ã«ã¯ä»¥ä¸ã®ãããªãããå¤å¦çãç¨ãã¾ãããããã§è²¼ã£ãé³å£°ã¯å¨é¨ãã®ä»çµã¿ã§åãã¦ãããåç´ã§ãããããªãã«ä¸æãæ©è½ãã¦ããããã§ãã&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;def is_end_of_frames(output, eps=0.2):
    return (output.data &amp;lt;= eps).all()
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;è«æããã¯éèªæãªç¹ã®ä¸ã¤ã¨ãã¦ãã¨ã³ã³ã¼ãã®åºåã®ãã¡ãå¥åã®ã¼ã­è©°ãããé¨åããã¹ã­ã³ã°ãããã©ãããã¨ãã£ãç¹ãããã¾ããããã¯ãæ¢å­å®è£ã«ãã£ã¦ãã¾ã¡ã¾ã¡ã§ãä¾ãã° &lt;a href=&#34;https://github.com/keithito/tacotron&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;keithito/tacotron&lt;/a&gt; ã§ã¯ãã¹ã­ã³ã°ãã¦ãã¾ãããã&lt;a href=&#34;https://github.com/barronalex/Tacotron/blob/2de9e507456cbe2b680cbc6b2beb6a761bd2eebd/models/tacotron.py#L51&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;barronalex/Tacotron&lt;/a&gt; ã§ã¯ãã¹ã¯ãã¦ãã¾ããåã¯ãã¹ã¯ããå ´åã¨ããªãå ´åã¨ä¸¡æ¹è©¦ããã®ã§ããï¼ããã«è²¼ã£ãçµæã¯ããã¹ã¯ãã¦ããªãå ´åã®ãã®ã§ãï¼ããã¹ã¯ããªãã»ããè¥å¹²è¯ããªã£ããããªæ°ããã¾ããçæ³çã«ã¯ãã¹ã¯ããã¹ãã ã¨æã£ãã®ã§ãããå®éã«è©¦ããã¨ããã©ã¡ãããå§åçã«æªãã¨ããçµæã§ã¯ããã¾ããã§ãããçºè¦ããå¤§ããªéãã®ä¸ã¤ã¯ããã¹ã¯ãªãã®å ´åã¯ã¢ãã³ã·ã§ã³ã¯å¤§ã¾ãã«monotonicã«ãªãä¸æ¹ã§ããã¹ã¯ããã®å ´åã¯ãç¡é³åºéã§ã¯ã¨ã³ã³ã¼ãåºåã®åé ­ã«ã¢ãã³ã·ã§ã³ã®éã¿ãå¤§ãããªãï¼ã®ã§ãmonotonicã§ã¯ãªãï¼ãã¨è¨ã£ããã¨ãããã¾ããããã¹ã¯ããã®é³å£°ãµã³ãã«ãã¢ã©ã¤ã¡ã³ãã®å¯è¦åã¯ãï¼å°ãå¤ãã§ããï¼&lt;a href=&#34;http://nbviewer.jupyter.org/github/r9y9/tacotron_pytorch/blob/bdad19fdff22016c7457a979707655bb7a605cd8/notebooks/Test%20Tacotron.ipynb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ãã&lt;/a&gt; ã«ããã¾ããåèã¾ã§ã«ãTensorflowã§ã¨ã³ã³ã¼ãã®åºåãã¹ã¯ããå ´åã¯ã&lt;code&gt;memory_sequence_length&lt;/code&gt; ãæå®ãã¾ã &lt;a href=&#34;https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/BahdanauAttention&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/BahdanauAttention&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;æ¥æ¬èªã§ãã£ãããmulti-speaker ã§ãã£ãããããã£ãã®ã§ãããã¨ã«ããå®é¨ã«æéããããã®ã§ãä»ã®ã¨ããåã®ä¸­ã§ã¯åªååº¦ãä½ãã«ãªã£ã¦ãã¾ãã¾ãããæéã¨è¨ç®è³æºã«ä½è£ãããã°ãããããã®ã§ããâ¦&lt;/li&gt;
&lt;li&gt;æ¥æ¬èªã§ããã«ã¯ãè±èªã¨åãããã«ã¯ããã¾ãããã¨ããã®ããchar-levelã§èããéã«ãèªå½ãå¤§ããããã®ã§ããããªãã°ãååå¤§ããªæ¥æ¬èªãã­ã¹ãã³ã¼ãã¹ããembeddingãå¥éå­¦ç¿ãã¦ï¼Tacotronã§ã¯ãã¢ãã«èªä½ã«embeddingãå¥ã£ã¦ãã¾ãï¼ããã®ä»ã®é¨åãé³å£°ã¤ãã³ã¼ãã¹ã§å­¦ç¿ãããã¨ãã£ãæ¹æ³ãè¯ãããªã¨æãã¾ããCSJã³ã¼ãã¹ã¯çµæ§åãã¦ããããããªããã¨æã£ã¦ãã¾ãã&lt;/li&gt;
&lt;li&gt;multi-speakerã¢ãã«ãèããå ´åãã©ãã«embeddingãå·®ãè¾¼ãã®ããã¨ãã£ããã¨ãéè¦ã«ãªã£ã¦ãã¾ããã&lt;a href=&#34;https://github.com/keithito/tacotron/issues/18&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;keithito/tacotron/issues/18&lt;/a&gt; ã &lt;a href=&#34;https://github.com/keithito/tacotron/issues/24&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;keithito/tacotron/issues/24&lt;/a&gt; ã«å°ãè­°è«ãããã®ã§ãèå³ã®ããäººã¯è¦ã¦ã¿ãã¨ããããããã¾ãããDeepVoiceã®è«æãåèã«ãªããã¨æãã¾ã&lt;/li&gt;
&lt;li&gt;ææ°ã®TensorFlowã§ã¯ãgriffin lim ã stftï¼GPUã§èµ°ããå¾éãæ±ããããï¼ãå®è£ããã¦ããã®ã§ãtacotronã¢ãã«ãå°ãæ¡å¼µãã¦ããµã³ãã«ã¬ãã«ã§ã­ã¹ãèãããã¨ãã£ããã¨ãç°¡åã«è©¦ããã¨æãã¾ãï¼ããæå³WaveNetã§ãï¼ããã ãããã®ãããè¨ç®ãªã½ã¼ã¹ãå¿è¦ã¨ããã®ãå®¹æã«æ³åãã¤ãã®ã§ãåã¯ãã£ã¦ãã¾ãããGPUè½ã¡ã¦ããªãããªããã&lt;/li&gt;
&lt;li&gt;Tacotronã®æ¡å¼µã¨ãã¦ãspeaker embeddingä»¥å¤ã«ããããããªæ½å¨å¤æ°ãåãè¾¼ãã§ã¿ãã¨ãæ¥½ãããã«æãã¾ãããä¾ãã°è©±éãææã¨ãã&lt;/li&gt;
&lt;li&gt;TensorFlowã®seq2seqãããã®ãã­ã¥ã¡ã³ã/ã³ã¼ããããèª­ãã§ããã®ã§ãããAPIãæ½è±¡åããããã¦ãã¦ã¤ãããªã¨æãã¾ãããä¾ãã°AttentionWrapperãã³ã¼ããèª­ã¾ãã«æåãçè§£ããã®ã¯ç¡çãªã®ã§ã¯ã¨æãã¾ãã &lt;a href=&#34;https://github.com/r9y9/tacotron_pytorch/issues/2#issuecomment-334255759&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/r9y9/tacotron_pytorch/issues/2#issuecomment-334255759&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/keithito/tacotron&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;keithito/tacotron&lt;/a&gt; ã¯æ¬å½ã«ããæ¸ããã¦ãããªã¨æã£ãã®ã§ãTensorFlowã«é·ãã¦ããæ¹ã«ã¯ãããããã§ã&lt;/li&gt;
&lt;li&gt;åã®å®è£ã§ã¯ãããããµã¤ãº32ã§GPUã¡ã¢ãª5GBç¨åº¦ããé£ããªãã®ã§ãTacotronã¯æ¯è¼çè»½ãã¢ãã«ãªã®ã ãªã¼ã¨æãã¾ãããç©ä½æ¤åºã§æåãª single shot multibox detector (éç§°SSD) ãªããã¯ãããããµã¤ãº16ã¨ãã§ãå¹³æ°ã§12GBã¨ãä½¿ã£ã¦ããã®ã§ï¼ä¸å¹´è¿ãåã®çµé¨ã§ããï¼ãç¡éã«GPUãªã½ã¼ã¹ãã»ãããªã£ã¦ãã¾ã&lt;/li&gt;
&lt;li&gt;ãããåã«ã¨ã£ã¦ãã¯ããã¦ã¾ã¨ãã«seq2seqãå®è£ããçµé¨ã§ãããè²ãåå¼·ããã®ã§ãããAttention mechanism ã«é¢ãã¦ã¯ã &lt;a href=&#34;http://colinraffel.com/blog/online-and-linear-time-attention-by-enforcing-monotonic-alignments.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://colinraffel.com/blog/online-and-linear-time-attention-by-enforcing-monotonic-alignments.html&lt;/a&gt; ãã¨ã¦ãåèã«ãªãã¾ããããã¨ã§ç¥ã£ãã®ã§ãããmonotonic attentionã®èèã¯åãæããä½¿ã£ã¦ããé³æ¥½ä¿¡å·å¦çã®ã©ã¤ãã©ãª &lt;a href=&#34;https://github.com/librosa/librosa&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;librosa&lt;/a&gt; ã®ã³ããã¿ã§ããï¼åãå¼±å°ã³ããã¿ã®ä¸äººï¼ãã¨ã¦ãä¾¿å©ã§ããããã¹ãããã¦ããã®ã§ãããããã§ãããªã¼ãã³ã½ã¼ã¹ã®Tacotronå®è£ã§ããé³å£°å¦çã«ãä½¿ããã¦ãã¾ã&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;ãããã«&#34;&gt;ãããã«&lt;/h2&gt;
&lt;p&gt;End-to-End é³å£°åæã¯ãè¨èªå¦çã®ãã­ã³ãã¨ã³ããï¼æä½éã®åå¦çãé¤ãï¼å¿è¦ã¨ããªãã¨ããç´ æ´ããããããã¾ããSampleRNNãChar2wavã¨ä»ã«ãè²ãããã¾ãããä»å¾ãã£ã¨çºå±ãã¦ããã®ã§ã¯ãªããã¨æã£ã¦ãã¾ããããã¾ãã&lt;/p&gt;
&lt;h2 id=&#34;åè&#34;&gt;åè&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1703.10135&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Tacotron: Towards End-to-End Speech Synthesis / arXiv:1703.10135&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;URLã«ã¯ç¾æç¹ã®gitã®ã³ãããããã·ã¥ãå¥ã£ã¦ãã¾ããææ°çã¯ã &lt;a href=&#34;https://github.com/r9y9/tacotron_pytorch&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/r9y9/tacotron_pytorch&lt;/a&gt; ããç´æ¥è¾¿ã£ã¦ãã ããã&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/keithito/tacotron/pull/43#issuecomment-332068107&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/keithito/tacotron/pull/43#issuecomment-332068107&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34;&gt;
&lt;p&gt;dropoutãåã£ã¦ãã¾ãã¨ãã¢ã©ã¤ã¡ã³ããæ­»ãã§ãã¾ãã¨ãããã°ï¼ã«è¦ããã§ããâ¦æªã åå ãçªãæ­¢ãããã¦ãã¾ãã&amp;#160;&lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:4&#34;&gt;
&lt;p&gt;ãã¨ãã°ã­ã¹ã¯ã¡ãã£ã¨éã£ã¦ãé«å¨æ³¢æ°å¸¯åã«æ¯ã¹ã¦ä½å¨æ³¢æ°å¸¯åã®éã¿ãå°ãå¤§ãããã¦ããããã¦ãã¾ããããã¯æ¢å­ã®tfå®è£ã«å¾ãã¾ããã&amp;#160;&lt;a href=&#34;#fnref:4&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>GAN æ¥æ¬èªé³å£°åæ [arXiv:1709.08041]</title>
      <link>https://r9y9.github.io/blog/2017/10/10/gantts-jp/</link>
      <pubDate>Tue, 10 Oct 2017 11:45:32 +0900</pubDate>
      <guid>https://r9y9.github.io/blog/2017/10/10/gantts-jp/</guid>
      <description>&lt;p&gt;&lt;strong&gt;10/11 è¿½è¨&lt;/strong&gt;: IEEE TASLPã®ãã¼ãã¼ (Open access) ãå¬éããããããªã®ã§ããªã³ã¯ãè²¼ã£ã¦ããã¾ã: &lt;a href=&#34;https://ieeexplore.ieee.org/document/8063435/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://ieeexplore.ieee.org/document/8063435/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;arXivè«æãªã³ã¯: &lt;a href=&#34;https://arxiv.org/abs/1709.08041&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;arXiv:1709.08041&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://r9y9.github.io/blog/2017/10/09/gantts/&#34;&gt;ååã®è¨äº&lt;/a&gt; ã®ç¶ãã§ããããã§ãã®ã·ãªã¼ãºã¯çµããã®äºå®ã§ãã&lt;/p&gt;
&lt;p&gt;ååã¯è±èªé³å£°åæã§ããããä»¥åæ¸ãã &lt;a href=&#34;https://r9y9.github.io/blog/2017/08/16/japanese-dnn-tts/&#34;&gt;DNNæ¥æ¬èªé³å£°åæã®è¨äº&lt;/a&gt; ã§ä½¿ã£ããã¼ã¿ã¨åããã®ãä½¿ããæ¥æ¬èªé³å£°åæããã£ã¦ã¿ã¾ããã®ã§ãçµæãæ®ãã¦ããã¾ãã&lt;/p&gt;
&lt;h2 id=&#34;å®é¨&#34;&gt;å®é¨&lt;/h2&gt;
&lt;h3 id=&#34;å®é¨æ¡ä»¶&#34;&gt;å®é¨æ¡ä»¶&lt;/h3&gt;
&lt;p&gt;HTSã®NIT-ATR503ã®ãã¢ãã¼ã¿ (&lt;a href=&#34;https://github.com/r9y9/nnmnkwii_gallery/blob/4899437e22528399ca50c34097a2db2bed782f8b/data/NIT-ATR503_COPYING&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ã©ã¤ã»ã³ã¹&lt;/a&gt;) ãããwavãã¼ã¿503çºè©±ãç¨ãã¾ãã442ãå­¦ç¿ç¨ã56ãè©ä¾¡ç¨ãæ®ã5ããã¹ãç¨ã«ãã¾ãï¼â»è±èªé³å£°ã¨train/evalã®æ¯çã¯åãã§ãï¼ãç¶ç¶é·ã¢ãã«ã¯ãstate-levelã§ã¯ãªãphone-levelã§ãããµã³ããªã³ã°å¨æ³¢æ°ã48kHzãªã®ã§ãmgcã®æ¬¡åã25ãã60ã«å¢ããã¾ãããã¢ãã«æ§é ã¯ããã¹ã¦è±èªé³å£°åæã®å ´åã¨åãã§ããADV loss ã¯0æ¬¡ãé¤ãmgcãç¨ãã¦è¨ç®ãã¾ãããF0ã¯å¥ãã¦ãã¾ããã&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/r9y9/gantts&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;gantts&lt;/a&gt; ã® &lt;a href=&#34;https://github.com/r9y9/gantts/tree/jp&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;jpãã©ã³ã&lt;/a&gt; ããã§ãã¯ã¢ã¦ããã¦ãä»¥ä¸ã®ã·ã§ã«ãå®è¡ããã¨ãããã«è²¼ã£ãçµæãå¾ããã¾ãã&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; ./jp_tts_demo.sh jp_tts_order59
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;ãã ããã·ã§ã«ä¸­ã«ã&lt;code&gt;HTS_ROOT&lt;/code&gt; ã¨ããå¤æ°ããããã·ã§ã«å®è¡åã«ãç°å¢ã«åããã¦ãã£ã¬ã¯ããªãæå®ããå¿è¦ãããã¾ãã&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt;diff --git a/jp_tts_demo.sh b/jp_tts_demo.sh
index 7a8f12c..b18e604 100755
--- a/jp_tts_demo.sh
+++ b/jp_tts_demo.sh
@@ -8,7 +8,7 @@ experiment_id=$1
 fs=48000

 # Needs adjastment
-HTS_DEMO_ROOT=~/local/HTS-demo_NIT-ATR503-M001
+HTS_DEMO_ROOT=HTSæ¥æ¬èªãã¢ã®å ´æãæå®ãã¦ãã ãã

 # Flags
 run_duration_training=1
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;å¤æé³å£°ã®æ¯è¼&#34;&gt;å¤æé³å£°ã®æ¯è¼&lt;/h3&gt;
&lt;h4 id=&#34;é³é¿ã¢ãã«ã®ã¿é©ç¨&#34;&gt;é³é¿ã¢ãã«ã®ã¿é©ç¨&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;èªç¶é³å£°&lt;/li&gt;
&lt;li&gt;ãã¼ã¹ã©ã¤ã³&lt;/li&gt;
&lt;li&gt;GAN&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;ã®é ã«é³å£°ãè²¼ãã¾ããè´ããããããã«ãsoxã§é³éãæ­£è¦åãã¦ãã¾ãã&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;nitech_jp_atr503_m001_j49&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/nit-atr503/nitech_jp_atr503_m001_j49.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-gantts/jp_tts_order59/acoustic_only/baseline/test/nitech_jp_atr503_m001_j49.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-gantts/jp_tts_order59/acoustic_only/gan/test/nitech_jp_atr503_m001_j49.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;&lt;strong&gt;nitech_jp_atr503_m001_j50&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/nit-atr503/nitech_jp_atr503_m001_j50.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-gantts/jp_tts_order59/acoustic_only/baseline/test/nitech_jp_atr503_m001_j50.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-gantts/jp_tts_order59/acoustic_only/gan/test/nitech_jp_atr503_m001_j50.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;&lt;strong&gt;nitech_jp_atr503_m001_j51&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/nit-atr503/nitech_jp_atr503_m001_j51.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-gantts/jp_tts_order59/acoustic_only/baseline/test/nitech_jp_atr503_m001_j51.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-gantts/jp_tts_order59/acoustic_only/gan/test/nitech_jp_atr503_m001_j51.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;&lt;strong&gt;nitech_jp_atr503_m001_j52&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/nit-atr503/nitech_jp_atr503_m001_j52.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-gantts/jp_tts_order59/acoustic_only/baseline/test/nitech_jp_atr503_m001_j52.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-gantts/jp_tts_order59/acoustic_only/gan/test/nitech_jp_atr503_m001_j52.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;&lt;strong&gt;nitech_jp_atr503_m001_j53&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/nit-atr503/nitech_jp_atr503_m001_j53.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-gantts/jp_tts_order59/acoustic_only/baseline/test/nitech_jp_atr503_m001_j53.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-gantts/jp_tts_order59/acoustic_only/gan/test/nitech_jp_atr503_m001_j53.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;h4 id=&#34;é³é¿ã¢ãã«ç¶ç¶é·ã¢ãã«ãé©ç¨&#34;&gt;é³é¿ã¢ãã«ï¼ç¶ç¶é·ã¢ãã«ãé©ç¨&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;nitech_jp_atr503_m001_j49&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/nit-atr503/nitech_jp_atr503_m001_j49.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-gantts/jp_tts_order59/duration_acoustic/baseline/test/nitech_jp_atr503_m001_j49.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-gantts/jp_tts_order59/duration_acoustic/gan/test/nitech_jp_atr503_m001_j49.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;&lt;strong&gt;nitech_jp_atr503_m001_j50&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/nit-atr503/nitech_jp_atr503_m001_j50.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-gantts/jp_tts_order59/duration_acoustic/baseline/test/nitech_jp_atr503_m001_j50.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-gantts/jp_tts_order59/duration_acoustic/gan/test/nitech_jp_atr503_m001_j50.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;&lt;strong&gt;nitech_jp_atr503_m001_j51&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/nit-atr503/nitech_jp_atr503_m001_j51.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-gantts/jp_tts_order59/duration_acoustic/baseline/test/nitech_jp_atr503_m001_j51.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-gantts/jp_tts_order59/duration_acoustic/gan/test/nitech_jp_atr503_m001_j51.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;&lt;strong&gt;nitech_jp_atr503_m001_j52&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/nit-atr503/nitech_jp_atr503_m001_j52.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-gantts/jp_tts_order59/duration_acoustic/baseline/test/nitech_jp_atr503_m001_j52.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-gantts/jp_tts_order59/duration_acoustic/gan/test/nitech_jp_atr503_m001_j52.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;&lt;strong&gt;nitech_jp_atr503_m001_j53&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/nit-atr503/nitech_jp_atr503_m001_j53.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-gantts/jp_tts_order59/duration_acoustic/baseline/test/nitech_jp_atr503_m001_j53.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-gantts/jp_tts_order59/duration_acoustic/gan/test/nitech_jp_atr503_m001_j53.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;ã©ãã§ãããããã¡ãã£ã¨æ©å£ã«ãªã£ã¦ãã¾ã£ã¦ããç®æãããã¾ãããå¨ä½çã«ã¯æç­æ§ãä¸ãã£ã¦ãåè³ªãæ¹åããããããªæãããã¾ããè¥å¹²ãã¤ã¸ã¼ãªæãã¯ãé³é¿ã¢ãã«ã«RNNãä½¿ãã°æ¹åãããã®ã§ãããä»åã¯è¨ç®ãªã½ã¼ã¹ã®é½åä¸ãFeed-forwardåã®ãµã³ãã«ã¨ãªã£ã¦ãã¾ãã&lt;/p&gt;
&lt;h3 id=&#34;gv&#34;&gt;GV&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;nitech_jp_atr503_m001_j49&lt;/code&gt; ã«å¯¾ãã¦è¨ç®ããçµæã§ãã&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/images/jp-gantts/nitech_jp_atr503_m001_j49_gv.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;è±èªé³å£°åæã®å®é¨ã§ãç¢ºèªãã¦ããã®ã§ãããmgcã®æ¬¡åãå¤§ããåãã¨ãé«æ¬¡åã§GVãè¥å¹²è½ã¡ãå¾åã«ããã¾ãããã ãã&lt;a href=&#34;https://twitter.com/r9y9/status/915213687891169280&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ä¸é±éåã®åã®ãã¤ã¼ã&lt;/a&gt; ã«ããã¨ããªãããããªãã¨ããªãï¼å½æã°ãã°ãã®ãã­ãã¿ã¤ãã³ã°ã®ææã ã£ãã®ã§ãã³ã¼ããæ®ã£ã¦ãããããã¾ã¯åç¾ã§ããªãã¨ããããããã¾ããï¼ãåãä½ããã¹ããã¦ããå¯è½æ§ãããã¾ãããã ãåè³ªã¯ãããªã«æªããªãããã«æãã¾ãã&lt;/p&gt;
&lt;h3 id=&#34;å¤èª¿ã¹ãã¯ãã«&#34;&gt;å¤èª¿ã¹ãã¯ãã«&lt;/h3&gt;
&lt;p&gt;è©ä¾¡ç¨ã»ããã§å¹³åãåã£ããã®ã§ãã&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/images/jp-gantts/ms.png&#34; /&gt;&lt;/div&gt;
&lt;h3 id=&#34;ç¹å¾´éã®åå¸&#34;&gt;ç¹å¾´éã®åå¸&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;nitech_jp_atr503_m001_j49&lt;/code&gt; ã«å¯¾ãã¦è¨ç®ããçµæã§ãã&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/images/jp-gantts/nitech_jp_atr503_m001_j49_scatter.png&#34; /&gt;&lt;/div&gt;
&lt;h3 id=&#34;ãã¾ã-htsãã¢ã¨è´ãæ¯ã¹&#34;&gt;ãã¾ã: HTSãã¢ã¨è´ãæ¯ã¹&lt;/h3&gt;
&lt;p&gt;HTSãã¢ãå®è¡ããã¨çæããããµã³ãã«ã¨ã®è´ãæ¯ã¹ã§ããæ³¨æäºé ã§ããã&lt;strong&gt;å®é¨æ¡ä»¶ãã¾ã£ããç°ãªãã¾ã&lt;/strong&gt;ãããã¾ã§åèç¨åº¦ã«ã©ããã&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;HTSãã¢&lt;/li&gt;
&lt;li&gt;ãã¼ã¹ã©ã¤ã³&lt;/li&gt;
&lt;li&gt;GAN&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;ã®é ã«é³å£°ãè²¼ãã¾ãã&lt;/p&gt;
&lt;p&gt;1 ããã«ã¡ã¯&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/hts_nit_atr503_2mix/phrase01.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-gantts/test/baseline/phrase01.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-gantts/test/gan/phrase01.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;2 ããã§ã¯ããããªã&lt;/p&gt;
&lt;p&gt;HTS&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/hts_nit_atr503_2mix/phrase02.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-gantts/test/baseline/phrase02.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-gantts/test/gan/phrase02.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;3 ã¯ããã¾ãã¦&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/hts_nit_atr503_2mix/phrase03.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-gantts/test/baseline/phrase03.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-gantts/test/gan/phrase03.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;4 ããããåå¤å±å·¥æ¥­å¤§å­¦ã¸&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/hts_nit_atr503_2mix/phrase04.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-gantts/test/baseline/phrase04.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-gantts/test/gan/phrase04.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;5 ä»å¤ã®åå¤å±ã®å¤©æ°ã¯é¨ã§ã&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/hts_nit_atr503_2mix/phrase05.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-gantts/test/baseline/phrase05.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-gantts/test/gan/phrase05.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;h2 id=&#34;ãããã«&#34;&gt;ãããã«&lt;/h2&gt;
&lt;p&gt;ã¢ã¤ãã¢ã¯ã·ã³ãã«ãå¹æã¯ç´ æ´ãããã¨ãããåã®å¥½ããªï¼è©¦ããããªãï¼ç ç©¶ã®ç´¹ä»ã§ããããããã¨ããããã¾ããã&lt;/p&gt;
&lt;p&gt;GANã·ãªã¼ãºã®ãã®ä»è¨äºã¸ã®ãªã³ã¯ã¯ä»¥ä¸ã®éãã§ãã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://r9y9.github.io/blog/2017/10/05/ganvc/&#34;&gt;GAN å£°è³ªå¤æ (en) ç·¨ã¯ãã¡ã&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://r9y9.github.io/blog/2017/10/09/gantts/&#34;&gt;GAN é³å£°åæ (en) ç·¨ã¯ãã¡ã&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;è¿½è¨: å³ãä½ãã®ã«ä½¿ã£ããã¼ãããã¯ã¯ &lt;a href=&#34;http://nbviewer.jupyter.org/gist/r9y9/185a56417cee27d9f785b8caf1c9f5ec&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ãã¡ã&lt;/a&gt; ã«ããã¦ããã¾ããã&lt;/p&gt;
&lt;h2 id=&#34;åè&#34;&gt;åè&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1709.08041&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Yuki Saito, Shinnosuke Takamichi, Hiroshi Saruwatari, &amp;ldquo;Statistical Parametric Speech Synthesis Incorporating Generative Adversarial Networks&amp;rdquo;, arXiv:1709.08041 [cs.SD], Sep. 2017&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>ãé³å£°åæç·¨ãStatistical Parametric Speech Synthesis Incorporating Generative Adversarial Networks [arXiv:1709.08041]</title>
      <link>https://r9y9.github.io/blog/2017/10/09/gantts/</link>
      <pubDate>Mon, 09 Oct 2017 02:00:00 +0900</pubDate>
      <guid>https://r9y9.github.io/blog/2017/10/09/gantts/</guid>
      <description>&lt;p&gt;&lt;strong&gt;10/11 è¿½è¨&lt;/strong&gt;: IEEE TASLPã®ãã¼ãã¼ (Open access) ãå¬éããããããªã®ã§ããªã³ã¯ãè²¼ã£ã¦ããã¾ã: &lt;a href=&#34;https://ieeexplore.ieee.org/document/8063435/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://ieeexplore.ieee.org/document/8063435/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;arXivè«æãªã³ã¯: &lt;a href=&#34;https://arxiv.org/abs/1709.08041&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;arXiv:1709.08041&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://r9y9.github.io/blog/2017/10/05/ganvc/&#34;&gt;ååã®è¨äº&lt;/a&gt; ã®ç¶ãã§ããé³é¿ã¢ãã«ã®å­¦ç¿ã«GANãä½¿ãã¨ããã¢ã¤ãã¢ã¯ãå£°è³ªå¤æã ãã§ãªãé³å£°åæã«ãå¿ç¨ã§ãã¾ãã&lt;a href=&#34;http://festvox.org/cmu_arctic/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CMU ARCTIC&lt;/a&gt; ãä½¿ã£ãè±èªé³å£°åæã®å®é¨ãè¡ã£ã¦ãããç¨åº¦è¯ãçµæãã§ãã®ã§ãã¾ã¨ãããã¨æãã¾ããé³å£°ãµã³ãã«ã ãè´ãããæ¹ã¯çãä¸­ã®æ¹ã¾ã§èª­ã¿é£ã°ãã¦ãã ããã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ã³ã¼ãã¯ãã¡ã: &lt;a href=&#34;https:github.com/r9y9/gantts&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;r9y9/gantts | PyTorch implementation of GAN-based text-to-speech and voice conversion (VC) &lt;/a&gt; (VCã®ã³ã¼ããä¸ç·ã§ã)&lt;/li&gt;
&lt;li&gt;é³å£°ãµã³ãã«ä»ããã¢ãã¼ãããã¯ã¯ãã¡ã: &lt;a href=&#34;http://nbviewer.jupyter.org/github/r9y9/gantts/blob/master/notebooks/Test%20TTS.ipynb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;The effects of adversarial training in text-to-speech synthesis | nbviewer&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ååã®è¨äºã§ãæ¸ããæ³¨ææ¸ãã§ãããå³å¯ã«åãçµæãåç¾ãããã¨ã¯æã£ã¦ãã¾ãããåæ§ã®ã¢ã¤ãã¢ãè©¦ããã¨ãã£ããã¨ã«ä¸»ç¼ãç½®ãã¦ãã¾ãã&lt;/p&gt;
&lt;h2 id=&#34;å®é¨&#34;&gt;å®é¨&lt;/h2&gt;
&lt;h3 id=&#34;å®é¨æ¡ä»¶&#34;&gt;å®é¨æ¡ä»¶&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;http://festvox.org/cmu_arctic/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CMU ARCTIC&lt;/a&gt; ãããè©±è &lt;code&gt;slt&lt;/code&gt; ã®wavãã¼ã¿ãããã1131çºè©±ãã¹ã¦ãç¨ãã¾ãã
&lt;a href=&#34;https://github.com/CSTR-Edinburgh/merlin&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Merlin&lt;/a&gt;  ã® slt ãã¢ã®æ¡ä»¶ã¨åæ§ã«ã1000ãå­¦ç¿ç¨ã126ãè©ä¾¡ç¨ãæ®ã5ããã¹ãç¨ã«ãã¾ããç¶ç¶é·ã¢ãã«ï¼state-levelï¼ã«ã¯ &lt;strong&gt;Bidirectional-LSTM RNN&lt;/strong&gt; ããé³é¿ã¢ãã«ã«ã¯ &lt;strong&gt;Feed-forwardå&lt;/strong&gt; ã®ãã¥ã¼ã©ã«ããããä½¿ç¨ãã¾ãã&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;ãç¶ç¶é·ã¢ãã«ãé³é¿ã¢ãã«ã®ä¸¡æ¹ã«GANãåãå¥ãã¾ãããè«æã®èã§ãã &lt;strong&gt;ADV loss&lt;/strong&gt; ã«ã¤ãã¦ã§ãããmgcã®ã¿ï¼0æ¬¡ã¯é¤ãï¼ãä½¿ã£ã¦è¨ç®ãããã¿ã¼ã³ã¨ãmgc + lf0ã§è¨ç®ãããã¿ã¼ã³ã¨ã§æ¯è¼ãã¾ãã&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;ã&lt;/p&gt;
&lt;p&gt;å®é¨ã®çµæ (ADV loss: mgcã®ã¿) ã¯ã &lt;a href=&#34;https://github.com/r9y9/gantts/tree/a5ec247ba7ee1a160875661f8899f56f8010be5b&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;a5ec247&lt;/a&gt; ããã§ãã¯ã¢ã¦ããã¦ãä¸è¨ã®ã·ã§ã«ãå®è¡ããã¨åç¾ã§ãã¾ãã&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;./tts_demo.sh tts_test
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;ãã¼ã¿ã®ãã¦ã³ã­ã¼ããç¹å¾´æ½åºãã¢ãã«å­¦ç¿ãé³å£°ãµã³ãã«åæã¾ã§ä¸éãè¡ããã¾ãã&lt;code&gt;tts_test&lt;/code&gt; ã®é¨åã¯ä½ã§ãããã§ããtensorboardç¨ã«åãã­ã°ã¤ãã³ãåãã¢ãã«åºååãé³å£°ãµã³ãã«åºååã®æ±ºå®ã«ä½¿ããã¾ããè©³ç´°ã¯ã³ã¼ããåç§ãã ããã (ADV loss: mgc + lf0) ã®çµæã¯ã&lt;a href=&#34;https://github.com/r9y9/gantts/blob/a5ec247ba7ee1a160875661f8899f56f8010be5b/hparams.py&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ãã¤ãã¼ãã©ã¡ã¼ã¿&lt;/a&gt;ãä¸è¨ã®ããã«å¤æ´ãã¦ã·ã§ã«ãå®è¡ããã¨åç¾ã§ãã¾ãã&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-diff&#34;&gt;diff --git a/hparams.py b/hparams.py
index d82296c..e73dc57 100644
--- a/hparams.py
+++ b/hparams.py
@@ -175,7 +175,7 @@ tts_acoustic = tf.contrib.training.HParams(
     # Streams used for computing adversarial loss
     # NOTE: you should probably change discriminator&#39;s `in_dim`
     # if you change the adv_streams
-    adversarial_streams=[True, False, False, False],
+    adversarial_streams=[True, True, False, False],
     # Don&#39;t switch this on unless you are sure what you are doing
     # If True, you will need to adjast `in_dim` for discriminator.
     # Rationale for this is that power coefficients are less meaningful
@@ -202,7 +202,7 @@ tts_acoustic = tf.contrib.training.HParams(
     # Discriminator
     discriminator=&amp;quot;MLP&amp;quot;,
     discriminator_params={
-        &amp;quot;in_dim&amp;quot;: 24,
+        &amp;quot;in_dim&amp;quot;: 25,
         &amp;quot;out_dim&amp;quot;: 1,
         &amp;quot;num_hidden&amp;quot;: 2,
         &amp;quot;hidden_dim&amp;quot;: 256,
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;å¤æé³å£°ã®æ¯è¼&#34;&gt;å¤æé³å£°ã®æ¯è¼&lt;/h3&gt;
&lt;h4 id=&#34;é³é¿ã¢ãã«ã®ã¿é©ç¨-adv-loss-mgcã®ã¿&#34;&gt;é³é¿ã¢ãã«ã®ã¿é©ç¨ (ADV loss: mgcã®ã¿)&lt;/h4&gt;
&lt;p&gt;ç¶ç¶é·ã¢ãã«ãé©ç¨ããªãããã¤ ADV lossã«mgcã®ã¿ãç¨ããå ´åã§ãã&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;èªç¶é³å£°&lt;/li&gt;
&lt;li&gt;ãã¼ã¹ã©ã¤ã³&lt;/li&gt;
&lt;li&gt;GAN&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;ã®é ã«é³å£°ãè²¼ãã¾ããè´ããããããã«ãsoxã§é³éãæ­£è¦åãã¦ãã¾ãã&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;arctic_b0535&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/slt/arctic_b0535.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/gantts/tts_order24/acoustic_only/baseline/test/arctic_b0535.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/gantts/tts_order24/acoustic_only/gan/test/arctic_b0535.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;&lt;strong&gt;arctic_b0536&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/slt/arctic_b0536.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/gantts/tts_order24/acoustic_only/baseline/test/arctic_b0536.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/gantts/tts_order24/acoustic_only/gan/test/arctic_b0536.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;&lt;strong&gt;arctic_b0537&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/slt/arctic_b0537.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/gantts/tts_order24/acoustic_only/baseline/test/arctic_b0537.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/gantts/tts_order24/acoustic_only/gan/test/arctic_b0537.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;&lt;strong&gt;arctic_b0538&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/slt/arctic_b0538.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/gantts/tts_order24/acoustic_only/baseline/test/arctic_b0538.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/gantts/tts_order24/acoustic_only/gan/test/arctic_b0538.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;&lt;strong&gt;arctic_b0539&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/slt/arctic_b0539.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/gantts/tts_order24/acoustic_only/baseline/test/arctic_b0539.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/gantts/tts_order24/acoustic_only/gan/test/arctic_b0539.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;VCã®å ´åã¨åãããã«ãé³å£°ã®æç­æ§ãä¸ãã£ãããã«æãã¾ãã&lt;/p&gt;
&lt;h4 id=&#34;é³é¿ã¢ãã«ç¶ç¶é·ã¢ãã«ãé©ç¨-adv-loss-mgcã®ã¿&#34;&gt;é³é¿ã¢ãã«ï¼ç¶ç¶é·ã¢ãã«ãé©ç¨ (ADV loss: mgcã®ã¿)&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;arctic_b0535&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/slt/arctic_b0535.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/gantts/tts_order24/duration_acoustic/baseline/test/arctic_b0535.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/gantts/tts_order24/duration_acoustic/gan/test/arctic_b0535.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;&lt;strong&gt;arctic_b0536&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/slt/arctic_b0536.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/gantts/tts_order24/duration_acoustic/baseline/test/arctic_b0536.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/gantts/tts_order24/duration_acoustic/gan/test/arctic_b0536.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;&lt;strong&gt;arctic_b0537&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/slt/arctic_b0537.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/gantts/tts_order24/duration_acoustic/baseline/test/arctic_b0537.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/gantts/tts_order24/duration_acoustic/gan/test/arctic_b0537.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;&lt;strong&gt;arctic_b0538&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/slt/arctic_b0538.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/gantts/tts_order24/duration_acoustic/baseline/test/arctic_b0538.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/gantts/tts_order24/duration_acoustic/gan/test/arctic_b0538.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;&lt;strong&gt;arctic_b0539&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/slt/arctic_b0539.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/gantts/tts_order24/duration_acoustic/baseline/test/arctic_b0539.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/gantts/tts_order24/duration_acoustic/gan/test/arctic_b0539.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;é³å£°ã®æç­æ§ãä¸ãã£ã¦ããã¨ã¯æãã¾ãããç¶ç¶é·ã«é¢ãã¦ã¯ããã¼ã¹ã©ã¤ã³/GANã§å·®ç°ãã»ã¨ãã©ãªãããã«æããããã¨æãã¾ããããã¯ãï¼åãå®é¨ããç¯å²ã§ã¯å°ãªãã¨ãï¼DiscriminatorãGeneartorã«åã¡ãããã¦ (é³é¿ã¢ãã«ã®å ´åã¯ããããªãã¨ã¯ãªã)ã ADV lossãä¸ããã©ãããä¸ãã£ã¦ãã¾ããçµæ MGE lossãæå°åããå ´åã¨ã»ã¨ãã©å¤ãã£ã¦ããªããã¨ããçµæã«ãªã£ã¦ãã¾ããè«æã«è¨è¼ã®åå®¹ã¨ã¯ç°ãªããstate-levelã®ç¶ç¶é·ã¢ãã«ã§ã¯ãããã®ã®ããã¤ãã¼ãã©ã¡ã¼ã¿ãªã©ãªã©ããããå¤ãã¦è©¦ããã®ã§ãããä¸æãããã¾ããã§ããã&lt;/p&gt;
&lt;h4 id=&#34;adv-loss-mgc-vs-mgc--lf0&#34;&gt;ADV loss: mgc vs mgc + lf0&lt;/h4&gt;
&lt;p&gt;æ¬¡ã«ãã­ã¹ã®æ¯è¼ã§ããF0ã®å¤åã«çç®ããããããã«ãç¶ç¶é·ã¢ãã«ãä½¿ãããé³é¿ã¢ãã«ã®ã¿ãé©ç¨ãã¾ãã&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;èªç¶é³å£°&lt;/li&gt;
&lt;li&gt;ADV loss (mgcã®ã¿, 24æ¬¡å)&lt;/li&gt;
&lt;li&gt;ADV loss (mgc + lf0, 25æ¬¡å)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;ã®é ã«é³å£°ãè²¼ãã¾ããã¾ããWORLD (dio + stonemask) ã§åæããF0ã®å¯è¦åçµæãä½µãã¦è²¼ã£ã¦ããã¾ãã&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;arctic_b0535&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/slt/arctic_b0535.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/gantts/tts_order24/acoustic_only/gan/test/arctic_b0535.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/gantts/tts_order24_advf0/acoustic_only/gan/test/arctic_b0535.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/images/gantts/arctic_b0535_f0.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;arctic_b0536&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/slt/arctic_b0536.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/gantts/tts_order24/acoustic_only/gan/test/arctic_b0536.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/gantts/tts_order24_advf0/acoustic_only/gan/test/arctic_b0536.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/images/gantts/arctic_b0536_f0.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;arctic_b0537&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/slt/arctic_b0537.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/gantts/tts_order24/acoustic_only/gan/test/arctic_b0537.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/gantts/tts_order24_advf0/acoustic_only/gan/test/arctic_b0537.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/images/gantts/arctic_b0537_f0.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;arctic_b0538&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/slt/arctic_b0538.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/gantts/tts_order24/acoustic_only/gan/test/arctic_b0538.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/gantts/tts_order24_advf0/acoustic_only/gan/test/arctic_b0538.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/images/gantts/arctic_b0538_f0.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;arctic_b0539&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/slt/arctic_b0539.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/gantts/tts_order24/acoustic_only/gan/test/arctic_b0539.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/gantts/tts_order24_advf0/acoustic_only/gan/test/arctic_b0539.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/images/gantts/arctic_b0539_f0.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;ã©ãã§ãããããä¸æããã£ã¦ããå ´åãï¼arctic_b537ã¨ãï¼ããã°ãä¸æããã£ã¦ããªãå ´å (arctic_b539ã¨ã) ãããããã«æãã¾ããåã«ã¯F0ãä¸èªç¶ã«æºãã¦ããããã«æãå ´åãå¤ãããã¾ãããããã§ã¯5ã¤ããé³å£°ãè²¼ã£ã¦ãã¾ãããããã®ä»126åã®è©ä¾¡ç¨é³å£°ã§ãè´ãæ¯ã¹ã¦ããã¨ãADV lossã«F0ãå¥ããªãæ¹ãããæ°ããã¾ããï¼ããã¾ã§åã®ä¸»è¦³ã§ãã&lt;/p&gt;
&lt;p&gt;ãã®ãããã¯ãF0ã®æ½åºæ³ãè£éæ³ã«å¼·ãä¾å­ãããã§ããä»åã¯ãF0æ½åºã®ãã©ã¡ã¼ã¿ãã¾ã£ãããã¥ã¼ãã³ã°ãã¦ããªãã®ã§ããã®ããããã£ãï¼f0åæã¨ã©ã¼ã«å¼ã£å¼µããã¦æªããªã£ãï¼ã®ããããã¾ããã&lt;/p&gt;
&lt;h3 id=&#34;global-variance-ã¯è£åããã¦ããã®ã&#34;&gt;Global variance ã¯è£åããã¦ããã®ãï¼&lt;/h3&gt;
&lt;p&gt;F0ã®è©±ã¯çµããã§ãã¹ãã¯ãã«ç¹å¾´éã«çç®ãã¦çµæãåæãã¦ããã¾ããä»¥ä¸ãADV loss (mgcã®ã¿)ãç¶ç¶é·ã¢ãã«ï¼é³é¿ã¢ãã«ãé©ç¨ãããµã³ãã«ã§ã®åæçµæã§ãã&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/images/gantts/arctic_b0537_gv.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;å¤§ã¾ãã«ãè«æã§ç¤ºããã¦ããã®ã¨åæ§ã®çµæãå¾ããã¾ããããªããããã¯ &lt;code&gt;arctic_b0537&lt;/code&gt; ã®ä¸çºè©±ã«å¯¾ãã¦è¨ç®ãããã®ã§ããã¹ãã»ããã®å¹³åã§ã¯ããã¾ããï¼ããã¾ããï¼ãã¾ããããã¯ãã¹ãã»ããä¸­ã®ãµã³ãã«ã®ä¸­ã§ãGVãè£åããã¦ãããã¨ãããããããä¾ãããã¯ã¢ãããã¾ããããã ããä»ã®ãã¹ããµã³ãã«ã«ããã¦ãåæ§ã®å¾åãè¦ãããã®ã¯ç¢ºèªãã¦ãã¾ãã&lt;/p&gt;
&lt;h3 id=&#34;modulation-spectrum-å¤èª¿ã¹ãã¯ãã«-ã¯è£åããã¦ããã®ã&#34;&gt;Modulation spectrum (å¤èª¿ã¹ãã¯ãã«) ã¯è£åããã¦ããã®ãï¼&lt;/h3&gt;
&lt;p&gt;è©ä¾¡ç¨ã®é³å£°126çºè©±ããããã§å¤èª¿ã¹ãã¯ãã«ãè¨ç®ãããããã®å¹³åãåããé©å½ãªç¹å¾´éã®æ¬¡åãããã¯ã¢ãããããã®ãç¤ºãã¾ããæ¨ªè»¸ã¯å¤èª¿å¨æ³¢æ°ã§ããä¸çªå³ç«¯ã50Hzã§ãã&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/images/gantts/ms.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;&lt;code&gt;arctic_b0537&lt;/code&gt; ã®ä¸çºè©±ã«å¯¾ãã¦è¨ç®ãããã®ã§ãã&lt;strong&gt;VCã®å ´åã¨ã¯ç°ãªã&lt;/strong&gt;ããã¼ã¹ã©ã¤ã³ãGANã¨ãã«ãä½æ¬¡åã§ãã£ã¦ã10Hzãè¶ããè¾ºãããèªç¶é³å£°ã¨ã¯å¤§ããç°ã£ã¦ãã¾ããããã¯ãªããªã®ããåã«ã¯ã¾ã ããã£ã¦ãã¾ãããã¾ããVCã®å ´åã¨åæ§ã«ãé«æ¬¡åã«ãªãã»ã©ãGANãã¼ã¹ã®æ¹ãå¤èª¿ã¹ãã¯ãã«ã¯èªç¶é³å£°ã«è¿ããã¨ããããã¾ããGANã«ãã£ã¦ãå¤èª¿ã¹ãã¯ãã«ã¯ããç¨åº¦è£åããã¦ããã¨è¨ããã¨æãã¾ãã&lt;/p&gt;
&lt;h3 id=&#34;ç¹å¾´éã®åå¸&#34;&gt;ç¹å¾´éã®åå¸&lt;/h3&gt;
 &lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/images/gantts/arctic_b0537_scatter.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;&lt;code&gt;arctic_b0537&lt;/code&gt; ã®ä¸çºè©±ã«å¯¾ãã¦è¨ç®ãããã®ã§ããè«æã§ç¤ºããã¦ããã»ã©é¡èã§ã¯ãªãæ°ããã¾ãããããã¾ãã«åæ§ã®çµæãå¾ããã¾ããã&lt;/p&gt;
&lt;h2 id=&#34;ææ³&#34;&gt;ææ³&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;GANã®ãã¥ã¼ãã³ã°ã¯é£ãããäººåï¼ç´æï¼ãã¤ãã¼ãã©ã¡ã¼ã¿ã®ãã¥ã¼ãã³ã°ãè©¦ãã¾ããããå¤§å¤ã§ãããããã¦ãã¾ããã¾ãã§ããèªä¿¡ãããã¾ãããæ½¤æ²¢ãªè¨ç®è³æºã§ãªãã¨ããããâ¦&lt;/li&gt;
&lt;li&gt;GANã®å­¦ç¿ã¯ä¸å®å®ï¼ã«æããï¼ããéå¸¸ã® MSE loss ã®å­¦ç¿ã¯å®å®ã§ããã¤Bidirectional LSTM RNNã¯å®å®ãã¦ããã§ãï¼çµæãããã«è²¼ã£ã¦ããªãã¦ç³ãè¨³ã§ããï¼ããã ããè¨ç®ã«ãã®ãããæéããããã®ã¨ãGPUã¡ã¢ãªãããªãä½¿ãã®ã§ãã¨ããããéå¸¸ã®feed forwardåã§å®é¨ããçµæãã¾ã¨ãã¾ãã&lt;/li&gt;
&lt;li&gt;state-levelã®ç¶ç¶é·ã¢ãã«ã«ãGANãä½¿ãã®ã¯ãã¾ãä¸æãã§ãã¾ããã§ãããããã«è²¼ã£ããµã³ãã«ããã¯ããããªãã®ã§ããï¼ããã¾ããï¼ãGã¨Dãä¸æãç«¶ãåãããDãåã£ã¦ãã¾ãå ´åãã»ã¨ãã©ã§ããï¼çµæãããä¸çªã¾ãï¼ãä¸æãç«¶ãåãããããã¨ããã¨ãæ©å£é³å£°ãçæããã¦ãã¾ã£ãããã¨å¤±æãããã¾ããã&lt;/li&gt;
&lt;li&gt;F0ã ADV lossã«å ããã¨ãããèªç¶é³å£°ã«è¿ã¥ãã¨æããå ´åãããããä¸æ¹ã§F0ãä¸èªç¶ã«æºãã¦ãã¾ãå ´åãããã¾ãããããã¯F0ã®æ½åºæ³ãè£éæ³ã«ãä¾å­ããã®ã§ãèª¿æ»ãå¿è¦ã§ã&lt;/li&gt;
&lt;li&gt;mgc, lf0, vuv, bapãã¹ã¦ã§ ADV lossã«å ããã¨ãæ®å¿µãªçµæãè¦ããã¨ã«ãªãã¾ãããçæ³çã«ã¯ããã§ãä¸æãããã¨æã£ã¦æåã«è©¦ããã®ã§ãããã ãã§ãããèå³ã®ããäººã¯ãããã¦ã¿ã¦ãã ãã&lt;/li&gt;
&lt;li&gt;mgcã®0æ¬¡ï¼ãã¯ã¼æåï¼ã¯ãADV lossã«å ããªãæ¹ããããèãã¦ã¿ãã¨ãç¹ã«ãã¬ã¼ã åä½ã®ã¢ãã«ã®å ´åï¼RNNã§ã¯ãªãï¼ããã¯ã¼æå ±ã¯natural/generated ã®è­å¥ã«ã¯ã»ã¨ãã©å¯ä¸ããªãããã§ããããã¯Arxivã®æ¹ã®è«æã«ã¯æ¸ãã¦ããªãã®ã§ããï¼åã®è¦éãã§ãªããã°ï¼ã&lt;a href=&#34;http://sython.org/papers/ASJ/saito2017asja.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ASJã®åç¨¿&lt;/a&gt; ã«ã¯æ¸ãã¦ãããã§ããã­ãä¸ã¤ã®ãããã©ããã§ãã&lt;/li&gt;
&lt;li&gt;Dã«RNNãä½¿ã£ãå®é¨ãå°ããã£ã¦ã¿ãã®ã§ããããã¾ãç«¶ãåãããã®ãé£ãããã§ãããDã«RNNãä½¿ãã®ã¯æ¬è³ªçã«ã¯è¯ãã¨æã£ã¦ããã®ã§ããã®è¾ºãã¯ããå°ãè²ãè©¦è¡é¯èª¤ãããã¨æã£ã¦ãã¾ã&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;ã¾ã¨ã&#34;&gt;ã¾ã¨ã&lt;/h2&gt;
&lt;p&gt;GANã®å­¦ç¿ã¯å¤§å¤ã§ããããä¸æãå­¦ç¿ã§ããã°åè³ªåä¸ã«ã¤ãªãããã¨ãç¢ºèªã§ãã¾ãããä»å¾ãè¨ç®ãªã½ã¼ã¹ãç©ºãæ¬¡ç¬¬ãRNNã§ã®å®é¨ãé²ãããã¨æãã®ã¨ãæ¥æ¬èªã§ãã£ã¦ã¿ããã¨æã£ã¦ãã¾ãã&lt;/p&gt;
&lt;p&gt;GANã·ãªã¼ãºã®ãã®ä»è¨äºã¸ã®ãªã³ã¯ã¯ä»¥ä¸ã®éãã§ãã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://r9y9.github.io/blog/2017/10/05/ganvc/&#34;&gt;GAN å£°è³ªå¤æ (en) ç·¨ã¯ãã¡ã&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://r9y9.github.io/blog/2017/10/10/gantts-jp/&#34;&gt;GAN é³å£°åæ (ja) ç·¨ã¯ãã¡ã&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;åè&#34;&gt;åè&lt;/h2&gt;
&lt;p&gt;Arxivã«ãããã¼ãã¼ã ãã§ãªãããã®ä»ããããåèã«ãã¾ããããããã¨ããããã¾ãã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1709.08041&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Yuki Saito, Shinnosuke Takamichi, Hiroshi Saruwatari, &amp;ldquo;Statistical Parametric Speech Synthesis Incorporating Generative Adversarial Networks&amp;rdquo;, arXiv:1709.08041 [cs.SD], Sep. 2017&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://sython.org/papers/SIG-SLP/saito201702slp.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Yuki Saito, Shinnosuke Takamichi, and Hiroshi Saruwatari, &amp;ldquo;Training algorithm to deceive anti-spoofing verification for DNN-based text-to-speech synthesis,&amp;rdquo; IPSJ SIG Technical Report, 2017-SLP-115, no. 1, pp. 1-6, Feb., 2017. (in Japanese)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.jstage.jst.go.jp/article/transinf/E100.D/8/E100.D_2017EDL8034/_article&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Yuki Saito, Shinnosuke Takamichi, and Hiroshi Saruwatari, &amp;ldquo;Voice conversion using input-to-output highway networks,&amp;rdquo; IEICE Transactions on Information and Systems, Vol.E100-D, No.8, pp.1925&amp;ndash;1928, Aug. 2017&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.slideshare.net/ShinnosukeTakamichi/dnnantispoofing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.slideshare.net/ShinnosukeTakamichi/dnnantispoofing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.slideshare.net/YukiSaito8/Saito2017icassp&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.slideshare.net/YukiSaito8/Saito2017icassp&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/SythonUK/whisperVC&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/SythonUK/whisperVC&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://sython.org/papers/ASJ/saito2017asja.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Yuki Saito, Shinnosuke Takamichi, and Hiroshi Saruwatari, &amp;ldquo;Experimental investigation of divergences in adversarial DNN-based speech synthesis,&amp;rdquo; Proc. ASJ, Spring meeting, 1-8-7, &amp;ndash;, Sep., 2017. (in Japanese)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;ç¶ç¶é·ã¢ãã«ãé³é¿ã¢ãã«ã¨ãã«RNNãä½¿ãã¨è¯ããªããã¨ãããã£ã¦ããã®ã§ãããè¨ç®ãªã½ã¼ã¹ã®é½åä¸ãä»åã¯é³é¿ã¢ãã«ã¯Feed-forwardã«ãã¾ãããFeed-forwardã ã¨30åã§çµããè¨ç®ããRNNã ã¨æ°æéããã£ã¦ãã¾ãã®ã§â¦&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34;&gt;
&lt;p&gt;ä»ãè²ããã£ãã®ã§ãããã ãããå¤±æã§ããã&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>ãå£°è³ªå¤æç·¨ãStatistical Parametric Speech Synthesis Incorporating Generative Adversarial Networks [arXiv:1709.08041]</title>
      <link>https://r9y9.github.io/blog/2017/10/05/ganvc/</link>
      <pubDate>Thu, 05 Oct 2017 23:25:36 +0900</pubDate>
      <guid>https://r9y9.github.io/blog/2017/10/05/ganvc/</guid>
      <description>&lt;p&gt;&lt;strong&gt;10/11 è¿½è¨&lt;/strong&gt;: IEEE TASLPã®ãã¼ãã¼ (Open access) ãå¬éããããããªã®ã§ããªã³ã¯ãè²¼ã£ã¦ããã¾ã: &lt;a href=&#34;https://ieeexplore.ieee.org/document/8063435/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://ieeexplore.ieee.org/document/8063435/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;arXivè«æãªã³ã¯: &lt;a href=&#34;https://arxiv.org/abs/1709.08041&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;arXiv:1709.08041&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;2017å¹´9ææ«ã«ãè¡¨é¡ã® &lt;a href=&#34;https://arxiv.org/abs/1709.08041&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;è«æ&lt;/a&gt; ãå¬éãããã®ã¨ã&lt;a href=&#34;https://github.com/r9y9/nnmnkwii&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;nnmnkwii&lt;/a&gt; ã¨ãã designed for easy and fast prototyping ãç®æãã©ã¤ãã©ãªãä½ã£ãã®ãããã®ã§ãå®è£ãã¦ã¿ã¾ãããåãå®é¨ããéãã§ã¯ãå£°è³ªå¤æ (Voice conversion; VC) ã§ã¯å®å®ãã¦è¯ããªãã¾ããï¼é³å£°åæã§ã¯ã¾ã å®é¨ä¸­ã§ãï¼ããã®è¨äºã§ã¯ãå£°è³ªå¤æã«ã¤ãã¦åãå®é¨ããçµæãã¾ã¨ãããã¨æãã¾ããé³å£°åæã«ã¤ãã¦ã¯ãã¾ãå¾æ¥ã¾ã¨ãã¾ã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ã³ã¼ãã¯ãã¡ã: &lt;a href=&#34;https:github.com/r9y9/gantts&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;r9y9/gantts | PyTorch implementation of GAN-based text-to-speech and voice conversion (VC) &lt;/a&gt; (TTSã®ã³ã¼ããä¸ç·ã§ã)&lt;/li&gt;
&lt;li&gt;é³å£°ãµã³ãã«ãè´ãããæ¹ã¯ãã¡ã: &lt;a href=&#34;http://nbviewer.jupyter.org/github/r9y9/gantts/blob/master/notebooks/Test%20VC.ipynb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;The effects of adversarial training in voice conversion | nbviewer&lt;/a&gt; (â»è§£èª¬ã¯ã¾ã£ããããã¾ããã®ã§ããããã)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ãªããå³å¯ã«åãçµæãåç¾ãããã¨ã¯æã£ã¦ãã¾ãããåæ§ã®ã¢ã¤ãã¢ãè©¦ããã¨ãã£ããã¨ã«ä¸»ç¼ãç½®ãã¦ãã¾ããã³ã¼ãã«é¢ãã¦ã¯ãããã«è²¼ã£ãçµæãåç¾ã§ããããã«æ°ãã¤ãã¾ããã&lt;/p&gt;
&lt;h2 id=&#34;æ¦è¦&#34;&gt;æ¦è¦&lt;/h2&gt;
&lt;p&gt;ä¸è¨ã§ããã°ãé³é¿ã¢ãã«ã®å­¦ç¿ã« Generative Adversarial Net (&lt;strong&gt;GAN&lt;/strong&gt;) ãå°å¥ãããã¨ãã£ããã®ã§ããå°ãå·ä½çã«ã¯ã&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;é³é¿ã¢ãã«ï¼çæã¢ãã«ï¼ãçæããé³é¿ç¹å¾´éãå½ç©ãæ¬ç©ããè¦åãããã¨ããè­å¥ã¢ãã«ã¨ã&lt;/li&gt;
&lt;li&gt;çæèª¤å·®ãå°ãããã¤ã¤ (Minimum Generation Error loss; &lt;strong&gt;MGE loss&lt;/strong&gt; ã®æå°å) ãçæããç¹å¾´éãè­å¥ã¢ãã«ã«æ¬ç©ã ã¨èª¤èªè­ããããã¨ãã (Adversarial loss; &lt;strong&gt;ADV loss&lt;/strong&gt; ã®æå°å) çæã¢ãã«&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;ãäº¤äºã«å­¦ç¿ãããã¨ã§ãèªç¶é³å£°ã®ç¹å¾´éã¨çæããç¹å¾´éã®åå¸ãè¿ã¥ãããããªãããè¯ãé³é¿ã¢ãã«ãç²å¾ãããã¨ãã£ãæ¹æ³ã§ãã&lt;/p&gt;
&lt;h2 id=&#34;ãã¼ã¹ã©ã¤ã³&#34;&gt;ãã¼ã¹ã©ã¤ã³&lt;/h2&gt;
&lt;p&gt;ãã¼ã¹ã©ã¤ã³ã¨ãã¦ã¯ã &lt;strong&gt;MGE training&lt;/strong&gt; ãæãããã¦ãã¾ããDNNé³å£°åæã§ããããã­ã¹é¢æ°ã¨ãã¦ãé³é¿ç¹å¾´é (éçç¹å¾´é + åçç¹å¾´é) ã«å¯¾ãã Mean Squared Error (&lt;strong&gt;MSE loss&lt;/strong&gt;) ã¨ãããã®ãããã¾ããããã¯ãç¹å¾´éã®åæ¬¡åæ¯ã«èª¤å·®ã«æ­£è¦åå¸ãèãã¦ããã®å¯¾æ°å°¤åº¦ãæå¤§åãããã¨ãæå³ãã¾ãã
ãããã&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;éçç¹å¾´éã¨åçç¹å¾´éã®éã«ã¯æ¬æ¥ deterministic ãªé¢ä¿ããããã¨ãç¡è¦ããã¦ãããã¨&lt;/li&gt;
&lt;li&gt;ã­ã¹ããã¬ã¼ã åä½ã§è¨ç®ãããã®ã§ã (åçç¹å¾´éãå«ã¾ãã¦ããã¨ã¯ãã) æéæ§é ãç¡è¦ããã¦ãã¾ã£ã¦ãããã¨&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;ããããããã®åé¡ãè§£æ±ºããããã«ãç³»ååä½ã§ããã¤ãã©ã¡ã¼ã¿çæå¾ã®éçç¹å¾´éã®é åã§ã­ã¹ãè¨ç®ããæ¹æ³ãMGE training ãææ¡ããã¦ãã¾ãã&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;h2 id=&#34;å®é¨&#34;&gt;å®é¨&lt;/h2&gt;
&lt;h3 id=&#34;å®é¨æ¡ä»¶&#34;&gt;å®é¨æ¡ä»¶&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;http://festvox.org/cmu_arctic/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;CMU ARCTIC&lt;/a&gt; ãããè©±è &lt;code&gt;clb&lt;/code&gt; ã¨ &lt;code&gt;slt&lt;/code&gt; ã®wavãã¼ã¿ãããã500çºè©±ãç¨ãã¾ãã439ãå­¦ç¿ç¨ã56ãè©ä¾¡ç¨ãæ®ã5ããã¹ãç¨ã«ãã¾ããé³é¿ç¹å¾´éã«ã¯ãWORLDãä½¿ã£ã¦59æ¬¡ã®ã¡ã«ã±ãã¹ãã©ã ãæ½åºãã0æ¬¡ãé¤ã59æ¬¡åã®ãã¯ãã«ãåãã¬ã¼ã æ¯ã®ç¹å¾´éã¨ãã¾ããF0ãéå¨ææ§ææ¨ã«é¢ãã¦ã¯ãåè©±èã®ãã®ããã®ã¾ã¾ä½¿ããå·®åã¹ãã¯ãã«æ³ãç¨ãã¦æ³¢å½¢åæãè¡ãã¾ãããF0ã®å¤æã¯ãã¦ãã¾ãããé³é¿ã¢ãã«ã«ã¯ã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.jstage.jst.go.jp/article/transinf/E100.D/8/E100.D_2017EDL8034/_article&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Yuki Saito, Shinnosuke Takamichi, and Hiroshi Saruwatari, &amp;ldquo;Voice conversion using input-to-output highway networks,&amp;rdquo; IEICE Transactions on Information and Systems, Vol.E100-D, No.8, pp.1925&amp;ndash;1928, Aug. 2017&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ã§è¿°ã¹ããã¦ãã highway network ãç¨ãã¾ãããã ããæ´»æ§åé¢æ°ãReLUããLeakyReLUã«ããããDropoutãå¥ããããã¢ã¼ã­ãã¯ãã£ã¯å¾®å¦ã«å¤ãã¦ãã¾ããåèã¯ãèª¿ã¹ããå¾éãæ¶ãã«ããã¦å­¦ç¿ã®ä¸å®å®ãªGANã«è¯ãã¨æ¸ãã¦ããè¨äºããã£ãã®ã§ï¼ã¡ããã¨çè§£ãã¦ãããå®ç´ã§ãããå®é¨ããã¨ããæªå½±é¿ã¯ãªãããã§ããã®ã§æ§å­è¦ï¼ãå¾èã¯ãGANã®å­¦ç¿ã®å®å®åã«ã¤ãªãã£ãæ°ããã¾ãï¼å°ãªãã¨ãTTSã§ã¯ï¼ãDiscriminatorã«ã¯ãDropoutä»ãã®å¤å±¤ãã¥ã¼ã©ã«ããããä½¿ãã¾ãããMGE loss ã¨ ADV loss ããã©ã³ã¹ããéã¿ &lt;code&gt;w_d&lt;/code&gt; ã¯ã 1.0 ã«ãã¾ãããå±¤ã®æ°ããã¥ã¼ã­ã³ã®æ°ç­ããã®ä»è©³ç´°ãç¥ãããæ¹ã¯ãã³ã¼ããåç§ãã¦ãã ãããå®é¨ã«ä½¿ç¨ããã³ã¼ãã®æ­£ç¢ºãªãã¼ã¸ã§ã³ã¯  &lt;a href=&#34;https://github.com/r9y9/gantts/tree/ccbb51b51634b272f0a71f29ad4c28edd8ce3429&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ccbb51b&lt;/a&gt; ã§ãããã¤ãã¼ãã©ã¡ã¼ã¿ã¯ &lt;a href=&#34;https://github.com/r9y9/gantts/blob/ccbb51b51634b272f0a71f29ad4c28edd8ce3429/hparams.py&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ãã¡ã&lt;/a&gt; ã§ãã&lt;/p&gt;
&lt;p&gt;ããã§ç¤ºãçµæãåç¾ãããå ´åã¯ã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ã³ã¼ãããã§ãã¯ã¢ã¦ã&lt;/li&gt;
&lt;li&gt;ããã±ã¼ã¸ã¨ä¾å­é¢ä¿ãã¤ã³ã¹ãã¼ã«&lt;/li&gt;
&lt;li&gt;&lt;code&gt;clb&lt;/code&gt; ã¨ &lt;code&gt;slt&lt;/code&gt; ã®ãã¼ã¿ããã¦ã³ã­ã¼ãï¼åã®å ´åã¯ã &lt;code&gt;~/data/cmu_arctic&lt;/code&gt; ã«ããã¾ã&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ããã¦ãä»¥ä¸ã®ã¹ã¯ãªãããå®è¡ããã°OKã§ãã&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;./vc_demo.sh ~/data/cmu_arctic
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;ãªãå®è¡ã«ã¯ãGPUã¡ã¢ãªã4GBãããã¯å¿è¦ã§ãï¼ããããµã¤ãº32ã®å ´åï¼ãGTX 1080Ti + i7-7700K ã®è¨ç®ç°å¢ã§ãç´1æéåãããã§çµããã¾ããã¹ã¯ãªããå®è¡ãå®äºããã°ã&lt;code&gt;generated&lt;/code&gt; ãã£ã¬ã¯ããªã«ããã¼ã¹ã©ã¤ã³/GAN ããããã§å¤æããé³å£°ãåºåããã¾ããä»¥ä¸ã«é ã«ç¤ºãå³ã«ã¤ãã¦ã¯ã&lt;a href=&#34;http://nbviewer.jupyter.org/github/r9y9/gantts/blob/master/notebooks/Test%20VC.ipynb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ãã¢ãã¼ãããã¯&lt;/a&gt; ãå®è¡ããã¨ä½ããã¨ãã§ãã¾ãã&lt;/p&gt;
&lt;h3 id=&#34;å¤æé³å£°ã®æ¯è¼&#34;&gt;å¤æé³å£°ã®æ¯è¼&lt;/h3&gt;
&lt;p&gt;ãã¹ãã»ããã®5ã¤ã®ãã¼ã¿ã«å¯¾ãã¦ã®å¤æé³å£°ãããã³ãã®åé³å£°ãã¿ã¼ã²ããé³å£°ãæ¯è¼ã§ããããã«è²¼ã£ã¦ããã¾ããä¸è¨ã®é çªã§ãã&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;åè©±èã®é³å£°&lt;/li&gt;
&lt;li&gt;ã¿ã¼ã²ããè©±èã®é³å£°&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;MGE Loss&lt;/strong&gt; ãæå°åãã¦å¾ãããã¢ãã«ã«ããå¤æé³å£°&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;MGE loss + ADV loss&lt;/strong&gt; ãæå°åãã¦å¾ãããã¢ãã«ã«ããå¤æé³å£°&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;æ¯è¼ããããããã«ãé³éã¯soxã§æ­£è¦åãã¾ããã&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;arctic_a0496&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/ganvc/src/arctic_a0496.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/ganvc/tgt/arctic_a0496.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/ganvc/baseline/test/arctic_a0496.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/ganvc/gan/test/arctic_a0496.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;&lt;strong&gt;arctic_a0497&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/ganvc/src/arctic_a0497.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/ganvc/tgt/arctic_a0497.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/ganvc/baseline/test/arctic_a0497.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/ganvc/gan/test/arctic_a0497.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;&lt;strong&gt;arctic_a0498&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/ganvc/src/arctic_a0498.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/ganvc/tgt/arctic_a0498.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/ganvc/baseline/test/arctic_a0498.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/ganvc/gan/test/arctic_a0498.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;&lt;strong&gt;arctic_a0499&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/ganvc/src/arctic_a0499.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/ganvc/tgt/arctic_a0499.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/ganvc/baseline/test/arctic_a0499.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/ganvc/gan/test/arctic_a0499.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;&lt;strong&gt;arctic_a0500&lt;/strong&gt;&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/ganvc/src/arctic_a0500.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/ganvc/tgt/arctic_a0500.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/ganvc/baseline/test/arctic_a0500.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/ganvc/gan/test/arctic_a0500.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;&lt;code&gt;clb&lt;/code&gt;, &lt;code&gt;slt&lt;/code&gt; ã¯éãããããã«ããã¨ä»¥åèª°ãããææãããã®ã§ãããããã«æ£ãã¦ãã¾ãã¾ããããããã¥ããã£ããããã¾ãããåã®è³ã§ã¯ãæç­æ§ãä¸ãã£ã¦ãè¯ããªã£ã¦ããããã«æãã¾ãã&lt;/p&gt;
&lt;h3 id=&#34;global-variance-ã¯è£åããã¦ããã®ã&#34;&gt;Global variance ã¯è£åããã¦ããã®ãï¼&lt;/h3&gt;
&lt;p&gt;çµ±è¨ãã¼ã¹ã®ææ³ã§ã¯ãå¤æé³å£°ã® &lt;strong&gt;Global variance (GV)&lt;/strong&gt; ãè½ã¡ã¦ãã¾ããåè³ªãå£åãã¦ãã¾ãåé¡ãããç¥ããã¦ãã¾ããGANãã¼ã¹ã®ææ³ã«ãã£ã¦ããã®åé¡ã«å¯¾å¦ã§ãã¦ããã®ãã©ãããå®éã«ç¢ºèªãã¾ãããä»¥ä¸ã«ããã¼ã¿ã»ããä¸­ã®ä¸ãµã³ãã«ãé©å½ã«ããã¯ã¢ãããã¦ãGVãè¨ç®ãããã®ãç¤ºãã¾ããç¸¦è»¸ã¯å¯¾æ°ãæ¨ªè»¸ã¯ã¡ã«ã±ãã¹ãã©ã ã®æ¬¡åã§ãã&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/images/ganvc/gv.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;ãããã¾ããè«æã§ç¤ºããã¦ããã®ã¨åç­ã®çµæãå¾ããã¨ãã§ãã¾ããã&lt;/p&gt;
&lt;h3 id=&#34;modulation-spectrum-å¤èª¿ã¹ãã¯ãã«-ã¯è£åããã¦ããã®ã&#34;&gt;Modulation spectrum (å¤èª¿ã¹ãã¯ãã«) ã¯è£åããã¦ããã®ãï¼&lt;/h3&gt;
&lt;p&gt;GVãããä¸è¬åãã®ã¨ãã¦ãå¤èª¿ã¹ãã¯ãã«ã¨ããæ¦å¿µãããã¾ããç«¯çã«è¨ãã°ããã©ã¡ã¼ã¿ç³»åã®æéæ¹åã«å¯¾ããé¢æ£ãã¼ãªã¨å¤æã®äºä¹ï¼ã®å¯¾æ°â»å®ç¾©ã«ããããã§ãããããã§ã¯å¯¾æ°ãã¨ã£ããã®ï¼ã§ããçµ±è¨å¦çã«ãã£ã¦å£åããå¤æé³å£°ã¯ãå¤èª¿ã¹ãã¯ãã«ãèªç¶é³å£°ã¨æ¯ã¹ã¦å°ãããªã£ã¦ãããã¨ãç¥ããã¦ãã¾ããã¨ããããã§ãGANãã¼ã¹ã®æ¹æ³ã«ãã£ã¦ãå¤èª¿ã¹ãã¯ãã«ã¯è£åããã¦ããã®ãï¼ã¨ãããã¨ãèª¿ã¹ã¦ã¿ã¾ãããããã¯ãè«æã«ã¯æ¸ãã¦ãã¾ããï¼ãããã£ã¨ããã¦ããã¨æãã¾ãï¼ãä»¥ä¸ã«ãè©ä¾¡ç¨ã®é³å£°56çºè©±ããããã§å¤èª¿ã¹ãã¯ãã«ãè¨ç®ãããããã®å¹³åãåããé©å½ãªç¹å¾´éã®æ¬¡åãããã¯ã¢ãããããã®ãç¤ºãã¾ããæ¨ªè»¸ã¯å¤èª¿å¨æ³¢æ°ã§ããä¸çªå³ç«¯ã50Hzã§ãã&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/images/ganvc/ms.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;ç¹ã«é«æ¬¡åã®å¤èª¿ã¹ãã¯ãã«ã«å¯¾ãã¦ããã¼ã¹ã©ã¤ã³ã¯å¤§ããè½ã¡ã¦ããä¸æ¹ã§ãGANãã¼ã¹ã§ã¯æ¯è¼çèªç¶é³å£°ã¨è¿ããã¨ããããã¾ããããããé«æ¬¡åã«ãªãã»ã©ãèªç¶é³å£°ã¨GANãã¼ã¹ã§ãéããåºã¦ããã®ããããã¾ããæ¹åã®ä½å°ã¯ããããã§ãã­ã&lt;/p&gt;
&lt;h3 id=&#34;ç¹å¾´éã®åå¸&#34;&gt;ç¹å¾´éã®åå¸&lt;/h3&gt;
&lt;p&gt;è«æã§ç¤ºããã¦ããscatter plotã§ãããåããã¨ããã£ã¦ã¿ã¾ããã&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/images/ganvc/scatter.png&#34; /&gt;&lt;/div&gt;
&lt;p&gt;æ¦ã­ãè«æéãã®çµæã¨ãªã£ã¦ãã¾ãã&lt;/p&gt;
&lt;h3 id=&#34;è©ç§°çã«ã¤ãã¦&#34;&gt;è©ç§°çã«ã¤ãã¦&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;w_d&lt;/code&gt; ãå¤åããã¦ãè©ç§°çãã©ããªããã¯å®é¨ãã¦ããªãã®ã§ããã&lt;code&gt;w_d = 1.0&lt;/code&gt; ã®å ´åã«ãã ããã0.7 ~ 0.9 ãããã«åã¾ããã¨ãç¢ºèªãã¾ãããTTSã§ã¯0.99ãããã®ãè«æã¨åæ§ã®çµæãåºã¾ãããããããã¨ããã®ã¯ãã©ã®ããã Discriminator ãå­¦ç¿ãããããåæåã¨ãã¦ã®MGEå­¦ç¿ï¼ä¾ãã°25epochãããï¼ã®ãã¨çæãããç¹å¾´éã«å¯¾ãã¦å­¦ç¿ãããã®ããããã¨ãåæåã¨ã¯å¥ã§ãã¼ã¹ã©ã¤ã³ç¨ã®ã¢ãã«ï¼100epochã¨ãï¼ãä½¿ã£ã¦çæãããç¹å¾´éã«å¯¾ãã¦å­¦ç¿ãããã®ããã«ãã£ã¦å¤ãã£ã¦ããã®ã¨ããã®è¾ºããè«æããã§ã¯ãã¾ãããããªãã£ãã®ã¨ãå­¦ç¿çãæé©åã¢ã«ã´ãªãºã ããã¼ã¿ã«ãã£ã¦ãå¤ãã£ã¦ããã®ã¨ãè©ç§°çã®è¨ç®ã¯åè³ªã«ã¯ã¾ã£ããé¢ä¿ãªãã®ããã£ã¦ããã¾ãçé¢ç®ã«ãã£ã¦ãã¾ãããããã¾ãã&lt;/p&gt;
&lt;h2 id=&#34;ææ³&#34;&gt;ææ³&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;å¹æã¯åçãæããã«è¯ããªãã¾ãããç´ æ´ãããã§ãã­&lt;/li&gt;
&lt;li&gt;è«æã§æ¸ããã¦ããåå¾©åæ° (25epochã¨ã)ãããã100, 200ã¨å¤ãå­¦ç¿ãããæ¹ãããã£ãã§ãï¼ç¥è¦çãªå·®ã¯å¾®å¦ã§ããï¼ã­ã¹ã¯ä¸ããç¶ãã¦ãã¾ããã&lt;/li&gt;
&lt;li&gt;å®è£ã¯ãããªã«å¤§å¤ã§ã¯ãªãã£ãã§ãããGANã®å­¦ç¿ãé£ããæãããã¾ããï¼VCã§ã¯ãã¾ãå¤±æããªãããTTSã§ã¯ããå¤±æãããè½ã¨ãæãæ¢ãä¸­&lt;/li&gt;
&lt;li&gt;Adam ã¯å­¦ç¿ã¯éãããéå­¦ç¿ããããããGANãä¸å®å®ã«ãªããã¡ãªæ°ããã¾ãã&lt;/li&gt;
&lt;li&gt;Adagrad ã¯åæã¯éãããå®å®&lt;/li&gt;
&lt;li&gt;MGE loss ã¨ ADV loss ã®éã¿ã®è¨ç®ã¯ãé©å½ã«clipããããã«ãã¾ãããããªãã¦ãã ãããåæãã¾ããããã°ãããã¨ç°¡åã«çºæ£ãã¾ãã­ãhaha&lt;/li&gt;
&lt;li&gt;gradient clipping ãããã¾ãããTTSã§ã¯å°ãªãã¨ãè¯ããªã£ãæ°ããã¾ããVCã¯ãªãã§ãå®å®ãã¦ããããã§ãã&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;ã¾ã¨ã&#34;&gt;ã¾ã¨ã&lt;/h2&gt;
&lt;p&gt;ã¨ã¦ãè¯ããªãã¾ãããç´ æ´ãããã§ããä»åãWORLDã«ãä¸è©±ã«ãªãã¾ãããç¶ãã¦ãTTSã§ãå®é¨ãé²ãã¦ããã¾ãã&lt;/p&gt;
&lt;p&gt;GANã·ãªã¼ãºã®ãã®ä»è¨äºã¸ã®ãªã³ã¯ã¯ä»¥ä¸ã®éãã§ãã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://r9y9.github.io/blog/2017/10/09/gantts/&#34;&gt;GAN é³å£°åæ (en) ç·¨ã¯ãã¡ã&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://r9y9.github.io/blog/2017/10/10/gantts-jp/&#34;&gt;GAN é³å£°åæ (ja) ç·¨ã¯ãã¡ã&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;åè&#34;&gt;åè&lt;/h2&gt;
&lt;p&gt;Arxivã«ãããã¼ãã¼ã ãã§ãªãããã®ä»ããããåèã«ãã¾ããããããã¨ããããã¾ãã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1709.08041&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Yuki Saito, Shinnosuke Takamichi, Hiroshi Saruwatari, &amp;ldquo;Statistical Parametric Speech Synthesis Incorporating Generative Adversarial Networks&amp;rdquo;, arXiv:1709.08041 [cs.SD], Sep. 2017&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://sython.org/papers/SIG-SLP/saito201702slp.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Yuki Saito, Shinnosuke Takamichi, and Hiroshi Saruwatari, &amp;ldquo;Training algorithm to deceive anti-spoofing verification for DNN-based text-to-speech synthesis,&amp;rdquo; IPSJ SIG Technical Report, 2017-SLP-115, no. 1, pp. 1-6, Feb., 2017. (in Japanese)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.jstage.jst.go.jp/article/transinf/E100.D/8/E100.D_2017EDL8034/_article&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Yuki Saito, Shinnosuke Takamichi, and Hiroshi Saruwatari, &amp;ldquo;Voice conversion using input-to-output highway networks,&amp;rdquo; IEICE Transactions on Information and Systems, Vol.E100-D, No.8, pp.1925&amp;ndash;1928, Aug. 2017&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.slideshare.net/ShinnosukeTakamichi/dnnantispoofing&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.slideshare.net/ShinnosukeTakamichi/dnnantispoofing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.slideshare.net/YukiSaito8/Saito2017icassp&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.slideshare.net/YukiSaito8/Saito2017icassp&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/SythonUK/whisperVC&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/SythonUK/whisperVC&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Kobayashi, Kazuhiro, et al. &amp;ldquo;Statistical Singing Voice Conversion with Direct Waveform Modification based on the Spectrum Differential.&amp;rdquo; Fifteenth Annual Conference of the International Speech Communication Association. 2014.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;è«æã§ã¯æå¹æ§ãç¤ºããã¦ãã¾ãããåãè©¦ããç¯å²åã§ããã¤åã®è³ã«ã«ããã°ããã¾ãå¤§ããªæ¹åã¯ç¢ºèªã§ãã¦ãã¾ãããå®¢è¦³çãªè©ä¾¡ã¯ããã®ãã¡ããäºå®ã§ãã&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>DNNé³å£°åæã®ããã®ã©ã¤ãã©ãªã®ç´¹ä»ã¨DNNæ¥æ¬èªé³å£°åæã®å®è£ä¾</title>
      <link>https://r9y9.github.io/blog/2017/08/16/japanese-dnn-tts/</link>
      <pubDate>Wed, 16 Aug 2017 23:10:56 +0900</pubDate>
      <guid>https://r9y9.github.io/blog/2017/08/16/japanese-dnn-tts/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://github.com/r9y9/nnmnkwii&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;nnmnkwii&lt;/a&gt; ã¨ããDNNé³å£°åæã®ããã®ã©ã¤ãã©ãªãå¬éãã¾ããã®ã§ããã®ç´¹ä»ããã¾ãã&lt;/p&gt;
&lt;blockquote class=&#34;twitter-tweet&#34; data-lang=&#34;en&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;&lt;a href=&#34;https://t.co/p8MnOxkVoH&#34;&gt;https://t.co/p8MnOxkVoH&lt;/a&gt; Library to build speech synthesis systems designed for easy and fast prototyping. Open sourced:)&lt;/p&gt;&amp;mdash; å±±æ¬ããããã¡ (@r9y9) &lt;a href=&#34;https://twitter.com/r9y9/status/897117170265501696&#34;&gt;August 14, 2017&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;//platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;p&gt;ãã­ã¥ã¡ã³ãã®ææ°çã¯ &lt;a href=&#34;https://r9y9.github.io/nnmnkwii/latest/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://r9y9.github.io/nnmnkwii/latest/&lt;/a&gt; ã§ããä»¥ä¸ã«ãããã¤ããªã³ã¯ãè²¼ã£ã¦ããã¾ãã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://r9y9.github.io/nnmnkwii/v0.0.1/design_jp.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ãªãä½ã£ãã®ãããã®èæ¯ã®èª¬æã¨è¨­è¨ (æ¥æ¬èª)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://r9y9.github.io/nnmnkwii/v0.0.1/nnmnkwii_gallery/notebooks/00-Quick%20start%20guide.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ã¯ã¤ãã¯ã¬ã¤ã&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://r9y9.github.io/nnmnkwii/v0.0.1/nnmnkwii_gallery/notebooks/tts/01-DNN-based%20statistical%20speech%20synthesis%20%28en%29.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;DNNè±èªé³å£°åæã®ãã¥ã¼ããªã¢ã«&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ãããããã°ãè¦§ãã ãã&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;ã&lt;/p&gt;
&lt;p&gt;ãã­ã¥ã¡ã³ãã¯ãã ãããè±èªã§ãç¡¬ãé°å²æ°ã§æ¸ããã®ã§ããã®è¨äºã§ã¯ãæ¥æ¬èªã§ã«ã¸ã¥ã¢ã«ã«èæ¯ãªã©ãèª¬æãããã¨æãã®ã¨ãï¼ãã­ã¥ã¡ã³ãã«ã¯è±èªé³å£°åæã®ä¾ãããªãã®ã§ï¼HTSã®ãã¢ã«åæ¢±ã®ATR503æã®ãã¼ã¿ã»ãããä½¿ã£ã¦ã&lt;strong&gt;DNNæ¥æ¬èªé³å£°åæ&lt;/strong&gt; ãå®è£ããä¾ãç¤ºãããã¨æãã¾ããçµæã ãç¥ãããæ¹ã¯ãé³å£°ãµã³ãã«ãä¸ã®æ¹ã«ããã®ã§ãé©å½ã«èª­ã¿é£ã°ãã¦ãã ããã&lt;/p&gt;
&lt;h2 id=&#34;ãªãä½ã£ãã®ã&#34;&gt;ãªãä½ã£ãã®ã&lt;/h2&gt;
&lt;p&gt;ä¸çªå¤§ããªçç±ã¯ãåã &lt;strong&gt;å¯¾è©±ç°å¢ï¼Jupyter, IPythonç­ï¼&lt;/strong&gt; ã§ä½¿ãããã¼ã«ãã»ããã£ãããã§ã&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;ã
åã¯çµæ§åããREPL (Read-Eval-Print-Loop) ä¿¡èã§ããã­ã°ã©ãã³ã°ã®ãããªãã®æéãREPLã§éããã¾ãã
IDEãå¥½ãã§ãããemacsãå¥½ããªã®ã§ãããåããããJupyterã&lt;a href=&#34;https://github.com/JuliaLang/julia&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Julia&lt;/a&gt;ã®REPLãå¥½ãã§ãã
ç¨éã«å¿ãã¦ä½¿ãåãã¾ãããç¹ã«ä½ããã¼ã¿ãåæããå¿è¦ããããããªæã«ãå³åº§ã«ãã¼ã¿ãå¯è¦åã§ããJupyter notebookã¯ãåã«ã¨ã£ã¦ãã­ã°ã©ãã³ã°ã«æ¬ ãããªããã®ã«ãªã£ã¦ãã¾ãã&lt;/p&gt;
&lt;p&gt;ã¨ããããHTSã®å¾ç¶ã¨ãã¦çã¾ããDNNé³å£°åæãã¼ã«ã§ãã &lt;a href=&#34;https://github.com/CSTR-Edinburgh/merlin&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Merlin&lt;/a&gt; ã¯ãã³ãã³ãã©ã¤ã³ãã¼ã«ã¨ãã¦ä½¿ãããæ³å®ã®ãã®ã§ãåã®è¦æãæºããã¦ããããã®ã§ã¯ããã¾ããã§ããã
ã¨ã¯ãããMerlinã¯åªç§ãªé³å£°ç ç©¶èãã¡ã®ç£ç©ã§ãããå½ç¶å½¹ã«ç«ã¤é¨åãå¤ããä½¿ã£ã¦ãã¾ããããããããã¨ãã­ãã¿ã¤ãã³ã°ã«ããã¦ã¯ããã¯ãå¯¾è©±ç°å¢ã§ãããããªãã¨ããæããå¼·ã¾ã£ã¦ããã¾ããã&lt;/p&gt;
&lt;p&gt;æ°ããä½ãã®ã§ã¯ãªããMerlinãä½¿ãç¶ãããMerlinãæ¹åããæ¹éãèãã¾ãããåãMerlinãä½¿ãå§ããé ãMerlinã¯python3ã§åããªãã£ãã®ã§ãåãããã« &lt;a href=&#34;https://github.com/CSTR-Edinburgh/merlin/pull/141&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ãã«ãªã¯&lt;/a&gt; ãåºãããã¨ãããã®ã§ãããã¾ãã¬ãã¥ã¼ã«æ°ã«æãããã£ã¦ãã¾ã£ãã®ã§ãããã¯æ°ãããã®ãä½ã£ãæ¹ããããªãã¨æãã«è³ãã¾ããã&lt;/p&gt;
&lt;p&gt;ä»¥ä¸ããåãæ°ãããã¼ã«ä½ããã¨æã£ãçç±ã§ãã&lt;/p&gt;
&lt;h2 id=&#34;ç¹å¾´&#34;&gt;ç¹å¾´&lt;/h2&gt;
&lt;p&gt;ãã¦ãMerlinã«å¯¾ããæ¬æã¨ä¸æºããçã¾ãããã¼ã«ã§ããã¾ããããã®ç¹å¾´ãç°¡åã«ã¾ã¨ãã¾ãã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;å¯¾è©±ç°å¢&lt;/strong&gt; ã§ã®ä½¿ç¨ãåæã«ãè¨­è¨ããã¦ãã¾ããã³ãã³ãã©ã¤ã³ãã¼ã«ã¯ããã¾ãããã¦ã¼ã¶ãå¿è¦ã«å¿ãã¦ä½ãã°ãããã¨ããèãã§ãã&lt;/li&gt;
&lt;li&gt;DNNé³å£°åæã®ãã¢ããã¼ãããã¯å½¢å¼ã§æä¾ãã¦ãã¾ãã&lt;/li&gt;
&lt;li&gt;å¤§è¦æ¨¡ãã¼ã¿ã§ãæ±ããããã«ããã¼ã¿ã»ããã¨ãã¼ã¿ã»ããã®ã¤ãã¬ã¼ã·ã§ã³ï¼ãã¬ã¼ã æ¯ãçºè©±æ¯ã®ä¸¡æ¹ï¼ã®ã¦ã¼ãã£ãªãã£ãæä¾ããã¦ãã¾ã&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Merlinã¨ã¯ç°ãªããé³é¿ã¢ãã«ã¯æä¾ãã¾ãã&lt;/strong&gt;ãèªåã§å®è£ããå¿è¦ãããã¾ãï¼ããä»ã®æä»£ç°¡åã§ããã­ãlstmã§ãæ°è¡ã§æ¸ããã®ã§&lt;/li&gt;
&lt;li&gt;ä»»æã®æ·±å±¤å­¦ç¿ãã¬ã¼ã ã¯ã¼ã¯ã¨ä½µãã¦ä½¿ããããã«ãè¨­è¨ããã¦ãã¾ã&lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;ï¼&lt;a href=&#34;https://r9y9.github.io/nnmnkwii/latest/references/autograd.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;autogradããã±ã¼ã¸&lt;/a&gt;ã®ã¿ãä»ã®ã¨ããPyTorchä¾å­ã§ã&lt;/li&gt;
&lt;li&gt;è¨èªç¹å¾´éã®æ½åºã®é¨åã¯ãMerlinã®ã³ã¼ãããªãã¡ã¯ã¿ãã¦ç¨ãã¦ãã¾ãããã®ããããã£ã¦ãMerlinã®ãã¢ã¨åç­ã®ããã©ã¼ãã³ã¹ãç°¡åã«å®ç¾ã§ãã¾ãã&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;å¯¾è±¡ã¦ã¼ã¶&#34;&gt;å¯¾è±¡ã¦ã¼ã¶&lt;/h2&gt;
&lt;p&gt;ã¾ãã¯ããã«ãå¤§éæã«ãã£ã¦ãé³å£°åæã®ç ç©¶ï¼or ãã®çä¼¼äºï¼ããã¦ã¿ããäººãä¸»ãªå¯¾è±¡ã§ãã
èªåã®ãã¼ã¿ãåã«ããã©ãã¯ããã¯ã¹ã§ããã®ã§é³å£°åæã¨ã³ã¸ã³ãä½ããããã¨ããäººã«ã¯å³ããããããã¾ããããã®åæãåã«ãå°ãæ´çãã¾ãã&lt;/p&gt;
&lt;h3 id=&#34;ãããªäººã«ããããã§ã&#34;&gt;ãããªäººã«ããããã§ã&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Jupyter notebookãå¥½ããªäºº&lt;/li&gt;
&lt;li&gt;REPLãå¥½ããªäºº&lt;/li&gt;
&lt;li&gt;Pythonã§å¦çãå®çµããããäºº&lt;/li&gt;
&lt;li&gt;ãªã¼ãã³ã½ã¼ã¹ã®æåã«å¯å®¹ãªäºº&lt;sup id=&#34;fnref:4&#34;&gt;&lt;a href=&#34;#fn:4&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;
&lt;li&gt;é³å£°åæã®ç ç©¶ãå§ãã¦ã¿ããäºº&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;ãããªäººã«ã¯åããªããã&#34;&gt;ãããªäººã«ã¯åããªããã&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;ã³ãã³ãã©ã¤ã³ãã¼ã«ããè³é«ãªäºº&lt;/li&gt;
&lt;li&gt;ãã¤ãã©ã¤ã³å¦çããè³é«ãªäºº&lt;/li&gt;
&lt;li&gt;SPTKã®ã³ãã³ãã©ã¤ã³ãã¼ã«è³é«ãªäºº&lt;/li&gt;
&lt;li&gt;ä¿¡é ¼ã®ããæ©é¢ãä½ã£ããã¼ã«ããä½¿ããªãäºº&lt;sup id=&#34;fnref:5&#34;&gt;&lt;a href=&#34;#fn:5&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;5&lt;/a&gt;&lt;/sup&gt;&lt;/li&gt;
&lt;li&gt;é³å£°ç ç©¶èã¬ãå¢ã§ãèªåã®ãã¼ã«ã§æºè¶³ãã¦ããäºº&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;dnnæ¥æ¬èªé³å£°åæã®å®è£ä¾&#34;&gt;DNNæ¥æ¬èªé³å£°åæã®å®è£ä¾&lt;/h2&gt;
&lt;p&gt;ãã¦ãåç½®ãã¯ãã®ãããã«ãã¦ãæ¥æ¬èªé³å£°åæã®å®è£ä¾ãç¤ºãã¾ããã·ã³ãã«ãªFeed forwardãªãããã¯ã¼ã¯ã¨ãBi-directional LSTM RNNã®2ãã¿ã¼ã³ãããã¼ãããã¯å½¢å¼ã§ä½æãã¾ããã&lt;/p&gt;
&lt;p&gt;ã½ã¼ã¹ã³ã¼ãã¯ã &lt;a href=&#34;https://github.com/r9y9/nnmnkwii_gallery&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/r9y9/nnmnkwii_gallery&lt;/a&gt; ã«ããã¾ããä»¥ä¸ã«ãç¾ç¶ç¹ã§ã®ç´ãªã³ã¯ï¼gitã®ã³ãããããã·ã¥ãURLã«å¥ã£ã¦ãã¾ãï¼ãè²¼ã£ã¦ããã¾ããnbviewerã«é£ã³ã¾ãã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://nbviewer.jupyter.org/github/r9y9/nnmnkwii_gallery/blob/bd4bd260eb22d0000ac2776b204b3a5afb693c49/notebooks/tts/jp-01-DNN-based%20statistical%20speech%20synthesis.ipynb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Feed forwardãªãããã¯ã¼ã¯ãä½¿ã£ãé³å£°åæã®ãã¼ãããã¯ã¸ã®ç´ãªã³ã¯&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://nbviewer.jupyter.org/github/r9y9/nnmnkwii_gallery/blob/bd4bd260eb22d0000ac2776b204b3a5afb693c49/notebooks/tts/jp-02-Bidirectional-LSTM%20based%20RNNs%20for%20speech%20synthesis.ipynb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Bi-directional LSTM RNNãä½¿ã£ãé³å£°åæã®ãã¼ãããã¯ã¸ã®ç´ãªã³ã¯&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;èå³ã®ããäººã¯ãã­ã¼ã«ã«ã«è½ã¨ãã¦å®è¡ãã¦ã¿ã¦ãã ãããCUDAç°å¢ããããã¨ãåæã§ãããéå¸¸ã®Feed forwardã®ãããã¯ã¼ã¯ãç¨ãããã¢ã¯ã
ç¹å¾´æ½åºã®æéï¼ååå®è¡æã«å¿è¦ï¼ãé¤ãã°ã5åã§å­¦ç¿&amp;amp;æ³¢å½¢çæãçµããã¾ããBi-directional LSTMã®ãã¢ã¯ãåã®ç°å¢ (i7-7700K, GTX 1080Ti) ã§ã¯ãç´2æéã§çµããã¾ããGPUã¡ã¢ãªãå°ãªãå ´åã¯ãããããµã¤ãºãå°ããããªããã°ãªãããããæéããããããããã¾ããã&lt;/p&gt;
&lt;h3 id=&#34;ãã¼ã¿ã»ãã&#34;&gt;ãã¼ã¿ã»ãã&lt;/h3&gt;
&lt;p&gt;ä»åã¯ãHTSã®NIT-ATR503ã®ãã¢ãã¼ã¿ (&lt;a href=&#34;https://github.com/r9y9/nnmnkwii_gallery/blob/4899437e22528399ca50c34097a2db2bed782f8b/data/NIT-ATR503_COPYING&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ã©ã¤ã»ã³ã¹&lt;/a&gt;) ãæåãã¾ããã©ã¤ãã©ãªãä½¿ã£ã¦é³å£°åæãå®ç¾ããããã®ãã¼ã¿ã¨ãã¦ãæä½éä»¥ä¸ãå¿è¦ã§ãã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;(state or phone level) ãã«ã³ã³ãã­ã¹ãã©ãã«&lt;/li&gt;
&lt;li&gt;Wavãã¡ã¤ã«&lt;/li&gt;
&lt;li&gt;è³ªåãã¡ã¤ã«ï¼è¨èªç¹å¾´éã®æ½åºã«å¿è¦ï¼&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ä¸2ã¤ã¯ãä»åã¯HTSã®ãã¢ã¹ã¯ãªããããã¾ãã¾ããã®ã¾ã¾ä½¿ãã¾ãï¼â»HTSã®ãã¢ã¹ã¯ãªãããåãå¿è¦ã¯ããã¾ããï¼ãè³ªåãã¡ã¤ã«ã¯ãã³ã³ãã­ã¹ãã¯ã©ã¹ã¿ãªã³ã°ã«ä½¿ãããè³ªåãã¡ã¤ã«ãåã«ãè³ªåæ°ãï¼æ¬å½ã«ï¼é©å½ã«æ¸ããã¦ãMerlinã®ãã¢ã®è³ªåãã¡ã¤ã«ããCQSã«è©²å½ããè³ªåãå ãã¦ãä½æãã¾ããã
ãã«ã³ã³ãã­ã¹ãã©ãã«ã«ã¯ãphone-levelã§ã¢ã©ã¤ã¡ã³ãããããã®ãä½¿ãã¾ããã
state-levelã§ã¢ã©ã¤ã¡ã³ãããããã®ãä½¿ãã°ãæ§è½ã¯ä¸ããã¨æãã¾ããä»åã¯ç°¡åã®ããã«phone-levelã®ã¢ã©ã¤ã¡ã³ããä½¿ãã¾ãã&lt;/p&gt;
&lt;p&gt;è³ªåã®é¸å®ã«ã¯ãæ¹åã®ä½å°ããããã¨ãããã£ã¦ãã¾ãããããã¾ã§ãã¢ã¨ãããã¨ã§ããäºæ¿ãã ããã&lt;/p&gt;
&lt;h3 id=&#34;é³å£°åæã®çµæ&#34;&gt;é³å£°åæã®çµæ&lt;/h3&gt;
&lt;p&gt;å¨ä½ã®å¦çã«èå³ãããå ´åã¯å¥éãã¼ãããã¯ãè¦ã¦ãããã¨ãã¦ãããã§ã¯çµæã ãè²¼ã£ã¦ããã¾ãã
HTSã®ãã¢ããã¨ã£ã¦ããä¾æ5ã¤ã«å¯¾ãã¦ããããã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Feed forward neural networks (MyNetã¨ãã¾ã) ã§çæãããã®&lt;/li&gt;
&lt;li&gt;Bi-directional LSTM recurrent neural networks (MyRNNã¨ãã¾ã)ã§çæãããã®&lt;/li&gt;
&lt;li&gt;HTSãã¢ã§çæãããã® (HTSã¨ãã¾ã)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ã®é çªã«ãé³å£°ãã¡ã¤ã«ãæ·»ä»ãã¦ããã¾ããè´ããããããã«ãsoxã§æ­£è¦åãã¦ãã¾ããããã§ã¯ã©ããã&lt;/p&gt;
&lt;p&gt;1 ããã«ã¡ã¯&lt;/p&gt;
&lt;p&gt;MyNet&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-01-tts/phrase01.wav&#34; type=&#34;audio/wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;MyRNN&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-02-tts/phrase01.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;HTS&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/hts_nit_atr503_2mix/phrase01.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;2 ããã§ã¯ããããªã&lt;/p&gt;
&lt;p&gt;MyNet&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-01-tts/phrase02.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;MyRNN&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-02-tts/phrase02.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;HTS&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/hts_nit_atr503_2mix/phrase02.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;3 ã¯ããã¾ãã¦&lt;/p&gt;
&lt;p&gt;MyNet&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-01-tts/phrase03.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;MyRNN&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-02-tts/phrase03.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;HTS&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/hts_nit_atr503_2mix/phrase03.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;4 ããããåå¤å±å·¥æ¥­å¤§å­¦ã¸&lt;/p&gt;
&lt;p&gt;MyNet&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-01-tts/phrase04.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;MyRNN&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-02-tts/phrase04.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;HTS&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/hts_nit_atr503_2mix/phrase04.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;5 ä»å¤ã®åå¤å±ã®å¤©æ°ã¯é¨ã§ã&lt;/p&gt;
&lt;p&gt;MyNet&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-01-tts/phrase05.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;MyRNN&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/jp-02-tts/phrase05.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;HTS&lt;/p&gt;
&lt;audio controls=&#34;controls&#34; &gt;
&lt;source src=&#34;https://r9y9.github.io/audio/hts_nit_atr503_2mix/phrase05.wav&#34; autoplay/&gt;
Your browser does not support the audio element.
&lt;/audio&gt;
&lt;p&gt;ä¸å¿HTSã§çæãããé³å£°ãè²¼ãã¾ããããããããå®é¨æ¡ä»¶ãéãããã&lt;sup id=&#34;fnref:6&#34;&gt;&lt;a href=&#34;#fn:6&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;6&lt;/a&gt;&lt;/sup&gt;ã®ã§ãåç´ã«æ¯è¼ãããã¨ã¯ã§ãã¾ããã
ããã¦ HTS ï¼ STRAIGHTã¨æ¯è¼ãããã£ãã¨ããã§ãããåã¯STRAIGHTãæã£ã¦ããªãã®ã§ãæ®å¿µãªããã§ãã¾ãããæ²ãã¿ã&lt;/p&gt;
&lt;p&gt;ãããããããªãã«ã¾ã¨ããªé³å£°ãåºã¦ãããããªæ°ããã¾ãã&lt;/p&gt;
&lt;h2 id=&#34;ãããã«&#34;&gt;ãããã«&lt;/h2&gt;
&lt;p&gt;ãã¾ã¾ã§ãããããæ±ç¨æ§ã¨ã¯ç¨é ãã¯ã½ã³ã¼ããæ¸ãã¦ãã¾ããããä»åããã¯å°ãã¯ãã·ãªãã®ãä½ããã¨æã£ã¦ä½ãã¾ãããåä»¥å¤ã®äººã«ãå½¹ã«ç«ã¦ã°å¹¸ãã§ãããã¨ããã®è¨äºãæ¸ããç®çã¯ãããããªäººã«ä½¿ã£ã¦ã¿ã¦ã»ããã®ã¨ãä½¿ã£ã¦ã¿ãçµæã®ãã£ã¼ãããã¯ãã»ããï¼ãã°è¦ã¤ãããããããã¨ã©ã¼ã§åããããããã¯ã½ãç­ï¼ã¨ãããã¨ãªã®ã§ããã£ã¼ãããã¯ããã ããã¨å©ããã¾ãããããããé¡ããã¾ãã&lt;/p&gt;
&lt;p&gt;ã¡ãªã¿ã«ååã§ããããªãªã¿ or ãã¡ã¿ã¨èª­ãã§ãã ãããä½ã§ãããã®ã§ãããå¸¸è­çã«èãã¦ããç¢ºãã«èª­ããªããªãã¨æãã¾ããï¼å°ä¸¦æï¼ããã­ã¥ã¡ã³ãã«ããã­ã´ã¯ãæä¸æ¬¡åç©ä½è¿½è·¡ã®å®é¨ããã¦ããã¨ãã«æ®ã£ããæã¢ã³ã®ãã¤ã³ãã¯ã©ã¦ãã§ããããã®ãã¡ä¸å³çãªç»åã«å¤ãããã¨æã£ã¦ãã¾ããé©å½ã§ããã¾ãã&lt;/p&gt;
&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;ãªã³ã¯åããæãã®ã§ãv0.0.1ã®ãªã³ã¯ãè²¼ãã¾ãããã§ããã°ãææ°çããè¦§ãã ããã &lt;a href=&#34;https://r9y9.github.io/nnmnkwii/latest/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://r9y9.github.io/nnmnkwii/latest/&lt;/a&gt; ãã¡ããããã©ãã¾ã&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34;&gt;
&lt;p&gt;ç¥ã£ã¦ããäººã«ã¯ã¾ãããã¨è¨ãããã&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34;&gt;
&lt;p&gt;é³é¿ã¢ãã«ã®æä¾ãã©ã¤ãã©ãªã®ç¯å²å¤ã¨ãããã¨ã§ãéæ¥çã«éæããã¦ãã¾ã&amp;#160;&lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:4&#34;&gt;
&lt;p&gt;ãã°ã«ã¨ã³ã«ã¦ã³ããããããã«ä½¿ãã®ãããã¦ãã¾ãäººã«ã¯ãåãã¦ããªãããããã¾ããã&amp;#160;&lt;a href=&#34;#fnref:4&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:5&#34;&gt;
&lt;p&gt;Merlinã¯ãã¨ã¸ã³ãã©å¤§å­¦ã®åªç§ãªç ç©¶èã®æ¹ãã«ãã£ã¦ä½ããã¦ãã¾ã&amp;#160;&lt;a href=&#34;#fnref:5&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:6&#34;&gt;
&lt;p&gt;f0åæãã¹ãã¯ãã«åçµ¡æ½åºãéå¨ææ§æåã®æ½åºæ³ããã¹ã¦ãã¨ãªããã¾ããã¹ããã£ã«ã¿ã®ç¨®é¡ãç°ãªããæ¡ä»¶ãããç¨åº¦æãã¦æ¯è¼ããã®ãé¢åããã ã£ãã®ã§ï¼ãªã«ãHTSãä½¿ã£ãã¢ãã«ã®å­¦ç¿ã¯æ°æéããããâ¦ï¼ãæãæãã¾ãããããã¾ãã&amp;#160;&lt;a href=&#34;#fnref:6&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>DNNçµ±è¨çé³å£°åæãã¼ã«ã­ãã Merlin ã®ä¸­èº«ãçè§£ããã</title>
      <link>https://r9y9.github.io/blog/2017/08/16/trying-to-understand-merlin/</link>
      <pubDate>Wed, 16 Aug 2017 03:00:00 +0900</pubDate>
      <guid>https://r9y9.github.io/blog/2017/08/16/trying-to-understand-merlin/</guid>
      <description>&lt;p&gt;ãã®è¨äºã§ã¯ãé³å£°åæãã¼ã«ã­ããã§ããMerlinããå·ä½çã«ä½ããã¦ããã®ãï¼ç¹å¾´éã®æ­£è¦åãç¡é³åºéã®åé¤ããã¹ããã£ã«ã¿ãªã©ãã³ã¼ããèª­ã¾ãªãã¨ããããªããã¨ï¼ããã®ä¸­èº«ãåãçè§£ããç¯å²ã§ã¾ã¨ãã¾ãã
ãªããHMMé³å£°åæã«ã¤ãã¦ç°¡åã«çè§£ãã¦ãããã¨ï¼HMMã¨ã¯ãç¶æã¨ã¯ããã«ã³ã³ãã­ã¹ãã©ãã«ã¨ã¯ããããï¼ãåæã¨ãã¾ãã&lt;/p&gt;
&lt;h2 id=&#34;ã¯ããã«&#34;&gt;ã¯ããã«&lt;/h2&gt;
&lt;p&gt;Merlinã®æ¦è¦ã«ã¤ãã¦ã¯ä»¥ä¸ããè¦§ãã ããã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://ssw9.net/papers/ssw9_PS2-13_Wu.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Wu, Zhizheng, Oliver Watts, and Simon King. &amp;ldquo;Merlin: An open source neural network speech synthesis system.&amp;rdquo; Proc. SSW, Sunnyvale, USA (2016).&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://ssw9.net/papers/ssw9_DS-3_Ronanki.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;&amp;ldquo;A Demonstration of the
Merlin Open Source Neural Network Speech Synthesis System&amp;rdquo;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://cstr-edinburgh.github.io/merlin/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;å¬å¼ãã­ã¥ã¡ã³ã&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Merlinã«ã¯ãã¢ã¹ã¯ãªãããã¤ãã¦ãã¾ããåºæ¬çã«ã¦ã¼ã¶ãä½¿ãã¤ã³ã¿ãã§ã¼ã¹ã¯run_merlin.pyã¨ããã³ãã³ãã©ã¤ã³ã¹ã¯ãªããã§ã
ãã¢ã¹ã¯ãªããã§ã¯run_merlin.pyã«ç¨éã«å¿ããè¨­å®ãã¡ã¤ã«ãä¸ãããã¨ã§ãç¶ç¶é·ã¢ãã«ã®å­¦ç¿/é³é¿ã¢ãã«ã®å­¦ç¿/ãã©ã¡ã¼ã¿çæãªã©ãé³å£°åæã«å¿è¦ãªã¹ããããå®ç¾ãã¦ãã¾ãã&lt;/p&gt;
&lt;p&gt;ãã¢ã¹ã¯ãªãããå®è¡ããã¨ãé³å£°ãã¼ã¿ (wav) ã¨è¨èªç¹å¾´éï¼HTSã®ãã«ã³ã³ãã­ã¹ãã©ãã«ï¼ãããå¤æé³å£°ãåæãããã¨ããã¾ã§ã¾ãã£ã¨ãã£ã¦ãããã®ã§ãããããã ãã§ã¯åé¨ã§ä½ããã£ã¦ããã®ããçè§£ãããã¨ã¯ã§ãã¾ããã
ãã¼ã«ã­ãããä½¿ãç®çããèªåãç¨æãããã¼ã¿ã»ããã§é³å£°åæå¨ãä½ããããã¨ãã£ãå ´åã«ã¯ãç¹ã«åé¨ãç¥ãå¿è¦ã¯ããã¾ããã
ã¾ããè¨­å®ãã¡ã¤ã«ãã¡ããã£ã¨ãããã ãã§ãã¨æ¸ãã®ã§ããã°ãç¥ãå¿è¦ã¯ãªãããããã¾ããã
ããããã¢ãã«æ§é ãå¤ããããå­¦ç¿ã¢ã«ã´ãªãºã ãå¤ãããããã¹ããã£ã«ã¿ãå¥ããããã¨ãã£ãããã«ãå°ãé²ãã ä½¿ãæ¹ããããã¨ããã°ãåé¨æ§é ãçè§£ããªãã¨ã§ããªããã¨ãå¤ãã¨æãã¾ãã&lt;/p&gt;
&lt;p&gt;run_merlin.py ã¯ããããå¦ç (å·ä½çã«ã¯ãã¨ã§è¿°ã¹ã¾ã) ã®ã¨ã³ããªã¼ãã¤ã³ãã«ãªã£ã¦ãããããã«ãã³ã¼ãã¯ãªããªãã«è¤éã«ãªã£ã¦ãã¾ã&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;ããã®è¨äºã§ã¯ãrun_merlin.pyããã£ããä½ããã¦ããã®ããèª­ã¿è§£ããçµæãã¾ã¨ãã¾ãã&lt;/p&gt;
&lt;h2 id=&#34;merlinã§ã¯æä¾ããªããã¨&#34;&gt;Merlinã§ã¯æä¾ããªããã¨&lt;/h2&gt;
&lt;p&gt;Merlinãä½ãæä¾ãã¦ãããã®ããçè§£ããåã«ãä½ãæä¾ããªãã®ããããã£ããã¨æ´çãã¾ããä»¥ä¸ã®ã¨ããã§ãã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Text-processing (&lt;strong&gt;Frontend&lt;/strong&gt;)&lt;/li&gt;
&lt;li&gt;Speech analysis/synthesis (&lt;strong&gt;Backend&lt;/strong&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;HTSã¨åæ§ã«ãfrontend, backendã¨ãã£ãé¨åã¯æä¾ãã¦ãã¾ãããMerlinã®è«æã«ãããããã«ãHTSã®å½±é¿ãåãã¦ããããã§ãã&lt;/p&gt;
&lt;p&gt;Frontendã«ã¯ãè±èªãªãFestivalãBackendã«ã¯WORLDãSTRAIGHTãä½¿ã£ã¦ãããããã£ã¦ã­ãã¨ããã¹ã¿ã³ã¹ã§ãã
Backendã«é¢ãã¦ã¯ãMerlinã®ã¤ã³ã¹ãã¼ã«ã¬ã¤ãã«ããããã«ãWOLRDãã¤ã³ã¹ãã¼ã«ããããã«ä¿ããã¾ãã&lt;/p&gt;
&lt;p&gt;ãã¢ã¹ã¯ãªããã§ã¯ãFrontendã«ãã£ã¦çæããããã«ã³ã³ãã­ã¹ãã©ãã«ï¼HTSæ¸å¼ï¼ãäºåã«åæ¢±ããã¦ããã®ã§ãFestivalãã¤ã³ã¹ãã¼ã«ããå¿è¦ã¯ããã¾ããã
miscä»¥ä¸ã«ãFestivalãä½¿ã£ã¦ãã«ã³ã³ãã­ã¹ãã©ãã«ãä½ãã¹ã¯ãªãã (make_labels) ãããã®ã§ããã¢ãã¼ã¿ä»¥å¤ã®ãã¼ã¿ã»ãããä½¿ãå ´åã¯ããããä½¿ãã¾ãã&lt;/p&gt;
&lt;h2 id=&#34;steps&#34;&gt;Steps&lt;/h2&gt;
&lt;p&gt;æ¬ç·¨ã§ããslt_arcticã®ãã¢ã¹ã¯ãªããã«å¾ããããããã®ã¹ãããã«åãã¦ãè©³ç´°ã«è¦ã¦ããã¾ãããªããä»¥ä¸ãã¢ã¹ã¯ãªããã¨æ¸ããéã«ã¯ãslt_arcticã®ãã¢ã¹ã¯ãªãããæããã®ã¨ãã¾ãã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ç¶ç¶é·ã¢ãã«ã®å­¦ç¿&lt;/li&gt;
&lt;li&gt;é³é¿ã¢ãã«ã®å­¦ç¿&lt;/li&gt;
&lt;li&gt;å¤æé³å£°ã®åæ&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ãªããMerlinã®ã¹ã¯ãªããã«ãã£ã¦ã¯ããããã¼ã¿ã¯ãåºæ¬çã«&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;x.astype(np.float32).tofile(&amp;quot;foobar.bin&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;ã¨ãã£ãæãã§ã32bitæµ®åå°æ°ç¹ã®numpyã®éåãããããªãã®ãã¤ããªãã©ã¼ãããã§ä¿å­ããã¦ãã¾ãããããã°æã«ã¯ã&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-py&#34;&gt;np.fromfile(&amp;quot;foobar.bin&amp;quot;, dtype=np.float32)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;ã¨ãã¦ããã¡ã¤ã«ãèª­ã¿è¾¼ãã§ã¤ã³ã¹ãã¯ãããã®ãä¾¿å©ã§ããæ³¨æäºé ã¨ãã¦ãããããããã¨ã«ãæ¡å¼µå­ã¯ä¿¡é ¼ã§ãã¾ããã&lt;code&gt;.lab&lt;/code&gt; ã¨ããæ¡å¼µå­ã§ãã£ã¦ãããã«ã³ã³ãã­ã¹ãã©ãã«ã®ãã­ã¹ããã¡ã¤ã«ã§ããå ´åãããã°ãä¸è¿°ã®ããã«ãã¤ããªãã©ã¼ãããã§ããå¯è½æ§ãããã¾ããã¤ããã§ãã­ï¼&lt;/p&gt;
&lt;h3 id=&#34;ç¶ç¶é·ã¢ãã«ã®å­¦ç¿&#34;&gt;ç¶ç¶é·ã¢ãã«ã®å­¦ç¿&lt;/h3&gt;
&lt;p&gt;ç¶ç¶é·ã¢ãã«ã¨ã¯ãè¨èªç¹å¾´éãããç¶ç¶é·ãäºæ¸¬ããã¢ãã«ã§ããMerlinã§ã¯ãphone-level / state-level ã®ã©ã¡ãããé¸æå¯è½ã§ããMerlinã®æä¾ããDNNé³å£°åæã§ã¯ãç¶ç¶é·ã®äºæ¸¬âé³é¿ç¹å¾´éã®äºæ¸¬âåæãã¨ãã£ãã¹ã¿ã¤ã«ãã¨ãã¾ãã
ããã©ã«ãã§ã¯ãstate-levelã§ç¶ç¶é·ï¼å·ä½çã«ã¯ä¸ç¶æå½ããã®ç¶ç¶ãã¬ã¼ã æ°ï¼ãäºæ¸¬ãã¾ããç¶æã¬ãã«ã®ã¢ã©ã¤ã¡ã³ãã®ã»ãããæéè§£ååº¦ã®é«ãã³ã³ãã­ã¹ããå¾ãããçµæé³å£°åæã®åè³ªãè¯ããªãã®ã§ãããã©ã«ãã«ãªã£ã¦ããã®ã ã¨æãã¾ãã &lt;a href=&#34;https://github.com/CSTR-Edinburgh/merlin/issues/18&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/CSTR-Edinburgh/merlin/issues/18&lt;/a&gt; ã«å°ãè­°è«ãããã¾ãã&lt;/p&gt;
&lt;p&gt;ãã¢ã¹ã¯ãªãããå®è¡ããã¨ã &lt;code&gt;experiments/slt_arctic_demo/duration_model/&lt;/code&gt; ä»¥ä¸ã«ç¶ç¶é·ã¢ãã«ç¨ã®ãã¼ã¿ãã¯åºåããã¾ããããã¤ãéè¦ãªãã®ã«ã¤ãã¦ãä»¥ä¸ã«ç¤ºãã¾ãã&lt;/p&gt;
&lt;h4 id=&#34;data&#34;&gt;data&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;label_phone_align&lt;/code&gt;: é³ç´ ã¬ãã«ã§ã®ãã«ã³ã³ãã­ã¹ãã©ãã«ã§ã&lt;/li&gt;
&lt;li&gt;&lt;code&gt;dur&lt;/code&gt;: ç¶æå¥ç¶ç¶é·ã§ããæ­£ç¢ºã«ã¯ã&lt;code&gt;T&lt;/code&gt; ããã«ã³ã³ãã­ã¹ãã©ãã«ä¸­ã®é³ç´ æ°ã¨ãã¦ã&lt;code&gt;(T, 5)&lt;/code&gt; ã®éåãçºè©±ãã¨ã«ä¿å­ããã¾ãã5ã¯é³ç´ ãããã®HMMã®ç¶ææ°ã§ãæ£ä¾çã«ï¼5ãä½¿ç¨ããã¦ãããããªæ°ããã¾ãã&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;inter_module&#34;&gt;inter_module&lt;/h4&gt;
&lt;p&gt;ä¸­éçµæã®ãã¡ã¤ã«ç¾¤ã§ã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;binary_label_416/&lt;/code&gt;: HTSå½¢å¼ã®è³ªåãã¡ã¤ã«ãåã«çæãããè¨èªç¹å¾´éè¡åã§ãããã¢ã¹ã¯ãªããã§ã¯ã416åã®è³ªåãããã®ã§ãä¸ç¶æããã416æ¬¡åã®ç¹å¾´ãã¯ãã«ã«ãªãã¾ããbinaryãªç¹å¾´éï¼æ¯é³ãå¦ãï¼ã¨é£ç¶çãªç¹å¾´éï¼åèªä¸­ã®sylalbleã®æ°ç­ï¼ãããã¾ãã&lt;code&gt;(T, 416)&lt;/code&gt; ã®è¡åããçºè©±ãã¨ã«ä¿å­ããã¦ãã¾ãã&lt;/li&gt;
&lt;li&gt;&lt;code&gt;label_norm_HTS_416.dat&lt;/code&gt;: 416æ¬¡åã®ç¹å¾´ãã¯ãã«ã®æ­£è¦åã«å¿è¦ãªæå ±ã§ãããã¢ã¹ã¯ãªããã§ã¯ãè¨èªç¹å¾´éã«é¢ãã¦ã¯min/maxæ­£è¦åãè¡ãããã®ã§ãminããã³maxã®416æ¬¡åã®ãã¯ãã«ï¼è¨416*2æ¬¡åï¼ãä¿å­ããã¦ãã¾ãã&lt;/li&gt;
&lt;li&gt;&lt;code&gt;nn_dur_5/&lt;/code&gt;: ç¡é³åºéãé¤å»ããããç¶æå¥ç¶ç¶é·ã§ãããã©ã«ãåããã¯å¯ãããã¨ã¯é£ããã§ãããç¡é³åºéãé¤å»ããã¦ãã¾ãã&lt;/li&gt;
&lt;li&gt;&lt;code&gt;nn_no_silence_lab_416/&lt;/code&gt;: ç¡é³åºéãé¤å»ããããè¨èªç¹å¾´éè¡åã§ãã&lt;/li&gt;
&lt;li&gt;&lt;code&gt;nn_no_silence_lab_norm_416/&lt;/code&gt;: ç¡é³åºéãé¤å»ããããmin/maxæ­£è¦åãããè¨èªç¹å¾´éè¡åã§ãã&lt;/li&gt;
&lt;li&gt;&lt;code&gt;nn_norm_dur_5/&lt;/code&gt; ç¡é³åºéãé¤å»ããããmean/varianceæ­£è¦åãããç¶æå¥ç¶ç¶é·ã§ãã&lt;/li&gt;
&lt;li&gt;&lt;code&gt;norm_info_dur_5_MVN.dat&lt;/code&gt;: ç¶ç¶é·ã®æ­£è¦åã«å¿è¦ãªæå ±ã§ããå·ä½çã«ã¯ãMean-varianceæ­£è¦åï¼N(0, 1)ã«ãªãããã«ããï¼ãè¡ãããã®ã§ãå¹³åã¨æ¨æºåå·®ï¼not åæ£ï¼ãå¥ã£ã¦ãã¾ããç¶æã¬ãã«ã§ã®ã¢ã©ã¤ã¡ã³ããä½¿ç¨ããå ´åã¯ã5*2ã§è¨10æ¬¡åã®ãã¯ãã«ã§ãã&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ref_data/&lt;/code&gt;: RMSEãªã©ã®è©ä¾¡åºæºãè¨ç®ããéã«ä½¿ãããç¶ç¶é·ã®ãã¹ããã¼ã¿ã§ãã&lt;code&gt;data/dur&lt;/code&gt; ãã£ã¬ã¯ããªã®ç¶ç¶é·ãã¼ã¿ãåã«ãç¡é³åºéãé¤å»ããããã®ã§ã&lt;/li&gt;
&lt;li&gt;&lt;code&gt;var/&lt;/code&gt;: ç¶ç¶é·ã®åæ£ï¼not æ¨æºåå·®ï¼ã§ãããã©ã¡ã¼ã¿çæ (MLPG) ã«ä½¿ãããæ³å®ã®ãã¼ã¿ã§ã&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ãã£ããããããããã¾ãã­ãããã ãã§ããããã«å¤ãã®ãã¨ãrun_merlin.pyã«ãã£ã¦ãªããã¦ããããããããã¨æãã¾ãã&lt;/p&gt;
&lt;h4 id=&#34;å¥ååºå&#34;&gt;å¥å/åºå&lt;/h4&gt;
&lt;p&gt;ä¸­éãã¡ã¤ã«ããããããã£ã¦ãããããã§ãããæ´çããã¨ããããã¯ã¼ã¯å­¦ç¿ã«ç¨ããå¥åã¨åºåã¯ä»¥ä¸ã«ãªãã¾ãã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;å¥å: &lt;code&gt;nn_no_silence_lab_norm_416&lt;/code&gt;, ä¸çºè©±ãããã®ç¹å¾´éã®shape: &lt;code&gt;(T, 416)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;åºå: &lt;code&gt;nn_norm_dur_5&lt;/code&gt;, ä¸çºè©±ãããã®ç¹å¾´éã®shape: &lt;code&gt;(T, 5)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;å­¦ç¿ãããã¢ãã«ã¯ã &lt;code&gt;nnets_model&lt;/code&gt;ã¨ãããã©ã«ãã«ä¿å­ããã¾ãã&lt;/p&gt;
&lt;h3 id=&#34;é³é¿ã¢ãã«ã®å­¦ç¿&#34;&gt;é³é¿ã¢ãã«ã®å­¦ç¿&lt;/h3&gt;
&lt;p&gt;é³é¿ã¢ãã«ã¨ã¯ãè¨èªç¹å¾´éããã¡ã«ã±ãã¹ãã©ã ãF0ãéå¨ææ§æåãªã©ã®é³é¿ç¹å¾´éãäºæ¸¬ããã¢ãã«ã§ããMerlinã®ãã¢ã¹ã¯ãªããã§ã¯ã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ã¡ã«ã±ãã¹ãã©ã : 60æ¬¡åï¼åçç¹å¾´éãåãããã¨ã180æ¬¡å)&lt;/li&gt;
&lt;li&gt;å¯¾æ°F0: 1æ¬¡åï¼åçç¹å¾´éãåãããã¨ã3æ¬¡å)&lt;/li&gt;
&lt;li&gt;æå£° or ç¡å£°ãã©ã° (voiced/unvoiced; vuv): 1æ¬¡å&lt;/li&gt;
&lt;li&gt;éå¨ææ§æå: 1æ¬¡åï¼åçç¹å¾´éãåãããã¨ã3æ¬¡å)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ã®è¨187æ¬¡åã®é³é¿ç¹å¾´éãäºæ¸¬ããã¢ãã«ãèãã¾ããç¶ç¶é·ã¢ãã«ã®ã¨ãã¨åæ§ã«ãåºåããããã¡ã¤ã«ã«ã¤ãã¦ããããèª¬æãã¾ãã&lt;/p&gt;
&lt;h4 id=&#34;data-1&#34;&gt;data&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;bap&lt;/code&gt;: çºè©±æ¯ã«è¨ç®ãããéå¨ææ§æåãå¥ã£ã¦ãã¾ããbapã¯band averaged aperiodicityã®ç¥ã§ãï¼å°éå®¶ã®äººã«ã¨ã£ã¦ã¯å½ããåãã¨æãã¾ãããä¸å¿&lt;/li&gt;
&lt;li&gt;&lt;code&gt;label_phone_align&lt;/code&gt;: phone-levelã§ã¢ã©ã¤ã¡ã³ããããHTSã®ã³ã³ãã­ã¹ãã©ãã«ãå¥ã£ã¦ãã¾ããããã©ã«ãã®è¨­å®ã§ã¯ä½¿ãã¾ããã&lt;/li&gt;
&lt;li&gt;&lt;code&gt;label_state_align&lt;/code&gt;: state-levelã§ã¢ã©ã¤ã¡ã³ããããHTSã®ã³ã³ãã­ã¹ãã©ãã«ãå¥ã£ã¦ãã¾ã&lt;/li&gt;
&lt;li&gt;&lt;code&gt;lf0&lt;/code&gt;: å¯¾æ°F0ã§ãããªããWORLDã§ã¯ãããF0ã¯ç¡å£°åºéã§0ãåãã¾ãããç¡å£°åºéã®é¨åãç·å½¢è£éãããã¨ã«ãã£ã¦ãéã¼ã­ã®å¤ã§è£å®ãã¦ãã¾ãã&lt;/li&gt;
&lt;li&gt;&lt;code&gt;mgc&lt;/code&gt;: ã¡ã«ã±ãã¹ãã©ã ã§ãï¼ãã©ã«ãåã¯ãæ£ç¿çã«ã¡ã«ä¸è¬åã±ãã¹ãã©ã ãè¡¨ã &lt;code&gt;mgc&lt;/code&gt;ã¨ãªã£ã¦ãã¾ããããã¢ã¹ã¯ãªããã§ã¯å®éã«ã¯ã¡ã«ã±ãã¹ãã©ã ã§ãï¼&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;inter_module-1&#34;&gt;inter_module&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;binary_label_425/&lt;/code&gt;: è¨èªç¹å¾´éã®è¡åã§ããç¶ç¶é·ã¢ãã«ã®å ´åã¨éã£ã¦ããã¬ã¼ã åä½ã§çæããã¦ããã®ã¨ããã¬ã¼ã åä½ãªãã§ã¯ã®ç¹å¾´éï¼é³ç´ ä¸­ã®ä½ãã¬ã¼ã ç®ãªã®ããç­ï¼ãè¿½å ããã¦ãã¾ãããã¬ã¼ã æ°ã &lt;code&gt;T&lt;/code&gt; ã¨ãã¦ã &lt;code&gt;(T, 425)&lt;/code&gt; ã®éåãçºè©±ãã¨ã«ä¿å­ããã¦ãã¾ãã&lt;/li&gt;
&lt;li&gt;&lt;code&gt;label_norm_HTS_425.dat&lt;/code&gt;: è¨èªç¹å¾´éã®min/maxæ­£è¦åã«å¿è¦ãªmin/maxã®ãã¯ãã«ã§ãã&lt;/li&gt;
&lt;li&gt;&lt;code&gt;nn_mgc_lf0_vuv_bap_187/&lt;/code&gt;: mgc, lf0, vuv, bapãçµåããé³é¿ç¹å¾´éã§ããããcmp (composed featureããæ¥ã¦ããã¨æããã) ã¨è¡¨ããããã®ã§ãããã£ã¬ã¯ããªåããã¯å¤å¥ãä»ãã¾ããããç¡é³åºéã¯åé¤ããã¦ãã¾ããããããã&lt;/li&gt;
&lt;li&gt;&lt;code&gt;nn_no_silence_lab_425/&lt;/code&gt;: &lt;code&gt;binary_label_425&lt;/code&gt; ã®è¨èªç¹å¾´éããç¡é³åºéãåé¤ãããã®ã§ã&lt;/li&gt;
&lt;li&gt;&lt;code&gt;nn_no_silence_lab_norm_425/&lt;/code&gt;: ãããããã«min/maxæ­£è¦åãããã®ã§ã&lt;/li&gt;
&lt;li&gt;&lt;code&gt;nn_norm_mgc_lf0_vuv_bap_187/&lt;/code&gt;: &lt;code&gt;nn_mgc_lf0_vuv_bap_187/&lt;/code&gt;ã®é³é¿ç¹å¾´éãN(0, 1)ã«ãªãããã«mean/varianceæ­£è¦åãããã®ã§ã&lt;/li&gt;
&lt;li&gt;&lt;code&gt;norm_info_mgc_lf0_vuv_bap_187_MVN.dat&lt;/code&gt;: é³é¿ç¹å¾´éã®æ­£è¦åã«å¿è¦ãªãå¹³åã¨æ¨æºåå·®ã§ã&lt;/li&gt;
&lt;li&gt;&lt;code&gt;var/&lt;/code&gt;: mgc, lf0, bap, vuvããããã®åæ£ã§ãããã®ãã¡vuvã¯ããã©ã¡ã¼ã¿çææã«MLPGãè¡ãã¾ããããä¿å­ã¯ããã¦ãã¾ãã&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;å¥ååºå-1&#34;&gt;å¥å/åºå&lt;/h4&gt;
&lt;p&gt;ç¶ç¶é·ã¢ãã«ã®å ´åã¨åæ§ã®ä¸­éç¹å¾´éãåºåããã¦ãã¾ããæ¹ãã¦æ´çããã¨ãé³é¿ã¢ãã«ã®å­¦ç¿ã«ä½¿ç¨ããå¥åã¨åºåã¯ãä»¥ä¸ã®ã¨ããã§ãã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;å¥å: &lt;code&gt;nn_no_silence_lab_norm_425/&lt;/code&gt;, ä¸çºè©±ãããã®ç¹å¾´éã®shape: &lt;code&gt;(T, 425)&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;åºå: &lt;code&gt;nn_norm_mgc_lf0_vuv_bap_187&lt;/code&gt;, ä¸çºè©±ãããã®ç¹å¾´éã®shape: &lt;code&gt;(T, 187)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;å­¦ç¿ãããã¢ãã«ã¯ã &lt;code&gt;nnets_model&lt;/code&gt;ã¨ãããã©ã«ãã«ä¿å­ããã¾ãã&lt;/p&gt;
&lt;h3 id=&#34;æ³¢å½¢çæ&#34;&gt;æ³¢å½¢çæ&lt;/h3&gt;
&lt;p&gt;å¾ãããç¶ç¶é·ã¢ãã«ã¨é³é¿ã¢ãã«ãããæ³¢å½¢ãçæããå¦çã¯ãå¤§éæã«ãã£ã¦ä»¥ä¸ã®æé ã§è¡ããã¾ãã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ãã«ã³ã³ãã­ã¹ãã©ãã«ããå¾ãããè¨èªç¹å¾´éãåã«ãç¶ç¶é·ã¢ãã«ãä½¿ã£ã¦ç¶ç¶é·ãäºæ¸¬ãã&lt;/li&gt;
&lt;li&gt;äºæ¸¬ãããç¶ç¶é·ãä½¿ã£ã¦ããã«ã³ã³ãã­ã¹ãã©ãã«ãæ¸ãæãããããå·ä½çã«ã¯ãç¶ææ¯ã® start_time, end_time ã®é¨åãæ¸ãæããã&lt;/li&gt;
&lt;li&gt;æ¸ãæãããããã«ã³ã³ãã­ã¹ãã©ãã«ãããé³é¿ã¢ãã«ç¨ã®ãã¬ã¼ã ã¬ãã«ã®è¨èªç¹å¾´éãè¨ç®ããé³é¿ã¢ãã«ãä½¿ã£ã¦é³é¿ç¹å¾´éãäºæ¸¬ãã&lt;/li&gt;
&lt;li&gt;äºæ¸¬ãããé³é¿ç¹å¾´éï¼static + delta + delta-delta) ãããéçç¹å¾´éãMLPGã«ãã£ã¦çæãããMLPGã«ãã£ã¦çæããã®ã¯ãmgc, lf0, bapã®ã¿ã§ãvuvã«ã¤ãã¦ã¯ãã®ã¾ã¾ä½¿ããæ³¢å½¢åæã«ã¯vuvãç´æ¥ä½¿ãã®ã§ã¯ãªããvuv &amp;lt; 0.5ä»¥ä¸ã®f0ã0ã¨ãã¦æ±ãã&lt;/li&gt;
&lt;li&gt;çæãããã¡ã«ã±ãã¹ãã©ã ã«å¯¾ãã¦ãMerlinãæè£½ãã¹ããã£ã«ã¿ãæãã&lt;/li&gt;
&lt;li&gt;å¾ãããé³é¿ç¹å¾´é (mgc, f0, bap) ãããWORLDãä½¿ã£ã¦æ³¢å½¢åæããã&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ä»¥ä¸ã§ããMerlinã®è¯ãæã®ä¸ã¤ã«ãã­ã°ãããããã¯ãã¦ãããã¨ããã®ãããã¾ãããããããã®ãã¡ãã¹ããã£ã«ã¿ï¼ããã©ã«ãã§ONã§ãï¼ã«é¢ãã¦ã¯ä¸åï¼ããã©ã«ãã§ã¯ï¼ã­ã°ãã¯ããããæ°ã¥ãã®ã«æéããããã¾ããã&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;ã¾ããåäººçãªæè¦ã§ããããã®ãã¹ããã£ã«ã¿ã®å½±é¿ã¯çµ¶å¤§ã«æãã¾ãããã³ã¼ããè¦ã¦ãä½ããã¦ããã®ãåã«ã¯çè§£ã§ãã¾ããã§ãããããã¥ã¼ãªã¹ãã£ãã¯ãªæ¹æ³ãå«ãã§ããããã«æãã¾ãããèå³ã®ããæ¹ã¯ã æ³¢å½¢åæç¨ã®confãã¡ã¤ã«ãéãã¦ã&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[Waveform]
do_post_filtering: False
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;ã®ããã«ã&lt;code&gt;[Waveform]&lt;/code&gt; ã»ã¯ã·ã§ã³ã« &lt;code&gt;do_post_filtering&lt;/code&gt; ã¨ããé ç®ãå ãã¦ãçæçµæãè´ãæ¯ã¹ã¦ã¿ããã¨ããããããã¾ãããã¹ããã£ã«ã¿ã«ãã£ã¦åçã«é³è³ªãæ¹åããã¦ããã®ããããã¨æãã¾ããããã«èå³ã®ããæ¹ã¯ãã³ã¼ããèª­ãã§ã¿ã¦ãã ãããåèæç®ãæ¢ãã¾ããããåã«ã¯è¦ã¤ããã¾ããã§ããããå­ç¥ã®æ¹ãããã°æãã¦ããã ãããã§ãã&lt;/p&gt;
&lt;h2 id=&#34;ãããã«&#34;&gt;ãããã«&lt;/h2&gt;
&lt;p&gt;Merlinãæåã¯ä½¿ãã«ãããªã¨æã£ã¦ãã¾ããããé å¼µã£ã¦èª­ãã§ã¿ãã°ãã¨ã¦ãåå¼·ã«ãªãã¾ããï¼ä½¿ããããã¨ã¯è¨ã£ã¦ããªãï¼ãå¾åã¯ã ãã¦ãé©å½ãªã¾ã¨ãã«ãªã£ã¦ãã¾ã£ãããããã¾ãããããã¾ãããããããã®ä¸æºãã&lt;a href=&#34;https://github.com/r9y9/nnmnkwii&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;æ°ãããã¼ã«&lt;/a&gt;ãä½ãã¾ããããããã¯ã¾ãå¥ã®æ©ä¼ã«ç´¹ä»ãããã¨æãã¾ãããããã¨ããããã¾ããã&lt;/p&gt;
&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;&lt;a href=&#34;http://jrmeyer.github.io/merlin/2017/02/14/Installing-Merlin.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://jrmeyer.github.io/merlin/2017/02/14/Installing-Merlin.html&lt;/a&gt; ã«ããã°ãThis is a very clearly written Python script ã ããã§ãâ¦ãåã«èª­è§£åããªãã ãã®å¯è½æ§ãããã¾ã&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34;&gt;
&lt;p&gt;èªåã§ä½ã£ãã¢ãã«ããã©ããã¦ãmerlinã«åã¦ãªãããªãã ãã¨æ©ãã§ããã¨ããMerlinã«è¨åãã¦ããè«æã®ä¸ã¤ã«ããã¹ããã£ã«ã¿ãä½¿ã£ã¦ããã¨ã®è¨è¿°ããããæ¢ã£ã¦ã¿ãã¨ãããã«ãã£ããã¨ããæãã§ããã&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>è¨èªå¦ç100æ¬ããã¯ 2015 ããã¹ã¦ããã¾ãã</title>
      <link>https://r9y9.github.io/blog/2017/06/09/nlp100/</link>
      <pubDate>Fri, 09 Jun 2017 21:58:50 +0900</pubDate>
      <guid>https://r9y9.github.io/blog/2017/06/09/nlp100/</guid>
      <description>&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/images/nlp100_summary.png&#34; /&gt;&lt;/div&gt;
&lt;ul&gt;
&lt;li&gt;æ¬å®¶ãµã¤ã: &lt;a href=&#34;http://www.cl.ecei.tohoku.ac.jp/nlp100/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://www.cl.ecei.tohoku.ac.jp/nlp100/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;åãæ¸ããã³ã¼ã: &lt;a href=&#34;https://github.com/r9y9/nlp100&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/r9y9/nlp100&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;æè¿ãèªç¶è¨èªå¦ç(NLP)ãåå¼·ãããã¨ããç±ãåºã¾ãããããèªç¶è¨èªå¦çã®åé¡ãè§£ãããã£ãã®ã§ããã
ç¡ç¥ã®ããã«ãç´æãã¾ã£ããåãããããã¯ã¾ããã¨æããã®ã§ã
å¥éçãªã®ã«æãåºããã¨æã£ãæ¬¡ç¬¬ã§ãã
çµæãæ¯æ¥ããã¤ã¥ãã¦ã12æ¥ãããã¾ããï¼ä¸å³ã¯ãæ¨ªè»¸ãæ¥ä»ãç¸¦è»¸ãéæããåé¡æ°ã§ããå³ã¯&lt;a href=&#34;https://github.com/r9y9/nlp100/blob/master/summary.py&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;seabornã§é©å½ã«ä½ãã¾ãã&lt;/a&gt;ï¼ã
éåº¦éè¦&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;ã§åé¡ãè§£ãã¾ããããæã£ããããã¾ãé²ã¾ãå¤§å¤ã ã£ããã¨ããã®ãæ­£ç´ãªææ³ã§ããä»¥ä¸ãéå¤ãªææ³ã§ãã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;mecab, cabocha, CoreNLPã®è§£æçµæããã¼ã¹ããã³ã¼ããæ¸ãã®ã¯ããã ãã é¢åã«æãã&lt;/li&gt;
&lt;li&gt;NERå®è£ãããã¿ãããªåé¡ããã£ããããæ¥½ããã£ãããªã¨æã£ã&lt;/li&gt;
&lt;li&gt;æ­£è¦è¡¨ç¾ãã¾ã£ããä½¿ãããªãã¦ããªãã£ããã¨ãããã£ãã®ã§ãåå¼·ãç´ãã¦ããã£ã&lt;/li&gt;
&lt;li&gt;å¨ä½ãéãã¦ãç¬¬9ç« ã®word embeddingãèªåã§ä½ãé¨åãä¸çªæ¥½ããã£ã&lt;/li&gt;
&lt;li&gt;ããè¦ãã§ãã&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;ãåé¡æä¸­ã«è¡¨ç¾ãæ­£ç¢ºã§ãªãï¼ã¨æããï¼é¨åããã£ã¦ãå°æãããã¨ããã£ã&lt;/li&gt;
&lt;li&gt;9å²pythonã1å²juliaã§æ¸ãã¾ããããsklearn, numpy, scipyãªã©ãä½¿ããªãã¦ããããã¤éåº¦ãéè¦ãªå ´åã¯ãç°¡åã«éãã§ããã®ã§juliaè¯ã&lt;/li&gt;
&lt;li&gt;pythonãã©ã¤ãã©ãªãåå®ãããã¦ãã¦æ¬å½ã«æ¥½&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://qiita.com/segavvy/items/fb50ba8097d59475f760&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;ç´ äººã®è¨èªå¦ç100æ¬ããã¯:ã¾ã¨ã - Qiita&lt;/a&gt; ãã¨ã¦ãä¸å¯§ã§ãè§£ããã¯ãããã®ã®èªä¿¡ããªãã¨ããªã©ã«ãã¡ããã¡ããè¦ã¦ãã¾ãããåèã«ãªãã¾ãã&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;ä»å¾&#34;&gt;ä»å¾&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://www.amazon.co.jp/dp/4061529242&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;æ·±å±¤å­¦ç¿ã«ããèªç¶è¨èªå¦ç&lt;/a&gt;ãè²·ã£ãã®ã§&lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;ããããèª­ãã§ãèªç¶è¨èªå¦çã®åå¼·ãç¶ãããã¨æãã¾ãã&lt;/p&gt;
&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;ãã¤ã¼ããªå®è£å¤ããã³ããå¤ããdescriptiveã§ãªãå¤æ°åå¤ããç­&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34;&gt;
&lt;p&gt;æãè¿ãã¦æ¢ãæ°åããªãã»ã»ã»&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34;&gt;
&lt;p&gt;Amazonã«ããã¨ãåã¯5/29ã«è²·ã£ã¦ããæ¨¡æ§ããªãç¾å¨ã®é²æã¯0&amp;#160;&lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>pysptk: SPTKã®pythonã©ããã¼ãä½ã£ã (part 2)</title>
      <link>https://r9y9.github.io/blog/2015/09/06/pysptk/</link>
      <pubDate>Sun, 06 Sep 2015 00:00:00 +0000</pubDate>
      <guid>https://r9y9.github.io/blog/2015/09/06/pysptk/</guid>
      <description>&lt;p&gt;2015/09/05:&lt;/p&gt;
&lt;div align=&#34;center&#34;&gt;
&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;&lt;a href=&#34;https://t.co/WFBmYEIVce&#34;&gt;https://t.co/WFBmYEIVce&lt;/a&gt; SPTKã®pythonã©ããã¼ï¼ãã·ãªãã¤ï¼å®æ&lt;br&gt;ãã­ã¥ã¡ã³ã &lt;a href=&#34;http://t.co/jYhw1y3Bzg&#34;&gt;http://t.co/jYhw1y3Bzg&lt;/a&gt;&lt;br&gt;pip install pysptk ã§ã¤ã³ã¹ãã¼ã«ã§ããããã«ãªãã¾ãããpypiç«¥è²æ¨ã¦ãã&lt;/p&gt;&amp;mdash; å±±æ¬ é¾ä¸ / Ryuichi Yamamoto (@r9y9) &lt;a href=&#34;https://twitter.com/r9y9/status/639848868075560960?ref_src=twsrc%5Etfw&#34;&gt;September 4, 2015&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;/div&gt;
&lt;p&gt;ããã¶ãåã«ãswigéã³ãããã¦ãpythonã®ã©ããã¼ãæ¸ãã¦ãããã§ãããcythonãä½¿ã£ã¦æ°ããä½ããªããã¾ãããããªããã¯ã¼ã¢ãããã¾ããã&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;pip install pysptk
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;ã§ã¤ã³ã¹ãã¼ã«ã§ããã®ã§ããããããã°ã©ãã&lt;/p&gt;
&lt;h2 id=&#34;ãªãä½ã£ãã®ã&#34;&gt;ãªãä½ã£ãã®ã&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;cythonã¨sphinxã§éãã§ããã§ãã&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;ä½¿ãæ¹&#34;&gt;ä½¿ãæ¹&lt;/h2&gt;
&lt;p&gt;ä»¥ä¸ã®ãã¢ãåèã«ã©ãã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://nbviewer.ipython.org/github/r9y9/pysptk/blob/51c103e5a7e9746c96cd78043df4e48fe2d6a3a8/examples/pysptk%20introduction.ipynb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Introduction to pysptk&lt;/a&gt;: ã¡ã«ä¸è¬åã±ãã¹ãã©ã åæã¨ã&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://nbviewer.ipython.org/github/r9y9/pysptk/blob/51c103e5a7e9746c96cd78043df4e48fe2d6a3a8/examples/Speech%20analysis%20and%20re-synthesis.ipynb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Speech analysis and re-synthesis&lt;/a&gt;: é³å£°ã®åæã»ååæã®ãã¢ãåæé³å£°ã¯notebookä¸ã§åçã§ãã¾ã&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;ãã­ã¥ã¡ã³ã&#34;&gt;ãã­ã¥ã¡ã³ã&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;http://pysptk.readthedocs.org&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;http://pysptk.readthedocs.org&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;ã¼ãã&#34;&gt;ã¼ãã&lt;/h2&gt;
&lt;p&gt;SPTKã®é¢æ°ãå¤ãªå¤å¥ããã¨exitãããã»ã°ãã©ã£ããããã®ã§ãã¡ããã¨ãã¹ãæ¸ãã¦ã»ãããªã&lt;/p&gt;
&lt;h2 id=&#34;é¢é£&#34;&gt;é¢é£&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://r9y9.github.io/blog/2014/08/10/sptk-from-python/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SPTKã®Pythonã©ããã¼ãæ¸ãã - LESS IS MORE&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>SPTKã®Pythonã©ããã¼ãæ¸ãã</title>
      <link>https://r9y9.github.io/blog/2014/08/10/sptk-from-python/</link>
      <pubDate>Sun, 10 Aug 2014 00:00:00 +0000</pubDate>
      <guid>https://r9y9.github.io/blog/2014/08/10/sptk-from-python/</guid>
      <description>&lt;h2 id=&#34;20150906-è¿½è¨&#34;&gt;2015/09/06 è¿½è¨&lt;/h2&gt;
&lt;p&gt;ã¾ããªpythonã©ããã¼ãæ°ããä½ãã¾ãã: &lt;a href=&#34;https://r9y9.github.io/blog/2015/09/06/pysptk/&#34;&gt;Pysptk: SPTKã®pythonã©ããã¼ãä½ã£ã (Part 2)&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;20140810-è¿½è¨&#34;&gt;2014/08/10 è¿½è¨&lt;/h2&gt;
&lt;p&gt;ipython notebookã«ããç°¡åãªãã¥ã¼ããªã¢ã«ãè²¼ã£ã¦ããã¾ã&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://nbviewer.ipython.org/github/r9y9/SPTK/blob/master/notebook/SPTK%20calling%20from%20python.ipynb&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;SPTK ã Pythonããå¼ã¶ | nbviewer&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;20141109&#34;&gt;2014/11/09&lt;/h2&gt;
&lt;p&gt;ã¿ã¤ãä¿®æ­£ãã¾ããâ¦&lt;/p&gt;
&lt;p&gt;scipy.mixture -&amp;gt; sklearn.mixture&lt;/p&gt;
&lt;p&gt;SPTKã®ä¸­ã§æãä¾¡å¤ãããï¼ã¨åãæã£ã¦ããï¼ã¡ã«ã±ãã¹ãã©ã åæãã¡ã«ã±ãã¹ãã©ã ããã®æ³¢å½¢åæï¼MLSA filterï¼ãpythonããå¯è½ã«ãªãã¾ãã&lt;/p&gt;
&lt;p&gt;ãèªç±ã«ã©ãã&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/r9y9/SPTK&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Speech Signal Processing Toolkit (SPTK) for API use with python | Github&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;æ³¨æã§ããã&lt;code&gt;SPTK.h&lt;/code&gt;ã«ããé¢æ°ãå¨é¨ã©ãããã¦ããããã§ã¯ãªãã§ããåãå¿è¦ãªãã®ãããç¾ç¶ã¯ã©ãããã¦ãã¾ããï¼ä¾ãã°ãGMMã¨ãã©ããããå¿è¦ãªãã§ããã­ï¼sklearn.mixtureä½¿ãã°ãããï¼ããã ãå¤§æ¹æç¨ãªãã®ã¯ã©ããããã¨æãã¾ãã&lt;/p&gt;
&lt;h2 id=&#34;åè&#34;&gt;åè&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://r9y9.github.io/blog/2014/02/10/sptk-go-wrapper/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Goã§é³å£°ä¿¡å·å¦çããããã®ã§SPTKã®Goã©ããã¼ãæ¸ã - LESS IS MORE&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Goã§ãæ¸ããã®ã«Pythonã§ãæ¸ãã¦ãã¾ã£ãã&lt;/p&gt;
&lt;p&gt;ä¸å¹´ãããåã«åæå°æå¡ã®åçã¨ãPythonããä½¿ãããããã§ããã­ãã¨è©±ããã¦ãã¾ãããåçãããããæ¸ãã¾ããã&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Tokyo.Scipyã«åå ãã¦ãã</title>
      <link>https://r9y9.github.io/blog/2014/08/05/tokyo-scipy/</link>
      <pubDate>Tue, 05 Aug 2014 00:00:00 +0000</pubDate>
      <guid>https://r9y9.github.io/blog/2014/08/05/tokyo-scipy/</guid>
      <description>&lt;h2 id=&#34;tokyoscipyhttpsgithubcomtokyo-scipyarchive&#34;&gt;&lt;a href=&#34;https://github.com/tokyo-scipy/archive&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Tokyo.SciPy&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;ããã·ã¥ã¿ã°: &lt;a href=&#34;https://twitter.com/search?q=%23tokyoscipy&amp;amp;src=tyah&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;#tokyoscipy&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Tokyo.Scipy ã¯ç§å­¦æè¡è¨ç®ã§ Python ãå©ç¨ããããã®åå¼·ä¼ã§ãï¼&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;ã¨ã®ãã¨ã§ããæè¿ãpython/numpy/scipyã«ãããä¸è©±ã«ãªã£ã¦ããã®ã§ãåå ãã¦ã¿ã¾ãããéæãã¡ã¢ãã¦ããã¾ãã&lt;/p&gt;
&lt;h2 id=&#34;tokyoscipy-006httpsgithubcomtokyo-scipyarchivetreemaster006&#34;&gt;&lt;a href=&#34;https://github.com/tokyo-scipy/archive/tree/master/006&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Tokyo.Scipy 006&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;ç¬¬6åã®ããã§ããããã­ã°ã©ã ã ããã£ã¨ã¾ã¨ããã¨ã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ããããå¤§è¦æ¨¡Pythonä¸¦å/ãã¤ãã©ã¤ã³å¦çå¥é w/o MapReduceã¬ã¸ã¼ã  (æééå¤ª @yutakashino) 45å&lt;/li&gt;
&lt;li&gt;åå¿èãé¥ãNåã®ç½ ãããé²ãNumpy/Scipyã®é (@nezuq) 15å&lt;/li&gt;
&lt;li&gt;Making computations reproducible (@fuzzysphere) 30å&lt;/li&gt;
&lt;li&gt;IPython Notebookã§å§ãããã¼ã¿åæã¨å¯è¦å (æä¸æ© @lucidfrontier45) 30å&lt;/li&gt;
&lt;li&gt;PyMCãããã°ï¼ãã¤ãºæ¨å®ã§ããæ³£ããããªããããªã (ç¥å¶æå¼ @shima__shima) 45å&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ã¨ããæããåçã«ã¯ã@shima__shima åçã®çºè¡¨ãç®å½ã¦ã ã£ã&lt;/p&gt;
&lt;h2 id=&#34;éæ&#34;&gt;éæ&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;ä»åï¼ï¼ï¼ã¯scipyã®è©±ã¯ã»ã¨ãã©ãªãã£ããpythonãä½¿ã£ãç§å­¦æè¡è¨ç®ã«é¢ããå¹åºããããã¯ãæ±ã£ã¦ãå°è±¡ã&lt;/li&gt;
&lt;li&gt;ipython ã¯ãã£ã±ä¾¿å©ã§ãã­ãåãè¯ãä½¿ãã¾ã&lt;/li&gt;
&lt;li&gt;@shima__shima åçã®çºè¡¨ãã¨ã¦ãããããããã£ãã®ã§ãæ¬å½ã«åèã«ããã&lt;/li&gt;
&lt;li&gt;æ­£ç´ãã£ã¨ã³ã¢ãªè©±ããã£ã¦ããã®ã§ã¯ãã¨æã£ã&lt;/li&gt;
&lt;li&gt;æè¦ªä¼ã§æ°ã¥ããããæå¤ã¨é³å£°ä¿¡å·å¦çãã£ã¦ãï¼ãï¼äººããã¦ã³ã£ãããã&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/scikit-learn/scikit-learn&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;scikit-learn&lt;/a&gt; ãåæã®é ã«ä½ããã¦ãæ¹ &lt;a href=&#34;https://twitter.com/cournape&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;@cournape&lt;/a&gt; ããã¦ã³ã£ãããéçºå½åã¯GMMã¨SVMããããããªãã¦å¨ç¶ã¦ã¼ã¶ã¼ãã¤ããªãã£ããªã©ãªã©ãè£è©±ãè²ãèãã&lt;/li&gt;
&lt;li&gt;ãã©ã³ã¹äººã®ããã¶ãå¤§ä¸å¤«ãã¯çµ¶å¯¾ç¡çã®æï¼ããã&lt;/li&gt;
&lt;li&gt;Rust, juliaãããã¨æãã¦ããã£ãããã¡juliaã¯ä»ãã£ã¦ã¿ã¦ãããªããªããã&lt;/li&gt;
&lt;li&gt;çºè¡¨ã§ãè©±é¡ã«ä¸ãã£ããã©ãPandasãããã¨ããè©±ãèããã®ã§ãè©¦ãã¦ã¿ãã&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;éå¶ã®æ¹ããçºè¡¨ãããæ¹ãããããã¨ããããã¾ãããåãæ©ä¼ãåãã°ä½ãçºè¡¨ããã&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Goã§ãã¥ã¼ã©ã«ãããããã¤ãæ¸ãããã©ãã£ã±Pythonãæ¥½ã§ããã§ãã­</title>
      <link>https://r9y9.github.io/blog/2014/07/29/neural-networks-in-go-and-python/</link>
      <pubDate>Tue, 29 Jul 2014 00:00:00 +0000</pubDate>
      <guid>https://r9y9.github.io/blog/2014/07/29/neural-networks-in-go-and-python/</guid>
      <description>&lt;p&gt;ãã¾ãã¡ææåºãªãã®ã§æ°åè»¢æã«ãã­ã°ãã ãã ãæ¸ãã¦ã¿ããã¹ãã§ãã&lt;/p&gt;
&lt;h2 id=&#34;ã¾ããã&#34;&gt;ã¾ããã&lt;/h2&gt;
&lt;p&gt;åå¹´ãããåã«ãææ·±å±¤å­¦ç¿ã«èå³ãæã£ã¦ãã£ã¦ã¿ããããªã¼ã¨æã£ã¦ããææããã£ã¦ããã®æã«Goã§ããã¤ããã¥ã¼ã©ã«ããããæ¸ãã¾ããï¼åèï¼&lt;a href=&#34;http://r9y9.github.io/blog/2014/03/06/restricted-boltzmann-machines-mnist/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Restricted Boltzmann Machines with MNIST - LESS IS MORE&lt;/a&gt;ã&lt;a href=&#34;https://github.com/r9y9/nnet&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;githubã«ä¸ããã³ã¼ã&lt;/a&gt;ï¼ããªãGoã ã£ããã¨ããã¨ãåãGoã«èå³ãæã¡å§ãã¦ããããã¨ããã®ãå¤§ããã§ããGoãç¥ãåã¯ãããããè¨ç®ãããããªã³ã¼ããæ¸ãã¨ãã¯C++ã ã£ãããã©ãC++ã¯è²ãã¤ãããã®ãããããGoã¯C++ã«ã¯éåº¦é¢ã§å£ããã®ã®ããããéãããã¤ã¹ã¯ãªããçãªæ¸ãããããããã¾ããC++ã®ãããã°ãã¡ã³ãã«è²»ããè¨å¤§ãªæéã«æ¯ã¹ãã°ãè¨ç®æéã1.5~2åã«å¢ãããããæ°ã«ããªãã¨ããã¹ã¿ã³ã¹ã§ãåã¯C++ã®ãããGoãä½¿ããã¨ãã¦ãã¾ããï¼â»ä»ã§ãééã£ã¦ããã¨ã¯æãã¾ããããã¨ã¯ãããå³ããããã©ã¼ãã³ã¹ãæ±ããããå ´åãæ¢å­ã®è³ç£ãæå¹æ´»ç¨ãããå ´åãªã©ãå¿è¦ãªå ´é¢ã§ã¯C++ãæ¸ãã¦ãã¾ãï¼ã&lt;/p&gt;
&lt;h2 id=&#34;goã§æ©æ¢°å­¦ç¿&#34;&gt;Goã§æ©æ¢°å­¦ç¿&lt;/h2&gt;
&lt;p&gt;åã¯æ©æ¢°å­¦ç¿ããã£ããå¥½ããªã®ã§ãGoã§ã³ã¼ãæ¸ããã¼ã¨æã£ã¦ããã®ã§ãããçµæã¨ãã¦ã¾ã£ããæãã¾ããã§ããããã¥ã¼ã©ã«ããããã¦ãã¨ã¼ã«æ¸ãããããã§ãã&lt;/p&gt;
&lt;p&gt;æ¤ç´¢ããã¨ãããã¾ãããç¾ç¶ãä»ã®ä¸»æµãªè¨èªã«æ¯ã¹ã¦å§åçã«æ°å¤è¨ç®ã®ã©ã¤ãã©ãªãå°ãªãã§ããç¹ã«ãç·å½¢ä»£æ°ãè¡åæ¼ç®ã®ããã¡ã¯ãçãªã©ã¤ãã©ãªããªãã®ã¯ã¤ããã§ããããã¤ãä»£è¡¨çãªãã®ãããã¾ãã&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/skelterjohn/go.matrix&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;skelterjohn/go.matrix&lt;/a&gt; - ããã¾ã£ããã¡ã³ãããã¦ããªããããã¶ãããã¤ããã¯ãªãã¨æãã¾ããä½¿ãåæã¯ãåã«ã¨ã£ã¦ã¯ãããªã«æªããªãã£ãï¼è©¦ãã«&lt;a href=&#34;https://gist.github.com/r9y9/9030922&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;NMF&lt;/a&gt;ãæ¸ãã¦ã¿ãï¼ã§ãããå®è£ã¯ç´ç²ãªGoã§æ¸ããã¦ãã¦ãGPUãä½¿ã£ã¦è¨ç®ããã®ãæµè¡ããªæä»£ã§ã¯ãä¾ãã°å¤§ããªãã¥ã¼ã©ã«ãããããã©ã¡ã¼ã¿ãå¤ããªããä½åº¦ãå­¦ç¿ããã®ã«ã¯ããã©ãã¨æãã¾ããã&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/gonum/matrix&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;gonum/matrix&lt;/a&gt; - æ¯è¼çæè¿åºã¦ããã©ã¤ãã©ãªã§ã&lt;a href=&#34;https://code.google.com/p/biogo/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;biogo&lt;/a&gt; ããè¡åæ¼ç®ã«é¢ããé¨åãåãåºãã¦ä½ããããã®ã®ããã§ããè¡åæ¼ç®ã®åé¨ã§blasãä½¿ã£ã¦ãã¦ããã¤å°æ¥çã«ã¯cublasã«ãå¯¾å¿ããããã¿ãããªæç¨¿ãGoogle Groupsã§è¦ãã®ããã£ã¦ãåå¹´ãããåã«ã¯goã§è¡åæ¼ç®ãè¡ããªããã®ã©ã¤ãã©ãªãä½¿ãã¹ãã ã¨å¤æ­ãã¾ããï¼ä»¥åãã£ããèª¿ã¹ã¾ããï¼&lt;a href=&#34;http://qiita.com/r9y9/items/7f93a89e3a88bb4ed263&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;gonum/matrix ã®ãã¶ã¤ã³ã³ã³ã»ããã«é¢ããã¡ã¢ - Qiita&lt;/a&gt;ï¼ãããããããã»ã©é »ç¹ã«ã¢ãããã¼ãããã¦ãã¾ããããæ©è½ãã¾ã å°ãªãã§ãã&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;èªåã§ä½ããã¼ãã¨ããèããçã¾ããªãã£ããã¨ã¯ãªãã§ãããç«¯çã«è¨ãã°ãããè¡ãã ãã®ããæ°ãããã¾ããã§ãããã¾ãæ¬å½ã«å¿è¦ã ã£ããå¤å°é£ããã¦ãããã®ã§ãããã»ããåéã«ã¯pythonããããããªãã§ããâ¦&lt;/p&gt;
&lt;h2 id=&#34;pythonã§æ©æ¢°å­¦ç¿&#34;&gt;Pythonã§æ©æ¢°å­¦ç¿&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://www.google.co.jp/search?q=python&amp;#43;%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92&amp;amp;oq=python&amp;#43;%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;python æ©æ¢°å­¦ç¿ - Google æ¤ç´¢&lt;/a&gt; ç´ 119,000 ä»¶ï¼2014/07/29ç¾å¨ï¼&lt;/p&gt;
&lt;p&gt;ããã¿ããªãã£ã¦ã¾ããã­ã&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.google.co.jp/search?q=Golang&amp;#43;%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92&amp;amp;oq=Golang&amp;#43;%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Golang æ©æ¢°å­¦ç¿ - Google æ¤ç´¢&lt;/a&gt; ç´ 9,130 ä»¶ï¼2014/07/29ç¾å¨ï¼&lt;/p&gt;
&lt;p&gt;ãã¤ãpythonã®ããã«å¢ãããã§ãããããæ­£ç´ã«è¨ã£ã¦ããããã¾ããï¼æ­£ç¢ºã«ã¯ãããã¾èãã¦ãã¾ããããããªããï¼&lt;/p&gt;
&lt;p&gt;ãã¦ãåãããpythonä½¿ãã¾ããæ©æ¢°å­¦ç¿ã®ã³ã¼ããæ¸ãã¨ãã¯ãã ãããpythonãä½¿ãããã«ãªãã¾ããï¼æã¯C++ã§æ¸ãã¦ãã¾ããï¼ããªããã£ã¦ãnumpy, scipyã®ãããã§ãã¨ã¦ãç°¡æ½ã«ããã¤ä¸æãæ¸ãã°ããããéãæ¸ããããã§ããå ãã¦ãã©ã¤ãã©ãªãã¨ã¦ãè±å¯ãªãã§ããã­ãæ©æ¢°å­¦ç¿ã«ããããããnumpy, scipyã«å ãã¦ãmatplotlibã¨ããåªç§ãªæç»ã©ã¤ãã©ãªãããã®ããåãpythonãä½¿ãå¤§ããªçç±ã«ãªã£ã¦ãã¾ãã&lt;/p&gt;
&lt;p&gt;pythonã®æ©æ¢°å­¦ç¿ã©ã¤ãã©ãªã¯ã&lt;a href=&#34;http://scikit-learn.org/stable/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;scikit-learn&lt;/a&gt; ãç¹ã«æåã§ãããããåãã¡ããã¡ããä½¿ãã¾ããä½¿ã£ã¦ãã¦æè¿ãã©ãããã®ã¯ãscipy.mixtureã«ã¯éå¸¸ã®GMMã ãã§ãªãå¤åGMMãç¡éæ··åGMMãå¥ã£ã¦ãããã¨ã§ããã­ãèªåã§å®è£ãããã¨ãããããã¶ãã¨ã¦ãå¤§å¤ã§ããæå¤åGMMã®æ´æ°å¼ãå°åºãããã¨ãããã¾ãããä½åº¦ãå¿ãæãããã«ãªãã¾ãããããã¼ãããæä»£ã«ãªã£ãããã§ããâ¦ï¼é ãç®&lt;/p&gt;
&lt;h2 id=&#34;pythonã§ãã¥ã¼ã©ã«ãããpylearn2ãä½¿ãã&#34;&gt;Pythonã§ãã¥ã¼ã©ã«ãããï¼pylearn2ãä½¿ããï¼&lt;/h2&gt;
&lt;p&gt;Deepä½ã¨ããå«ãæµè¡ãã®ãã¥ã¼ã©ã«ããããä½¿ããæ©æ¢°å­¦ç¿ã®ã©ã¤ãã©ãªã§ã¯ãåã¯ &lt;a href=&#34;https://github.com/lisa-lab/pylearn2&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;pylearn2&lt;/a&gt; ãããæ°ã ãªã¼ã¨æã£ã¦ãã¾ããçç±ã¯ãé«éãã¤æ¡å¼µæ§ãé«ãããã§ããpylearn2ã¯ãæ°å­¦çãªè¨å·è¡¨ç¾ããGPUã³ã¼ãï¼GPUããªããã°CPUåãã®ã³ã¼ãï¼ãçæããmathã³ã³ãã¤ã© &lt;a href=&#34;https://github.com/Theano/Theano&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Theano&lt;/a&gt; ã§æ¸ããã¦ããããpythonã§ãããªããé«éã§ããã¤æ©æ¢°å­¦ç¿ã«ç½®ãã¦éè¦ãªã³ã³ãã¼ãã³ãã§ãããã¼ã¿ãã¢ãã«ãã¢ã«ã´ãªãºã ãä¸æãåé¢ããã¦è¨­è¨ããã¦ããã®ãããã¨ããããªã¨æãã¾ãï¼å¨é¨ãã£ã¡ãã«æ¸ãã¦ãã¾ãããï¼åã¯ããã§ãããããªããããã¼ã¿ã¯ã¨ãããã¢ãã«ã¨å­¦ç¿ãä¸æãåãåããã®é£ããï¼ãA Machine Learning library based on Theanoã¨ã®ãã¨ã§ãããDeep learningã§æåãª &lt;a href=&#34;http://lisa.iro.umontreal.ca/index_en.html&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;lisa lab&lt;/a&gt; çºã¨ãããã¨ãããããã¥ã¼ã©ã«ãããã®ã©ã¤ãã©ãªã¨ããå°è±¡ãå°ãå¼·ãã§ãã­ã&lt;/p&gt;
&lt;p&gt;ä¸ã¤éè¦ãªãã¨ã¨ãã¦ããã®ã©ã¤ãã©ãªã¯ããªãç ç©¶èåãã§ãããã©ãã¯ããã¯ã¹ã¨ãã¦ä½¿ãã®ã§ã¯ãªããä¸­èº«ãèª­ãã§å¿è¦ã«å¿ãã¦èªåã§æ¡å¼µãæ¸ãããäººã«åãã¦ãããã¨æãã¾ãã&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://arxiv.org/pdf/1308.4214v1.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ian J. Goodfellow, David Warde-Farley, Pascal Lamblin, Vincent Dumoulin, Mehdi Mirza, Razvan Pascanu, James Bergstra, FrÃ©dÃ©ric Bastien, and Yoshua Bengio. âPylearn2: a machine learning research libraryâ. arXiv preprint arXiv:1308.4214&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;âã®è«æã®Introductionã®é¨åã«ããã®æ¨ã¯æè¨ããã¦ãã¾ããã¨ãè«æã®ãªã³ã¯ãè²¼ã£ã¦ããã¦ãªãã§ããã&lt;a href=&#34;http://www-etud.iro.umontreal.ca/~goodfeli/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Ian Goodfellow&lt;/a&gt; ã®ãã¼ã ãã¼ã¸ã«ãã£ã¨ç°¡æ½ã«æ¸ãã¦ããã¾ãããä»¥ä¸ãå¼ç¨ãã¾ãã&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I wrote most of Pylearn2, a python library designed to make machine learning research convenient. Its mission is to provide a toolbox of interchangeable parts that provide a lot of flexibility for setting up machine learning experiments, providing enough extensibility that pretty much any research idea is feasible within the context of the library. This is in contrast to other machine learning libraries such as scikits-learn that are designed to be black boxes that just work. Think of pylearn2 as user friendly for machine learning researchers and scikits-learn as user friendly for developers that want to apply machine learning.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;pylearn2ã§ã¯ãMulti-layer Perceptron (MLP)ãDeep Bolztmann Machines (DBM)ãæ°ãããã®ã§Maxout Networkç­ãæè»½ã«è©¦ããã¨ãã§ãã¾ãï¼ã¾ãããã¦è¨ç®ã¯ãã£ã¡ãæéããããã©ï¼ãåè¿°ã®éãmathã³ã³ãã¤ã©ã® &lt;a href=&#34;https://github.com/Theano/Theano&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Theano&lt;/a&gt; ãä½¿ã£ã¦å®è£ããã¦ããã®ã§ãGPUãããå ´åã¯GPUãä½¿ã£ã¦è¨ç®ãã¦ããã¾ããç°å¢æ§ç¯ã«é¢ãã¦ã¯ãä»ã¯AWSã¨ããä¾¿å©ãªãµã¼ãã¹ãããã®ã§ãGPUãæã£ã¦ããªãã¦ãã¦ã§ãä¸ã§ãããããã¦ãã ãã§ç°¡åã«GPUç°å¢ãæ§ç¯ã§ãã¾ãï¼åèï¼&lt;a href=&#34;http://r9y9.github.io/blog/2014/07/20/pylearn2-on-ec2-g2-2xlarge/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Pylearn2, theanoãEC2 g2.x2large ã§åããæ¹æ³ - LESS IS MORE&lt;/a&gt;ï¼ãæ¬å½ã«ããæä»£ã«ãªã£ããã®ã§ãã­ï¼äºåç®&lt;/p&gt;
&lt;p&gt;pylearn2ãã³ã¼ãããã­ã¥ã¡ã³ããæ´»çºãªgithubã§ã®éçºãè­°è«ãè¦ã¦ãã¦ãç´ æ´ããããªã¼ã¨æãã¾ããï¼ã¾ã ä½¿ãå§ããã°ããã®åã®æè¦ã«ãã¾ãä¿¡ææ§ã¯ãªãã®ã§ããâ¦ï¼ãåããããããæ±ç¨æ§ãæ¡å¼µæ§ã®ããã³ã¼ããæ¸ãããäººçã§ããâ¦ï¼èªåã®æ¸ãããã¥ã¼ã©ã«ãããã®ã³ã¼ããè¦ãªããï¼&lt;/p&gt;
&lt;h2 id=&#34;pylearn2ã¯éãã£ã¦&#34;&gt;Pylearn2ã¯éãã£ã¦ï¼&lt;/h2&gt;
&lt;p&gt;æ¬å½ã«éããæ±ãããªã &lt;a href=&#34;https://code.google.com/p/cuda-convnet2/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;cuda-convnet2&lt;/a&gt; ã &lt;a href=&#34;http://caffe.berkeleyvision.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Cafee&lt;/a&gt;ããããã¯ç´ã§cudaã®APIãã ãªâ¦ã¨è¨ãããã¨ããã§ãããç¢ºãã«pylearn2ã¯ä»ã®æ·±å±¤å­¦ç¿ã®ã©ã¤ãã©ãªã«æ¯ã¹ã¦éãããã§ããæè¿ãConvolutional Neural Network (CNN) ã«é¢ãããã³ããã¼ã¯ãGithubã§å¬éããã¦ãã¾ããã&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/soumith/convnet-benchmarks&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;soumith/convnet-benchmarks&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;ç¾æç¹ã§ã¾ã  work in progressã¨æ¸ãã¦ããã¾ãããåèã«ãªãã¨æãã¾ããåªå£ã®åé¡ã§ã¯ãªããå¿è¦ã«å¿ãã¦ä½¿ãåããã°ããã¨åã¯æã£ã¦ãã¾ãã&lt;/p&gt;
&lt;p&gt;ãã¦ãã¦ãæ¬å½ã¯ããããåãæ¸ããGoã®ãã¥ã¼ã©ã«ãããã®ã³ã¼ããããã«ã¯ã½ãã¨ããè©±ãæ¸ãããã¨æã£ãã®ã§ãããé·ããªã£ãã®ã§ã¾ãä»åº¦ã«ãã¾ãã&lt;/p&gt;
&lt;h2 id=&#34;ã¾ã¨ã&#34;&gt;ã¾ã¨ã&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Goã§ãã¥ã¼ã©ã«ãããã¨ãæ©æ¢°å­¦ç¿ãããã®ã¯ç¾ç¶ããã©ããï¼&lt;a href=&#34;https://github.com/sjwhitworth/golearn&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;golearn&lt;/a&gt;ã¨ããããã©ãã¾ã ã¾ã early stageï¼ããã¨ãªããpythonä½¿ãã®ãç¡é£&lt;/li&gt;
&lt;li&gt;pythonã¯ãã£ã±ãæ¥½ãã©ã¤ãã©ãªè±å¯ã ãããã¥ã¼ã©ã«ããããªãpylearn2ãããããããã ãèªåã§æ¡å¼µã¾ã§æ¸ãããäººåãã§ãã&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;æ£ãpythonãããããã¦ã¾ãããã©ã¡ããã¨ããã°åã¯Goã®æ¹ãå¥½ãã§ããæ©æ¢°å­¦ç¿ã«ã¯ç¾ç¶pythonãä½¿ãã®ãããããããªãããªã¼ã¨æã£ã¦ãGoã§ãã¥ã¼ã©ã«ããããæ¸ãã¦ããæãæãåºããªããã¤ãã¤ãã¨æ¸ãã¦ã¿ã¾ããã&lt;/p&gt;
&lt;p&gt;ãããã&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Pythonã«ãããã¥ã¼ã©ã«ãããã®Toyã³ã¼ã</title>
      <link>https://r9y9.github.io/blog/2014/05/11/python-feed-forward-neural-network-toy-code/</link>
      <pubDate>Sun, 11 May 2014 00:00:00 +0000</pubDate>
      <guid>https://r9y9.github.io/blog/2014/05/11/python-feed-forward-neural-network-toy-code/</guid>
      <description>&lt;p&gt;1000çªçãã ãã©ãç¥ãåãã«ãã¥ã¼ã©ã«ããããæãã¦ãã¦ããã®éç¨ã§æ¸ããã³ã¼ããããããããéè¦ã&lt;/p&gt;
&lt;p&gt;ãã®ããã«ãèª¤å·®ä¼æ­æ³ãnåå°åºãã¾ããï¼æè¨³ï¼ä½åãã¡ã¢ãªããã¾ããï¼&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;#!/usr/bin/python
# coding: utf-8

# ãã¥ã¼ã©ã«ãããã¯ã¼ã¯(Feed-Forward Neural Networks)ã®å­¦ç¿ãèªè­ã®
# ãã¢ã³ã¼ãã§ãã
# èª¤å·®ä¼æ¬æ³ã«ãã£ã¦ãã¥ã¼ã©ã«ããããå­¦ç¿ãã¾ãã
# XORã®å­¦ç¿ããã¹ãã®ç°¡åãªãã¢ã³ã¼ããã¤ãã¦ãã¾ã
# 2014/05/10 Ryuichi Yamamoto

import numpy as np

def sigmoid(x):
    return 1.0 / (1.0 + np.exp(-x))

def dsigmoid(y):
    return y * (1.0 - y)

class NeuralNet:
    def __init__(self, num_input, num_hidden, num_output):
        &amp;quot;&amp;quot;&amp;quot;
        ãã©ã¡ã¼ã¿ã®åæå
        &amp;quot;&amp;quot;&amp;quot;
        # å¥åå±¤ããé ãå±¤ã¸ã®éã¿è¡å
        self.W1 = np.random.uniform(-1.0, 1.0, (num_input, num_hidden))
        self.hidden_bias = np.ones(num_hidden, dtype=float)
        # é ãå±¤ããåºåå±¤ã¸ã®éã¿è¡å
        self.W2 = np.random.uniform(-1.0, 1.0, (num_hidden, num_output))
        self.output_bias = np.ones(num_output, dtype=float)

    def forward(self, x):
        &amp;quot;&amp;quot;&amp;quot;
        ååãä¼æ¬ã®è¨ç®
        &amp;quot;&amp;quot;&amp;quot;
        h = sigmoid(np.dot(self.W1.T, x) + self.hidden_bias)
        return sigmoid(np.dot(self.W2.T, h) + self.output_bias)

    def cost(self, data, target):
        &amp;quot;&amp;quot;&amp;quot;
        æå°åãããèª¤å·®é¢æ°
        &amp;quot;&amp;quot;&amp;quot;
        N = data.shape[0]
        E = 0.0
        for i in range(N):
            y, t = self.forward(data[i]), target[i]
            E += np.sum((y - t) * (y - t))
        return 0.5 * E / float(N)

    def train(self, data, target, epoches=30000, learning_rate=0.1,\
              monitor_period=None):
        &amp;quot;&amp;quot;&amp;quot;
        Stochastic Gradient Decent (SGD) ã«ããå­¦ç¿
        &amp;quot;&amp;quot;&amp;quot;
        for epoch in range(epoches):
            # å­¦ç¿ãã¼ã¿ãã1ãµã³ãã«ãã©ã³ãã ã«é¸ã¶
            index = np.random.randint(0, data.shape[0])
            x, t = data[index], target[index]

            # å¥åããåºåã¾ã§ååãã«ä¿¡å·ãä¼æ¬
            h = sigmoid(np.dot(self.W1.T, x) + self.hidden_bias)
            y = sigmoid(np.dot(self.W2.T, h) + self.output_bias)

            # é ãå±¤-&amp;gt;åºåå±¤ã®éã¿ã®ä¿®æ­£éãè¨ç®
            output_delta = (y - t) * dsigmoid(y)
            grad_W2 = np.dot(np.atleast_2d(h).T, np.atleast_2d(output_delta))

            # é ãå±¤-&amp;gt;åºåå±¤ã®éã¿ãæ´æ°
            self.W2 -= learning_rate * grad_W2
            self.output_bias -= learning_rate * output_delta

            # å¥åå±¤-&amp;gt;é ãå±¤ã®éã¿ã®ä¿®æ­£éãè¨ç®
            hidden_delta = np.dot(self.W2, output_delta) * dsigmoid(h)
            grad_W1 = np.dot(np.atleast_2d(x).T, np.atleast_2d(hidden_delta))

            # å¥åå±¤-&amp;gt;é ãå±¤ã®éã¿ãæ´æ°
            self.W1 -= learning_rate * grad_W1
            self.hidden_bias -= learning_rate * hidden_delta

            # ç¾å¨ã®ç®çé¢æ°ã®å¤ãåºå
            if monitor_period != None and epoch % monitor_period == 0:
                print &amp;quot;Epoch %d, Cost %f&amp;quot; % (epoch, self.cost(data, target))

        print &amp;quot;Training finished.&amp;quot;

    def predict(self, x):
        &amp;quot;&amp;quot;&amp;quot;
        åºåå±¤ã®æãåå¿ãããã¥ã¼ã­ã³ã®çªå·ãè¿ãã¾ã
        &amp;quot;&amp;quot;&amp;quot;
        return np.argmax(self.forward(x))

if __name__ == &amp;quot;__main__&amp;quot;:
    import argparse

    parser = argparse.ArgumentParser(description=&amp;quot;Specify options&amp;quot;)
    parser.add_argument(&amp;quot;--epoches&amp;quot;, dest=&amp;quot;epoches&amp;quot;, type=int, required=True)
    parser.add_argument(&amp;quot;--learning_rate&amp;quot;, dest=&amp;quot;learning_rate&amp;quot;,\
                        type=float, default=0.1)
    parser.add_argument(&amp;quot;--hidden&amp;quot;, dest=&amp;quot;hidden&amp;quot;, type=int, default=20)
    args = parser.parse_args()

    nn = NeuralNet(2, args.hidden, 1)

    data = np.array([[0, 0], [0 ,1], [1, 0], [1, 1]])
    target = np.array([0, 1, 1, 0])

    nn.train(data, target, args.epoches, args.learning_rate,\
             monitor_period=1000)

    for x in data:
        print &amp;quot;%s : predicted %s&amp;quot; % (x, nn.forward(x))
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;#!/usr/bin/python
# coding: utf-8

# MNISTãç¨ãããã¥ã¼ã©ã«ãããã«ããææ¸ãæ°å­èªè­ã®ãã¢ã³ã¼ãã§ã
# å­¦ç¿æ¹æ³ããã©ã¡ã¼ã¿ã«ããã¾ãããã ããã 90 ~ 97% ãããã®ç²¾åº¦åºã¾ãã
# ä½¿ãæ¹ã¯ãã³ã¼ããèª­ããã
# python mnist_net.py -h
# ã¨ãã¦ãã ãã
# åèã¾ã§ã«ã
# python mnist_net.py --epoches 50000 --learning_rate 0.1 --hidden 100
# ã¨ããã¨ããã¹ãã»ããã«å¯¾ãã¦ã93.2%ã®æ­£è§£çã§ã
# åã®ç°å¢ã§ã¯ãå­¦ç¿ãèªè­åããã¦ï¼ã ãããï¼5åããããããã¾ããã
# 2014/05/10 Ryuichi Yamamoto

import numpy as np
from sklearn.externals import joblib
import cPickle
import gzip
import os

# ä½æãããã¥ã¼ã©ã«ãããã®ããã±ã¼ã¸
import net

def load_mnist_dataset(dataset):
    &amp;quot;&amp;quot;&amp;quot;
    MNISTã®ãã¼ã¿ã»ããããã¦ã³ã­ã¼ããã¾ã
    &amp;quot;&amp;quot;&amp;quot;
    # Download the MNIST dataset if it is not present
    data_dir, data_file = os.path.split(dataset)
    if (not os.path.isfile(dataset)) and data_file == &#39;mnist.pkl.gz&#39;:
        import urllib
        origin = &#39;http://www.iro.umontreal.ca/~lisa/deep/data/mnist/mnist.pkl.gz&#39;
        print &#39;Downloading data from %s&#39; % origin
        urllib.urlretrieve(origin, dataset)

    f = gzip.open(dataset, &#39;rb&#39;)
    train_set, valid_set, test_set = cPickle.load(f)
    f.close()

    return train_set, valid_set, test_set

def augument_labels(labels, order):
    &amp;quot;&amp;quot;&amp;quot;
    1æ¬¡åã®ã©ãã«ãã¼ã¿ããã©ãã«ã®ç¨®é¡æ°(order)æ¬¡åã«æ¡å¼µãã¾ã
    &amp;quot;&amp;quot;&amp;quot;
    new_labels = []
    for i in range(labels.shape[0]):
        v = np.zeros(order)
        v[labels[i]] = 1
        new_labels.append(v)

    return np.array(new_labels).reshape((labels.shape[0], order))

if __name__ == &amp;quot;__main__&amp;quot;:
    import argparse

    parser = argparse.ArgumentParser(description=&amp;quot;MNISTææ¸ãæ°å­èªè­ã®ãã¢&amp;quot;)
    parser.add_argument(&amp;quot;--epoches&amp;quot;, dest=&amp;quot;epoches&amp;quot;, type=int, required=True)
    parser.add_argument(&amp;quot;--learning_rate&amp;quot;, dest=&amp;quot;learning_rate&amp;quot;,\
                        type=float, default=0.1)
    parser.add_argument(&amp;quot;--hidden&amp;quot;, dest=&amp;quot;hidden&amp;quot;, type=int, default=100)
    args = parser.parse_args()

    train_set, valid_set, test_set = load_mnist_dataset(&amp;quot;mnist.pkl.gz&amp;quot;)
    n_labels = 10 # 0,1,2,3,4,5,6,7,9
    n_features = 28*28

    # ã¢ãã«ãæ°ããä½ã
    nn = net.NeuralNet(n_features, args.hidden, n_labels)

    # ã¢ãã«ãèª­ã¿è¾¼ã
    # nn = joblib.load(&amp;quot;./nn_mnist.pkl&amp;quot;)

    nn.train(train_set[0], augument_labels(train_set[1], n_labels),\
             args.epoches, args.learning_rate, monitor_period=2000)

    ## ãã¹ã
    test_data, labels = test_set
    results = np.arange(len(test_data), dtype=np.int)
    for n in range(len(test_data)):
        results[n] = nn.predict(test_data[n])
        # print &amp;quot;%d : predicted %s, expected %s&amp;quot; % (n, results[n], labels[n])
    print &amp;quot;recognition rate: &amp;quot;, (results == labels).mean()

    # ã¢ãã«ãä¿å­
    model_filename = &amp;quot;nn_mnist.pkl&amp;quot;
    joblib.dump(nn, model_filename, compress=9)
    print &amp;quot;The model parameters are dumped to &amp;quot; + model_filename
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/r9y9/python-neural-net-toy-codes&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://github.com/r9y9/python-neural-net-toy-codes&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;ä»¥ä¸ã®ãããªã³ãã³ããå©ãã¦ãæ­£è§£çã97%ãããã«ãªãã¾ã§å­¦ç¿ãã¦ããå¥åå±¤ããé ãå±¤ã¸ã®éã¿ãå¯è¦åãã¦ã¿ã&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# python mnist_net.py --epoches 50000 --learning_rate 0.1 --hidden 100 # epochesã¯é©å½ã«
&lt;/code&gt;&lt;/pre&gt;
&lt;div align=&#34;center&#34;&gt;&lt;img src=&#34;https://r9y9.github.io/images/nn_mnist_W1_100.png&#34; alt=&#34;Input to Hidden weight filters after trained on MNIST.&#34; class=&#34;image&#34;&gt;&lt;/div&gt;
&lt;p&gt;èå³æ·±ããã¨ã«ãRBMã¨éã£ã¦éã¿è¡åã®è§£éã¯ãã«ãããçæã¢ãã«ã®å°¤åº¦ãæå¤§åãããã¨ã¨ãèª¤å·®ãæå°åãããã¨ã¯ãããªã«ãéããã ãªãã¨ããããªã¿ãªææ³&lt;/p&gt;
&lt;p&gt;RBMã«ã¤ãã¦ã¯ãä»¥ä¸ã¸&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://r9y9.github.io/blog/2014/03/06/restricted-boltzmann-machines-mnist/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Restricted Boltzmann Machines with MNIST - LESS IS MORE&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;ããã&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
